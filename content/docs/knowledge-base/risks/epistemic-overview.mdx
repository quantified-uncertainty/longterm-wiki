---
numericId: E824
title: "Epistemic Risks (Overview)"
description: Overview of risks to human knowledge, truth-finding, and collective sense-making from AI systems, including deepfakes, disinformation, epistemic collapse, and the erosion of shared reality.
sidebar:
  label: Overview
  order: 0
clusters:
  - ai-safety
  - epistemics
subcategory: epistemic
entityType: overview
---
import {EntityLink} from '@components/wiki';

## Overview

Epistemic risks arise when AI systems undermine humanity's ability to know what is true, make informed decisions, and maintain shared understanding of reality. These risks span individual cognition (learned helplessness, sycophancy effects), institutional decision-making (decision capture, expertise atrophy), and societal epistemics (authentication collapse, reality fragmentation). Unlike many AI risks that require highly capable systems, several epistemic risks are already manifesting with current-generation AI.

## Authentication and Trust

Risks to the ability to verify information authenticity:

- **<EntityLink id="E27">Authentication Collapse</EntityLink>**: AI-generated content becomes indistinguishable from authentic content, undermining trust in all media
- **<EntityLink id="E360">Trust Cascade Failure</EntityLink>**: Loss of trust in one domain spreading to undermine trust in institutions broadly
- **<EntityLink id="E362">Trust Decline</EntityLink>**: Gradual erosion of institutional and interpersonal trust as AI-generated deception becomes pervasive

## Information Manipulation

Risks from AI being used to distort information environments:

- **<EntityLink id="E72">Consensus Manufacturing</EntityLink>**: Using AI to create the appearance of broad agreement where none exists
- **<EntityLink id="E230">Preference Manipulation</EntityLink>**: AI systems that learn and exploit individual psychological vulnerabilities to shape beliefs and behaviors
- **<EntityLink id="E155">Historical Revisionism</EntityLink>**: AI-enabled alteration of historical records and narratives at scale
- **<EntityLink id="E276">Scientific Knowledge Corruption</EntityLink>**: AI-generated fraudulent research corrupting the scientific literature

## Cognitive and Epistemic Degradation

Risks to human cognitive capabilities and epistemic practices:

- **<EntityLink id="E119">Epistemic Collapse</EntityLink>**: Broad societal breakdown in the ability to form reliable beliefs and reach consensus on facts
- **<EntityLink id="E124">Epistemic Sycophancy</EntityLink>**: AI systems reinforcing rather than correcting human biases and errors
- **<EntityLink id="E133">Expertise Atrophy</EntityLink>**: Decline of human expertise as AI automates cognitive tasks, reducing the human capacity to verify AI outputs
- **<EntityLink id="E187">Epistemic Learned Helplessness</EntityLink>**: Humans losing the ability or motivation to evaluate claims independently due to AI dependence
- **<EntityLink id="E83">Cyber Psychosis & AI-Induced Psychological Harm</EntityLink>**: Psychological effects of immersive AI interactions

## Institutional and Structural Epistemic Risks

Risks to organizational and societal knowledge structures:

- **<EntityLink id="E166">Institutional Decision Capture</EntityLink>**: Institutions becoming dependent on AI systems for decisions, losing the ability to exercise independent judgment
- **<EntityLink id="E183">AI Knowledge Monopoly</EntityLink>**: Concentration of knowledge and information access in AI systems controlled by a few actors
- **<EntityLink id="E244">Reality Fragmentation</EntityLink>**: AI-enabled personalized information environments creating incompatible worldviews across groups
- **<EntityLink id="E188">Legal Evidence Crisis</EntityLink>**: AI-generated content undermining the reliability of evidence in legal proceedings

## Key Dynamics

**Compounding effects**: Epistemic risks tend to compoundâ€”<EntityLink id="E27">authentication collapse</EntityLink> makes <EntityLink id="E72">consensus manufacturing</EntityLink> easier, which accelerates <EntityLink id="E362">trust decline</EntityLink>, which worsens <EntityLink id="E119">epistemic collapse</EntityLink>.

**Already manifesting**: Unlike many AI risks that are prospective, several epistemic risks are observably occurring with current AI capabilities. Deepfakes, AI-generated disinformation, and epistemic sycophancy from LLMs are present-day phenomena.

**Defense is harder than offense**: Generating convincing false content is generally cheaper and easier than detecting it, creating a structural asymmetry that favors epistemic degradation.
