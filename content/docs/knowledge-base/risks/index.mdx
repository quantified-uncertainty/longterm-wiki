---
title: AI Risks
description: Documentation of potential failure modes and hazards from advanced AI systems
sidebar:
  label: Overview
  order: 0
---
import {EntityLink} from '@components/wiki';


## Overview

This section documents the potential risks from advanced AI systems, organized into four major categories based on the source and nature of the risk.

## Risk Categories

### <EntityLink id="risks/accident/scheming">Accident Risks</EntityLink>
Unintended failures from AI systems pursuing misaligned goals:
- <EntityLink id="risks/accident/scheming">Scheming</EntityLink> - AI strategically concealing misaligned goals
- <EntityLink id="risks/accident/deceptive-alignment">Deceptive Alignment</EntityLink> - Models appearing aligned during training
- <EntityLink id="risks/accident/mesa-optimization">Mesa-Optimization</EntityLink> - Learned optimizers with misaligned objectives
- <EntityLink id="risks/accident/goal-misgeneralization">Goal Misgeneralization</EntityLink> - Objectives that fail in deployment
- <EntityLink id="risks/accident/power-seeking">Power-Seeking</EntityLink> - <EntityLink id="instrumental-convergence">Instrumental convergence</EntityLink> toward acquiring resources

### <EntityLink id="risks/misuse/bioweapons">Misuse Risks</EntityLink>
Deliberate harmful applications of AI capabilities:
- <EntityLink id="risks/misuse/bioweapons">Bioweapons</EntityLink> - AI-assisted biological weapon development
- <EntityLink id="risks/misuse/cyberweapons">Cyberweapons</EntityLink> - Automated cyber attacks and vulnerabilities
- <EntityLink id="risks/misuse/disinformation">Disinformation</EntityLink> - Large-scale manipulation campaigns
- <EntityLink id="risks/misuse/autonomous-weapons">Autonomous Weapons</EntityLink> - Lethal autonomous systems

### <EntityLink id="risks/structural/racing-dynamics">Structural Risks</EntityLink>
Systemic issues from how AI development is organized:
- <EntityLink id="risks/structural/racing-dynamics">Racing Dynamics</EntityLink> - Competitive pressure reducing safety investment
- <EntityLink id="risks/structural/concentration-of-power">Concentration of Power</EntityLink> - Dangerous accumulation of AI capabilities
- <EntityLink id="risks/structural/lock-in">Lock-in</EntityLink> - Irreversible entrenchment of values or structures
- <EntityLink id="risks/structural/economic-disruption">Economic Disruption</EntityLink> - Labor market and economic instability

### <EntityLink id="risks/epistemic/trust-decline">Epistemic Risks</EntityLink>
Threats to society's ability to know and reason:
- <EntityLink id="risks/epistemic/trust-decline">Trust Decline</EntityLink> - Erosion of institutional and interpersonal trust
- <EntityLink id="risks/epistemic/authentication-collapse">Authentication Collapse</EntityLink> - Inability to verify authentic content
- <EntityLink id="risks/epistemic/expertise-atrophy">Expertise Atrophy</EntityLink> - Loss of human capability through AI dependence

## How Risks Connect

Many risks interact and compound. For example:
- <EntityLink id="racing-dynamics">Racing dynamics</EntityLink> → reduced safety testing → higher accident risk
- <EntityLink id="disinformation">Disinformation</EntityLink> → <EntityLink id="trust-decline">trust decline</EntityLink> → reduced <EntityLink id="coordination-capacity">coordination capacity</EntityLink>
- Power concentration → <EntityLink id="lock-in">lock-in</EntityLink> potential → governance failures

See the <EntityLink id="models/dynamics-models/risk-interaction-matrix">Risk Interaction Matrix</EntityLink> for detailed analysis.
