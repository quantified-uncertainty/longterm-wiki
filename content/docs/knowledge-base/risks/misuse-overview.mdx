---
numericId: "E825"
title: "Misuse Risks (Overview)"
description: "Overview of risks from deliberate misuse of AI systems for harmful purposes, including bioweapons development, cyberattacks, autonomous weapons, deepfakes, surveillance, and fraud."
sidebar:
  label: "Overview"
  order: 0
subcategory: "misuse"
entityType: "overview"
readerImportance: 58.5
tacticalValue: 62
quality: 40
llmSummary: "A high-level taxonomy of AI misuse risks organized into weapons/violence, information manipulation, and surveillance categories, with brief notes on asymmetric amplification and dual-use challenges; no quantitative estimates, primary sources, or detailed mitigation guidance provided."
ratings:
  focus: 8.5
  novelty: 2.5
  rigor: 3
  completeness: 5.5
  concreteness: 4
  actionability: 3.5
  objectivity: 6.5
clusters:
  - ai-safety
---
import {EntityLink} from '@components/wiki';

## Overview

Misuse risks arise when AI systems are deliberately used by humans for harmful purposes. Unlike accident risks (unintended failures) or structural risks (systemic effects), misuse risks involve intentional weaponization of AI capabilities. These risks are particularly concerning because AI can dramatically lower the barriers to conducting attacks that previously required specialized expertise, large organizations, or significant resources.

## Weapons and Violence

AI lowering barriers to development and deployment of weapons:

- **<EntityLink id="E42">Bioweapons</EntityLink>**: AI systems assisting in the design, synthesis, or deployment of biological weapons agents
- **<EntityLink id="E86">Cyberweapons</EntityLink>**: AI-powered offensive cyber capabilities including automated vulnerability discovery and exploit generation
- **<EntityLink id="E35">Autonomous Weapons</EntityLink>**: Weapons systems that select and engage targets without meaningful human control

## Information Manipulation

AI used to deceive, manipulate, or distort information:

- **<EntityLink id="E96">Deepfakes</EntityLink>**: AI-generated synthetic media (video, audio, images) used for deception, blackmail, or manipulation
- **<EntityLink id="E102">Disinformation</EntityLink>**: AI-generated or AI-amplified false information campaigns at scale
- **<EntityLink id="E145">AI-Powered Fraud</EntityLink>**: AI used for financial fraud, impersonation, and social engineering at unprecedented scale

## Surveillance and Control

AI enabling surveillance and authoritarian control:

- **<EntityLink id="E292">Mass Surveillance</EntityLink>**: AI dramatically expanding the scope and effectiveness of surveillance systems
- **<EntityLink id="E30">Authoritarian Tools</EntityLink>**: AI capabilities used to monitor, control, and suppress populations

## Emerging Threats

- **AI-Enabled Untraceable Misuse**: AI simultaneously amplifying harmful capabilities while obscuring attribution, enabling attacks with reduced risk of identification

## Risk Characteristics

**Asymmetric capability amplification**: AI often provides greater capability amplification to attackers than to defenders. A small team with AI tools can potentially cause harm that previously required nation-state resources.

**Dual-use challenge**: The same AI capabilities useful for beneficial purposes (drug discovery, cybersecurity defense, content creation) can be repurposed for harmful ones (bioweapons, cyberattacks, deepfakes). This makes risk mitigation through capability restriction difficult without also limiting beneficial uses.

**Evolving threat landscape**: As AI capabilities advance, the set of feasible misuse attacks expands. <EntityLink id="E42">Bioweapons</EntityLink> risk depends on AI systems' ability to provide actionable synthesis guidance; <EntityLink id="E86">cyberweapons</EntityLink> risk scales with AI coding capability; <EntityLink id="E96">deepfake</EntityLink> quality improves with generative model advancement.

## Mitigation Approaches

Key approaches to misuse risk reduction include:
- Pre-deployment safety evaluations and red-teaming
- Output filtering and refusal training
- Know-your-customer requirements for AI API access
- DNA synthesis screening for bioweapons risks
- International coordination on AI-enabled weapons
