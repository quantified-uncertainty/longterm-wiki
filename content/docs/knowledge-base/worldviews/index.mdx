---
title: Worldviews
description: Different perspectives on AI risk and safety priorities
sidebar:
  label: Overview
  order: 0
---
import {EntityLink} from '@components/wiki';


## Overview

People working on AI safety hold diverse worldviews that lead to different risk assessments and priorities. Understanding these worldviews helps explain disagreements and enables more productive dialogue.

## Major Worldviews

### <EntityLink id="doomer">Doomer</EntityLink>
Believes AI existential risk is very high (often >50% p(doom)):
- Alignment is fundamentally hard
- Current approaches are inadequate
- We may not get many chances to get it right
- Often associated with: <EntityLink id="miri">MIRI</EntityLink>, <EntityLink id="eliezer-yudkowsky">Eliezer Yudkowsky</EntityLink>, some AI safety researchers

### <EntityLink id="long-timelines">Long Timelines</EntityLink>
Believes transformative AI is further away (20+ years):
- More time to solve alignment
- Current risks are more speculative
- Near-term concerns deserve more attention
- Associated with: Some ML researchers, AI ethics community

### <EntityLink id="governance-focused">Governance Focused</EntityLink>
Prioritizes policy and institutional solutions:
- Technical alignment is necessary but insufficient
- <EntityLink id="racing-dynamics">Racing dynamics</EntityLink> are the key problem
- <EntityLink id="international-coordination">International coordination</EntityLink> is critical
- Associated with: <EntityLink id="govai">GovAI</EntityLink>, policy researchers, some EA organizations

### <EntityLink id="optimistic">Optimistic</EntityLink>
Believes alignment is likely to succeed:
- Current research is making real progress
- Markets and institutions create safety incentives
- Past technology fears were often overblown
- Associated with: Some lab researchers, techno-optimists

## How Worldviews Affect Priorities

| Worldview | Technical Research | Governance | Timelines | Key Intervention |
|-----------|-------------------|------------|-----------|------------------|
| Doomer | Critical but may be hopeless | Valuable | Short | Pause/slow down |
| Long Timelines | Important, time available | Moderate priority | Long | Gradual progress |
| Governance Focused | Necessary | Highest priority | Medium | Coordination |
| Optimistic | On track | Light touch | Medium | Continue current |

## Using Worldview Analysis

Explicitly identifying worldview assumptions helps:
- Understand why experts disagree
- Identify which cruxes would change conclusions
- Design robustly valuable interventions
- Have more productive conversations
