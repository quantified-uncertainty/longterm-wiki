---
title: NIST and AI Safety
description: The National Institute of Standards and Technology's role in developing AI standards, risk management frameworks, and safety guidelines for the United States
sidebar:
  order: 65
entityType: organization
subcategory: government
quality: 63
readerImportance: 76.5
researchImportance: 49
tacticalValue: 78
lastEdited: "2026-02-01"
update_frequency: 21
llmSummary: NIST plays a central coordinating role in U.S. AI governance through voluntary standards and risk management frameworks, but faces criticism for technical focus over systemic issues and funding constraints that limit effectiveness. The agency's AI Safety Institute represents a significant institutional development for AI safety evaluation and international coordination.
ratings:
  novelty: 4
  rigor: 7
  actionability: 6
  completeness: 8
clusters:
  - ai-safety
  - governance
  - community
---
import {EntityLink, KeyPeople, KeyQuestions, Section} from '@components/wiki';

## Quick Assessment

| Dimension | Assessment |
|-----------|------------|
| **Primary Role** | U.S. federal standards agency developing AI measurement tools, frameworks, and guidelines |
| **Key Initiative** | AI Risk Management Framework (AI RMF 1.0, released January 2023) |
| **Funding** | FY 2025 budget request: \$47.7M for AI work; \$20M for MITRE AI centers (2025) |
| **Recent Development** | U.S. AI Safety Institute (AISI) established under 2023 Executive Order |
| **Approach** | Voluntary, non-regulatory standards emphasizing trustworthy AI |
| **Influence** | Over 280 organizations in NIST AI Consortium; shapes U.S. AI policy implementation |

## Key Links

| Source | Link |
|--------|------|
| Official Website | [nist.gov](https://www.nist.gov/itl/ai-risk-management-framework) |

## Overview

The **National Institute of Standards and Technology (NIST)** is a U.S. Department of Commerce agency that has become central to American artificial intelligence governance through its development of measurement standards, risk management frameworks, and safety guidelines.[^1] Founded in 1901 as the National Bureau of Standards, NIST's AI work began in earnest around 2016-2018, though it has been involved in computing standards since the 1960s.[^2]

NIST's core AI mission focuses on promoting "trustworthy AI" through science-based standards and voluntary frameworks rather than regulation.[^3] The agency emphasizes that "safety breeds trust, trust enables adoption, and adoption accelerates innovation" as its guiding principle.[^4] This approach positions NIST as a coordinator between government, industry, and academia, creating consensus standards that organizations can voluntarily adopt.

The agency's influence expanded significantly with the October 2023 Executive Order on Safe, Secure, and Trustworthy AI, which established the **U.S. AI Safety Institute (AISI)** within NIST and gave the agency new mandates for AI system evaluation, red-teaming, and international standards coordination.[^5] NIST's work spans fundamental research, applied projects in manufacturing and cybersecurity, and the convening of large multi-stakeholder consortia to develop practical guidance for AI deployment.

## History and Evolution

### Early Computing Work

While NIST has conducted computing research since the mid-1960s—including developing MAGIC, one of the first intelligent computer graphics terminals—its explicit focus on artificial intelligence emerged much later.[^6] The agency's Information Technology Laboratory (ITL) built capabilities in cryptography, biometrics, and data processing standards through the 1990s and 2000s, establishing foundations for later AI work.[^7]

### Emergence of AI Focus (2016-2023)

NIST's dedicated AI program began taking shape around 2016-2018 with the **Fundamental and Applied Research and Standards for AI Technologies (FARSAIT)** initiative.[^8] This program aimed to develop comprehensive guidance on trustworthy AI systems, including terminology, taxonomy, and measurement approaches. However, the specific timeline of NIST's early AI involvement remains sparsely documented in public sources.

The agency's AI work accelerated dramatically with the release of the **AI Risk Management Framework (AI RMF 1.0)** in January 2023, following extensive public consultation.[^9] This voluntary framework provided organizations with a structured approach to managing AI risks through four core functions: Govern, Map, Measure, and Manage.[^10]

### AI Safety Institute Era (2023-Present)

The October 30, 2023 Executive Order on Safe, Secure, and Trustworthy AI transformed NIST's role by establishing the **U.S. AI Safety Institute (AISI)** within the agency.[^11] AISI published an initial draft report for Managing the Risk of Misuse for Dual-Use Foundation Models (AI 800-1).[^12]

In February 2024, Commerce Secretary Gina Raimondo announced the inaugural leadership team, appointing **Elizabeth Kelly** as director and **Elham Tabassi** as chief technology officer.[^13] The team expanded with five additional senior leaders, including **<EntityLink id="paul-christiano">Paul Christiano</EntityLink>** (former <EntityLink id="openai">OpenAI</EntityLink> leader and founder of the nonprofit Alignment Research Center) as Head of AI Safety, **Adam Russell** (director of the Information Sciences Institute's AI Division at the University of Southern California) as Chief Vision Officer, Mara Campbell as acting chief operating officer and chief of staff, Rob Reich as senior advisor, and Mark Latonero as head of international engagement.[^14]

## Major Programs and Initiatives

### AI Risk Management Framework

The AI RMF represents NIST's flagship contribution to <EntityLink id="ai-governance">AI governance</EntityLink>. Initiated in 2021 and released in January 2023, the framework addresses trustworthy AI attributes including validity, reliability, safety, security, and resilience.[^15] On July 26, 2024, NIST released **NIST AI 600-1**, the Generative AI Profile, which identifies unique risks posed by generative AI systems and proposes tailored management actions for organizations based on their goals and priorities.[^16]

At its core, the AI RMF is built on four functions: Govern, Map, Measure, and Manage, providing a systematic approach to improving the robustness and reliability of AI systems.[^17] Updated guidance released in 2025 expanded the framework to address supply chain vulnerabilities, model provenance, data integrity, and third-party risks, while introducing maturity model guidance for measuring organizational AI risk management capabilities.[^18]

### U.S. AI Safety Institute (AISI)

AISI operates with three core goals: advancing AI safety science through model testing and red-teaming, disseminating safety practices through guidelines and tools, and supporting stakeholder coordination.[^19] The institute established the **AI Safety Institute Consortium (AISIC)** in February 2024, bringing together over 200 members from academia, advocacy organizations, private industry, and government to develop standards collaboratively.[^20]

In practice, AISI focuses on developing evaluation approaches for frontier AI models, conducting security assessments, and creating measurement tools. The **Center for AI Standards and Innovation (CAISI)**, previously named the U.S. AI Safety Institute, leads evaluations of U.S. and adversary AI systems and has established voluntary agreements with multiple developers of cutting-edge AI models for collaborative research and testing.[^21]

### NIST AI Consortium

The **NIST AI Consortium** represents a major public-private partnership, with over 280 organizations from industry, academia, and civil society participating through Cooperative Research and Development Agreements (CRADAs).[^22] The consortium develops science-based guidelines and standards for AI measurement through open collaborative research, creating a foundation for global AI metrology.

Membership is open to organizations that can contribute expertise, products, data, or models. This approach allows NIST to leverage industry capabilities while maintaining its neutral convening role.

### Standards Development Initiatives

In March 2025, NIST launched the **AI Standards "Zero Drafts" Pilot Project**, an innovative approach to accelerate standards development.[^23] The project creates preliminary stakeholder-driven drafts on topics like AI risk management, transparency, and procurement, which are then submitted to formal standards developing organizations (SDOs) for consensus development. Organizations can provide input via aistandardszerodrafts@nist.gov.

NIST also released a **Global AI Standards Engagement Plan (NIST AI 100-5)** in July 2024, outlining the agency's approach to international AI standards development.[^24] The plan addresses both "horizontal" (cross-sector) and "vertical" (sector-specific) standards needs, aiming to ensure scientifically sound, accessible standards globally.

### Research and Testing Infrastructure

NIST's research portfolio includes applied AI work in advanced materials discovery, robotic manufacturing, wireless systems, and cybersecurity.[^25] The agency released **Dioptra**, an open-source software tool for adversarial AI testing, enabling organizations to evaluate how adversarial attacks affect AI system performance.[^26]

In December 2025, NIST announced a \$20 million partnership with **MITRE Corporation** to establish two research centers: the **AI Economic Security Center for U.S. Manufacturing Productivity** and the **AI Economic Security Center to Secure U.S. Critical Infrastructure from Cyberthreats**.[^27] These centers focus on developing technology evaluations and <EntityLink id="agentic-ai">agentic AI</EntityLink> tools to enhance critical infrastructure security and manufacturing competitiveness.

Additional partnerships include a \$6 million center with Carnegie Mellon University for <EntityLink id="cooperative-ai">cooperative AI</EntityLink> testing and evaluation research,[^28] and over \$1.8 million in Small Business Innovation Research (SBIR) awards to 18 companies developing AI-related products, with Phase II funding available up to \$400,000.[^29]

### Cybersecurity and AI Integration

On December 16, 2025, NIST released a preliminary draft of its **Cybersecurity Framework Profile for Artificial Intelligence (Cyber AI Profile, NISTIR 8596)**.[^30] This profile maps three AI focus areas—Secure (managing AI system cybersecurity risks), Defend (using AI to enhance cybersecurity), and Thwart (defending against adversarial AI uses)—onto the six core functions of NIST's Cybersecurity Framework 2.0.[^31]

The profile addresses securing AI dependencies, integrating AI risks into organizational risk tolerance, deploying AI-augmented security teams, and detecting threats in supplier models. Public comments were solicited through January 30, 2026.[^32]

## Funding and Resources

NIST's AI work operates on federal appropriations, which have faced constraints despite expanded mandates. The agency's overall annual budget is approximately \$1-1.3 billion, with the President's FY 2025 budget requesting \$47.7 million specifically for AI research, testing infrastructure, risk management guidance, and frameworks.[^33]

However, funding has consistently fallen short of requests since FY 2022. The Fiscal Responsibility Act of 2023 set discretionary spending limits through FY 2029, further constraining available resources.[^34] This persistent underfunding has prompted discussions about establishing an "agency-related foundation" to attract private investment for AI talent fellowships, rapid evaluations, and benchmark development, potentially bypassing federal procurement limitations.[^35]

Recent major investments include:
- **\$20 million** for MITRE AI centers (manufacturing and critical infrastructure, 2025)[^36]
- **\$6 million** for Carnegie Mellon AI cooperative research center (2024)[^37]
- **\$1.8 million** in SBIR Phase I awards to 18 small businesses (2025)[^38]
- **Up to \$70 million** over five years for an AI-focused Manufacturing USA institute (announced July 2024, awards pending)[^39]

## Leadership and Key Personnel

NIST's AI leadership structure centers on AISI's executive team:

| Role | Name | Background |
|------|------|-----------|
| **Director, AISI** | Elizabeth Kelly | Coordinates activities across Commerce, NIST, and the federal government[^40] |
| **Chief Technology Officer, AISI** | Elham Tabassi | Chief of Staff in the Information Technology Laboratory (ITL) at NIST[^41] |
| **Head of AI Safety** | Paul Christiano | Former <EntityLink id="openai">OpenAI</EntityLink> leader and founder of the <EntityLink id="arc">Alignment Research Center</EntityLink>, a nonprofit focused on <EntityLink id="alignment">AI alignment</EntityLink> research[^42] |
| **Chief Vision Officer** | Adam Russell | Director of the Information Sciences Institute's AI Division at the University of Southern California[^43] |
| **Acting Chief Operating Officer and Chief of Staff** | Mara Campbell | Former deputy chief operating officer at Commerce's Economic Development Administration[^44] |
| **Senior Advisor** | Rob Reich | Professor of political science at Stanford University and associate director of Stanford's Institute for Human-Centered AI[^45] |
| **Head of International Engagement** | Mark Latonero | Former deputy director of the National AI Initiative Office at the White House Office of Science and Technology Policy[^46] |

This leadership team shapes NIST's approach to AI safety evaluation, international standards coordination, and public-private partnership development.

## Criticisms and Controversies

### Technical Focus vs. Systemic Factors

Commenters on NIST's bias management proposal have raised concerns that the agency's approach focuses too heavily on technical and algorithmic solutions while neglecting the role of human decision-making and systemic factors.[^47] For example, commenters argued that accountability for bias is tied to human interventions in the decision-making process, and that defining societal bias purely as a byproduct of cognition fails to account for identifiable, hierarchical social systems that produce bias.[^48]

NIST itself acknowledges these limitations. In a March 2022 report, the agency noted that AI bias extends beyond data quality to include human biases (such as subjective decisions in filling data gaps) and systemic biases rooted in institutional discrimination.[^49] Research lead Reva Schwartz emphasized the need for socio-technical approaches, stating that "organizations often default to overly technical solutions for AI bias issues" that "do not adequately capture the societal impact of AI systems," and that purely technical efforts to solve the problem of bias will come up short.[^50]

### Exclusion of Critical Risks from Misuse Frameworks

The Electronic Privacy Information Center (EPIC) criticized NIST AI 800-1 for deprioritizing bias, discrimination, hallucinations, and privacy risks in its guidance on dual-use foundation models.[^51] EPIC argues that threat actors exploit these very vulnerabilities for misuse, and excluding them creates dangerous blind spots. The organization recommended incorporating sociotechnical factors as required by Executive Order 14110.[^52]

### Lack of Concrete Solutions

NIST's AI security concept papers have been criticized for identifying enterprise challenges—such as opacity in model training, unclear data usage, and difficulties maintaining AI system inventories—without offering specific mitigations.[^53] Jeff Man, a senior information security consultant, noted visibility problems: "How do you actually, as an enterprise, gain insight into what AI is deployed, and the data it's been trained on?"[^54]

Experts also worry whether traditional standards can adequately address emerging risks from agentic AI systems. Vince Worthington highlighted concerns about "cascading failures" where autonomous AI agents might create compounding problems, while Vince Berk of Apprentis Ventures expressed skepticism that standards processes can keep pace with AI threat evolution.[^55]

### AI-Enhanced Security Vulnerabilities

Research cited by NIST demonstrates concerning security implications of AI-assisted development. One study found that AI code improvements increase vulnerabilities by 37.6% after five iterations, emphasizing the critical need for human oversight.[^56] NIST acknowledges that AI accelerates various attack vectors including phishing, data poisoning, and coordinated campaigns by autonomous agents.[^57]

The Institute for Security and Technology (IST) suggested NIST should treat AI models themselves as potential insider threats, where autonomous agents might self-evolve or collude to bypass security controls.[^58]

### Implementation Challenges

Organizations implementing the AI RMF face practical difficulties including efficiency losses, high resource and expertise demands, incomplete market adoption, and risk of over-complexity.[^59] The voluntary nature of NIST's frameworks means adoption varies widely, and many organizations lack the specialized knowledge needed to implement guidance effectively.

Additionally, some experts worry about AI systems undermining the standards development process itself. Erik Avakian of Info-Tech Research Group warned about AI-generated comments flooding NIST's public input processes, potentially drowning out legitimate stakeholder feedback.[^60]

## Impact and Effectiveness

NIST's influence on AI governance stems primarily from its convening power and standard-setting authority rather than regulatory enforcement. The agency's frameworks have been widely referenced in policy discussions and adopted by organizations seeking to demonstrate responsible AI practices.

In 2023, NIST released the AI Risk Management Framework and launched the Trustworthy AI Resource Center to help organizations manage AI risks.[^61] NIST is actively aligning its AI RMF with the Cybersecurity Framework (CSF) and Privacy Framework, helping organizations unify governance and risk programs under one umbrella.[^62]

NIST's partnership model has proven effective at engaging major institutions. The AISIC includes over 200 members from academia, advocacy organizations, private industry, and the public sector.[^63] Voluntary agreements with frontier AI model developers enable NIST to conduct collaborative research and voluntary testing of industry models for priority national security capabilities that would otherwise be difficult for a government agency with limited resources.[^64]

However, the effectiveness of NIST's work faces limitations. The \$20 million investment to establish two AI centers focused on manufacturing productivity and critical infrastructure cybersecurity, while substantial, remains modest relative to private sector AI investment.[^65] NIST's investment remains modest relative to private sector AI investment. Funding has remained at a fractional level of the industries it is supposed to set standards for, and since FY22, NIST has received lower appropriations than it has requested. The agency is also struggling to attract the specialized science and technology talent it needs due to competition for technical talent and a lack of competitive pay compared to the private sector.[^66]

NIST will rely on existing resources to build on its expertise and carry forward recommendations in the White House's July 2025 America's AI Action Plan, including efforts to accelerate AI innovation and build American AI infrastructure.[^67]

## International Engagement

NIST participates actively in international AI governance efforts through multiple channels. The agency engages with the **Organisation for Economic Co-operation and Development (OECD)**, the **Quadrilateral Security Dialogue**, and bilateral initiatives across Asia, Europe, the Middle East, and North America, often partnering with the U.S. Department of State and International Trade Administration.[^68]

The July 2024 **Global AI Standards Engagement Plan (NIST AI 100-5)** outlines NIST's strategy for promoting scientifically sound, accessible standards in international forums.[^69] This work aims to ensure U.S. technical approaches shape global AI standards development rather than being shaped by standards developed elsewhere.

NIST's international role includes contributing to <EntityLink id="ai-safety-institutes">AI safety institutes</EntityLink> established by other countries. The agency participates in discussions and partnerships with counterpart organizations working on <EntityLink id="evaluation">AI evaluation</EntityLink> and safety testing as part of its broader engagement with U.S. and international AI governance efforts.[^68]

## Key Uncertainties

Several important questions remain about NIST's AI work:

1. **Resource Sufficiency**: Can NIST effectively fulfill its expanded AI mandate given persistent funding constraints and the Fiscal Responsibility Act's spending limits through 2029?

2. **Standards Pace**: Will voluntary standards development keep pace with rapid AI capability advances, particularly for agentic systems and novel architectures beyond current paradigms?

3. **International Influence**: To what extent will NIST's technical approaches shape global AI standards versus being influenced by standards developed in other jurisdictions with different governance philosophies?

4. **Voluntary Adoption**: How widely will organizations adopt NIST's voluntary frameworks, and will voluntary adoption prove sufficient to manage AI risks, or will future regulation mandate compliance?

5. **Evaluation Capabilities**: Can NIST develop evaluation methods that effectively assess frontier AI systems' safety properties, especially for <EntityLink id="emergent-capabilities">emergent capabilities</EntityLink> and long-horizon risks?

6. **Private Sector Relationship**: How will NIST's relationships with frontier AI developers evolve as commercial pressures potentially conflict with safety evaluation transparency?

7. **Technical vs. Governance Balance**: Will NIST successfully integrate sociotechnical considerations into its frameworks despite its historical focus on technical measurement and standards?

The answers to these questions will significantly shape NIST's effectiveness as a central coordinator of U.S. AI safety and governance efforts in coming years.

## Sources

[^1]: [NIST Artificial Intelligence Overview](https://www.nist.gov/artificial-intelligence)
[^2]: [NIST Timeline](https://www.nist.gov/timeline)
[^3]: [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)
[^4]: [AISI Strategic Vision Document](https://www.nist.gov/document/aisi-strategic-vision-document)
[^5]: [NIST News: Commerce Secretary Announces AISI Leadership](https://www.nist.gov/news-events/news/2024/02/us-commerce-secretary-gina-raimondo-announces-key-executive-leadership-us)
[^6]: [NIST ITL About ITL - ITL History Timeline](https://www.nist.gov/itl/about-itl/itl-history-timeline)
[^7]: [NIST Cyber History](https://csrc.nist.gov/nist-cyber-history)
[^8]: [NIST Artificial Intelligence - AI Research](https://www.nist.gov/artificial-intelligence/ai-research)
[^9]: [NIST AI RMF - Palo Alto Networks Cyberpedia](https://www.paloaltonetworks.com/cyberpedia/nist-ai-risk-management-framework)
[^10]: [NIST AI RMF - AuditBoard Blog](https://auditboard.com/blog/nist-ai-rmf)
[^11]: [Tech Policy Press: Unpacking New NIST Guidance on AI](https://techpolicy.press/unpacking-new-nist-guidance-on-artificial-intelligence)
[^12]: [AISI Strategic Vision Document](https://www.nist.gov/document/aisi-strategic-vision-document)
[^13]: [NIST News: Commerce Secretary Announces AISI Leadership](https://www.nist.gov/news-events/news/2024/02/us-commerce-secretary-gina-raimondo-announces-key-executive-leadership-us)
[^14]: [Nextgov: NIST Adds 5 New Members to AI Safety Institute](https://www.nextgov.com/artificial-intelligence/2024/04/nist-adds-5-new-members-its-ai-safety-institute/395783/)
[^15]: [NIST AI RMF - Palo Alto Networks Cyberpedia](https://www.paloaltonetworks.com/cyberpedia/nist-ai-risk-management-framework)
[^16]: [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)
[^17]: [NIST AI RMF - Palo Alto Networks Cyberpedia](https://www.paloaltonetworks.com/cyberpedia/nist-ai-risk-management-framework)
[^18]: [ISPartners: NIST AI RMF 2025 Updates](https://www.ispartnersllc.com/blog/nist-ai-rmf-2025-updates-what-you-need-to-know-about-the-latest-framework-changes/)
[^19]: [AISI Strategic Vision Document](https://www.nist.gov/document/aisi-strategic-vision-document)
[^20]: [Husch Blackwell: NIST Introduces AI Safety Institute Leaders and Consortium](https://www.huschblackwell.com/newsandinsights/nist-introduces-the-leaders-of-the-artificial-intelligence-safety-institute-and-announces-the-institutes-ai-consortium)
[^21]: [NIST News: NIST Launches Centers for AI in Manufacturing and Critical Infrastructure](https://www.nist.gov/news-events/news/2025/12/nist-launches-centers-ai-manufacturing-and-critical-infrastructure)
[^22]: [NIST AI Consortium](https://www.nist.gov/artificial-intelligence/nist-ai-consortium)
[^23]: [ANSI News: NIST Launches Pilot Project to Propel AI Innovation](https://www.ansi.org/standards-news/all-news/3-27-25-nist-launches-pilot-project-to-propel-ai-innovation)
[^24]: [NIST AI 100-5: A Plan for Global Engagement on AI Standards (PDF)](https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-5.pdf)
[^25]: [NIST Artificial Intelligence - AI Research](https://www.nist.gov/artificial-intelligence/ai-research)
[^26]: [King & Spalding: NIST Releases Series of AI Guidelines, Software](https://www.kslaw.com/news-and-insights/nist-releases-series-of-ai-guidelines-software-in-ongoing-response-to-ai-executive-order)
[^27]: [NIST News: NIST Launches Centers for AI in Manufacturing and Critical Infrastructure](https://www.nist.gov/news-events/news/2025/12/nist-launches-centers-ai-manufacturing-and-critical-infrastructure)
[^28]: [CMU News: NIST Awards \$6M to Carnegie Mellon University](https://www.cmu.edu/news/stories/archives/2024/september/nist-awards-6m-to-carnegie-mellon-university-to-establish-ai-cooperative-research-center)
[^29]: [NIST News: NIST Awards Over \$1.8 Million to Small Businesses](https://www.nist.gov/news-events/news/2025/08/nist-awards-over-18-million-small-businesses-advancing-ai-semiconductors)
[^30]: [JD Supra: AI Risk Meets Cyber Governance - NIST's Cybersecurity Framework Profile](https://www.jdsupra.com/legalnews/ai-risk-meets-cyber-governance-nist-s-3580524/)
[^31]: [Inside Privacy: NIST Publishes Preliminary Draft of Cybersecurity Framework Profile for AI](https://www.insideprivacy.com/artificial-intelligence/nist-publishes-preliminary-draft-of-cybersecurity-framework-profile-for-artificial-intelligence-for-public-comment/)
[^32]: [Crowell: NIST Releases Draft Framework for AI Cybersecurity](https://www.crowell.com/en/insights/client-alerts/nist-releases-draft-framework-for-ai-cybersecurity-solicits-public-comment-what-organizations-using-or-deploying-ai-should-know)
[^33]: [Ropes Data Philes: A Very Merry NISTmas - 2024 Updates](https://www.ropesdataphiles.com/2024/12/a-very-merry-nistmas-2024-updates-to-the-cybersecurity-and-ai-framework/)
[^34]: [FAS: NIST Foundation](https://fas.org/publication/nist-foundation/)
[^35]: [FAS: NIST Foundation](https://fas.org/publication/nist-foundation/)
[^36]: [NIST News: NIST Launches Centers for AI in Manufacturing and Critical Infrastructure](https://www.nist.gov/news-events/news/2025/12/nist-launches-centers-ai-manufacturing-and-critical-infrastructure)
[^37]: [CMU News: NIST Awards \$6M to Carnegie Mellon University](https://www.cmu.edu/news/stories/archives/2024/september/nist-awards-6m-to-carnegie-mellon-university-to-establish-ai-cooperative-research-center)
[^38]: [NIST News: NIST Awards Over \$1.8 Million to Small Businesses](https://www.nist.gov/news-events/news/2025/08/nist-awards-over-18-million-small-businesses-advancing-ai-semiconductors)
[^39]: [NIST News: NIST Announces Funding Opportunity for AI-Focused Manufacturing USA Institute](https://www.nist.gov/news-events/news/2024/07/nist-announces-funding-opportunity-ai-focused-manufacturing-usa-institute)
[^40]: [Husch Blackwell: NIST Introduces AI Safety Institute Leaders and Consortium](https://www.huschblackwell.com/newsandinsights/nist-introduces-the-leaders-of-the-artificial-intelligence-safety-institute-and-announces-the-institutes-ai-consortium)
[^41]: [Digital.gov: Overview of NIST Initiatives on AI Standards](https://digital.gov/event/2020/11/04/overview-of-nist-initiatives-on-ai-standards-principles-and-critical-ai-issues)
[^42]: [Nextgov: NIST Adds 5 New Members to AI Safety Institute](https://www.nextgov.com/artificial-intelligence/2024/04/nist-adds-5-new-members-its-ai-safety-institute/395783/)
[^43]: [Nextgov: NIST Adds 5 New Members to AI Safety Institute](https://www.nextgov.com/artificial-intelligence/2024/04/nist-adds-5-new-members-its-ai-safety-institute/395783/)
[^44]: [Nextgov: NIST Adds 5 New Members to AI Safety Institute](https://www.nextgov.com/artificial-intelligence/2024/04/nist-adds-5-new-members-its-ai-safety-institute/395783/)
[^45]: [Nextgov: NIST Adds 5 New Members to AI Safety Institute](https://www.nextgov.com/artificial-intelligence/2024/04/nist-adds-5-new-members-its-ai-safety-institute/395783/)
[^46]: [Nextgov: NIST Adds 5 New Members to AI Safety Institute](https://www.nextgov.com/artificial-intelligence/2024/04/nist-adds-5-new-members-its-ai-safety-institute/395783/)
[^47]: [NIST: Comments Received on Proposal for Identifying and Managing Bias in AI](https://www.nist.gov/artificial-intelligence/comments-received-proposal-identifying-and-managing-bias-artificial)
[^48]: [NIST: Comments Received on Proposal for Identifying and Managing Bias in AI](https://www.nist.gov/artificial-intelligence/comments-received-proposal-identifying-and-managing-bias-artificial)
[^49]: [NIST News: There's More to AI Bias Than Biased Data](https://www.nist.gov/news-events/news/2022/03/theres-more-ai-bias-biased-data-nist-report-highlights)
[^50]: [NIST News: There's More to AI Bias Than Biased Data](https://www.nist.gov/news-events/news/2022/03/theres-more-ai-bias-biased-data-nist-report-highlights)
[^51]: [EPIC: Comments to NIST on Managing the Risks of Misuse with AI Foundation Models](https://epic.org/documents/epic-comments-to-nist-on-managing-the-risks-of-misuse-with-ai-foundation-models/)
[^52]: [EPIC: Comments to NIST on Managing the Risks of Misuse with AI Foundation Models](https://epic.org/documents/epic-comments-to-nist-on-managing-the-risks-of-misuse-with-ai-foundation-models/)
[^53]: [CSO Online: NIST's Attempts to Secure AI Yields Many Questions, No Answers](https://www.csoonline.com/article/4042627/nists-attempts-to-secure-ai-yields-many-questions-no-answers.html)
[^54]: [CSO Online: NIST's Attempts to Secure AI Yields Many Questions, No Answers](https://www.csoonline.com/article/4042627/nists-attempts-to-secure-ai-yields-many-questions-no-answers.html)
[^55]: [CSO Online: NIST's Attempts to Secure AI Yields Many Questions, No Answers](https://www.csoonline.com/article/4042627/nists-attempts-to-secure-ai-yields-many-questions-no-answers.html)
[^56]: [Nextgov: Artificial Intelligence Friend, Foe, or Frenemy - NIST Wants to Find Out](https://www.nextgov.com/artificial-intelligence/2025/08/artificial-intelligence-friend-foe-or-frenemy-nist-wants-find-out/407792/)
[^57]: [Nextgov: Artificial Intelligence Friend, Foe, or Frenemy - NIST Wants to Find Out](https://www.nextgov.com/artificial-intelligence/2025/08/artificial-intelligence-friend-foe-or-frenemy-nist-wants-find-out/407792/)
[^58]: [IST: Managing Misuse - IST Submits Comments](https://securityandtechnology.org/blog/managing-misuse-ist-submits-comments/)
[^59]: [Lumenova AI: Pros and Cons of Implementing the NIST AI RMF](https://www.lumenova.ai/blog/pros-and-cons-of-implementing-the-nist-ai-risk-management-framework/)
[^60]: [CSO Online: NIST's Attempts to Secure AI Yields Many Questions, No Answers](https://www.csoonline.com/article/4042627/nists-attempts-to-secure-ai-yields-many-questions-no-answers.html)
[^61]: [Future of Life Institute: NIST](https://futureoflife.org/us-agency/national-institute-of-standards-and-technology-nist/)
[^62]: [ISPartners: NIST AI RMF 2025 Updates](https://www.ispartnersllc.com/blog/nist-ai-rmf-2025-updates-what-you-need-to-know-about-the-latest-framework-changes/)
[^63]: [Husch Blackwell: NIST Introduces AI Safety Institute Leaders and Consortium](https://www.huschblackwell.com/newsandinsights/nist-introduces-the-leaders-of-the-artificial-intelligence-safety-institute-and-announces-the-institutes-ai-consortium)
[^64]: [NIST News: NIST Launches Centers for AI in Manufacturing and Critical Infrastructure](https://www.nist.gov/news-events/news/2025/12/nist-launches-centers-ai-manufacturing-and-critical-infrastructure)
[^65]: [Industrial Cyber: NIST, MITRE Invest \$20 Million in AI Centers](https://industrialcyber.co/ai/nist-mitre-invest-20-million-in-ai-centers-to-counter-cyberthreats-boost-us-manufacturing-competitiveness/)
[^66]: [FAS: NIST Foundation](https://fas.org/publication/nist-foundation/)
[^67]: [NIST News: NIST Launches Centers for AI in Manufacturing and Critical Infrastructure](https://www.nist.gov/news-events/news/2025/12/nist-launches-centers-ai-manufacturing-and-critical-infrastructure)
[^68]: [NIST: Technical Contributions to AI Governance](https://www.nist.gov/artificial-intelligence/technical-contributions-ai-governance)
[^69]: [NIST AI 100-5: A Plan for Global Engagement on AI Standards (PDF)](https://nvlpubs.nist.gov/nistpubs/ai/NIST.AI.100-5.pdf)
