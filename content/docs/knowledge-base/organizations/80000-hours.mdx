---
title: 80,000 Hours
description: 80,000 Hours is the leading career guidance organization in the effective altruism community, founded in 2011 by Benjamin Todd and William MacAskill. The organization provides research-backed career advice to help people find high-impact careers, with AI safety as their top priority since 2016. They have reached over 10 million website readers, maintain 400,000+ newsletter subscribers, and report over 3,000 significant career plan changes attributed to their work. The organization spun out from Effective Ventures in April 2025 and has received over $20 million in funding from Coefficient Giving.
sidebar:
  order: 5
quality: 45
llmSummary: 80,000 Hours is the largest EA career organization, reaching 10M+ readers and reporting 3,000+ significant career plan changes, with 80% of $10M+ funding from Coefficient Giving. Since 2016 they've prioritized AI safety, shifting explicitly to AGI focus in 2025, providing career guidance through their guide, podcast (315+ episodes), job board (10K+ monthly clicks), and one-on-one advising.
lastEdited: "2026-01-29"
importance: 42
update_frequency: 21
ratings:
  novelty: 2
  rigor: 4.5
  actionability: 3
  completeness: 6.5
metrics:
  wordCount: 1411
  citations: 51
  tables: 47
  diagrams: 2
clusters:
  - community
  - ai-safety
subcategory: safety-orgs
---
import {Backlinks, Mermaid, DataExternalLinks, EntityLink} from '@components/wiki';

<DataExternalLinks pageId="80000-hours" />

## Quick Assessment

| Dimension | Assessment | Evidence |
|-----------|------------|----------|
| **Scale** | Largest EA Career Organization | 10M+ website readers; 400K+ newsletter subscribers |
| **Primary Focus** | AI Safety Careers | Top priority since 2016; explicit AGI focus since 2025 |
| **Key Outputs** | Career Advice + Research | Problem profiles, career reviews, podcast, job board |
| **Impact Metric** | Career Plan Changes | 3,000+ self-reported significant changes |
| **Funding Model** | Philanthropic Grants | 80% from Coefficient Giving; 20% from other donors |
| **Cumulative Funding** | \$10M+ | Primarily from Coefficient Giving |
| **Independence** | Newly Independent | Spun out from Effective Ventures in April 2025 |
| **Target Audience** | Analytical Altruists | College-educated, 18-45, English-speaking, impact-focused |

## Organization Details

| Attribute | Details |
|-----------|---------|
| **Full Name** | 80,000 Hours |
| **Type** | Nonprofit career guidance organization |
| **Founded** | July 2011 |
| **Founders** | Benjamin Todd, William MacAskill |
| **Origin** | University of Oxford; student society → nonprofit |
| **Current CEO** | Niel Bowerman (since January 2024) |
| **President** | Benjamin Todd |
| **COO** | Brenton Mayer (as of 2025) |
| **Staff Size** | ≈25 FTEs (as of 2022; grown from 14 in 2020) |
| **Primary Funder** | Coefficient Giving (formerly <EntityLink id="open-philanthropy">Coefficient Giving</EntityLink>) |
| **Former Parent** | Effective Ventures Foundation (until April 2025) |
| **Legal Status** | Independent nonprofit (post-spinout) |
| **Headquarters** | London, UK |
| **Website** | [80000hours.org](https://80000hours.org/) |
| **Job Board** | [jobs.80000hours.org](https://jobs.80000hours.org/) |
| **Y Combinator** | 2015 cohort (one of first nonprofits in YC) |

## Overview

80,000 Hours is the leading career guidance organization in the effective altruism movement, providing research-backed advice to help people find careers with maximum positive impact. The organization's name refers to the approximately 80,000 hours a person spends working during their career—and the premise that this represents one of the most significant resources individuals can direct toward solving global problems.

Founded in 2011 by Benjamin Todd and William MacAskill at the University of Oxford, 80,000 Hours evolved from a student lecture series to one of the most influential career resources for impact-focused professionals. The organization became one of the first nonprofits accepted into Y Combinator's startup accelerator in 2015, signaling its innovative approach to the traditionally underserved space of career guidance for social impact.

As of 2025, 80,000 Hours has reached over 10 million website readers, maintains a newsletter community of over 400,000 subscribers, and reports that more than 3,000 people have made significant career changes they attribute to the organization's guidance. Their free resources include an in-depth career guide, problem profiles ranking global issues by importance, career reviews for specific paths, a curated job board, and one-on-one advising for selected applicants.

The organization has prioritized AI safety as their top recommended problem area since 2016. In early 2025, they announced an explicit strategic shift to focus more specifically on "helping people work on navigating the transition to a world with powerful AGI," reflecting their assessment that transformative AI may arrive within the decade and represents the most pressing challenge of our time.

## History and Evolution

### Timeline

| Year | Event | Significance |
|------|-------|--------------|
| **2011** | Founded at Oxford | Benjamin Todd and William MacAskill start 80,000 Hours as a student project |
| **2012** | First full-time staff | Organization professionalizes; begins systematic research |
| **2012** | Co-founded EA movement | Helped establish effective altruism alongside Giving What We Can, CEA |
| **2015** | Y Combinator acceptance | One of first nonprofits in YC; gained startup methodology and credibility |
| **2016** | AI safety becomes top priority | Identified risks from AI as most pressing problem area |
| **2016** | Published career guide book | *80,000 Hours: Find a fulfilling career that does good* |
| **2017** | Podcast launch | Rob Wiblin begins hosting The 80,000 Hours Podcast |
| **2020** | Reached 14 FTEs | Steady organizational growth |
| **2022** | Leadership transition | Benjamin Todd moves from CEO to President; Howie Lempel becomes CEO |
| **2022** | Reached 25 FTEs | Organization nearly doubles in size |
| **2024** | New CEO appointed | Niel Bowerman becomes CEO (former FHI Assistant Director) |
| **2025** | Strategic shift to AGI | Announced focus on navigating transition to powerful AGI |
| **2025** | Spin-out from Effective Ventures | Became independent nonprofit (April 1, 2025) |

### Founding Story

80,000 Hours began as a collaboration between two Oxford students who would become central figures in the effective altruism movement. Benjamin Todd was completing his studies at Oxford when he partnered with William MacAskill, a philosopher who was simultaneously co-founding Giving What We Can (a pledge-based donation community) and developing the philosophical foundations of effective altruism.

The initial concept emerged from MacAskill's academic work on "replaceability"—the question of whether taking a job prevents someone else from doing the same work, and thus whether the marginal impact of career choices differs from their apparent impact. This led to the core insight that guides 80,000 Hours: career choice may be the single largest lever most people have for positive impact, yet receives remarkably little systematic attention.

The organization grew from a lecture to a student society to a professional nonprofit, with Todd managing this evolution while MacAskill focused on academic philosophy and other EA projects. By 2022, 80,000 Hours had raised over \$10 million in funding and employed 25+ staff.

### The Effective Ventures Relationship

Until April 2025, 80,000 Hours operated as a project within Effective Ventures—the umbrella organization that also housed Giving What We Can, the <EntityLink id="cea">Centre for Effective Altruism</EntityLink>, and several other EA-affiliated projects. This structure provided administrative support and legal infrastructure but limited operational flexibility.

The 2025 spin-out established 80,000 Hours as an independent legal entity, giving the organization greater control over its systems, benefits, and strategic direction. This change reflected broader restructuring across the EA ecosystem following the 2022 FTX collapse and subsequent organizational reforms.

## Career Guidance Approach

### Core Framework

80,000 Hours structures career advice around three key questions:

| Question | Framework | Key Insight |
|----------|-----------|-------------|
| **What problems should I work on?** | Problem profiles | Scale × Neglectedness × Tractability |
| **What career paths can address these problems?** | Career reviews | Direct work, earning to give, research, advocacy |
| **How should I plan my career?** | Career strategy | Explore → Build career capital → Apply to pressing problems |

### Problem Prioritization Framework

The organization evaluates global problems using the ITN framework (Importance, Tractability, Neglectedness):

| Criterion | Definition | Application |
|-----------|------------|-------------|
| **Scale/Importance** | How big is the problem? How many affected, how deeply? | AI risk: potentially all humans; existential |
| **Neglectedness** | How much attention/resources does it receive? | AI safety: ≈\$100M/year vs \$14B AI investment |
| **Tractability** | Can additional effort make progress? | Can you find leverage points for intervention? |

### Career Capital Emphasis

A distinctive feature of 80,000 Hours' advice is emphasis on "career capital"—the skills, connections, credentials, and resources that increase future impact potential:

| Career Capital Type | Examples | Strategic Value |
|--------------------|----------|-----------------|
| **Skills** | ML/AI, economics, policy analysis, operations | Directly applicable to priority problems |
| **Connections** | Networks in relevant fields, mentorship | Access to opportunities and information |
| **Credentials** | PhD, government experience, tech company tenure | Credibility and option value |
| **Runway** | Savings, financial security | Ability to take risks, switch paths |
| **Character** | Integrity, resilience, judgment | Long-term effectiveness |

### Target Audience

80,000 Hours explicitly defines their target audience:

| Characteristic | Description |
|---------------|-------------|
| **Education** | College degree (or pursuing one) |
| **Age** | 18-45 years old |
| **Geography** | Primarily US and UK; English-speaking countries |
| **Motivation** | Want to make impact a significant career focus |
| **Approach** | Analytical, willing to consider unconventional paths |
| **Privilege** | Have options for how to spend their careers |

They estimate their target audience at approximately 100,000 people—roughly 10x larger than the core EA community—indicating their goal of reaching beyond the existing movement.

## AI Safety Focus

### Strategic Priority

AI safety has been 80,000 Hours' top-ranked problem area since 2016, and in 2025 they announced an explicit strategic shift:

> "We believe that AGI by 2030 is plausible — much sooner than most would have predicted five years ago — based on analysis of current inputs into AI development and the speed of recent AI progress."

This assessment has led to significant changes in organizational priorities:

| Change | Description |
|--------|-------------|
| **Content focus** | Raising bar for non-AI content; AI safety becomes first priority |
| **Resource allocation** | Shifting staff capacity toward AI-related guidance |
| **Problem coverage** | Maintaining diverse topics where AI intersects with other risks (e.g., biosecurity) |
| **Explicit messaging** | Framing mission as "navigating the transition to powerful AGI" |

### AI Career Paths

80,000 Hours identifies multiple high-impact career paths for AI safety work:

| Path | Description | Difficulty | Impact Potential |
|------|-------------|------------|-----------------|
| **<EntityLink id="technical-research">Technical AI Safety Research</EntityLink>** | Developing solutions to prevent dangerous AI behavior | Very high (PhD-level) | Very high |
| **<EntityLink id="governance-policy">AI Governance and Policy</EntityLink>** | Shaping regulations and <EntityLink id="international-coordination">international coordination</EntityLink> | High | Very high |
| **AI Evaluations** | Assessing AI capabilities and risks | High | High |
| **Operations at AI Safety Orgs** | Enabling researchers to be more effective | Medium | Medium-high |
| **AI Journalism/Communications** | Informing public and policymakers | Medium | Medium |

### Key AI Safety Resources

80,000 Hours maintains extensive AI safety career resources:

| Resource | Description |
|----------|-------------|
| **[Problem Profile: Risks from Power-Seeking AI](https://80000hours.org/problem-profiles/risks-from-power-seeking-ai/)** | Comprehensive analysis of existential AI risk |
| **[Problem Profile: Catastrophic AI Misuse](https://80000hours.org/problem-profiles/catastrophic-ai-misuse/)** | Analysis of AI-enabled harm by malicious actors |
| **[Career Review: AI Safety Technical Research](https://80000hours.org/career-reviews/ai-safety-researcher/)** | Guide to becoming a safety researcher |
| **[Career Review: AI Governance and Policy](https://80000hours.org/career-reviews/ai-policy-and-strategy/)** | Guide to AI policy careers |
| **[AI Safety Syllabus](https://80000hours.org/articles/ai-safety-syllabus/)** | Curated reading list for self-study |
| **[Technical AI Safety Upskilling Resources](https://80000hours.org/2025/06/technical-ai-safety-upskilling-resources/)** | Practical guides for skill-building |
| **[AGI Career Guide](https://80000hours.org/agi/)** | How to use your career to mitigate AI risk |

### Comparison with Other Problem Areas

| Problem Area | 80,000 Hours Assessment | Relative Priority |
|--------------|------------------------|-------------------|
| **Risks from <EntityLink id="power-seeking">Power-Seeking AI</EntityLink>** | Top priority; potentially existential | Highest |
| **Catastrophic AI Misuse** | Major concern; exacerbates other risks | Very high |
| **Preventing Catastrophic Pandemics** | Significant; intersects with AI biosecurity | High (AI intersection prioritized) |
| **Nuclear Security** | Important; less neglected than AI safety | Medium (AI intersection prioritized) |
| **Building Effective Altruism** | Meta-priority; talent pipeline | Medium |
| **Climate Change** | Important but less neglected | Lower priority for 80K resources |

## Key Products and Resources

### Career Guide

The flagship product is a free, research-backed [career guide](https://80000hours.org/career-guide/) developed over 10+ years:

| Component | Description |
|-----------|-------------|
| **Core Guide** | Multi-chapter introduction to high-impact career planning |
| **Problem Profiles** | Deep dives into priority global problems |
| **Career Reviews** | Analysis of specific career paths |
| **Planning Process** | Step-by-step framework for career decisions |
| **Advice by Expertise** | Tailored recommendations for specific backgrounds |

### The 80,000 Hours Podcast

<Mermaid chart={`
flowchart TD
    subgraph Podcast["80,000 Hours Podcast"]
        HOST["Host: Rob Wiblin<br/>(+ Luisa Rodriguez)"]
        EPISODES["315+ Episodes<br/>(as of 2025)"]
        FORMAT["Long-form interviews<br/>(2-4 hours typical)"]
    end

    subgraph Topics["Key Topics"]
        AI["AI Safety & Governance"]
        BIO["Biosecurity"]
        EA["Effective Altruism"]
        CAREERS["Career Strategy"]
        RESEARCH["Research Profiles"]
    end

    subgraph Impact["Reach & Impact"]
        GROWTH["60% YoY growth<br/>(2025 vs 2024)"]
        PLATFORMS["Spotify, Apple,<br/>YouTube, Web"]
    end

    Podcast --> Topics
    Podcast --> Impact

    style AI fill:#ffcccc
    style GROWTH fill:#ccffcc
`} />

The podcast has become one of the most influential long-form interview shows in the effective altruism and AI safety space:

| Metric | Value |
|--------|-------|
| **Episodes** | 315+ (as of 2025) |
| **Format** | Long-form interviews (typically 2-4 hours) |
| **Primary Host** | Rob Wiblin (Director of Research) |
| **Co-Host** | Luisa Rodriguez |
| **Growth** | 60% higher listenership in 2025 vs 2024 |
| **Notable Guests** | AI researchers, policymakers, EA leaders, scientists |

### Job Board

The [80,000 Hours Job Board](https://jobs.80000hours.org/) curates high-impact opportunities:

| Metric | Value |
|--------|-------|
| **User Engagement** | 670+ hours per month browsing |
| **Click-throughs** | 10,000+ monthly clicks to employer sites |
| **Focus Areas** | AI safety, biosecurity, EA organizations, policy |
| **Curation** | Handpicked for alignment with priority problems |
| **Features** | Filters by cause area, job alerts, career capital roles |

### One-on-One Advising

80,000 Hours provides free personalized career advising to selected applicants:

| Aspect | Description |
|--------|-------------|
| **Cost** | Free |
| **Selection** | Competitive; based on fit with priority problems |
| **Format** | Video calls with trained advisors |
| **Scope** | Career strategy, networking, job search support |
| **Cumulative** | 5,000+ people advised (as of 2024) |

## Impact Metrics

### Key Statistics (as of 2024-2025)

| Metric | Value | Source |
|--------|-------|--------|
| **Website Readers** | 10+ million | 80,000 Hours |
| **Newsletter Subscribers** | 400,000+ | 80,000 Hours |
| **Significant Career Plan Changes** | 3,000+ | Self-reported surveys |
| **One-on-One Advising Sessions** | 5,000+ | Cumulative through 2024 |
| **Podcast Episodes** | 315+ | As of 2025 |
| **EA Community Source** | Largest single source | EA Survey data |

### Plan Change Methodology

80,000 Hours tracks "significant plan changes"—when someone reports changing their intended career path in a way they believe increases their impact:

| Criterion | Definition |
|-----------|------------|
| **Threshold** | Change credence in pursuing a path by 20%+ |
| **Attribution** | Person attributes change to 80,000 Hours |
| **Plausibility** | 80,000 Hours plausibly caused the change |
| **Impact Weighting** | Rated 0.1, 1, or 10 based on estimated counterfactual impact |

Historical plan change data:

| Year | Plan Changes | Notes |
|------|--------------|-------|
| **2015** | ≈300 | Early growth phase |
| **2016** | 1,400+ (900+ impact-adjusted) | 4x increase from 2015 |
| **2016 Cumulative** | 1,854 total (1,505 impact-adjusted) | Through November 2016 |
| **2024** | 3,000+ total | Cumulative "significant" changes |

### Notable Outcomes

Examples of impact attributed to 80,000 Hours:

| Outcome | Description |
|---------|-------------|
| **Organization Founding** | ≈10 new organizations founded by advised individuals |
| **Policy Influence** | Advised individuals in government and policy roles |
| **Research Careers** | Researchers at AI safety labs, academia |
| **Donation Commitments** | \$10M+ in pledged donations to high-impact charities |
| **Animal Charity Evaluators** | Helped create organization researching factory farming |
| **Earn to Give** | Individuals like Matt Wage (featured in NYT) donating 50%+ of income |

## Funding and Structure

### Coefficient Giving Grants

80,000 Hours receives approximately 80% of its funding from <EntityLink id="organizations/funders/coefficient-giving">Coefficient Giving</EntityLink>:

| Grant | Amount | Year | Purpose |
|-------|--------|------|---------|
| **General Support** | \$1,125,000 | 2016 | Staff, operations, initial marketing |
| **General Support** | \$1,250,000 | 2022 | Core operations |
| **Marketing** | \$1,000,000 | 2022 | Advertising and outreach |
| **Marketing** | \$1,492,000 | 2023 | Advertising and outreach |
| **General Support** | \$1,600,000 | 2022 | Multi-year support |
| **General Support** | \$1,250,000 | Various | Ongoing operations |
| **Marketing** | \$1,700,000 | 2025 | Advertising and outreach |
| **Cumulative** | \$10M+ | 2016-2025 | Total Coefficient funding |

### Funding Model

| Source | Share | Notes |
|--------|-------|-------|
| **Coefficient Giving** | ≈80% | Primary funder |
| **Other Donors** | ≈20% | Individual and foundation support |
| **Earned Revenue** | Minimal | All services provided free |

### Budget Estimate

Based on fundraising announcements, approximate annual budget:

| Component | Estimate | Notes |
|-----------|----------|-------|
| **General Operations** | ≈\$1.6M/year | Based on \$1.2M = 9 months |
| **Marketing** | ≈\$1.5-3M/year | Based on grant sizes |
| **Total Annual** | ≈\$1-5M | Rough estimate |

### Organizational Structure (Post-Spinout)

<Mermaid chart={`
flowchart TD
    subgraph Leadership["Leadership Team"]
        CEO["CEO: Niel Bowerman"]
        PRES["President: Benjamin Todd"]
        COO["COO: Brenton Mayer"]
        RD["Director of Research: Rob Wiblin"]
    end

    subgraph Teams["Functional Teams"]
        RESEARCH["Research Team"]
        ADVISING["Advising Team"]
        CONTENT["Content/Podcast"]
        JOBBOARD["Job Board"]
        OPS["Operations"]
    end

    subgraph Products["Key Products"]
        GUIDE["Career Guide"]
        PROFILES["Problem Profiles"]
        POD["Podcast"]
        JOBS["Job Board"]
        ONEONE["1-on-1 Advising"]
    end

    CEO --> Teams
    PRES --> RESEARCH
    RD --> CONTENT

    RESEARCH --> GUIDE
    RESEARCH --> PROFILES
    CONTENT --> POD
    JOBBOARD --> JOBS
    ADVISING --> ONEONE

    style CEO fill:#e6f3ff
    style PRES fill:#e6f3ff
`} />

### Key Staff

| Person | Role | Background |
|--------|------|------------|
| **Benjamin Todd** | President, Co-founder | Founded 80,000 Hours; led organization from student society to professional nonprofit |
| **Niel Bowerman** | CEO (since Jan 2024) | Physics PhD; former FHI Assistant Director; CEA co-founder |
| **Brenton Mayer** | COO | Operations leadership |
| **Rob Wiblin** | Director of Research | Genetics/economics background; podcast host since 2017 |
| **William MacAskill** | Co-founder (not operational) | Oxford philosopher; author of *What We Owe the Future*; co-founded EA movement |

## Problem Profiles

80,000 Hours maintains detailed "problem profiles" ranking global issues:

### Current Priority Rankings

| Problem | Priority Level | Key Reasoning |
|---------|---------------|---------------|
| **Risks from Power-Seeking AI** | Highest | Potentially existential; neglected relative to AI investment |
| **Catastrophic AI Misuse** | Very High | AI-enabled bioweapons, cyberattacks, manipulation |
| **Preventing Catastrophic Pandemics** | High | Existential risk; intersection with AI biosecurity |
| **Nuclear Security** | High | Catastrophic risk; less neglected than AI |
| **Building Effective Altruism** | Medium | Meta-priority; talent pipeline for other problems |
| **Climate Change** | Lower | Important but well-funded and well-known |

### AI Problem Profile Summary

The AI risk problem profile makes the following case:

| Element | Assessment |
|---------|------------|
| **Risk Level** | 2023 survey: median AI researcher estimates 5% chance of "extremely bad" outcome |
| **Expert Concern** | 41% say alignment is "very important"; 13% call it "among the most important problems" |
| **Institutional Recognition** | 2023 CAIS statement signed by top AI scientists and CEOs |
| **Comparative Neglectedness** | \$100M/year safety funding vs. \$14B AI investment |
| **Tractability** | Growing field with research progress; talent-constrained |

## Strengths and Limitations

### Organizational Strengths

| Strength | Evidence |
|----------|----------|
| **Research Quality** | 10+ years of systematic career research; evidence-based approach |
| **Scale of Reach** | 10M+ readers; largest source of EA community growth |
| **Free Resources** | All content, advising, and job board access completely free |
| **Specificity** | Detailed career reviews and problem profiles vs. generic advice |
| **Network Effects** | Job board connects talent to high-impact employers |
| **Podcast Influence** | Long-form interviews reach beyond EA community |
| **Credibility** | Y Combinator alumni; Oxford origins; Coefficient Giving backing |

### Known Limitations

| Limitation | Description |
|------------|-------------|
| **Narrow Audience** | Explicitly targets college-educated, English-speaking, 18-45 |
| **AI Focus Concentration** | 2025 shift may reduce coverage of other problems |
| **Self-Reported Impact** | Plan changes based on self-attribution, not verification |
| **EA Association** | Post-FTX reputational challenges for EA-affiliated orgs |
| **Advice Uncertainty** | Career advice inherently uncertain; recommendations may change |
| **Counterfactual Questions** | Would plan-changers have found impact anyway? |

### Criticisms and Controversies

| Criticism | Description | Response |
|-----------|-------------|----------|
| **Earn to Give Concerns** | Money-focused environments may reduce altruistic motivation | 80K now de-emphasizes earn to give; focuses on direct work |
| **Utilitarian Blindness** | Focus on aggregate utility may neglect justice, rights | 80K acknowledges philosophical diversity within EA |
| **Elitism** | Targets privileged individuals; ignores systemic change | Explicit about target audience; sees comparative advantage in analytical types |
| **AI Overemphasis** | May cause harm if AI timelines are longer than expected | Openly states uncertainty; maintains some problem diversity |
| **Community Insularity** | Risk of groupthink in EA career decisions | Published self-critical pieces; encourages independent thinking |

## Relationship with Effective Altruism

80,000 Hours sees itself as a project within effective altruism, focusing specifically on career impact while EA encompasses all ways of doing good (donations, volunteering, consumption, advocacy).

### EA Ecosystem Position

| Relationship | Organization | Description |
|--------------|--------------|-------------|
| **Former Parent** | Effective Ventures | Shared legal/admin infrastructure until 2025 |
| **Sister Project** | Giving What We Can | Donation pledges; complementary to career advice |
| **Sister Project** | Centre for Effective Altruism | Community building; conferences |
| **Primary Funder** | Coefficient Giving | \$10M+ cumulative; 80% of funding |
| **Research Alignment** | GiveWell | Evidence-based approach; different focus (charities vs careers) |
| **Talent Pipeline** | AI Safety Labs | Directs talent toward Anthropic, DeepMind, MIRI, etc. |

### EA Survey Findings

According to EA community surveys, 80,000 Hours is consistently the largest single source of people joining the effective altruism community, indicating significant influence on EA growth and composition.

## Future Outlook

### 2025 Strategic Priorities

| Priority | Description |
|----------|-------------|
| **AGI Focus** | "Navigating the transition to powerful AGI" as primary mission |
| **Capacity Building** | Increase podcast team capacity given 60% listenership growth |
| **Independence** | Leverage new operational flexibility post-spinout |
| **AI Intersection Coverage** | Maintain coverage where AI intersects with biosecurity, nuclear |

### Key Uncertainties

| Question | Implications |
|----------|--------------|
| **AGI Timelines** | If AGI arrives by 2030, current strategy is well-calibrated; if later, may have overcorrected |
| **Field Growth** | Will AI safety field continue absorbing talent 80K directs? |
| **Competitive Landscape** | Will other career organizations emerge for different worldviews? |
| **EA Reputation** | How will post-FTX dynamics affect trust and reach? |
| **Measurement Challenges** | Can impact tracking become more rigorous than self-report? |

## Sources and Citations

### Primary Sources
- [80,000 Hours Website](https://80000hours.org/)
- [80,000 Hours About Page](https://80000hours.org/about/)
- [80,000 Hours Impact Page](https://80000hours.org/about/impact/)
- [80,000 Hours Career Guide](https://80000hours.org/career-guide/)
- [80,000 Hours Job Board](https://jobs.80000hours.org/)
- [Meet the Team](https://80000hours.org/about/meet-the-team/)

### AI Safety Resources
- [Problem Profile: Risks from Power-Seeking AI](https://80000hours.org/problem-profiles/risks-from-power-seeking-ai/)
- [Problem Profile: Catastrophic AI Misuse](https://80000hours.org/problem-profiles/catastrophic-ai-misuse/)
- [Career Review: AI Safety Technical Research](https://80000hours.org/career-reviews/ai-safety-researcher/)
- [Career Review: AI Governance and Policy](https://80000hours.org/career-reviews/ai-policy-and-strategy/)
- [AGI Career Guide](https://80000hours.org/agi/)
- [AI Safety Syllabus](https://80000hours.org/articles/ai-safety-syllabus/)
- [Technical AI Safety Upskilling Resources](https://80000hours.org/2025/06/technical-ai-safety-upskilling-resources/)

### Strategic Announcements
- [We're Shifting Our Strategic Approach to Focus More on AGI](https://80000hours.org/2025/04/strategic-approach/)
- [80,000 Hours Completes Spin-Out from Effective Ventures](https://80000hours.org/2025/05/80000-hours-completes-spin-out-from-effective-ventures/)
- [Announcing Our Plan to Become an Independent Organisation](https://80000hours.org/2023/12/announcing-plan/)
- [FAQ on the Relationship Between 80,000 Hours and the EA Community](https://forum.effectivealtruism.org/posts/iCDcJdqqmBa9QrEHv/faq-on-the-relationship-between-80-000-hours-and-the)

### Funding Sources
- <EntityLink id="coefficient-giving">Coefficient Giving</EntityLink>: 80,000 Hours General Support
- <EntityLink id="coefficient-giving">Coefficient Giving</EntityLink>: 80,000 Hours Marketing 2025
- <EntityLink id="coefficient-giving">Coefficient Giving</EntityLink>: 80,000 Hours Marketing 2023
- <EntityLink id="coefficient-giving">Coefficient Giving</EntityLink>: 80,000 Hours Marketing 2022
- [80,000 Hours Spin-Out Announcement and Fundraising](https://forum.effectivealtruism.org/posts/4ebRNGi3aHWnCw5m8/80-000-hours-spin-out-announcement-and-fundraising-1)

### Podcast and Content
- [The 80,000 Hours Podcast](https://80000hours.org/podcast/)
- [All Podcast Episodes](https://80000hours.org/podcast/episodes/)
- [2024 Highlightapalooza](https://80000hours.org/podcast/episodes/2024-highlights/)
- [Benjamin Todd on the History of 80,000 Hours](https://80000hours.org/after-hours-podcast/episodes/benjamin-todd-history-80k/)

### Impact and Metrics
- [80,000 Hours Impact Survey Evaluation (2014)](https://80000hours.org/2014/03/80-000-hours-impact-survey-evaluation/)
- [End of Year Update on Plan Changes (2016)](https://80000hours.org/2016/12/metrics-report-2016/)
- [80,000 Hours Annual Review (2016)](https://80000hours.org/2016/12/annual-review-dec-2016/)

### External References
- [80,000 Hours - Wikipedia](https://en.wikipedia.org/wiki/80,000_Hours)
- [William MacAskill - Wikipedia](https://en.wikipedia.org/wiki/William_MacAskill)
- [80,000 Hours - EA Forum](https://forum.effectivealtruism.org/topics/80-000-hours)
- [80,000 Hours - Giving What We Can](https://www.givingwhatwecan.org/charities/80000-hours)

## External Links

- [80,000 Hours Website](https://80000hours.org/)
- [80,000 Hours Job Board](https://jobs.80000hours.org/)
- [The 80,000 Hours Podcast](https://80000hours.org/podcast/)
- [Career Guide](https://80000hours.org/career-guide/)
- [Problem Profiles](https://80000hours.org/problem-profiles/)
- [Career Reviews](https://80000hours.org/career-reviews/)
- [Apply for Advising](https://80000hours.org/advising/)

<Backlinks />
