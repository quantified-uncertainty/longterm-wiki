---
title: Samotsvety
description: Elite forecasting group known for dominating prediction tournaments and providing probabilistic forecasts on AI timelines, nuclear risks, and global catastrophic events
importance: 28.5
lastEdited: "2026-02-01"
update_frequency: 45
sidebar:
  order: 60
ratings:
  focus: 8.5
  novelty: 2
  rigor: 6
  completeness: 7.5
  concreteness: 7
  actionability: 2.5
clusters:
  - epistemics
  - community
quality: 61
llmSummary: Elite forecasting group Samotsvety dominated INFER competitions 2020-2022 with relative Brier scores twice as good as competitors, providing influential probabilistic forecasts including 28% TAI by 2030, 60% by 2050, and 25% misaligned AI takeover by 2100. Their work is widely cited in EA/rationalist circles but faces criticisms around methodology (overreliance on base rates for nuclear risk), selection bias (EA skew), and fundamental limits of forecasting novel events.
metrics:
  wordCount: 2734
  citations: 78
  tables: 2
  diagrams: 0
subcategory: epistemic-orgs
---
import {EntityLink, Section} from '@components/wiki';

## Quick Assessment

| Dimension | Assessment |
|-----------|------------|
| **Type** | Forecasting team / research group |
| **Founded** | ≈2020 (originated as Slack channel) |
| **Key Focus** | Probabilistic predictions on AI timelines, nuclear risks, global catastrophic risks |
| **Core Strength** | Exceptional track record in forecasting competitions (dominated INFER 2020-2022) |
| **Notable Work** | AI risk forecasts, nuclear risk assessments, prediction market research |
| **Community Role** | Influential in EA/rationalist forecasting ecosystem |

## Key Links

| Source | Link |
|--------|------|
| Official Website | [samotsvety.org](https://samotsvety.org/blog/2024/10/22/p-calamity/) |
| Wikipedia | [en.wikipedia.org](https://en.wikipedia.org/wiki/Samotsvety) |
| Wikidata | [wikidata.org](https://www.wikidata.org/wiki/Q4406987) |
| EA Forum | [forum.effectivealtruism.org](https://forum.effectivealtruism.org/posts/KRFXjCqqfGQAYirm5/samotsvety-nuclear-risk-forecasts-march-2022) |

## Overview

**Samotsvety Forecasting** is a team of elite superforecasters recognized as among the world's best at probabilistic predictions on impactful global events.[^1] The group specializes in using only publicly available information to generate forecasts on high-stakes questions, emphasizing track record transparency and rigorous self-scoring for accuracy.[^2] Scott Alexander described their competition victories as won "by an absolutely obscene margin, around twice as good as the next-best team in relative Brier score."[^3]

The group originated as a Slack channel where co-founders Misha Yagudin and <EntityLink id="E579">Nuño Sempere</EntityLink> discussed forecasting, eventually expanding to approximately 15 members worldwide selected for their strong performance on platforms like <EntityLink id="E199">Metaculus</EntityLink> and INFER.[^4][^5] Rather than relying on insider knowledge, Samotsvety focuses on recognizing overlooked patterns in public data, following co-founder Yagudin's principle: "Oft hat eine kleine Beobachtung mehr Gewicht als 1000 Fakten" (Often a small observation weighs more than 1000 facts).[^6]

Samotsvety's work has influenced the broader forecasting ecosystem through their consulting services, published forecasts on critical topics like AI timelines and nuclear escalation risks, and methodological contributions to <EntityLink id="E228">prediction markets</EntityLink> and aggregation techniques. Their forecasts are frequently cited in <EntityLink id="E538">LessWrong</EntityLink> and EA Forum discussions about existential risks.

## History

Samotsvety emerged from informal forecasting discussions between Misha Yagudin and Nuño Sempere on a Slack channel focused on prediction questions.[^7] The group's breakthrough came with their dominant performance in the <EntityLink id="E524">CSET</EntityLink>-Foretell (INFER) competition series from 2020-2022.

### Competition Dominance (2020-2022)

In **2020**, Samotsvety achieved first place in CSET-Foretell with a team relative Brier score of -0.912 compared to -0.062 for the second-place team, with individual members finishing 5th, 6th, and 7th.[^8] The core team of Nuño, Misha, and <EntityLink id="E435">Eli Lifland</EntityLink> repeated this success in **2021**, winning with a relative score of -3.259 versus -0.889 for second place and -0.267 for "Pro Forecasters," while occupying the 1st, 2nd, 4th, and 5th individual positions.[^9]

By September 2022, Samotsvety members held the top four spots on INFER's all-time leaderboard.[^10] Several members earned designation as **Superforecasters™**, and the group maintained first place in 2022 despite reduced participation.[^11] They also placed 4th on the Insight Prediction leaderboard due to a successful large bet correctly predicting the Russian invasion of Ukraine.[^12]

### Evolution and Expansion (2022-Present)

Following their competition success, Samotsvety shifted focus toward impactful forecasting applications. In March 2022, they published nuclear risk forecasts aggregating predictions from eight forecasters on questions like the probability of nuclear explosions in major cities.[^13] This work received expert review from nuclear specialists and was recommended for retroactive funding by the Future Fund.[^14]

Throughout 2023-2024, the group released influential AI risk forecasts, including timelines for transformative AI (28% by 2030, 60% by 2050, 89% by 2100) and estimates of misaligned AI takeover (25% by 2100).[^15][^16] Their work has been incorporated into literature reviews by <EntityLink id="E125">Epoch AI</EntityLink> and cited in discussions about AI safety policy.[^17]

In October 2024, Samotsvety published probabilities from seven forecasters on catastrophes causing \>1 million direct deaths within the next decade, tying into work on early warning systems for global risks.[^18] Co-founder Nuño Sempere launched <EntityLink id="E566">Sentinel</EntityLink>, a non-profit focused on early-warning systems for catastrophes, building on Samotsvety's forecasting methods.[^19]

## Core Team and Contributors

- **Misha Yagudin**: Co-founder and team leader; world-class forecaster who co-runs <EntityLink id="E514">Arb Research</EntityLink> consultancy focused on forecasting and AI safety research[^20]
- **Nuño Sempere**: Co-founder; top-ranked forecaster who founded <EntityLink id="E566">Sentinel</EntityLink> non-profit for catastrophic risk early warning; Head of Foresight at Sentinel; fellow in the 2025 <EntityLink id="E585">AI for Human Reasoning Fellowship</EntityLink>[^21]
- **<EntityLink id="E435">Eli Lifland</EntityLink>**: Co-lead; top competition winner; co-founder of <EntityLink id="E511">AI Futures Project</EntityLink>; formerly worked on <EntityLink id="E526">Elicit</EntityLink> at Ought[^22]
- **Gavin Leech**: Associated forecaster; nearly completed AI PhD at University of Bristol; co-founder of <EntityLink id="E514">Arb Research</EntityLink>; Emergent Ventures grant recipient[^23]

The group maintains approximately 15 active members selected based on demonstrated performance in forecasting competitions, particularly on Metaculus and INFER platforms.[^24] Members include several certified Superforecasters™ and individuals who have topped various forecasting leaderboards.[^25]

## Major Forecasting Work

### AI Timelines and Risk Assessments

Samotsvety's AI forecasts represent some of their most cited work, providing probabilistic timelines for transformative AI (TAI) and artificial general intelligence (AGI). Their aggregated forecasts from eight members include:[^26]

- **28% probability of TAI by 2030**
- **60% probability by 2050**
- **89% probability by 2100** (conditional on no prior catastrophe)
- **Median TAI arrival: 2043** (with 10th percentile at 2024, 90th percentile at 2104)

The group's methodology shifted from outside-view reference class forecasting to inside-view models based on AI capabilities progress, which shortened their estimated timelines compared to earlier reports.[^27] They estimated an 81% chance of TAI by 2100 when accounting for the possibility of civilization-ending catastrophes before TAI development.[^28]

For AI risk specifically, Samotsvety forecasters provided a 25% aggregate probability of misaligned AI takeover by 2100, with many individual forecasters assigning 5-10% or higher probability to AI-driven disempowerment of humanity by 2070.[^29] These estimates reflect near-consensus among group members about substantial existential risks from advanced AI systems.[^30]

### Nuclear Risk Forecasting

In March 2022, following Russia's invasion of Ukraine, Samotsvety aggregated forecasts from eight members on nuclear escalation scenarios using beta prior and binomial likelihood modeling.[^31] The forecasts covered questions like "death in next month due to nuclear explosion in London" and received expert review from specialists including J. Peter Scoblic and Joshua Rosenberg.[^32]

The group's nuclear risk estimates tended to be lower than some external experts, partly due to different assumptions about evacuation possibilities and their aggregation methodology emphasizing mutual assured destruction (MAD) principles and historical de-escalation patterns.[^33] An October 2022 update maintained low escalation probabilities even as Russia crossed various "red lines," though some critics argued this reflected overreliance on base rates and underestimation of tail risks.[^34]

### Other Forecasting Projects

Beyond AI and nuclear risks, Samotsvety has contributed to:

- **Prediction Markets in Corporate Settings**: Analysis of adoption barriers including technological underdevelopment, social disruptiveness, and difficulty writing informative questions[^35]
- **Forecasting Methodology**: Development of better scoring rules, alignment of forecasting platforms, and micro-grants for forecasting research[^36]
- **GJO Calibration App**: Tools for forecaster training and improvement[^37]
- **Bottlenecks to Impactful Crowd Forecasting**: Research on systemic limitations in prediction platforms[^38]

## Research Outputs and Publications

While Samotsvety's primary outputs are forecasts rather than traditional academic publications, team members have contributed to research through affiliations with the <EntityLink id="E147">Forecasting Research Institute</EntityLink> (FRI) and related organizations. FRI publications involving Samotsvety members or methods include:[^39]

- [Karger et al. (2025) - "Forecasting with Large Language Models"](https://openreview.net/forum?id=JDud6zbpFv) (ICLR 2025)
- [Atanasov et al. (2024) - "Project Improbable" on improving low-probability judgments](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4714914) (SSRN)
- Merkle et al. (2024) - Identifying good forecasters via tests
- [Karger et al. (2022) - Improving judgments of existential risk](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4001628) (SSRN)

Through Arb Research, members including Misha Yagudin and Gavin Leech have contributed to:[^40]

- **Shallow Review of AI Safety** (2025) - 3x larger than prior year, with editorial 6x larger; keynoted at HAAISS conference
- **AI Bias Paper** with ACS, published in PNAS on human text bias
- **Scientific Breakthroughs Collection** - 200 biggest discoveries of the year for Renaissance Philanthropy
- **Hidden Interpolation in Frontier AI** - Self-funded project (forthcoming)

Samotsvety forecasts have been incorporated into Epoch AI's 2024 transformative AI timelines literature review and referenced in discussions about AI safety policy across the effective altruism and rationalist communities.[^41]

## Impact and Recognition

### Competition Performance

The four most accurate forecasters in INFER/RAND history are Samotsvety members, with a substantial gap separating them from the fifth-place forecaster.[^42] Individual members have achieved top rankings across multiple platforms:

- **Top 4 positions on INFER all-time leaderboard** (as of September 2022)[^43]
- **Multiple Superforecaster™ certifications**[^44]
- **4th place on Insight Prediction leaderboard** due to Ukraine invasion prediction[^45]

### Media Recognition

Samotsvety has been featured and praised in multiple media outlets and by prominent forecasting advocates:

- **Scott Alexander** (Astral Codex Ten): Described them as "some of the best superforecasters in the world" winning competitions by "obscene margins"[^46]
- **Vox**: Featured as a "ragtag band of internet friends" dominating leaderboards, with praise from expert Jason Matheny for their accuracy and commitment to self-scoring[^47]
- **Nasdaq**: Profiled as "one of the world's best predictors of the future"[^48]
- **Spektrum** (German): International group excelling without insider information[^49]

### Influence on Forecasting Ecosystem

Samotsvety's work has been incorporated into major AI safety analyses and cited in policy discussions. Their forecasts appear in studies aggregating 9,300+ AGI/singularity predictions and have influenced estimates used in AI Index reports.[^50][^51] The group maintains an open consulting practice (contact: info@samotsvety.org) and actively collaborates with organizations including the Forecasting Research Institute, Quantified Uncertainty Research Institute (QURI), Epoch AI, and Arb Research.[^52][^53]

## Collaborations and Partnerships

Samotsvety maintains relationships with several organizations in the forecasting and AI safety ecosystems:

- **Forecasting Research Institute (FRI)**: Collaboration on forecasting research and methodology[^54]
- **Quantified Uncertainty Research Institute (QURI)**: Members contributed to <EntityLink id="E200">Metaforecast</EntityLink> and <EntityLink id="E286">Squiggle</EntityLink> forecasting tools[^55]
- **Arb Research**: Co-leaders Gavin Leech and Misha Yagudin run this research consultancy; co-authored comparative studies of forecasters versus domain experts[^56]
- **Epoch AI**: Provided updated <EntityLink id="E399">AGI timeline</EntityLink> forecasts for literature reviews on transformative AI timelines[^57]
- **Sentinel**: Samotsvety probabilities on catastrophes inform this early-warning system for global risks[^58]

The group participated in projects with Sage (Impactful Forecasting Prize, Pastcasting), developed tools for <EntityLink id="E532">Good Judgment</EntityLink> Open, and maintains active presence on the EA Forum and LessWrong where their forecasts generate substantial community discussion.[^59]

## Criticisms and Limitations

### Methodological Concerns

Critics have identified several limitations in Samotsvety's forecasting approach. Their analysis of academic literature on prediction markets concluded that the academic consensus **overstates benefits and promisingness** due to perverse incentives that emphasize promising results while downplaying technological underdevelopment.[^60] This self-critique suggests awareness of systemic biases in the forecasting field itself.

On complex topics like AI timelines, Samotsvety has noted that ML researchers surveyed displayed "very incoherent views depending on the question being asked and elicitation techniques," suggesting many forecasters "haven't thought about it that deeply."[^61] Wide ranges and large differences in estimates often reflect "very-hard-to-resolve deep disagreements in intuitions" rather than genuine uncertainty quantification.[^62]

### Selection Bias and Generalization Limits

Samotsvety forecasters are selected for interest in AI and strong performance on existing platforms, which may not generalize well to long-term, radically novel events.[^63] The group may be "relatively bullish on transformative technological change from AI" compared to other forecasting organizations like the Forecasting Research Institute.[^64] Several members noted that the group has some EA (effective altruism) skew due to social connections influencing member selection.[^65]

### Fundamental Epistemological Limits

Forecasting AI progress encounters fundamental limits of Bayesian reasoning itself, as forecasters may face true hypotheses outside their previous hypothesis space.[^66] Critics argue that forecasters often lack serious evaluation of past predictive errors, making systematic improvement impossible.[^67] Some analyses suggest Samotsvety members sometimes use "reference class stuff" without showing requisite reasoning about counterfactuals and assumptions, raising questions about whether summary probability estimates reflect genuine complex reasoning or hidden shortcuts.[^68]

### Prediction Market Implementation

Beyond individual forecasting, Samotsvety's analysis of prediction markets identified multiple barriers to practical adoption:[^69]

- **Underdeveloped technology** limiting market functionality
- **Difficulty writing good and informative questions** that resolve cleanly
- **Social disruptiveness** - markets expose hypocrisy and remove excuses, creating interpersonal friction similar to "a very direct socially awkward person"
- **Imperceptible improvements** - benefits may be too small to notice, leading to abandonment after trials

### Nuclear Risk Criticisms

Some nuclear experts and forecasters criticized Samotsvety's March 2022 nuclear risk estimates as too low, arguing they reflected overreliance on base rates and underestimated tail risks like Putin's willingness to escalate.[^70] The group's aggregation methods and assumptions about evacuation possibilities led to estimates about an order of magnitude below some nuclear specialists.[^71]

## Community Reception

Samotsvety maintains active presence on the EA Forum and LessWrong, where their forecasts generate substantial discussion. Community opinions are generally positive but include some critiques:[^72]

**Positive reception:**

- Expected to "comfortably outperform" community aggregates even without extraordinary effort[^73]
- Strong performance on short-term (within 12 months) geopolitics and technology questions[^74]
- Outperforms EA Forum/Metaculus community aggregates (e.g., log scores: 0.280 vs. 0.261)[^75]

**Critical perspectives:**

- EA skew from social member additions; calls for pre-registered question sets to reduce selection effects[^76]
- Some methodological concerns about aggregation techniques and baseline assumptions[^77]
- Questions about whether private year-by-year forecasts (like their LLM capability predictions) should be made public for accountability[^78]

Individual Samotsvety members have strong track records across multiple forecasting platforms, contributing to the team's overall reputation in the forecasting ecosystem.[^79]

## Key Uncertainties

- How well do Samotsvety's forecasting methods generalize beyond the types of questions featured in competitions like INFER?
- Do their strong performances on 12-month geopolitical and technology questions translate to accuracy on 10-50 year timelines for transformative AI?
- How much does selection bias (EA affiliation, AI interest) skew their AI risk estimates compared to a more diverse forecaster pool?
- Can their nuclear risk methodologies adequately capture tail risks and novel escalation scenarios that lack historical precedent?
- What is the optimal aggregation method for combining forecasts from superforecasters versus domain experts when they systematically disagree?
- How should policymakers weigh Samotsvety forecasts against <EntityLink id="E132">expert opinion</EntityLink> when they diverge significantly on questions like nuclear escalation probability?

## Sources

[^1]: [Samotsvety - Media Mentions](https://samotsvety.org/media-mentions/)
[^2]: [Samotsvety - Home](https://samotsvety.org)
[^3]: [Samotsvety - Home](https://samotsvety.org)
[^4]: [Nasdaq - A Look at Samotsvety Forecasting](https://www.nasdaq.com/articles/a-look-at-samotsvety-forecasting-one-of-the-worlds-best-predictors-of-the-future)
[^5]: [Samotsvety - Media Mentions](https://samotsvety.org/media-mentions/)
[^6]: [Samotsvety - Media Mentions](https://samotsvety.org/media-mentions/)
[^7]: [Nasdaq - A Look at Samotsvety Forecasting](https://www.nasdaq.com/articles/a-look-at-samotsvety-forecasting-one-of-the-worlds-best-predictors-of-the-future)
[^8]: [Samotsvety - Track Record](https://samotsvety.org/track-record/)
[^9]: [Samotsvety - Track Record](https://samotsvety.org/track-record/)
[^10]: [Samotsvety - Track Record](https://samotsvety.org/track-record/)
[^11]: [Samotsvety - Track Record](https://samotsvety.org/track-record/)
[^12]: [Samotsvety - Track Record](https://samotsvety.org/track-record/)
[^13]: [EA Forum - Samotsvety Nuclear Risk Forecasts March 2022](https://forum.effectivealtruism.org/posts/KRFXjCqqfGQAYirm5/samotsvety-nuclear-risk-forecasts-march-2022)
[^14]: [EA Forum - Samotsvety Nuclear Risk Forecasts March 2022](https://forum.effectivealtruism.org/posts/KRFXjCqqfGQAYirm5/samotsvety-nuclear-risk-forecasts-march-2022)
[^15]: [Foxy Scout - Samotsvety's AI Risk Forecasts](https://www.foxy-scout.com/samotsvetys-ai-risk-forecasts/)
[^16]: [EA Forum - Samotsvety's AI Risk Forecasts](https://forum.effectivealtruism.org/posts/EG9xDM8YRz4JN4wMN/samotsvety-s-ai-risk-forecasts)
[^17]: [Epoch AI - Literature Review of TAI Timelines](https://epoch.ai/blog/literature-review-of-transformative-artificial-intelligence-timelines)
[^18]: [Samotsvety Blog - 2024](https://samotsvety.org/blog/2024/)
[^19]: [Alethios Substack - Interview with Nuño Sempere](https://alethios.substack.com/p/with-nuno-sempere-superforecasting)
[^20]: [ASPR Team](https://www.aspr.camp/team)
[^21]: [EA Forum - Sentinel Funding Memo](https://forum.effectivealtruism.org/posts/SzuF29o9uQpLpYrqJ/sentinel-funding-memo-mitigating-gcrs-with-forecasting-and)
[^22]: [Quantified Uncertainty - Eli Lifland Interview](https://quantifieduncertainty.org/posts/eli-lifland-on-navigating-the-ai-722/)
[^23]: [ASPR Team](https://www.aspr.camp/team)
[^24]: [Samotsvety - Media Mentions](https://samotsvety.org/media-mentions/)
[^25]: [Samotsvety - Track Record](https://samotsvety.org/track-record/)
[^26]: [Foxy Scout - Samotsvety's AI Risk Forecasts](https://www.foxy-scout.com/samotsvetys-ai-risk-forecasts/)
[^27]: [Epoch AI - Literature Review of TAI Timelines](https://epoch.ai/blog/literature-review-of-transformative-artificial-intelligence-timelines)
[^28]: [Foxy Scout - Samotsvety's AI Risk Forecasts](https://www.foxy-scout.com/samotsvetys-ai-risk-forecasts/)
[^29]: [EA Forum - Samotsvety's AI Risk Forecasts](https://forum.effectivealtruism.org/posts/EG9xDM8YRz4JN4wMN/samotsvety-s-ai-risk-forecasts)
[^30]: [EA Forum - Samotsvety's AI Risk Forecasts](https://forum.effectivealtruism.org/posts/EG9xDM8YRz4JN4wMN/samotsvety-s-ai-risk-forecasts)
[^31]: [EA Forum - Samotsvety Nuclear Risk Forecasts March 2022](https://forum.effectivealtruism.org/posts/KRFXjCqqfGQAYirm5/samotsvety-nuclear-risk-forecasts-march-2022)
[^32]: [EA Forum - Samotsvety Nuclear Risk Forecasts March 2022](https://forum.effectivealtruism.org/posts/KRFXjCqqfGQAYirm5/samotsvety-nuclear-risk-forecasts-march-2022)
[^33]: [Samotsvety Blog - March 2022 Nuclear Risk Forecasts](https://samotsvety.org/blog/2022/03/10/samotsvety-nuclear-risk-forecasts-march-2022/)
[^34]: [Samotsvety Blog - October 2022 Nuclear Risk Update](https://samotsvety.org/blog/2022/10/03/samotsvety-nuclear-risk-update-october-2022/)
[^35]: [Samotsvety Blog - Prediction Markets in the Corporate Setting](https://samotsvety.org/blog/2021/12/31/prediction-markets-in-the-corporate-setting/)
[^36]: [Samotsvety Projects](https://samotsvety.org/projects/)
[^37]: [Samotsvety Projects](https://samotsvety.org/projects/)
[^38]: [Samotsvety Projects](https://samotsvety.org/projects/)
[^39]: [Forecasting Research Institute - Publications](https://forecastingresearch.org/publications)
[^40]: [Arb Research - Work](https://arbresearch.com/work/)
[^41]: [Epoch AI - Literature Review of TAI Timelines](https://epoch.ai/blog/literature-review-of-transformative-artificial-intelligence-timelines)
[^42]: [Samotsvety - Media Mentions](https://samotsvety.org/media-mentions/)
[^43]: [Samotsvety - Track Record](https://samotsvety.org/track-record/)
[^44]: [Samotsvety - Track Record](https://samotsvety.org/track-record/)
[^45]: [Samotsvety - Track Record](https://samotsvety.org/track-record/)
[^46]: [Samotsvety - Home](https://samotsvety.org)
[^47]: [Samotsvety - Media Mentions](https://samotsvety.org/media-mentions/)
[^48]: [Nasdaq - A Look at Samotsvety Forecasting](https://www.nasdaq.com/articles/a-look-at-samotsvety-forecasting-one-of-the-worlds-best-predictors-of-the-future)
[^49]: [Samotsvety - Media Mentions](https://samotsvety.org/media-mentions/)
[^50]: [AIM Multiple - AGI Singularity Timing](https://research.aimultiple.com/artificial-general-intelligence-singularity-timing/)
[^51]: [JAIR - AI Futures Paper](https://dl.acm.org/doi/pdf/10.1613/jair.1.19087)
[^52]: [Samotsvety - Home](https://samotsvety.org)
[^53]: [Samotsvety - Media Mentions](https://samotsvety.org/media-mentions/)
[^54]: [Notion - Research Consultancy Organizations](https://saul-munn.notion.site/Research-consultancy-organizations-b111d45fa15d4945a1aa8daf7bbc1345)
[^55]: [Samotsvety Projects](https://samotsvety.org/projects/)
[^56]: [IFP - Can Policymakers Trust Forecasters](https://ifp.org/can-policymakers-trust-forecasters/)
[^57]: [Samotsvety Blog](https://samotsvety.org/blog/)
[^58]: [Samotsvety Blog](https://samotsvety.org/blog/)
[^59]: [Samotsvety Projects](https://samotsvety.org/projects/)
[^60]: [Samotsvety Blog - Prediction Markets in the Corporate Setting](https://samotsvety.org/blog/2021/12/31/prediction-markets-in-the-corporate-setting/)
[^61]: [EA Forum - Samotsvety's AI Risk Forecasts](https://forum.effectivealtruism.org/posts/EG9xDM8YRz4JN4wMN/samotsvety-s-ai-risk-forecasts)
[^62]: [EA Forum - Samotsvety's AI Risk Forecasts](https://forum.effectivealtruism.org/posts/EG9xDM8YRz4JN4wMN/samotsvety-s-ai-risk-forecasts)
[^63]: Benjamin Todd, "Shortening AGI Timelines Review" (Substack) - Discussion of selection effects in forecasting AI timelines
[^64]: Nuño Sempere, "Hurdles Forecasting AI" (Blog) - Analysis of forecaster biases toward transformative technological change
[^65]: [EA Forum - Samotsvety's AI Risk Forecasts](https://forum.effectivealtruism.org/posts/EG9xDM8YRz4JN4wMN/samotsvety-s-ai-risk-forecasts)
[^66]: Nuño Sempere, "Hurdles Forecasting AI" (Blog) - Exploration of epistemological limitations in AI forecasting
[^67]: Nuño Sempere, "Hurdles Forecasting AI" (Blog) - Critique of lack of error evaluation in forecasting practice
[^68]: Astral Codex Ten, "In Continued Defense of Non-Frequentist" (Comments) - Methodological critiques of reference class reasoning
[^69]: [Samotsvety Blog - Prediction Markets in the Corporate Setting](https://samotsvety.org/blog/2021/12/31/prediction-markets-in-the-corporate-setting/)
[^70]: [Samotsvety Blog - March 2022 Nuclear Risk Forecasts](https://samotsvety.org/blog/2022/03/10/samotsvety-nuclear-risk-forecasts-march-2022/)
[^71]: [Samotsvety Blog - March 2022 Nuclear Risk Forecasts](https://samotsvety.org/blog/2022/03/10/samotsvety-nuclear-risk-forecasts-march-2022/)
[^72]: [EA Forum - Samotsvety's AI Risk Forecasts](https://forum.effectivealtruism.org/posts/EG9xDM8YRz4JN4wMN/samotsvety-s-ai-risk-forecasts)
[^73]: [EA Forum - Samotsvety's AI Risk Forecasts](https://forum.effectivealtruism.org/posts/EG9xDM8YRz4JN4wMN/samotsvety-s-ai-risk-forecasts)
[^74]: [EA Forum - Update to Samotsvety AGI Timelines](https://forum.effectivealtruism.org/posts/ByBBqwRXWqX5m9erL/update-to-samotsvety-agi-timelines)
[^75]: [EA Forum - Samotsvety's AI Risk Forecasts](https://forum.effectivealtruism.org/posts/EG9xDM8YRz4JN4wMN/samotsvety-s-ai-risk-forecasts)
[^76]: [EA Forum - Samotsvety's AI Risk Forecasts](https://forum.effectivealtruism.org/posts/EG9xDM8YRz4JN4wMN/samotsvety-s-ai-risk-forecasts)
[^77]: [Samotsvety Blog - October 2022 Nuclear Risk Update](https://samotsvety.org/blog/2022/10/03/samotsvety-nuclear-risk-update-october-2022/)
[^78]: [EA Forum - Update to Samotsvety AGI Timelines](https://forum.effectivealtruism.org/posts/ByBBqwRXWqX5m9erL/update-to-samotsvety-agi-timelines)
[^79]: [EA Forum - Samotsvety's AI Risk Forecasts](https://forum.effectivealtruism.org/posts/EG9xDM8YRz4JN4wMN/samotsvety-s-ai-risk-forecasts)

