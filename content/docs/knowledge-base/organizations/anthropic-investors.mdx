---
title: Anthropic (Funder)
description: "Analysis of EA-aligned philanthropic capital at Anthropic. At $380B valuation (Series G, Feb 2026): $27-76B risk-adjusted EA capital from founder pledges (80% of equity from all 7 co-founders), investor stakes (Tallinn $2-6B, Moskovitz $3-9B), and employee matching programs ($20-40B in DAFs). Critical caveats: only 2/7 founders have documented EA connections; matching program reduced from 3:1@50% to 1:1@25% for new hires."
entityType: organization
subcategory: funders
quality: 65
readerImportance: 33
researchImportance: 58
tacticalValue: 88
lastEdited: "2026-02-16"
update_frequency: 45
llmSummary: "Comprehensive model of EA-aligned philanthropic capital at Anthropic. At $380B valuation (Series G, Feb 2026, $30B raised): $27-76B risk-adjusted EA capital expected. Total funding raised exceeds $67B. Sources: all 7 co-founders pledged 80% of equity, but only 2/7 (Dario and Daniela Amodei) have documented strong EA connections. Early EA investors Jaan Tallinn ($2-6B) and Dustin Moskovitz ($3-9B) hold substantial stakes. Employee matching program historically 3:1 at 50% of equity, now reduced to 1:1 at 25% for new hires—$20-40B estimated already in DAFs. Extended scenarios: at $500-700B (moderate bull), EA capital reaches $50-140B; at $1T+ (strong bull), $70-200B+. Key uncertainty: cause allocation of non-EA founders (Brown, Kaplan, McCandlish, Clark, Olah). Timeline: employee capital 2027-2030 (IPO liquidity); founder capital 2030-2040 (gradual liquidation)."
ratings:
  novelty: 5
  rigor: 5
  actionability: 6
  completeness: 6
clusters:
  - community
  - ai-safety
  - governance
todos:
  - Track donation announcements as they occur post-IPO
  - Update secondary market prices quarterly (last updated Feb 2026 on diversification page)
  - Research Tallinn's actual Anthropic holdings if disclosed - as of Feb 2026, exact stake size remains undisclosed; he led seed and Series A ($124M at $550M valuation) and participated through Series B
  - Track whether founders without formal EA commitments (Brown, Kaplan, McCandlish, Clark, Olah) announce specific giving plans or cause preferences - as of Feb 2026, none are Giving Pledge signatories
  - Document legal status of founder pledges (binding vs. aspirational) - employee equity pledges appear legally binding (transferred to DAFs), but founder 80% pledges are reportedly not legally binding per LessWrong sources
  - Research whether matching program changes signal shift in company priorities - confirmed reduced from 3:1@50% to lower terms for new hires; original program no longer available per LessWrong reports; existing pledges still in effect
---
import {EntityLink, SquiggleEstimate, F} from '@components/wiki';

:::note[Page Scope]
This page covers EA-aligned philanthropic capital at Anthropic, including founder pledges, employee matching programs, EA investor stakes, and cause allocation. For valuation analysis, see <EntityLink id="E405">Anthropic Valuation Analysis</EntityLink>. For company overview, see <EntityLink id="E22">Anthropic</EntityLink>.

**Data as of**: February 2026. Current valuation: \$380B (Series G). Risk-adjusted EA capital estimate: \$27-76B.
:::

## Quick Assessment

| Dimension | Assessment | Evidence |
|-----------|------------|----------|
| **Total Raised** | \$67B+ | Including \$30B Series G (Feb 2026) |
| **Current Valuation** | \$380B | Series G post-money (Feb 2026); up from \$61.5B in March 2025 |
| **Total EA-Aligned Equity** | 20-45% | Founders + Tallinn + Moskovitz + EA employees |
| **Expected EA Capital (risk-adjusted)** | \$27-76B | Wide range: conservative (2/7 EA founders) to optimistic (all founders) |
| **Legally Bound Capital** | \$25-50B | Employee pledges + matching in DAFs; reduced for program changes |
| **Founder Donation Pledges** | 80% of equity | All seven co-founders; only 2/7 have strong EA connections |
| **EA Investor Stakes** | \$5-16B | Tallinn (\$2-6B conservative) + Moskovitz (\$3-9B) + others |
| **IPO Timeline** | 2026-2027 | See <EntityLink id="E409">Anthropic IPO</EntityLink> for details |
| **Pledge Fulfillment Risk** | Variable | Legally bound: 90-100%; Founder pledges: 40-60% |

## Overview

<EntityLink id="E22">Anthropic</EntityLink>'s rapid valuation growth—from \$550 million in May 2021 to <F e="anthropic" f="6796e194" /> by February 2026 (Series G)—has created what may become the largest single source of longtermist philanthropic capital in history. [Anthropic](https://www.anthropic.com/news/anthropic-raises-30-billion-series-g-funding-380-billion-post-money-valuation) EA-aligned equity spans multiple sources: all seven co-founders have pledged to donate 80% of their equity (\$43-64B at current valuation, though only 2 of 7 have documented strong EA connections), early investors <EntityLink id="E577">Jaan Tallinn</EntityLink> (\$2-6B conservative estimate) and <EntityLink id="E436">Dustin Moskovitz</EntityLink> (\$3-9B) hold substantial stakes, and early employees transferred billions to donor-advised funds under Anthropic's historical 3:1 matching program (now reduced to 1:1 at 25% for new hires). [Fortune](https://fortune.com/2026/01/27/anthropic-billionaire-cofounders-ceo-dario-amodei-giving-away-80-percent-of-wealth-fighting-inequality-ai-revolution/)

Total EA-aligned capital at current valuations ranges from **\$33-172B gross** (conservative to optimistic), with a risk-adjusted expected value of **\$27-76B**—the wide range reflecting genuine uncertainty about founder cause allocation (only 2 of 7 have documented strong EA connections). An estimated \$20-40B is already legally bound in DAFs through the employee matching program—though DAF donors retain discretion over which charities receive grants, and the matching program has been reduced from 3:1 at 50% to 1:1 at 25% for new employees. [IPS](https://ips-dc.org/report-giving-pledge-at-15/)

This page provides comprehensive analysis of all EA-aligned capital sources at Anthropic, models funding flows under different scenarios, and assesses when this capital will reach effective causes.

## Funding History

Anthropic has raised over \$67 billion, including the \$30 billion Series G closed in February 2026. [Anthropic](https://www.anthropic.com/news/anthropic-raises-30-billion-series-g-funding-380-billion-post-money-valuation) [Tracxn](https://tracxn.com/d/companies/anthropic/__SzoxXDMin-NK5tKB7ks8yHr6S9Mz68pjVCzFEcGFZ08/funding-and-investors)

### Complete Funding Timeline

| Round | Date | Amount | Valuation | Lead Investors | EA-Connected? |
|-------|------|--------|-----------|----------------|---------------|
| Seed | Early 2021 | Undisclosed | — | Jaan Tallinn, <EntityLink id="E436">Dustin Moskovitz</EntityLink>, Eric Schmidt | **Yes** |
| Series A | May 2021 | \$124M | \$550M pre | Jaan Tallinn (lead) | **Yes** |
| Series B | April 2022 | \$580M | ≈\$4B | Spark Capital | Partial |
| FTX Investment | 2022 | \$500M | — | FTX/Alameda | **Yes** (EA-adjacent) |
| Google (initial) | Late 2022 | \$300M | — | Google (10% stake) | No |
| Series C | May 2023 | \$450M | — | Spark Capital, Google, Salesforce | No |
| Amazon (initial) | Sept 2023 | \$4B | — | Amazon | No |
| Google (follow-on) | Oct 2023 | \$2B | — | Google | No |
| Series D | Dec 2023 | \$2B | \$18B | Various | No |
| Amazon (follow-on) | Mar 2024 | \$2.75B | — | Amazon | No |
| Amazon (third) | Nov 2024 | \$4B | — | Amazon | No |
| Google (third) | Early 2025 | \$1B | — | Google | No |
| Series E | Mar 2025 | \$3.5B | \$61.5B | Lightspeed Venture Partners | No |
| Series F | Sept 2025 | \$13B | \$183B | Altimeter, Baillie Gifford, BlackRock | No |
| Microsoft/Nvidia | Nov 2025 | Up to \$15B | \$350B | Microsoft (up to \$5B), Nvidia (up to \$10B) | No |
| Series G | Feb 2026 | \$30B | \$380B | GIC, Coatue (co-leads); D.E. Shaw Ventures, Dragoneer, Founders Fund, ICONIQ, MGX (co-leads) | No |

### Early Rounds: EA-Dominated (2021-2022)

Anthropic's founding capital came primarily from EA-connected investors who prioritized AI safety:

**<EntityLink id="E577">Jaan Tallinn</EntityLink>** led the Series A at a \$550 million pre-money valuation. [Anthropic](https://www.anthropic.com/news/anthropic-raises-124-million-to-build-more-reliable-general-ai-systems) Tallinn, co-founder of Skype and Kazaa, has become one of EA's most significant funders, having "poured millions into effective altruism-linked nonprofits and AI startups." [Semafor](https://www.semafor.com/article/11/21/2023/how-effective-altruism-led-to-a-crisis-at-openai)

**Dustin Moskovitz**, co-founder of Facebook and funder of <EntityLink id="E521">Coefficient Giving</EntityLink> (formerly <EntityLink id="E552">Coefficient Giving</EntityLink>), participated in both seed and Series A rounds. Through Good Ventures, Moskovitz later moved a \$500 million Anthropic stake into a nonprofit vehicle to reinvest returns. [Fortune](https://fortune.com/2025/11/10/meet-the-millennial-meta-cofounder-and-his-wife-who-are-giving-away-20-billion/)

**Other early investors** included Eric Schmidt (former Google CEO), James McClave, and the Center for Emerging Risk Research.

### Strategic Tech Investments (2023-2025)

Later rounds shifted to massive strategic capital from technology giants:

**Google**: Invested approximately \$3.3 billion total:
- \$300 million in late 2022 for 10% stake
- \$2 billion in October 2023
- \$1 billion in early 2025
- Now owns approximately 14% of Anthropic [Verdict](https://www.verdict.co.uk/us-doj-google-anthropic-partnership/)

**Amazon**: Invested \$10.75 billion total across three rounds:
- \$4 billion in September 2023
- \$2.75 billion in March 2024
- \$4 billion in November 2024
- AWS became Anthropic's "primary cloud and training partner"
- Remains minority investor without board seat

### Institutional Investors (Series F)

The September 2025 Series F brought diversified institutional capital: [Anthropic](https://www.anthropic.com/news/anthropic-raises-series-f-at-usd183b-post-money-valuation)
- Sovereign wealth funds: Qatar Investment Authority, GIC (Singapore)
- Pension funds: Ontario Teachers' Pension Plan
- Asset managers: BlackRock, T. Rowe Price, Goldman Sachs Alternatives
- Growth equity: Altimeter, General Catalyst, General Atlantic, TPG, Insight Partners
- Trading firms: Jane Street
- Investment managers: Baillie Gifford, Coatue, D1 Capital Partners, WCM Investment Management

### Microsoft and Nvidia Partnership (November 2025)

In November 2025, Microsoft and Nvidia announced a strategic partnership with Anthropic involving up to \$15 billion in investment: [CNBC](https://www.cnbc.com/2025/11/18/anthropic-ai-azure-microsoft-nvidia.html)

**Investment commitments:**
- Microsoft: up to \$5 billion
- Nvidia: up to \$10 billion

**Cloud infrastructure:**
- Anthropic committed to purchasing \$30 billion in Azure compute capacity from Microsoft
- Contracted for up to 1 gigawatt of compute capacity (estimated \$20-25 billion cost)
- Amazon remains primary cloud provider and training partner

**Technology partnership:**
- First deep technology partnership between Nvidia and Anthropic
- Joint optimization of Anthropic models for Nvidia architectures (Grace Blackwell, Vera Rubin)
- Claude models available on all three major cloud services (AWS, Azure, Google Cloud)

This deal represented Microsoft's effort to diversify away from exclusive reliance on OpenAI for AI capabilities. [Anthropic](https://www.anthropic.com/news/microsoft-nvidia-anthropic-announce-strategic-partnerships)

### Secondary Market Activity

Anthropic shares trade actively on secondary markets with significant price variation: [Premier Alternatives](https://www.premieralts.com/companies/anthropic/secondary-market-price)

| Platform | Share Price (Dec 2025) | Implied Valuation |
|----------|----------------------|-------------------|
| Forge Global | \$270 | ≈\$300B |
| Premier Alternatives | \$273 | ≈\$305B |
| Hiive | \$302 | ≈\$340B |
| Notice | \$270 | ≈\$300B |

The Forge price represents a 381% increase over the prior year. [Forge Global](https://forgeglobal.com/insights/anthropic-upcoming-ipo-news/) Anthropic conducted its first employee share buyback in March 2025 at \$56.09/share (\$61.5B valuation), allowing employees with 2+ years tenure to sell up to 20% of equity, capped at \$2 million each. [Maginative](https://www.maginative.com/article/anthropic-launches-first-employee-share-buyback-at-61-5-billion-valuation/)

For detailed analysis of Anthropic's competitive position, talent moat, and potential undervaluation, see <EntityLink id="E22">Anthropic</EntityLink>. For comprehensive bull and bear case arguments, see <EntityLink id="E405">Anthropic Valuation Analysis</EntityLink>. For IPO timeline and extended growth scenarios (2-10x to \$700B-\$3.5T), see <EntityLink id="E409">Anthropic IPO</EntityLink>.

## Founder Equity and Donation Pledges

### The 80% Commitment

All seven Anthropic co-founders—<EntityLink id="E91">Dario Amodei</EntityLink>, <EntityLink id="E90">Daniela Amodei</EntityLink>, <EntityLink id="E59">Chris Olah</EntityLink>, Tom Brown, Jack Clark, Jared Kaplan, and Sam McCandlish—have pledged to donate 80% of their equity. [Fortune](https://fortune.com/2026/01/27/anthropic-billionaire-cofounders-ceo-dario-amodei-giving-away-80-percent-of-wealth-fighting-inequality-ai-revolution/)

The pledge was announced alongside Dario Amodei's 38-page essay ["The Adolescence of Technology"](https://www.darioamodei.com/essay/the-adolescence-of-technology) (January 2026), which frames AI-driven inequality as the central motivation. [EA Forum](https://forum.effectivealtruism.org/posts/TPJju3zv7b2fdwgmE/dario-amodei-on-ai-risk-and-anthropic-s-approach-the) Amodei argues that "wealthy individuals have an obligation to help solve this problem" and criticizes tech leaders who have "adopted a cynical and nihilistic attitude that philanthropy is inevitably fraudulent or useless."

Amodei wrote: "The thing to worry about is a level of wealth concentration that will break society." He cited <EntityLink id="E116">Elon Musk</EntityLink>'s nearly \$700 billion net worth exceeding John D. Rockefeller's Gilded Age wealth as evidence of unprecedented concentration, noting this is "before most of AI's economic impact has even materialized." The essay also calls for progressive taxation and government intervention as longer-term solutions, framing private philanthropy as a way to "buy time." [Inc](https://www.inc.com/ben-sherry/ai-ceo-says-inequality-will-skyrocket-and-wants-the-most-powerful-to-pay-more/91293031)

### Founder Equity Estimates

Founder stakes have diluted from approximately 6% each at founding to 2-3% each after multiple funding rounds: [Brand Vision](https://www.brandvm.com/post/dario-amodei-net-worth-in-2025)

| Scenario | Est. Stake | Value per Founder | Total Founder Wealth | 80% Pledge Value |
|----------|------------|-------------------|---------------------|------------------|
| Current (\$380B) | 2-3% | \$7.6-11.4B | \$53-80B | \$43-64B |
| Conservative (\$183B) | 2-3% | \$3.7-5.5B | \$26-38B | \$21-31B |
| Downside (\$100B) | 2-3% | \$2-3B | \$14-21B | \$11-17B |
| Major correction (\$50B) | 2-3% | \$1-1.5B | \$7-10.5B | \$5.6-8.4B |

### Individual EA Connections

**Dario Amodei (CEO)**:
- 43rd signatory of the Giving What We Can pledge (2010s)
- Wrote guest posts for GiveWell around 2007-2008
- Lived in a group house with <EntityLink id="E156">Holden Karnofsky</EntityLink> and <EntityLink id="E220">Paul Christiano</EntityLink>
- Described as "a very early GiveWell fan" [EA Forum](https://forum.effectivealtruism.org/posts/53Gc35vDLK2u5nBxP/anthropic-is-not-being-consistently-candid-about-their)

**Daniela Amodei (President)**:
- Married to <EntityLink id="E156">Holden Karnofsky</EntityLink>, co-founder of GiveWell and former CEO of Coefficient Giving
- Previously expressed commitment to EA in her 2017 wedding announcement
- This connection creates a direct bridge between Anthropic wealth and the EA funding ecosystem
- Karnofsky joined Anthropic in January 2025 as a member of technical staff, working on responsible scaling policy and safety planning under Chief Science Officer Jared Kaplan [Fortune](https://fortune.com/2025/02/13/anthropic-hired-president-daniela-amodei-husband-ai-safety-responsible-scaling/)
- Karnofsky was previously on the OpenAI board of directors (2017-2021) and was Dario's former roommate

**Chris Olah**: Pioneer in neural network interpretability whose research focus aligns directly with <EntityLink id="E631">technical AI safety</EntityLink> priorities. No documented Giving What We Can pledge or explicit EA affiliation—safety-focused but not necessarily EA-aligned in donation preferences.

**Jack Clark**: Former Policy Director at <EntityLink id="E218">OpenAI</EntityLink>; co-founded Anthropic with focus on responsible AI development. No documented EA connections or donation pledges beyond the 80% commitment.

**Tom Brown, Jared Kaplan, Sam McCandlish**: No documented EA connections. Brown was lead author of GPT-3 at OpenAI; Kaplan is Chief Science Officer known for scaling laws research; McCandlish focuses on AI alignment research.

**Summary of founder EA alignment:**
- **Strong EA connections (2/7)**: Dario Amodei (GWWC signatory, GiveWell history), Daniela Amodei (married to Holden Karnofsky)
- **Safety-focused, EA uncertain (2/7)**: Chris Olah, Jack Clark
- **No documented EA connections (3/7)**: Tom Brown, Jared Kaplan, Sam McCandlish

This represents a significant uncertainty: **5 of 7 founders (71% of founder equity)** may direct donations to causes outside traditional EA priorities, or their EA alignment is undocumented.

## EA-Aligned Investor Equity

Beyond founders and employees, two major EA-aligned investors hold significant Anthropic stakes: Jaan Tallinn and Dustin Moskovitz. Their equity represents additional EA-directed capital that the founder-only model fails to capture.

### Jaan Tallinn

<EntityLink id="E577">Jaan Tallinn</EntityLink>, co-founder of Skype and Kazaa, led Anthropic's Series A at a \$550 million pre-money valuation. [Anthropic](https://www.anthropic.com/news/anthropic-raises-124-million-to-build-more-reliable-general-ai-systems) Tallinn has been one of the most significant individual funders of AI safety, having "poured millions into effective altruism-linked nonprofits and AI startups." [Semafor](https://www.semafor.com/article/11/21/2023/how-effective-altruism-led-to-a-crisis-at-openai)

**Equity estimate:**

| Parameter | Estimate | Reasoning |
|-----------|----------|-----------|
| Series A investment | \$40-80M | Typical lead investor share of \$124M round |
| Initial stake (post-Series A) | 6-12% | Based on \$674M post-money valuation |
| Dilution through 16 rounds | 60-75% | Typical for early investors through multiple rounds |
| Current estimated stake | 1.5-4% | After dilution, retaining 25-40% of original |
| Value at \$380B | **\$5.7-15.2B** | Range based on stake uncertainty |

Tallinn co-founded the <EntityLink id="E523">Centre for the Study of Existential Risk</EntityLink> (CSER) and the <EntityLink id="E528">Future of Life Institute</EntityLink> (FLI), and has consistently directed wealth toward existential risk reduction. Given his track record, his Anthropic holdings are highly likely to be directed toward EA-aligned causes.

**Important caveats on Tallinn estimate:**
- Tallinn's publicly reported net worth (≈\$1-2B) is far below the \$5.7-15.2B estimate above, suggesting either: (a) he sold shares in secondary transactions, (b) public estimates haven't caught up with Anthropic's valuation growth, or (c) our investment estimate is too high
- Early investors often sell portions of stakes in later funding rounds or secondary markets
- A more conservative estimate assuming partial sales: **\$2-6B** (0.6-1.7% stake)
- Without public disclosure, significant uncertainty remains

**Tallinn's stated investment philosophy:**
> "His policy is roughly to 'invest in AI and spend the proceeds on AI safety'... his philanthropy volume is correlated with his net worth, and his philanthropy is more needed in worlds where AI progresses faster." [LessWrong](https://www.lesswrong.com/users/jaan)

Tallinn has also expressed ambivalence about Anthropic specifically: "I'm not sure if they should be [dealing with dangerous stuff]. I'm not sure if anyone should be." [36Kr](https://eu.36kr.com/en/p/3472884024679040) This suggests his philanthropic direction may prioritize AI safety organizations outside the lab ecosystem.

### Dustin Moskovitz

<EntityLink id="E436">Dustin Moskovitz</EntityLink>, co-founder of Facebook and Asana, participated in both Anthropic's seed and Series A rounds. In November 2025, Fortune reported that Moskovitz "moved a \$500 million Anthropic stake into a nonprofit vehicle to reinvest returns." [Fortune](https://fortune.com/2025/11/10/meet-the-millennial-meta-cofounder-and-his-wife-who-are-giving-away-20-billion/)

**Equity estimate:**

| Parameter | Estimate | Reasoning |
|-----------|----------|-----------|
| Seed + Series A investment | \$20-50M | Smaller than lead investor Tallinn |
| Initial stake | 3-8% | Based on investment size and early valuations |
| Current estimated stake | 0.8-2.5% | After dilution through multiple rounds |
| Value at \$380B | **\$3-9.5B** | Range based on stake uncertainty |
| Confirmed nonprofit transfer | \$500M+ | Reported in Fortune; likely partial stake |

Moskovitz and his wife Cari Tuna have committed to giving away virtually all their wealth through <EntityLink id="E521">Coefficient Giving</EntityLink> (formerly Open Philanthropy's funding arm). The \$500M nonprofit transfer confirms at least a portion is already legally committed to charitable purposes. Their total Anthropic stake likely exceeds this figure.

### Other Early Investors

Other early investors with potential EA alignment include:

- **Eric Schmidt**: Participated in seed round; has funded AI safety research but not primarily EA-aligned
- **Center for Emerging Risk Research**: Early investor with explicit existential risk focus
- **Various angel investors**: Some early angels may have EA connections, but stakes are likely small

**Investor equity estimates:**

| Investor | Optimistic Stake | Conservative Stake | Value (Conservative) | Likelihood of EA Direction |
|----------|------------------|-------------------|---------------------|---------------------------|
| Jaan Tallinn | 1.5-4% (\$5-14B) | 0.6-1.7% (\$2-6B) | **\$2-6B** | Very high (>90%) |
| Dustin Moskovitz | 0.8-2.5% (\$3-9B) | 0.8-2.5% (\$3-9B) | **\$3-9B** | Certain (already committed) |
| Other EA-aligned angels | 0.1-0.5% | 0.1-0.3% | **\$0.35-1B** | Moderate (50%) |
| **Total EA investor equity** | **2.4-7%** (\$8-25B) | **1.5-4.5%** (\$5-16B) | **\$5-16B** | — |

## Employee Equity Analysis

### Total Employee Equity Pool

Startups typically reserve 10-20% of equity for employee compensation. Based on Anthropic's growth trajectory:

| Parameter | Estimate | Notes |
|-----------|----------|-------|
| Total employee option pool | 12-18% | Standard for Series G+ companies |
| Value at \$380B | \$46-68B | Total employee equity |
| Employees as of Dec 2024 | 870-2,847 | Range from different sources |
| Early employees (first 100-150) | 40-60% of pool | Larger individual grants |
| Early employee equity | \$17-38B | First 100-150 employees |

### EA-Aligned Employee Fraction

The EA Forum notes that "a lot of the early employees and higher-ups have EA-ish perspectives... this fraction is expected to decrease among more recent employees." [EA Forum](https://forum.effectivealtruism.org/posts/rRBaP7YbXfZibSn3C/front-load-giving-because-of-anthropic-donors)

**Estimated EA alignment by employee cohort:**

| Cohort | Headcount | Share of Pool | EA-Aligned % | EA-Aligned Equity |
|--------|-----------|---------------|--------------|-------------------|
| Founding team (2021) | 15-20 | 25-35% | 60-80% | \$6-17B |
| Early hires (2021-2022) | 50-80 | 20-30% | 40-60% | \$3-11B |
| Growth phase (2023-2024) | 200-400 | 15-25% | 15-30% | \$1-5B |
| Recent hires (2025+) | 500-2000 | 10-15% | 5-15% | \$0.2-1B |
| **Total** | **765-2500** | **70-105%** | — | **\$10-34B** |

Note: Percentages may exceed 100% due to additional grants and refreshers for early employees.

### The Matching Program: Historical vs. Current

Anthropic's employee donation matching program has **changed significantly over time**:

**Historical program (2021-2024):**
> "For most of Anthropic's existence, employees could pledge up to 50% of their equity to nonprofits, with Anthropic matching that 3:1—an unusually strong incentive to pledge money to charity up-front" [EA Forum](https://forum.effectivealtruism.org/posts/rRBaP7YbXfZibSn3C/front-load-giving-because-of-anthropic-donors)

- Employee pledges up to 50% of their equity to a 501(c)(3)
- Anthropic matches the pledge 3:1 (adds 3x the pledged amount)
- Pledges are legally binding—equity transferred to DAFs
- Example: \$10M equity → pledge 50% (\$5M) → 3:1 match (\$15M) → **\$20M total** (4x multiplier)

**Current program (2025+):**
Anthropic's careers page now lists **1:1 matching at up to 25% of equity grants**—a significant reduction from the historical program. [Anthropic Careers](https://www.anthropic.com/careers)

- Employee pledges up to 25% of their equity
- Anthropic matches 1:1 (adds 1x the pledged amount)
- Example: \$10M equity → pledge 25% (\$2.5M) → 1:1 match (\$2.5M) → **\$5M total** (2x multiplier)

**Implications for estimates:**
- Early employees (2021-2024) who locked in under the 3:1 program retain those terms
- New employees face 1:1 at 25%—dramatically less generous
- Our employee matching estimates (\$21-53B) may be **overstated by 50-70%** for the portion from recent hires
- The "legally bound" capital figure (\$35-60B) should be understood as primarily from early employees under the old program

### Employee Pledge Participation Estimates

| Scenario | EA Employees Participating | Avg Pledge % | Direct Pledges | 3:1 Matching | Total |
|----------|---------------------------|--------------|----------------|--------------|-------|
| Conservative | 30% of EA-aligned | 30% avg | \$1-3B | \$3-9B | \$4-12B |
| Base case | 50% of EA-aligned | 40% avg | \$2-7B | \$6-21B | \$8-28B |
| Optimistic | 70% of EA-aligned | 50% avg | \$3.5-12B | \$10.5-36B | \$14-48B |

**Key constraints and uncertainties:**
- Matching only covers 501(c)(3) organizations, excluding policy-focused 501(c)(4)s
- Some employees may prefer to retain flexibility rather than lock in pledges
- Tax optimization may favor post-IPO giving over pre-IPO pledges
- **Matching source unclear**: Anthropic funds matching from treasury/reserves or equity pool—this may dilute founders or come from a pre-allocated pool, but specifics are not public
- **Program significantly reduced**: Matching changed from 3:1 at 50% to **1:1 at 25%** for new employees—estimates based on historical program may overstate future flows
- **DAF cause allocation flexible**: Money in DAFs is legally committed to *some* 501(c)(3), but donors retain advisory control over which charities receive grants—not all DAF capital will necessarily go to EA causes

### Named EA-Connected Employees

**Amanda Askell**: 67th signatory of the GWWC pledge; ex-husband is William MacAskill, a co-founder of the EA movement. As an early employee focused on AI ethics, likely holds significant equity. [EA Forum](https://forum.effectivealtruism.org/posts/53Gc35vDLK2u5nBxP/anthropic-is-not-being-consistently-candid-about-their)

**<EntityLink id="E156">Holden Karnofsky</EntityLink>**: Joined January 2025 as member of technical staff. As Daniela Amodei's spouse, co-founder of GiveWell, and former CEO of Coefficient Giving, represents a direct bridge to EA funding infrastructure. Later hire likely means smaller equity stake but high influence on donation decisions.

**Anonymous employee quote**: "I've made a legally binding pledge to allocate half of [my equity] to 501(c)(3) charities... I expect to donate the majority of the remainder."

**Kyle Fish**: First full-time AI welfare researcher at a major AI lab. [Transformer News](https://www.transformernews.ai/p/anthropic-ai-welfare-researcher)

### Long-Term Benefit Trust Members

The LTBT includes several members with deep EA backgrounds who influence company direction:

- **Zach Robinson**: CEO of <EntityLink id="E517">Centre for Effective Altruism</EntityLink>
- **Neil Buddy Shah**: Former GiveWell Managing Director; CEO of Clinton Health Access Initiative
- **Kanika Bahl**: CEO of Evidence Action (GiveWell top charity)

While Trust members don't directly benefit from equity, their presence signals organizational commitment to EA-aligned values.

### Comparison with OpenAI

For context, OpenAI's restructuring created a different philanthropic vehicle: [NBC News](https://www.nbcnews.com/tech/tech-news/openai-restructuring-company-structure-chatgpt-invest-own-rcna240138)

| Dimension | Anthropic | OpenAI |
|-----------|-----------|--------|
| Structure | Public Benefit Corporation | PBC (post-restructuring) |
| Philanthropic stake | Founder pledges (private) | Foundation holds 26% (\$130B) |
| Governance | Long-Term Benefit Trust | Foundation appoints all directors |
| Control mechanism | Trust elects board majority by 2027 | Foundation can replace directors anytime |
| Enforcement | Reputational only | Foundation has legal control |

The OpenAI Foundation's 26% stake at current valuations is worth approximately \$130 billion, making it one of the best-resourced philanthropic organizations globally. [Inside Philanthropy](https://www.insidephilanthropy.com/home/openai-now-has-a-foundation-we-have-some-questions) Unlike Anthropic's pledge-based model, the OpenAI Foundation has direct legal control.

## The FTX Stake: A Cautionary Tale

FTX invested approximately \$500 million for a 13.56% stake in Anthropic before its November 2022 bankruptcy. Due to subsequent funding rounds, this diluted to approximately 7.84% by 2024. [CNBC](https://www.cnbc.com/2024/03/25/ftx-estate-sells-majority-stake-in-startup-anthropic-for-884-million.html)

### Bankruptcy Sale

The FTX bankruptcy estate sold the stake in two tranches:

| Tranche | Date | Amount | Price/Share | Buyers |
|---------|------|--------|-------------|--------|
| First (2/3 of stake) | March 2024 | \$884M | ≈\$20 | Mubadala (≈\$500M), Jane Street, HOF Capital, Ford Foundation, Fidelity |
| Second (remaining) | Late 2024 | \$452M | \$30 | G Squared (lead), others |
| **Total** | — | **\$1.34B** | — | — |

**Return**: 2.7x on \$500M investment, but proceeds went to FTX creditors rather than EA-aligned causes. Had FTX not collapsed, this stake would be worth approximately \$27 billion at current valuations—capital that might have flowed to EA causes given SBF's stated intentions.

## IPO Timeline and Liquidity

*See <EntityLink id="E409">Anthropic IPO</EntityLink> for comprehensive analysis of preparation status, competitive dynamics, valuation trajectory, and detailed timeline estimates.*

Anthropic is actively preparing for a potential 2026-2027 IPO, having hired Wilson Sonsini Goodrich & Rosati in December 2025 and initiated preliminary bank discussions. Key facts relevant to philanthropic funding flows:

- **Timeline**: Late 2026 possible but uncertain; prediction markets favor mid-2027
- **Probability**: Kalshi assigns 72% chance Anthropic IPOs before OpenAI
- **Revenue trajectory**: \$1B → \$9B+ ARR in 2025; targeting \$26B in 2026
- **Liquidity events**: First employee buyback in March 2025 at \$61.5B valuation

An IPO would unlock founder and employee liquidity, enabling pledge fulfillment. Lock-up periods (typically 6-12 months post-IPO) would delay capital deployment until 2027-2028 at earliest.

### Alternative Exit: Acquisition

Anthropic could be acquired rather than IPO, with implications for EA-aligned capital:

**Potential acquirers:**
- **Google** (14% stake): Already largest strategic investor; acquisition would face severe antitrust scrutiny
- **Amazon** (\$10.75B invested): Primary cloud partner; similar antitrust concerns
- **Microsoft**: Recent partnership; diversifying from OpenAI dependency
- **Apple, Meta**: Less likely but possible as AI competition intensifies

**Acquisition implications:**
- Immediate liquidity for all shareholders (no lock-up periods)
- Valuation might be premium or discount to public market estimates
- Long-Term Benefit Trust governance provisions would be tested
- Strategic acquirer might impose restrictions on founder/employee share sales
- Regulatory approval could take 12-24+ months given current antitrust climate

**Probability estimate**: Acquisition before 2028 is ~15-25% likely, based on regulatory barriers and Anthropic's stated preference for independence.

### Valuation Uncertainty

The \$380B valuation reflects the closed Series G round (February 2026), a firmer datapoint than the earlier \$350B term sheet. Secondary market data from late 2025 showed variation:

| Source | Implied Valuation | Date |
|--------|-------------------|------|
| Series G (closed) | \$380B | Feb 2026 |
| Series G term sheet | \$350B | Jan 2026 |
| Hiive secondary | \$340B | Dec 2025 |
| Forge Global secondary | \$300B | Dec 2025 |

The closed Series G at \$380B provides more certainty than the previous term sheet figure, though secondary market prices may still diverge. All estimates in this analysis use \$380B for consistency with the closed round.

## Historical Evidence on Pledge Fulfillment

*For comprehensive analysis of the Giving Pledge and billionaire philanthropy patterns, see <EntityLink id="E531">Giving Pledge</EntityLink>.*

### Giving Pledge Track Record

The <EntityLink id="E531">Giving Pledge</EntityLink>, founded in 2010 by Bill Gates and Warren Buffett, provides the most relevant historical comparison. A 2025 Institute for Policy Studies analysis reveals concerning patterns: [IPS](https://ips-dc.org/report-giving-pledge-at-15/)

**Deceased pledgers (n=22):**
- Met 50% threshold: 8 (36%)
- Did not meet threshold: 13 (59%)
- Lost fortune before death: 1 (5%)

**Living original pledgers:**
- Only Laura and John Arnold have exceeded 50% giving during their lifetimes
- Original 32 U.S. pledgers still billionaires saw wealth increase 283% (166% inflation-adjusted)
- Five pledgers experienced wealth increases exceeding 500%
- Mark Zuckerberg and Priscilla Chan's wealth grew over 4,000%

**Where the money goes:**
- Private foundations: 80% of \$206B total
- Donor-advised funds: ≈\$5B
- Working charities: ≈\$40B (20%)

This suggests that even honored pledges may not reach working organizations for years or decades.

### Age and Cohort Effects

The IPS analysis suggests older pledgers or those near billionaire threshold were more likely to fulfill commitments. Of 11 original pledgers no longer billionaires, 7 gave sufficiently to drop below threshold. This may be relevant to Anthropic founders, who are relatively young (30s-40s).

> "Maintaining altruistic giving after sudden wealth is really difficult. There are surprisingly few cases of young people (under 40) giving away millions after a cash windfall." [EA Forum](https://forum.effectivealtruism.org/posts/rRBaP7YbXfZibSn3C/front-load-giving-because-of-anthropic-donors)

### Facebook/Meta Comparison

The 2012 Facebook IPO created thousands of employee millionaires. Evidence on their philanthropy: [Chronicle of Philanthropy](https://philanthropy.com/article/Charities-Seek-Some-of/156577)
- Dustin Moskovitz: \$4B+ donated through Good Ventures/Coefficient Giving
- Most other early employees: Limited public philanthropic activity
- Studies suggest tech entrepreneurs give ~2x more than inherited wealth, but absolute rates remain modest

## Comprehensive Funding Flow Model

Previous estimates focused only on founder equity (\$39-59B at current valuation). This understates total EA-aligned capital by excluding:
- EA-aligned investors (Tallinn, Moskovitz)
- Employee pledges with 3:1 matching
- Non-pledged EA-aligned employee giving

### All Sources of EA-Aligned Capital at \$380B Valuation

**Optimistic scenario** (uses historical matching terms, optimistic Tallinn estimate):

| Source | Equity Stake | Gross Value | EA-Directed % | EA-Directed Value |
|--------|--------------|-------------|---------------|-------------------|
| **Founders (7)** | 14-21% | \$49-74B | 80% (pledged) | \$39-59B |
| **Jaan Tallinn** | 1.5-4% | \$5-14B | 80-95% (likely) | \$4-13B |
| **Dustin Moskovitz** | 0.8-2.5% | \$3-9B | 95-100% (committed) | \$3-9B |
| **Other EA investors** | 0.1-0.5% | \$0.35-1.75B | 50% (uncertain) | \$0.2-0.9B |
| **Employee pledges** | 2-5% | \$7-18B | 100% (legally bound) | \$7-18B |
| **3:1 matching** | 6-15% | \$21-53B | 100% (legally bound) | \$21-53B |
| **Non-pledged EA employees** | 1-3% | \$3.5-10.5B | 30-50% (estimated) | \$1-5B |
| **Total (optimistic)** | **25-51%** | **\$89-180B** | — | **\$75-158B** |

**Conservative adjustments:**

| Factor | Optimistic | Conservative | Reduction |
|--------|------------|--------------|-----------|
| Tallinn stake (possible sales) | \$4-13B | \$1.6-5.4B | -50% |
| Non-strongly-EA founders (5/7, 71% of equity) | Count as EA | Exclude | -\$28-42B |
| Matching (1:1@25% for new hires) | Full 3:1@50% | 50% reduction for 2025+ cohort | -\$5-15B |
| **Total conservative** | **\$75-158B** | **\$30-70B** | — |

**Recommended planning range:**
- **Optimistic** (all founders count as EA-aligned): \$75-158B gross, \$56-70B risk-adjusted
- **Conservative** (only 2/7 strongly EA-aligned founders): \$30-70B gross, \$25-50B risk-adjusted
- **For planning purposes, use: \$25-70B risk-adjusted**, acknowledging the wide range reflects genuine uncertainty about cause allocation

### Scenario Analysis: Total EA-Aligned Capital

| Scenario | Valuation | Founders | Investors | Employees + Match | Total EA Capital |
|----------|-----------|----------|-----------|-------------------|------------------|
| **Bull** | \$500B | \$56-84B | \$10-33B | \$42-109B | \$108-226B |
| **Base** | \$380B | \$43-64B | \$7.6-25B | \$32-83B | \$82-172B |
| **Conservative** | \$150B | \$17-25B | \$3-10B | \$13-33B | \$33-68B |
| **Bear** | \$50B | \$5.6-8.4B | \$1-3B | \$4-11B | \$11-22B |
| **Failure** | \$0 | \$0 | \$0 | \$0 | \$0 |

### Extended Growth Scenarios (2-10x)

The base scenario analysis caps at \$500B. Given Anthropic's trajectory—revenue growing from \$1B to \$9B in 2025 alone, enterprise market leadership, and potential AGI premium—higher valuations are plausible:

| Scenario | Valuation | Multiple | Probability | Key Drivers |
|----------|-----------|----------|-------------|-------------|
| **Extended Bull** | \$700B | 2x | 10-15% | Sustained 3x annual revenue growth, 40x forward multiple, enterprise dominance |
| **Market Dominance** | \$1T | 2.9x | 5-10% | Winner-take-most dynamics, AI platform leader, \$70B+ revenue |
| **Exceptional** | \$1.75T | 5x | 2-5% | AGI proximity signals, infrastructure-level adoption |
| **AGI Premium** | \$3.5T | 10x | 1-3% | First-mover AGI advantage, platform monopoly effects |

**Historical precedent**: Nvidia's valuation increased ~15x from 2020-2024 as it became the dominant AI infrastructure provider. If Anthropic achieves similar positioning in AI applications/models, comparable multiples are possible.

**Extended EA Capital Estimates:**

| Scenario | Valuation | Founders (80%) | Investors | Employees + Match | Total EA Capital |
|----------|-----------|----------------|-----------|-------------------|------------------|
| Extended Bull | \$700B | \$78-118B | \$14-46B | \$59-153B | \$151-317B |
| Dominance | \$1T | \$112-168B | \$20-66B | \$84-218B | \$216-452B |
| Exceptional | \$1.75T | \$196-294B | \$35-116B | \$147-382B | \$378-792B |
| AGI Premium | \$3.5T | \$392-588B | \$70-231B | \$294-764B | \$756-1,580B |

At 10x current valuation (\$3.5T), total EA-aligned capital could exceed \$1 trillion—though probability-weighted, this adds only \$8-16B to expected value given low likelihood.

### Interactive Estimate Models

<SquiggleEstimate title="Anthropic Valuation Scenarios (probability-weighted)" code={`
// Valuation scenarios as continuous distributions
bull = 400e9 to 650e9           // wide bull case
base = 250e9 to 450e9           // broad base case
conservative = 100e9 to 220e9   // conservative range
bear = 20e9 to 80e9             // bear / down-round range

valuationDist = mixture(
  bull, base, conservative, bear,
  [0.15, 0.40, 0.25, 0.15]
)

valuationDist
`} />

<SquiggleEstimate title="Founder Equity: EA-Directed Capital" code={`
// 7 founders, 2-3% stake each, 80% pledged
founderStakePct = 0.02 to 0.03
numFounders = 7
pledgeRate = 0.8
valuation = mixture(
  400e9 to 650e9, 250e9 to 450e9,
  100e9 to 220e9, 20e9 to 80e9,
  [0.15, 0.4, 0.25, 0.15]
)

totalFounderEquity = valuation * founderStakePct * numFounders
pledgedAmount = totalFounderEquity * pledgeRate

// Only 2/7 founders have strong EA connections
// Probability each founder's pledged amount goes to EA causes
eaFounderFraction = beta(3, 4) // ~40% expected, wide uncertainty
eaDirectedCapital = pledgedAmount * eaFounderFraction

eaDirectedCapital
`} />

<SquiggleEstimate title="Total EA-Aligned Capital (all sources)" code={`
// Valuation distribution (continuous scenarios)
valuation = mixture(
  400e9 to 650e9, 250e9 to 450e9,
  100e9 to 220e9, 20e9 to 80e9,
  [0.15, 0.4, 0.25, 0.15]
)

// Founder capital (7 founders, 2-3% each, 80% pledged)
founderEquity = valuation * (0.02 to 0.03) * 7 * 0.8
// Risk-adjust: only ~40-60% likely to go to EA causes
founderEA = founderEquity * beta(5, 5)

// EA Investor capital (Tallinn + Moskovitz)
tallinnStake = valuation * (0.006 to 0.017) * (0.7 to 0.9)
moskovitzStake = valuation * (0.008 to 0.025) * (0.9 to 1.0)
investorEA = tallinnStake + moskovitzStake

// Employee pledges + matching (legally bound in DAFs)
employeePool = valuation * (0.12 to 0.18)
eaEmployeeFraction = 0.15 to 0.40
participationRate = 0.3 to 0.7
avgPledgePct = 0.3 to 0.5
directPledges = employeePool * eaEmployeeFraction * participationRate * avgPledgePct
// Matching: mix of old 3:1 and new 1:1 programs
matchMultiplier = 1.5 to 3.0
employeeEA = directPledges * (1 + matchMultiplier) * (0.8 to 0.95)

totalEA = founderEA + investorEA + employeeEA
totalEA
`} />

### Expected Value Calculation

**Note**: The scenario analysis table above uses optimistic assumptions (all founders counted as EA-aligned). The expected value calculations below reflect the full range from conservative to optimistic.

**Probability-weighted EA capital (optimistic assumptions):**

| Scenario | Probability | Midpoint (Optimistic) | Expected Value |
|----------|-------------|-----------------------|----------------|
| Bull | 15% | \$167B | \$25B |
| Base | 40% | \$127B | \$51B |
| Conservative | 25% | \$50B | \$12.5B |
| Bear | 15% | \$17B | \$2.5B |
| Failure | 5% | \$0 | \$0 |
| **Total (optimistic)** | **100%** | — | **\$91B** |

**With conservative founder assumptions (only 2/7 strongly EA-aligned):**
- Reduce founder contribution by ~60%
- Adjusted expected value: **\$48-58B**

**Final recommended range**: \$27-76B risk-adjusted, depending on assumptions about founder EA alignment and cause allocation.

### Adjusting for Pledge Fulfillment Risk

Different capital sources have different fulfillment reliability:

| Source | Gross Expected | Fulfillment Rate | Risk-Adjusted |
|--------|----------------|------------------|---------------|
| Strongly EA-aligned founders (2/7) | \$11-17B | 50-70% | \$6-12B |
| Safety-focused founders (2/7) | \$11-17B | 30-50% (uncertain cause) | \$3-8B |
| Non-EA founders (3/7) | \$17-25B | 10-30% (unlikely EA) | \$2-7B |
| Tallinn (conservative) | \$2-6B | 70-90% | \$1.4-5.4B |
| Moskovitz | \$3-9B | 90-100% | \$2.7-9B |
| Employee pledges + match | \$20-40B | 80-95% (legally bound, cause flexible) | \$16-38B |
| Non-pledged EA employees | \$2B | 20-40% | \$0.4-0.8B |
| **Total (optimistic)** | **\$66-116B** | — | **\$31-80B** |
| **Total (conservative, EA-only)** | **\$36-72B** | — | **\$25-65B** |

**Key insight**: Employee pledges and matching are **legally binding** (equity already transferred to DAFs), making them more reliable than founder pledges which face Giving Pledge-style fulfillment risk. This shifts the model's center of gravity toward employee capital.

### Capital by Reliability Tier

| Tier | Sources | Amount | Notes |
|------|---------|--------|-------|
| **Legally bound** | Employee pledges, matching, Moskovitz nonprofit transfer | \$25-50B | Already in DAFs/nonprofits; reduced for program changes |
| **Highly likely** | Tallinn (conservative), committed EA employees | \$3-10B | Track record of giving; Tallinn may have sold shares |
| **Pledge-dependent** | Strongly EA-aligned founder pledges (2/7 founders) | \$6-12B | Subject to Giving Pledge risk; only Dario and Daniela |
| **Uncertain** | Safety-focused founders (2/7), non-EA founders (3/7), non-pledged employees, other investors | \$15-40B | May go to non-EA or non-traditional-EA causes |

### Timing Uncertainty

Capital availability depends on:
1. **IPO timing** (2026-2028 most likely)
2. **Lock-up periods** (typically 6-12 months post-IPO)
3. **Founder decision timing** (immediate vs. gradual over decades)
4. **Foundation vs. direct giving** (foundations delay deployment)
5. **Employee liquidity** (buybacks provide early access; first occurred March 2025)

**Timeline estimates by source:**

| Source | Earliest | Peak Flow | Notes |
|--------|----------|-----------|-------|
| Employee pledges (DAF) | 2025-2026 | 2027-2030 | Already transferring; IPO unlocks full value |
| Moskovitz | 2026-2027 | 2027-2030 | Nonprofit vehicle already established |
| Tallinn | 2027-2028 | 2028-2032 | Likely post-IPO, gradual |
| Founders | 2028-2030 | 2030-2040 | Younger age suggests longer timeline |

Realistic timeline for significant capital deployment: **2027-2035**, with legally-bound employee capital arriving earliest.

### Model Limitations and Caveats

This analysis contains significant uncertainties that could materially affect estimates:

**Potential double-counting:**
- The 3:1 matching pool must come from somewhere—likely company equity reserves or founder dilution. If matching comes from founder equity, the "Founders" and "Matching" rows may partially overlap.
- Some employee pledges may come from employees who are also counted as "EA-aligned" in other categories.

**Overestimate risks:**
- **Tallinn stake**: Our estimate (\$5-14B) implies wealth far exceeding his reported net worth (≈\$1-2B), suggesting he may have sold shares. Conservative estimate: \$2-6B.
- **EA alignment assumption**: We assume most early employee pledges will go to EA causes, but DAF donors retain discretion. Some may fund universities, hospitals, or non-EA charities.
- **Limited strong EA connections among founders**: Only 2 of 7 founders (Dario and Daniela Amodei) have documented strong EA connections. Chris Olah and Jack Clark are safety-focused but have no documented EA pledges. Tom Brown, Jared Kaplan, and Sam McCandlish have no documented EA connections. This means **71% of founder equity** may go to causes outside traditional EA priorities.
- **Matching program reduced**: The program changed from 3:1 at 50% to **1:1 at 25%** for new employees. Our matching estimates (\$21-53B) may be overstated by 50-70% for the portion from 2025+ hires. Only early employees (2021-2024) benefit from the generous historical terms.

**Underestimate risks:**
- Additional EA-aligned employees not captured in our estimates
- Founders may donate more than 80% (some EA-aligned founders have expressed intentions to give nearly everything)
- Valuation could exceed \$350B at IPO

**Structural uncertainties:**
- **Valuation basis**: \$380B is a closed Series G round figure, more reliable than the earlier \$350B term sheet
- **Acquisition scenario**: 15-25% probability of acquisition before IPO, with different implications for liquidity timing
- **AI industry risk**: Regulatory action, technical setbacks, or competition could significantly reduce valuation

**Recommendation**: Use the **risk-adjusted range of \$27-76B** for planning purposes, acknowledging that actual outcomes could fall outside this range in either direction.

## Cause Allocation Uncertainty

### Likely Beneficiaries

**High confidence (AI safety/technical alignment):**
- Anthropic's mission alignment makes AI safety natural focus
- Founders' technical backgrounds suggest interest in technical research
- <EntityLink id="E91">Dario Amodei</EntityLink>'s background in ML research
- Mechanistic interpretability research specifically expects "an influx of funding soon" [EA Forum](https://forum.effectivealtruism.org/posts/rRBaP7YbXfZibSn3C/front-load-giving-because-of-anthropic-donors)

**Medium confidence (EA-adjacent):**
- Global health (Dario's early GiveWell involvement)
- Pandemic preparedness/biosecurity (Anthropic's risk-focused culture)
- <EntityLink id="E154">AI governance and policy</EntityLink>
- AI welfare research (Anthropic hired Kyle Fish in 2024 as first full-time AI welfare researcher) [Transformer News](https://www.transformernews.ai/p/anthropic-ai-welfare-researcher)

**Lower confidence:**
- Animal welfare: Frequent "second favorite" cause among longtermists, but when surveyed, EA community thinks 18-24% of resources should go to animal advocacy while actual allocation is ~7% [EA Forum](https://forum.effectivealtruism.org/posts/FxZdQJXs45fTFnMEe/ea-is-underfunding-animal-advocacy-according-to-our-own)
- Digital minds: Very neglected area with few researchers
- Non-EA causes (inequality, climate): Dario's essay mentions inequality concerns but unclear if this translates to non-EA giving

**Policy-focused organizations (501(c)(4)s):**
- Americans for Responsible Innovation (ARI): AI policy advocacy
- AI Policy Network: Political donations for AI safety
- Note: Anthropic's matching program only covers 501(c)(3)s, limiting incentives for policy donations

### Donor Advising Ecosystem

Several organizations are positioning to advise Anthropic employees: [EA Forum](https://forum.effectivealtruism.org/posts/H8SqwbLxKkiJur3c4/preparing-for-a-flush-future-work-giving-and-conduct)

| Organization | Focus | Scale |
|--------------|-------|-------|
| <EntityLink id="E542">Longview Philanthropy</EntityLink> | AI safety, GCR; donors >\$100k/year | \$60M+ advised in 2025, scaling to \$100M+ in 2026 |
| GiveWell | Global health | \$1B+ annually |
| <EntityLink id="E521">Coefficient Giving</EntityLink> | EA cause areas broadly | Largest EA funder |
| Senterra Funders | Animal welfare | Emerging |

One EA Forum commenter noted their job "involves a non-zero amount of advising Anthropic folks" on donation decisions.

### Differential Impact by Cause

From EA Forum analysis: [EA Forum](https://forum.effectivealtruism.org/posts/rRBaP7YbXfZibSn3C/front-load-giving-because-of-anthropic-donors)

> "AI safety likely receives more Anthropic employee funding, while animal welfare and global health may face different dynamics."

This suggests Anthropic wealth may significantly expand AI safety funding while having less impact on other EA cause areas.

### Concerns About Allocation

**Value drift risk:** The fraction of employees with EA-ish perspectives is expected to decrease among more recent hires. One commenter noted: "a lot of the early employees and higher-ups have EA-ish perspectives... this fraction is expected to decrease among more recent employees."

**Time constraints:** Anthropic employees are described as "incredibly time poor," and some interventions are very time-sensitive if donors have short AI timelines.

**US-centric focus:** One analysis raised concerns about "a strong focus on US-centric actions, which might [be] very suboptimal" for global impact.

**Procrastination risk:** "Empirically, it's common for billionaires to pledge a lot of money to charity and then be very slow at giving it away."

## Strategic Implications

### Scale Comparison

The EA movement has historically directed approximately \$1 billion annually. [EA Forum](https://forum.effectivealtruism.org/posts/H8SqwbLxKkiJur3c4/preparing-for-a-flush-future-work-giving-and-conduct) Potential Anthropic-derived funding using the comprehensive model (founders + investors + employees):

| Scenario | Annual EA Funding | Anthropic Potential (Total) | Multiple |
|----------|-------------------|----------------------------|----------|
| Current | ≈\$1B/year | — | — |
| Conservative (\$150B val) | ≈\$1B/year | +\$33-68B | 33-68x one-time |
| Base case (\$380B val) | ≈\$1B/year | +\$82-172B | 82-172x one-time |
| Risk-adjusted base | ≈\$1B/year | +\$48-76B | 48-76x one-time |
| If deployed over 10 years | ≈\$1B/year | +\$4.8-7.6B/year | 4.8-7.6x ongoing |

Note: Previous estimates using founder equity only showed \$39-59B; the comprehensive model including investors and employees is 2-2.5x larger.

### Front-Loading vs. Waiting

Arguments for current donors giving now: [EA Forum](https://forum.effectivealtruism.org/posts/rRBaP7YbXfZibSn3C/front-load-giving-because-of-anthropic-donors)

> "A \$100k gift represents 9% of current funding versus only 1% of projected future funding... organizations become less constrained by money than capacity."

Arguments for waiting:
- Coordination may avoid redundant capacity building
- Current giving has higher certainty of impact
- Anthropic wealth remains uncertain

### Absorption Capacity Concerns

Whether the AI safety and broader EA ecosystem can productively absorb billions in additional funding remains unclear:

- **Talent constraints**: Top researchers are scarce; funding doesn't create talent
- **Organizational scaling**: Rapid growth often reduces effectiveness
- **Grant evaluation**: Evaluating \$50B+ requires infrastructure that doesn't exist
- **Diminishing returns**: Best opportunities get funded first
- **Potential for reduced rigor**: Easy money may lower standards

## Governance and Accountability

### Long-Term Benefit Trust

Anthropic's <EntityLink id="E407">Long-Term Benefit Trust</EntityLink> (LTBT) provides some mission accountability through five financially disinterested trustees with growing board appointment power (majority by 2027). However, critics note stockholder override provisions and the Trust's limited use of its appointment power to date. See the dedicated page for full analysis.

### Pledge Enforcement

Unlike the OpenAI Foundation's legal control over board appointments, Anthropic founder pledges have no legal enforcement mechanism:
- Pledges are public commitments, not contracts
- Enforcement relies on reputational cost
- No third-party oversight of fulfillment
- Founders retain full discretion on timing, vehicles, and recipients

For analysis of interventions that could increase pledge fulfillment probability—including legal pledge conversion, DAF pre-commitment campaigns, and public accountability tracking—see <EntityLink id="E411">Anthropic Founder Pledge Interventions</EntityLink>.

## Prediction Markets

A [Manifold Markets prediction market](https://manifold.markets/MichaelDickens/by-the-end-of-2030-how-much-anthrop) asks: "By the end of 2030, how much Anthropic money will have been donated to charity?" The market covers donations from all Anthropic-derived wealth, including individual donations from founders and employees who gained wealth through equity, as well as company matching contributions.

| Outcome Bracket | Notes |
|-----------------|-------|
| \$0 | No significant donations before 2030 |
| \<\$100M | Token giving only |
| \$100M–\$1B | Modest fulfillment; comparable to early employee buyback-era giving |
| \$1B–\$3B | Partial pledge fulfillment; likely employee DAF distributions |
| \$3B–\$10B | Substantial giving; consistent with legally bound employee capital arriving post-IPO |
| \$10B–\$30B | Near full deployment of legally bound capital plus some founder giving |
| \>\$30B | Exceeds most conservative risk-adjusted estimates for this timeline |

This market provides a useful external reference point for the estimates on this page. The risk-adjusted range of \$27-76B estimated above covers total eventual EA-aligned capital, but much of that is expected to deploy over 2027-2035. By end of 2030, actual donations may be substantially lower than the total eventual figure, depending on IPO timing, lock-up periods, and founder decision timelines.

## Key Uncertainties Summary

| Uncertainty | Range | Key Drivers |
|-------------|-------|-------------|
| IPO timing | 2026-2030+ | Market conditions, regulatory, company choice |
| IPO valuation | \$50B-\$500B+ | AI market, revenue growth, competition |
| Founder pledge fulfillment | 40-60% | Historical Giving Pledge base rates |
| Employee pledge fulfillment | 90-100% | Already legally bound in DAFs |
| Investor giving (Tallinn/Moskovitz) | 80-100% | Strong track record, some already committed |
| Cause allocation | Concentrated-Diverse | AI safety favored; other causes uncertain |
| Deployment timeline | 5-30 years | Foundation vs. direct, tax optimization |
| EA absorption capacity | \$5-15B/year | Talent, organizations, evaluation infrastructure |
| Employee EA fraction decline | Moderate-High | Early hires more EA-aligned than recent |
