---
title: "Dustin Moskovitz (AI Safety Funder)"
description: "Dustin Moskovitz is a Facebook co-founder who became the world's youngest self-made billionaire in 2011. Together with his wife Cari Tuna, he has given away over \\$4 billion through Good Ventures and Coefficient Giving (formerly Open Philanthropy), including approximately \\$336 million to AI safety research since 2017. As the largest individual funder of AI safety, his contributions have supported organizations including MIRI, Redwood Research, Center for AI Safety, and ARC/METR, while funding critical evaluation and governance work."
roles: ['funder', 'entrepreneur']
sidebar:
  order: 11
quality: 49
llmSummary: "Dustin Moskovitz and Cari Tuna have given $4B+ since 2011, with ~$336M (12% of total) directed to AI safety through Coefficient Giving, making them the largest individual AI safety funders globally. In 2024, their $63.6M represented ~60% of all external AI safety investment, supporting organizations like MIRI ($20M+), Redwood ($15M+), and METR ($10M+), while maintaining balanced optimism about AI benefits and risks."
lastEdited: "2026-02-03"
importance: 70
update_frequency: 45
ratings:
  novelty: 2.5
  rigor: 5
  actionability: 3
  completeness: 7
clusters: ["ai-safety","community"]
entityType: person
---
import {DataInfoBox, Mermaid, EntityLink} from '@components/wiki';

## Quick Assessment

| Dimension | Assessment | Evidence |
|-----------|------------|----------|
| **Net Worth** | ≈\$17B (2025) | [Forbes](https://en.wikipedia.org/wiki/Dustin_Moskovitz), [Bloomberg Billionaires Index](https://www.bloomberg.com/billionaires/profiles/dustin-a-moskovitz/) |
| **Lifetime Giving** | \$4B+ | Through Good Ventures since 2011 |
| **AI Safety Funding** | ≈\$336M | Via Coefficient Giving (2017-2024) |
| **Primary Vehicle** | <EntityLink id="coefficient-giving">Coefficient Giving</EntityLink> | Formerly <EntityLink id="open-philanthropy">Coefficient Giving</EntityLink> |
| **Public Profile** | Low-to-Moderate | Increasingly vocal on AI policy |
| **Giving Pledge** | 2010 | Youngest signatories (25/26) |

## Personal Details

| Attribute | Details |
|-----------|---------|
| **Full Name** | Dustin Aaron Moskovitz |
| **Born** | May 22, 1984, Gainesville, Florida |
| **Hometown** | Ocala, Florida |
| **High School** | Vanguard High School (IB Diploma Program) |
| **Education** | Harvard University (economics, attended 2002-2004, did not graduate) |
| **Net Worth** | ≈\$17.4 billion (Forbes, May 2025) |
| **Spouse** | Cari Tuna (married October 2013) |
| **Company** | Asana (Co-founder, Board Chair since July 2025) |
| **Giving Vehicle** | Good Ventures / <EntityLink id="coefficient-giving">Coefficient Giving</EntityLink> |
| **Giving Pledge** | Signed December 2010 (youngest male signatory at 26) |

## Net Worth Over Time

Moskovitz's net worth has been remarkably flat over the past 6+ years despite holding stakes in two major technology companies. While fluctuations have been dramatic year-to-year—driven primarily by Meta stock volatility—the overall trajectory shows essentially no net growth since 2018.

<Mermaid chart={`
%%{init: {'theme':'default', 'themeVariables': {'xyChart': {'plotColorPalette': '#2563eb'}}}}%%
xychart-beta
    title "Net Worth Over Time (Billions USD)"
    x-axis ["2011", "2017", "2018", "2019", "2020", "2021", "2022", "2023", "2024", "2025", "2026"]
    y-axis "Net Worth (\$B)" 0 --> 20
    line [3.5, 10.3, 14.1, 11.4, 8.8, 16.8, 10.8, 9.4, 16.3, 17.4, 12.4]
`} />

| Year | Net Worth | Annual Giving | Notable Events |
|------|-----------|---------------|----------------|
| **2011** | ≈\$3.5B | ≈\$5M | Became youngest self-made billionaire (Forbes); Good Ventures founded |
| **2017** | \$10.3B | ≈\$200M | Open Phil scales up grantmaking |
| **2018** | \$14.1B | ≈\$170M | Near recent peak |
| **2019** | \$11.4B | ≈\$200M | |
| **2020** | \$8.8B | ≈\$200M | COVID crash, then recovery; Asana IPO |
| **2021** | \$16.8B | ≈\$400M | Peak (Meta stock all-time high); \$300M to GiveWell |
| **2022** | \$10.8B | ≈\$650M | Meta stock crashed 64%; giving accelerated post-FTX |
| **2023** | \$9.4B | ≈\$750M | Recent low; \$1.9B transfer to Good Ventures |
| **2024** | \$16.3B | ≈\$650M | Meta recovery; multi-donor fund launches |
| **2025** | ≈\$17.4B | ≈\$600M+ | Forbes (May 2025); Coefficient Giving rebrand |
| **2026** | ≈\$12.4B | — | Bloomberg (Feb 2026) |

*Annual Giving figures are grants recommended by <EntityLink id="coefficient-giving">Coefficient Giving</EntityLink> (formerly Open Philanthropy), funded primarily by Good Ventures. Figures from Open Phil annual reports use approximate language ("over \$X million"); values shown are midpoint estimates. Sources: [Coefficient Giving annual reports](https://coefficientgiving.org/research/), [ProPublica 990s](https://projects.propublica.org/nonprofits/organizations/461008520).*

Sources: [Grizzly Bulls Billionaire Index](https://grizzlybulls.com/billionaires/dustin-moskovitz), [Forbes](https://en.wikipedia.org/wiki/Dustin_Moskovitz), [Bloomberg Billionaires Index](https://www.bloomberg.com/billionaires/profiles/dustin-a-moskovitz/)

### Key Observations

**Flat long-term growth despite major holdings**: From 2018 (\$14.1B) to 2026 (\$12.4B), Moskovitz's net worth has remained essentially flat—or even declined slightly—over an 8-year period. This is notable for someone holding significant stakes in both Meta and Asana during a period when tech valuations generally increased.

**Extreme volatility**: His net worth has swung from a peak of \$16.8B (2021) to a low of \$8.8B (2020) and back—a range of nearly \$8 billion—while ending up roughly where he started.

**Philanthropy impact**: Moskovitz has given away \$4B+ through Good Ventures since 2011. His 2023 transfer of \$1.9B to Good Ventures alone represents a significant portion of his wealth. Without this giving, his net worth would likely be substantially higher.

**Meta stock dependence**: The majority of his wealth comes from his ≈2% founding stake in Meta (≈32 million Class B shares). Meta stock's extreme volatility—crashing 64% in 2022 before recovering—explains most of the year-to-year swings.

**Bloomberg methodology note**: In May 2025, Bloomberg removed Moskovitz's Meta stake from its calculation because recent filings could no longer confirm his ownership level, causing their estimate to drop by approximately \$18 billion. This explains some discrepancy between sources.

**Anthropic stake not included**: Most net worth estimates likely do not fully reflect Moskovitz's <EntityLink id="anthropic-investors">Anthropic stake</EntityLink>, estimated at 0.8-2.5% of the company (\$3-9B at Anthropic's \$350B January 2026 valuation). He participated in both seed and Series A rounds (estimated \$20-50M invested). In November 2025, he moved a \$500M portion of this stake into a nonprofit vehicle. If this stake were fully valued, his total wealth would be substantially higher than reported figures suggest.

## Overview

Dustin Moskovitz is a Facebook co-founder who became the world's youngest self-made billionaire in 2011 and has since become the largest individual funder of AI safety research through his philanthropy with Coefficient Giving (formerly Open Philanthropy). Together with his wife Cari Tuna, Moskovitz has given away over \$4 billion since 2011 and committed to giving away the vast majority of their wealth during their lifetimes through the [Giving Pledge](https://givingpledge.org/pledger?pledgerId=252).

Moskovitz's path from tech entrepreneur to major philanthropist began during his time at Harvard, where he roomed with Mark Zuckerberg and helped build Facebook from a dorm-room project into a global platform. After leaving Facebook in 2008, he co-founded Asana, a work management software company that went public in 2020. His wealth derives primarily from his founding stakes in both Meta Platforms and Asana.

Unlike many tech philanthropists who maintain high public profiles, Moskovitz initially took a hands-off approach to his giving, delegating authority to professional staff. However, he has become increasingly vocal about AI risks, signing the [Center for AI Safety's 2023 statement](https://www.safe.ai/work/statement-on-ai-risk) declaring AI extinction risk a "global priority" and advocating for pre-deployment safety evaluations of advanced AI systems.

Moskovitz's impact on AI safety is substantial. Coefficient Giving has directed approximately \$336 million to AI safety since 2017 (about 12% of its \$2.8 billion total giving), making it the largest external funder of AI safety research in the world. In 2023 alone, the organization spent \$46 million on AI safety, and in 2024 deployed \$63.6 million—nearly 60% of all external AI safety investment globally.

## Career Timeline

| Year | Event | Significance |
|------|-------|--------------|
| **2002** | Enrolled at Harvard | Economics major, roomed with Zuckerberg and Chris Hughes |
| **Feb 2004** | Co-founded Facebook | One of four co-founders with Zuckerberg, Saverin, Hughes |
| **Jun 2004** | Moved to Palo Alto | Left Harvard to work on Facebook full-time |
| **Dec 2004** | Facebook reaches 1M users | After \$500K seed from Peter Thiel |
| **2004-2006** | First CTO | Built early technical infrastructure |
| **2006-2008** | VP of Engineering | Focused on scalability and growth |
| **Oct 2008** | Founded Asana | With Justin Rosenstein (former Facebook/Google engineer) |
| **Mar 2011** | Youngest self-made billionaire | Forbes recognition based on 2.34% Facebook stake |
| **Sep 2020** | Asana IPO | Direct listing at ≈\$5.5B valuation |
| **Mar 2025** | Announced CEO transition | Planned retirement from Asana CEO role |
| **Jul 2025** | Became Board Chair | Dan Rogers appointed as new CEO |

### Facebook (2004-2008)

| Aspect | Details |
|--------|---------|
| **Role** | Co-founder, first CTO, then VP of Engineering |
| **Period** | February 2004 - October 2008 |
| **Co-founders** | Mark Zuckerberg, Eduardo Saverin, Chris Hughes, Andrew McCollum |
| **Key Contribution** | Technical infrastructure, scalability |
| **Stake at Departure** | 2.34% (source of initial billions) |

Moskovitz was Mark Zuckerberg's freshman roommate at Harvard University. According to Zuckerberg, Moskovitz "learned programming in a few days" and joined the founding team as a programmer when Facebook (originally "thefacebook.com") launched in February 2004. He served as the company's first Chief Technology Officer, building much of the early technical infrastructure. In June 2004, Moskovitz, Zuckerberg, and Hughes moved to Palo Alto, hiring eight employees and receiving \$500,000 in seed funding from Peter Thiel. By December 2004, Facebook had nearly 1 million users.

As VP of Engineering, Moskovitz focused on scaling the platform to handle rapid global growth. He departed in October 2008 to start Asana, taking with him the insight that internal work management tools—like those he'd seen at Facebook and Google—could be "democratized" for all organizations.

### Asana (2008-2025)

| Aspect | Details |
|--------|---------|
| **Role** | Co-founder, CEO (Oct 2010 - Jul 2025), Board Chair (Jul 2025-present) |
| **Co-founder** | Justin Rosenstein (former Google/Facebook engineer) |
| **Founded** | October 3, 2008 |
| **Mission** | "Help humanity thrive by enabling the world's teams to work together effortlessly" |
| **IPO** | September 2020 (direct listing, NYSE: ASAN) |
| **Valuation at IPO** | ≈\$5.5 billion |
| **2024 Revenue** | >\$700 million annually |
| **Customers** | 170,000+, including 85%+ of Fortune 500 |
| **Moskovitz Stake** | ≈53% (123M Class A/B shares as of 2024) |

Moskovitz announced Asana's founding on October 3, 2008, explaining that they were "democratizing what was the secret sauce of a lot of tech companies"—internal collaborative work management systems. Google had "Tasks" (built by co-founder Justin Rosenstein), Apple had "Radar," and Amazon had "Simple Issue Tracker." Asana would bring this capability to all organizations.

Rosenstein initially served as CEO, but Moskovitz took over the role in October 2010 "by necessity." He later acknowledged that managing people was "ill-suited to his personality," stating: "By personality, I don't like to manage teams, and it wasn't my intention when we started Asana."

In March 2025, Moskovitz announced plans to transition to Board Chair, with former ServiceNow and Rubrik executive Dan Rogers becoming CEO in July 2025. Moskovitz described the CEO role as "exhausting" and expressed eagerness to focus more on philanthropy and AI safety work.

## The Giving Pledge

In December 2010, Dustin Moskovitz and Cari Tuna became the youngest couple to sign the <EntityLink id="giving-pledge">Giving Pledge</EntityLink>, the philanthropic commitment launched by Warren Buffett and Bill and Melinda Gates asking billionaires to give away at least half their wealth. Tuna was 25 and Moskovitz was 26—making them the youngest signatories in the Pledge's history. (See the <EntityLink id="giving-pledge">Giving Pledge</EntityLink> page for analysis of historical fulfillment rates and criticisms.)

### The Pledge Letter

| Aspect | Details |
|--------|---------|
| **Signed** | December 2010 |
| **Commitment** | Give away majority of wealth during lifetime |
| **Co-signers that day** | 17 billionaires including Mark Zuckerberg |
| **Key Quote** | "We will donate and invest with both urgency and mindfulness, aiming to foster a safer, healthier and more economically empowered global community" |

The timing was notable: Moskovitz had just become a billionaire through Facebook's growth, and the term "effective altruism" had not yet been coined. However, the couple was already developing the research-driven approach to philanthropy that would become their hallmark. Their [full pledge letter](https://givingpledge.org/pledger?pledgerId=252) is available on the Giving Pledge website.

### Context: Youngest Self-Made Billionaire

In March 2011, Forbes reported Moskovitz as the world's youngest self-made billionaire based on his 2.34% stake in Facebook. He held this distinction until around 2014, when Snapchat's co-founders surpassed him. Notably, Moskovitz is just eight days younger than Mark Zuckerberg—making their near-simultaneous billionaire status a unique case.

## Philanthropic Activities

<Mermaid chart={`
flowchart TD
    DM[Dustin Moskovitz] --> GV[Good Ventures<br/>Foundation, 2011]
    CT[Cari Tuna] --> GV

    GV --> CG[Coefficient Giving<br/>formerly Open Phil]

    CG --> AI[AI Safety<br/>~12% / \$336M]
    CG --> BIO[Biosecurity<br/>~15%]
    CG --> FAW[Farm Animal Welfare<br/>~15%]
    CG --> GH[Global Health<br/>~40%]
    CG --> OTHER[Other Causes<br/>~18%]

    AI --> RESEARCH[Research Orgs<br/>MIRI, Redwood, CAIS]
    AI --> EVALS[Evaluations<br/>ARC/METR, Epoch]
    AI --> GOV[Governance<br/>GovAI, RAND]

    GH --> MALARIA[Malaria Consortium<br/>\$300M+]
    GH --> EVIDENCE[Evidence Action<br/>\$200M+]

    style DM fill:#e6f3ff
    style CT fill:#e6f3ff
    style GV fill:#ccffcc
    style CG fill:#ffffcc
`} />

### Good Ventures

| Aspect | Details |
|--------|---------|
| **Founded** | 2011 |
| **Structure** | Good Ventures Foundation (private foundation, 2012) + Good Ventures LLC (impact investments, 2012) |
| **Leadership** | Cari Tuna (Co-founder, Chair) |
| **Staff** | No direct employees; relies on Coefficient Giving for research and grantmaking |
| **Lifetime Giving** | \$4B+ (2011-2025) |
| **Major Gift** | \$1.9B transfer from Moskovitz to Good Ventures (June 2023) |

Good Ventures is the private foundation through which Moskovitz and Tuna channel their philanthropy. The organization works closely with Coefficient Giving (formerly Open Philanthropy), which provides research, analysis, and grantmaking recommendations. Good Ventures has no staff of its own—all operations are conducted through Coefficient Giving.

In June 2023, Moskovitz quietly donated \$1.9 billion to Good Ventures, equivalent to the entire endowment of major legacy foundations like the Alfred P. Sloan Foundation. This gift enabled significantly expanded giving capacity.

### Coefficient Giving (formerly Open Philanthropy)

The evolution of Moskovitz and Tuna's grantmaking infrastructure reflects their deepening partnership with effective altruism:

| Year | Development |
|------|-------------|
| **2010** | Moskovitz and Tuna meet GiveWell co-founders Holden Karnofsky and Elie Hassenfeld |
| **2011** | Tuna joins GiveWell board; Good Ventures founded |
| **2012** | GiveWell Labs created as joint initiative |
| **2014** | GiveWell Labs rebranded as Open Philanthropy Project |
| **2017** | Coefficient Giving becomes independent LLC |
| **2019** | Shortened to "Coefficient Giving" |
| **2024** | Lead Exposure Action Fund launches (\$125M) as first multi-donor fund |
| **2025** | Rebranded to "Coefficient Giving" to reflect multi-donor expansion |

<EntityLink id="coefficient-giving">Coefficient Giving</EntityLink> now serves as the primary vehicle for Moskovitz's giving:

| Aspect | Details |
|--------|---------|
| **Total Giving (2017-2024)** | ≈\$2.8 billion |
| **2024 Grants** | >\$650 million |
| **2025 YTD** | >\$600 million |
| **Staff** | ≈100 |
| **Cause Areas** | Global health, AI safety, biosecurity, farm animal welfare, scientific research |
| **AI Safety Total** | ≈\$336 million (12% of total) |
| **Multi-Donor Funds** | Lead Exposure Action Fund (\$125M), Abundance & Growth Fund (\$120M) |

The rebrand to "Coefficient Giving" signals a strategic shift from serving primarily one anchor donor (Good Ventures) to operating multi-donor funds that other philanthropists can join. The name reflects the mathematical concept: a coefficient multiplies whatever it's paired with, just as the organization aims to amplify philanthropic impact.

### Giving Scale

| Period | Amount | Key Developments |
|--------|--------|------------------|
| 2011-2015 | ≈\$100M | GiveWell top charities, EA infrastructure |
| 2016-2019 | ≈\$500M | Grantmaking grows, AI safety begins |
| 2020-2022 | ≈\$1B | Major AI safety scaling, pandemic response |
| 2023 | ≈\$600M | Post-FTX expansion, \$1.9B transfer to Good Ventures |
| 2024 | ≈\$650M | Multi-donor fund launches |
| 2025 | ≈\$600M+ | Coefficient Giving rebrand |
| **Lifetime** | **\$4B+** | Through Good Ventures/Coefficient Giving |

### Major Non-AI Grants

| Recipient | Amount | Focus |
|-----------|--------|-------|
| Malaria Consortium | \$300M+ | Malaria prevention |
| Evidence Action | \$200M+ | Deworming, water treatment |
| Helen Keller International | \$100M+ | Vitamin A supplementation |
| GiveDirectly | \$50M+ | Direct cash transfers |

## AI Safety Philanthropy

<Mermaid chart={`
flowchart LR
    subgraph TECHNICAL["Technical Research"]
        MIRI[MIRI<br/>\$20M+]
        REDWOOD[Redwood<br/>\$15M+]
        ARC[ARC/METR<br/>\$10M+]
        FAR[FAR.AI<br/>\$1.3M+]
    end

    subgraph GOVERNANCE["Governance & Policy"]
        GOVAI[GovAI<br/>\$10M+]
        RAND[RAND<br/>\$10M]
        CAIS[CAIS<br/>\$12M+]
    end

    subgraph ACADEMIC["Academic Programs"]
        BERKELEY[Berkeley]
        STANFORD[Stanford]
        OXFORD[Oxford]
        CAMBRIDGE[Cambridge]
    end

    CG[Coefficient Giving<br/>≈\$336M AI Safety] --> TECHNICAL
    CG --> GOVERNANCE
    CG --> ACADEMIC

    style CG fill:#ffffcc
    style TECHNICAL fill:#e6f3ff
    style GOVERNANCE fill:#ccffcc
    style ACADEMIC fill:#ffe6cc
`} />

### Funding Overview

Coefficient Giving (formerly Open Philanthropy) has become the world's largest external funder of AI safety research:

| Metric | Value | Source |
|--------|-------|--------|
| **Total AI Safety Grants** | ≈\$336M | 2017-2024 |
| **Share of Total Giving** | ≈12% | Of \$2.8B total |
| **2023 AI Safety Spending** | \$46M | [LessWrong Analysis](https://www.lesswrong.com/posts/WGpFFJo2uFe5ssgEb/an-overview-of-the-ai-safety-funding-situation) |
| **2024 AI Safety Spending** | \$63.6M | ≈60% of all external AI safety investment |
| **Median Grant Size** | ≈\$257K | Across all AI safety grants |
| **Average Grant Size** | \$1.67M | Skewed by large grants |

### Major AI Safety Grant Recipients

| Recipient | Total Funding | Focus Area | Notable Grants |
|-----------|---------------|------------|----------------|
| **MIRI** | \$20M+ | Technical alignment | \$7.7M general support, \$4.1M (2024) |
| **Redwood Research** | \$15M+ | Interpretability, alignment | \$5.3M (2023), \$6.2M (2024) |
| **Center for AI Safety** | \$12M+ | Advocacy, research, field-building | \$1.87M exit grant (2023), \$1.43M philosophy fellowship |
| **<EntityLink id="organizations/safety-orgs/metr">METR</EntityLink>** | \$10M+ | Evaluations | \$265K (2022), \$10M to RAND/METR Canary project |
| **<EntityLink id="organizations/epistemic-orgs/epoch-ai">Epoch AI</EntityLink>** | \$5M+ | AI forecasting | Multiple grants |
| **GovAI** | \$10M+ | AI governance research | Core support |
| **FAR.AI** | \$1.3M+ | Alignment research | \$645K (Jan 2024), \$680K (Jul 2024) |
| **University Programs** | \$30M+ | Academic research | Berkeley, Stanford, Oxford, Cambridge |

### 2024 Technical AI Safety Initiative

In 2024, Coefficient Giving launched a major Request for Proposals for technical AI safety research:

| Aspect | Details |
|--------|---------|
| **Initial Budget** | \$40M over 5 months |
| **Research Areas** | 21 areas across 5 categories |
| **Focus** | Interpretability, alignment, evaluations |
| **Flexibility** | "Additional funding available depending on application quality" |

Key 2024 grants under this initiative included \$25 million for developing better benchmarks for LLM agent capabilities, with results already being used by the U.S. and UK governments, OpenAI, and Anthropic to measure AI systems' potential for cyberattacks and pandemic creation assistance.

### METR/ARC Evals Partnership

A notable success story in Coefficient Giving's AI safety portfolio is the support for AI evaluations work:

| Entity | Founded | Relationship |
|--------|---------|--------------|
| **Alignment Research Center (ARC)** | April 2021 | Founded by Paul Christiano (former OpenAI) |
| **ARC Evals** | 2022 | Founded by Beth Barnes within ARC |
| **METR** | December 2023 | Spun out as independent nonprofit |

METR (formerly ARC Evals) now partners with OpenAI and Anthropic to evaluate advanced AI models before release. In a notable 2023 test, ARC evaluated GPT-4's ability to exhibit power-seeking behavior, including a test where GPT-4 successfully solved a CAPTCHA by hiring a human on TaskRabbit and deceiving them into believing it was vision-impaired.

### Anthropic Connection

While Coefficient Giving has not made direct large grants to Anthropic (which has raised >\$7 billion in venture capital), there are significant connections:

| Aspect | Details |
|--------|---------|
| **FTX Investment** | \$500M (2022, now in bankruptcy proceedings) |
| **Coefficient Connection** | Holden Karnofsky (Coefficient co-founder) joined Anthropic in 2025 |
| **Karnofsky's Role** | Working on Responsible Scaling Policy |
| **Board Structure** | Long-Term Benefit Trust controls 3 of 5 board seats |

Note: The \$500M investment commonly associated with AI safety philanthropy was actually from FTX, not Coefficient Giving. Holden Karnofsky, Coefficient Giving's co-founder and Anthropic President Daniela Amodei's husband, joined Anthropic's technical staff in early 2025 to work on safety protocols.

## Philosophy and Approach

### Effective Altruism Connection

Moskovitz and Tuna have been central figures in the effective altruism movement since before the term was coined:

| Year | Milestone |
|------|-----------|
| **2010** | Met GiveWell founders Karnofsky and Hassenfeld |
| **2011** | Tuna joined GiveWell board; Good Ventures founded |
| **2012** | GiveWell partnership formalized |
| **2014** | Open Philanthropy Project launched |
| **2015+** | Major funding for 80,000 Hours, CEA, EA Global |

According to one analysis, "It is difficult to separate them from the movement" and "They are the figureheads." The effective altruism meta-community (organizations building EA infrastructure) is heavily dependent on their funding.

### The ITN Framework

Moskovitz and Tuna's giving follows the effective altruism "ITN" framework for cause prioritization:

| Criterion | Description | Application |
|-----------|-------------|-------------|
| **Importance** | Scale of the problem | AI risk: potential extinction-level |
| **Tractability** | Can progress be made? | Safety research showing results |
| **Neglectedness** | Is it underfunded? | AI safety was ≈\$50M/year before OP scaled |

### Giving Style

| Characteristic | Description |
|----------------|-------------|
| **Delegated Authority** | Empowers professional staff to make independent decisions |
| **Research-Driven** | Extensive investigation before major grants |
| **Spend-Down** | Aims to give away wealth during lifetime, not create perpetual foundation |
| **Cause-Neutral** | Willing to shift funding based on evidence |
| **High Risk Tolerance** | Funds speculative bets on transformative research |
| **Increasingly Vocal** | Shifting from low-profile to public AI advocacy |

### Key Priorities

| Priority | Rationale | Share of Giving |
|----------|-----------|-----------------|
| **Global Health** | Proven, cost-effective interventions | ≈40% |
| **AI Safety** | Potential to prevent catastrophe | ≈12% |
| **Biosecurity** | High-impact, neglected | ≈15% |
| **Farm Animal Welfare** | Enormous scale of suffering | ≈15% |
| **Scientific Research** | Enabling innovation | ≈10% |
| **Other** | Policy, EA infrastructure | ≈8% |

## Views on AI Risk

Unlike some AI safety funders who maintain either strong pessimism ("doomerism") or optimism, Moskovitz explicitly rejects this binary framing. His views have evolved from early AI optimism to nuanced concern:

### Evolution of Views

| Period | Position |
|--------|----------|
| **Early 2010s** | Self-described "AI accelerationist"; invested in Vicarious |
| **Mid-2010s** | Began funding AI safety through Coefficient (then Open Philanthropy) |
| **2020s** | "Neither doomer nor accelerationist"—supports safety research while remaining optimistic |

### Key Statements

Moskovitz has articulated his AI risk philosophy in several interviews:

> "The people I least understand in the AI risk debate are the ones who have ~100% confidence that AI will or will not destroy us—either way, how can they really know something like that?"

> "The AI safety community takes a third position: AI is going to be great and we need to mitigate some very real problems."

On the false dichotomy he sees in AI debates:

> "Opponents are deliberately creating a polarized frame that does not exist—on one side are 'doomers who think everything is awful and want to ban math,' and on the other are 'libertarians who think AI is going to be amazing.' I purposefully reject this binary."

### The Car Safety Analogy

Moskovitz frequently uses a car safety analogy to explain his position:

> "When you get into a car, you expect to go to your destination, but you put on a seatbelt and follow the rules of the road. There's a regulatory system and licensing system for drivers that helps ensure mutual safety for everyone, including pedestrians. I think about AI safety in the same way—we are heading towards something really awesome, but there are some serious risks we need to address."

### Policy Positions

| Position | Details |
|----------|---------|
| **Pre-deployment Evaluations** | "The thing I'm most interested in is making sure state-of-the-art later generations, like GPT-5, GPT-6, get run through safety evaluations before being released" |
| **Regulation** | Supports coordinated regulatory frameworks; helped craft 12-point policy list for U.S. lawmakers |
| **CAIS Statement** | Signed May 2023 statement declaring AI extinction risk a "global priority" |
| **Short Timelines** | "I'm pretty much a short timelines person, so I think these problems are now" |

### Personal Optimism

Despite his concerns, Moskovitz maintains optimism:

> "I believe we will figure out a positive way forward with AI and unlock a future that is unimaginably good."

## Personal Characteristics

| Trait | Description | Evidence |
|-------|-------------|----------|
| **Analytical** | Data-driven approach to giving | Research-intensive grantmaking process |
| **Uncertainty-Embracing** | Acknowledges limits of knowledge | Skeptical of 100% confidence claims |
| **Delegating** | Empowers professional staff | Coefficient Giving operates independently |
| **Long-term Focused** | Thinks about future generations | AI safety, biosecurity focus |
| **Increasingly Vocal** | Moving from private to public role | Podcast interviews, policy advocacy |
| **Introverted** | Prefers not to manage teams | Stepped down as Asana CEO |

### Personal Life

| Aspect | Details |
|--------|---------|
| **Met Cari Tuna** | 2009, blind date arranged by mutual friend |
| **Married** | October 2013 |
| **Cari's Background** | Yale graduate, former Wall Street Journal reporter (San Francisco bureau) |
| **Cari's Role** | Co-founder and Chair of Good Ventures and Coefficient Giving |
| **Shared Interests** | Burning Man attendance, effective altruism |
| **Children** | Not publicly disclosed |

### Cari Tuna

Cari Tuna (born October 4, 1985) deserves significant credit for the couple's philanthropic work. While Moskovitz provided the capital, Tuna has been the driving force behind their giving strategy:

| Aspect | Details |
|--------|---------|
| **Education** | Yale University graduate |
| **Career** | Former Wall Street Journal reporter |
| **Role at Good Ventures** | Co-founder and Chair |
| **Role at Coefficient Giving** | Chair |
| **GiveWell Involvement** | Joined board in 2011 |
| **Recognition** | TIME100 Philanthropy 2025 |

Tuna met the GiveWell founders (Holden Karnofsky and Elie Hassenfeld) and was impressed by their commitment to transparency and cause neutrality. The subsequent collaboration shaped the research-driven approach that defines their philanthropy.

## Comparison with Other Major AI Safety Donors

| Aspect | Moskovitz | <EntityLink id="jaan-tallinn">Tallinn</EntityLink> | Vitalik Buterin |
|--------|-----------|---------|-----------------|
| **Net Worth** | ≈\$17B | ≈\$500M | ≈\$1B |
| **Annual Giving** | \$200M+ | \$50M | Variable |
| **AI Safety Focus** | ≈12% | ≈85% | Variable |
| **Primary Vehicle** | Coefficient Giving | <EntityLink id="sff">SFF</EntityLink> | Direct/various |
| **Public Profile** | Low-Moderate | Medium | High |
| **Delegation Level** | High | Medium | Low |
| **Risk Tolerance** | Medium-High | High | High |
| **Wealth Source** | Facebook, Asana | Skype, Kazaa | Ethereum |

## Criticisms and Discussions

| Topic | Description | Response/Context |
|-------|-------------|------------------|
| **Field Influence** | Concerns about single donor shaping AI safety research agenda | Coefficient Giving expanding to multi-donor model |
| **EA Concentration** | Heavy EA infrastructure dependence on Moskovitz/Tuna funding | Acknowledged; no clear alternative funding source |
| **Post-FTX Scrutiny** | Association with effective altruism after FTX collapse | Increased emphasis on governance, diversification |
| **Capability vs. Safety** | Questions about funding organizations that advance AI capabilities | Moskovitz argues safety work requires frontier access |
| **Neglecting Near-term Harms** | Focus on existential risk over present AI harms | Coefficient Giving also funds bias research, misuse prevention |

### The Concentration Problem

A key concern in the AI safety community is heavy dependence on a small number of funders. Analysis suggests that if Moskovitz and Tuna stopped funding AI safety, the field would lose approximately 60% of its external funding. This concentration creates risks:

- Research agendas may reflect donor preferences
- Organizations may self-censor to maintain funding
- Loss of major funder could collapse multiple organizations simultaneously

Coefficient Giving's 2025 rebrand and multi-donor fund structure explicitly aims to address this by attracting additional philanthropists.

## Public Communications

### Media Appearances

| Venue | Date | Topic |
|-------|------|-------|
| **Tim Ferriss Show (#686)** | August 2023 | AI risks, energy management, Asana |
| **Stratechery Interview** | 2025 | AI, SaaS, and Safety |
| **CNBC** | June 2023 | AI concerns and policy positions |
| **Medium** | Ongoing | "Works in Progress" blog |

### Key Publications

- [Works in Progress: The Long Journey to Doing Good Better](https://medium.com/@moskov/works-in-progress-the-long-journey-to-doing-good-better-9dfb68e50868) (Medium)
- [AI can make work more human](https://asana.com/inside-asana/asana-dustin-moskovitz-on-artificial-intelligence) (Asana blog)
- [Giving Pledge Letter](https://givingpledge.org/pledger?pledgerId=252)

## External Links

- [Dustin Moskovitz - Wikipedia](https://en.wikipedia.org/wiki/Dustin_Moskovitz)
- [Coefficient Giving](https://coefficientgiving.org/) (formerly Open Philanthropy)
- [Good Ventures](https://www.goodventures.org/)
- [Giving Pledge Profile](https://givingpledge.org/pledger?pledgerId=252)
- [Asana](https://asana.com/)
- [Bloomberg Billionaires Index](https://www.bloomberg.com/billionaires/profiles/dustin-a-moskovitz/)

## References

1. [Dustin Moskovitz - Wikipedia](https://en.wikipedia.org/wiki/Dustin_Moskovitz)
2. [Bloomberg Billionaires Index - Dustin Moskovitz](https://www.bloomberg.com/billionaires/profiles/dustin-a-moskovitz/)
3. [Cari Tuna - Wikipedia](https://en.wikipedia.org/wiki/Cari_Tuna)
4. [Good Ventures - About Us](https://www.goodventures.org/about-us/)
5. [Coefficient Giving - Wikipedia](https://en.wikipedia.org/wiki/Coefficient_Giving)
6. [Coefficient Giving Is Now Coefficient Giving](https://coefficientgiving.org/research/open-philanthropy-is-now-coefficient-giving/)
7. [The Story Behind Our New Name - Coefficient Giving](https://coefficientgiving.org/research/the-story-behind-our-new-name/)
8. [Four Lessons From \$4 Billion in Impact-focused Giving - SSIR](https://ssir.org/articles/entry/philanthropy-lessons-impact-focused-giving)
9. [An Overview of the AI Safety Funding Situation - LessWrong](https://www.lesswrong.com/posts/WGpFFJo2uFe5ssgEb/an-overview-of-the-ai-safety-funding-situation)
10. [Our Progress in 2024 and Plans for 2025 - Coefficient Giving](https://www.openphilanthropy.org/research/our-progress-in-2024-and-plans-for-2025/)
11. [Asana Announces CEO Succession Plan](https://investors.asana.com/news-releases/news-release-details/asana-announces-ceo-succession-plan)
12. [An Interview with Asana Founder Dustin Moskovitz - Stratechery](https://stratechery.com/2025/an-interview-with-asana-founder-dustin-moskovitz-about-ai-saas-and-safety/)
13. [Tim Ferriss Show #686 Transcript](https://tim.blog/2023/08/10/dustin-moskovitz-2-transcript/)
14. [Asana's Dustin Moskovitz is bullish on AI but concerned about risks - CNBC](https://www.cnbc.com/2023/06/24/asanas-dustin-moskovitz-is-bullish-on-ai-but-concerned-about-risks.html)
15. [Redwood Research - General Support 2023 - Coefficient Giving](https://www.openphilanthropy.org/grants/redwood-research-general-support-2023/)
16. [Center for AI Safety - General Support 2023 - Coefficient Giving](https://www.openphilanthropy.org/grants/center-for-ai-safety-general-support-2023/)
17. [METR (formerly ARC Evals) - Giving What We Can](https://www.givingwhatwecan.org/charities/arc-evals)
18. [Giving Pledge - Dustin Moskovitz and Cari Tuna](https://givingpledge.org/pledger?pledgerId=252)

