---
title: Daniela Amodei
description: Co-founder and President of Anthropic, overseeing business operations, commercial strategy, and enterprise partnerships while publicly advocating for safety-focused AI development and deployment practices.
sidebar:
  order: 50
entityType: person
subcategory: lab-leadership
quality: 21
readerImportance: 27.5
researchImportance: 11
lastEdited: "2026-02-22"
llmSummary: Biographical profile of Anthropic's President covering her education, early career, roles at Stripe and OpenAI, and her operational and commercial leadership at Anthropic. Includes fundraising history, named enterprise partnerships, sourced quotes, and documented external criticisms of Anthropic's commercial-safety balance.
ratings:
  novelty: 1.5
  rigor: 2
  actionability: 1
  completeness: 4
clusters: ["ai-safety","governance"]
---
import {R, EntityLink, DataExternalLinks} from '@components/wiki';

<DataExternalLinks pageId="daniela-amodei" />

## Quick Assessment

| Aspect | Assessment |
|--------|-----------|
| **Primary Role** | Co-Founder and President, <EntityLink id="E22" name="anthropic">Anthropic</EntityLink> (2021–present) |
| **Key Contributions** | Operational leadership of Anthropic's commercial growth; oversaw fundraising across multiple rounds; leads enterprise partnerships and policy engagement |
| **Institutional Affiliation** | <EntityLink id="E22" name="anthropic">Anthropic</EntityLink>; member of Anthropic's Board of Directors |
| **Prior Roles** | VP of Safety & Policy, <EntityLink id="E218" name="openai">OpenAI</EntityLink> (2020); Engineering Manager and VP of People, <EntityLink id="E218" name="openai">OpenAI</EntityLink> (2018–2020); Risk Manager and Lead Technical Recruiter, Stripe (2013–2018) |
| **Influence on AI Safety** | Oversees Anthropic's safety-focused commercial strategy; public advocate for regulatory frameworks; has publicly explained <EntityLink id="E451" name="constitutional-ai">Constitutional AI</EntityLink> methodology to policymakers and enterprise customers |

## Overview

Daniela Amodei is Co-Founder and President of <EntityLink id="E22" name="anthropic">Anthropic</EntityLink>, an AI safety company she co-founded with her brother <EntityLink id="E91" name="dario-amodei">Dario Amodei</EntityLink> and several other former <EntityLink id="E218" name="openai">OpenAI</EntityLink> employees in December 2020.[^1] As President, she oversees Anthropic's business operations, commercial strategy, enterprise partnerships, and policy engagement. Dario Amodei serves as CEO and leads the technical research side of the organization.

Amodei's background is in operations, recruiting, risk management, and people programs — first at Stripe (2013–2018) and then at OpenAI (2018–2020). She left OpenAI in 2020, citing concerns about the pace of AI commercialization and disagreements about safe AI governance.[^2] At Anthropic, she has overseen the company's commercial growth from its founding through a series of major fundraising rounds and the expansion of its enterprise customer base.

As of February 2026, Anthropic's post-money valuation stands at <F e="anthropic" f="6796e194">\$380 billion</F> following a Series G round,[^3] and the company reports a run-rate revenue of <F e="anthropic" f="0ed4db9e">\$14 billion</F>.[^3] Approximately 85% of Anthropic's revenue derives from business customers.[^4]

## Background

### Education

Amodei graduated from Lowell High School in San Francisco.[^5] She attended the University of California, Santa Cruz, where she received a partial-tuition scholarship to study classical flute and won the 2008 Concerto competition as a soloist.[^5] She graduated with a BA in English Literature — with additional coursework in Politics and Music — earning summa cum laude honors, University Honors, College Honors, Literature Department Honors, and Dean's List recognition. She was also selected as winner of the Senior Thesis Colloquium.[^5] In a February 2026 ABC News interview, Amodei stated she has "zero regrets" about her English Literature degree, arguing that "the things that make us human will become much more important instead of much less important" in an AI-augmented world.[^6]

### Early Career

After graduating, Amodei worked in global health and politics. She served as Deputy Field Director and then Field Director on a successful congressional campaign in Pennsylvania, and subsequently managed scheduling and communications for U.S. Representative Matt Cartwright in Washington, D.C.[^5] In 2010, she began a role as a business development professional at the IRIS Center at the University of Maryland, College Park.[^5]

### Stripe (2013–2018)

Amodei joined Stripe in 2013 as approximately its 45th employee, initially focusing on recruiting.[^7] As Lead Technical Recruiter, she built a recruiting team of five members, hired 92 engineers across 11 teams, and achieved a candidate close rate exceeding 75%, helping scale Stripe's workforce from 45 to approximately 300 employees.[^7] In 2015, she transitioned to Risk Program Manager, and from January 2016 to July 2018 she served as Risk Manager, overseeing core operations, user policy, and underwriting.[^7]

### OpenAI (2018–2020)

Amodei left Stripe in 2018 to join <EntityLink id="E218" name="openai">OpenAI</EntityLink>. She served as Engineering Manager overseeing natural language processing and music generation teams, and concurrently as VP of People, working across recruiting, people programs, DEI, and learning and development.[^2] From May 2020 to December 2020, she served as VP of Safety and Policy.[^8]

She departed OpenAI in December 2020, citing concerns that the company was commercializing AI too quickly and disagreements about safe AI governance.[^2]

### Co-founding Anthropic (2020–present)

Amodei co-founded <EntityLink id="E22" name="anthropic">Anthropic</EntityLink> in December 2020 alongside Dario Amodei and several other former OpenAI colleagues.[^1] She serves as President and as a member of Anthropic's Board of Directors.[^9]

## Professional Background

| Role | Organization | Period | Notes |
|------|-------------|--------|-------|
| Co-Founder & President; Board Member | <EntityLink id="E22" name="anthropic">Anthropic</EntityLink> | Dec 2020–present | Oversees commercial operations, enterprise partnerships, fundraising |
| VP of Safety and Policy | <EntityLink id="E218" name="openai">OpenAI</EntityLink> | May–Dec 2020 | [Technology Magazine, 2024](https://technologymagazine.com/executive/daniela-amodei) |
| Engineering Manager; VP of People | <EntityLink id="E218" name="openai">OpenAI</EntityLink> | Oct 2018–May 2020 | NLP and music generation teams; recruiting, DEI, L&D |
| Risk Manager | Stripe | Jan 2016–Jul 2018 | Core operations, user policy, underwriting |
| Risk Program Manager | Stripe | 2015–2016 | Transition from recruiting to risk |
| Lead Technical Recruiter | Stripe | 2013–2015 | Scaled team from 45 to ≈300 employees; 92 engineers hired across 11 teams |
| Business Development | IRIS Center, University of Maryland | 2010–2013 | Pre-Stripe role |
| Congressional staffer / field director | Office of Rep. Matt Cartwright; Pennsylvania campaign | 2010s | Scheduling, communications, and field organizing |

## Fundraising and Commercial Growth

As President, Amodei oversees Anthropic's commercial and operational side, which includes fundraising and enterprise partnership development.[^4] Anthropic has raised capital across multiple rounds since its 2021 founding:

| Round | Date | Amount | Lead Investor(s) | Post-Money Valuation |
|-------|------|--------|-----------------|---------------------|
| Series A | May 2021 | \$124M | Dustin Moscovitz, Jaan Tallinn | ≈\$550M |
| Series B | Apr 2022 | \$580M | Sam Bankman-Fried / FTX | ≈\$4B |
| Series C | May 2023 | \$450M | Spark Capital; Google first invested | — |
| Series D | Sep 2023 | \$1.25B (initial) | Amazon | — |
| Amazon (additional) | Mar 2024 | \$2.75B | Amazon | — |
| Amazon (additional) | Nov 2024 | \$4B | Amazon | — |
| Series E | Mar 2025 | \$3.5B | Lightspeed Venture Partners | \$61.5B |
| Series F | Sep 2025 | \$13B | ICONIQ, Fidelity, Lightspeed | \$183B |
| Series G | Feb 2026 | <F e="anthropic" f="5b0663a0">\$30B</F> | GIC, Coatue, D.E. Shaw Ventures, Founders Fund, ICONIQ, MGX | <F e="anthropic" f="6796e194">\$380B</F> |

Sources: [Anthropic Series A press release](https://www.anthropic.com/news/anthropic-raises-124-million-to-build-more-reliable-general-ai-systems); [Tracxn funding data](https://tracxn.com/d/companies/anthropic/__SzoxXDMin-NK5tKB7ks8yHr6S9Mz68pjVCzFEcGFZ08/funding-and-investors); [Anthropic Series G press release](https://www.anthropic.com/news/anthropic-raises-30-billion-series-g-funding-380-billion-post-money-valuation)

Amodei personally announced Anthropic's Series B (\$580M) on X (Twitter) in April 2022.[^10] As President, she is described in reporting as having been involved in forging strategic alliances with Amazon and Google.[^4] The Series G, completed February 12, 2026, was the second-largest private financing round on record for a technology company at the time.[^3]

Anthropic's business customer base grew from under 1,000 to more than 300,000 over two years, with approximately 85% of revenue derived from business customers.[^4] Run-rate revenue grew from approximately <F e="anthropic" f="bc497a3d">\$1 billion</F> at the start of 2025[^11] to <F e="anthropic" f="0ed4db9e">\$14 billion</F> by February 2026.[^3]

## Enterprise Partnerships

Amodei oversees Anthropic's commercial and enterprise operations.[^4] Named enterprise customers running Claude at scale as of early 2026 include Novo Nordisk, the Norwegian sovereign wealth fund, Bridgewater, Stripe, and Slack.[^4] Anthropic signed a multi-year \$200 million partnership with Snowflake in December 2025 to make Claude models available on Snowflake's data platform.[^12]

Strategic investment partnerships include:

- **Amazon**: Invested a total of approximately \$10.75 billion across three tranches (2023–2024); Amazon Web Services is Anthropic's primary cloud infrastructure partner.[^12]
- **Google**: Invested \$500 million in October 2023; agreed to invest an additional \$1 billion in March 2025.[^12]
- **Microsoft and Nvidia**: Announced a combined commitment of up to \$15 billion in November 2025.[^12]

On January 11, 2026, Amodei announced Claude for Healthcare and Life Sciences, describing regulated industries as a primary strategic focus: "In regulated industries, the question isn't just which model is smartest — it's which model you can actually rely on."[^13]

## Key Contributions to AI Safety

### Anthropic's Safety-Oriented Business Model

Amodei has publicly framed Anthropic's commercial strategy as linked to its safety mission, arguing that enterprise adoption requires demonstrated reliability and that trust is a prerequisite for deployment at scale. In a January 2026 Fast Company interview, she stated: "Trust is what unlocks deployment at scale."[^13] In a January 2026 CNBC interview conducted inside Anthropic's headquarters, she described "do more with less" as a governing principle for Anthropic's strategy and characterized the key question as how quickly businesses and individuals can leverage AI technology in practice.[^14]

### Constitutional AI: Public Communication

Amodei has publicly explained <EntityLink id="E451" name="constitutional-ai">Constitutional AI</EntityLink> to policymakers and enterprise customers. She presented Anthropic's Constitutional AI approach at Stanford's eCorner, explaining how Claude is governed by a constitution that includes documents such as the UN's Universal Declaration of Human Rights, and describing how the methodology separates questions of what an AI system can do from what it should do.[^15] The Constitutional AI methodology was developed primarily by Anthropic's research team; Amodei is acknowledged in the original December 2022 arXiv paper for "help and support" but is not listed as a technical author of the methodology.[^16]

### Policy and Governance Advocacy

| Initiative | Role | Notes |
|------------|------|-------|
| AI Safety Institute partnerships | Institutional collaboration | Anthropic signed formal agreements with the US AI Safety Institute (August 2024) and collaborated with UK AISI (renamed AI Security Institute, 2025); CAISI and AISI evaluated iterations of Constitutional Classifiers on Claude Opus 4 and 4.1 prior to deployment [NIST, Aug 2024](https://www.nist.gov/news-events/news/2024/08/us-ai-safety-institute-signs-agreements-regarding-ai-safety-research); [Anthropic, 2025](https://www.anthropic.com/news/strengthening-our-safeguards-through-collaboration-with-us-caisi-and-uk-aisi) |
| Policy engagement | Media and public statements | Policy engagement through company statements, media interviews, and industry forums; Congressional testimony from Anthropic has been given by CEO Dario Amodei (Senate Judiciary Committee, July 25, 2023)[^17] |
| Industry standards | Participant | Contributed to responsible scaling frameworks; Anthropic's Responsible Scaling Policy is a documented output |
| TIME100 AI 2023 | Recognition | Named among TIME's 100 Most Influential People in AI alongside Dario Amodei[^18] |

### Responsible Scaling and Staged Deployment

Amodei has overseen Anthropic's implementation of staged deployment practices, including the Responsible Scaling Policy framework for capability evaluation before deployment. Her public communications have emphasized that safety practices are a prerequisite for enterprise adoption in regulated industries, particularly healthcare, insurance, and regulatory-facing sectors.[^13]

## Perspectives on AI Risk and Development

### Public Statements

In a November 2025 CBS News 60 Minutes segment hosted by Anderson Cooper, Amodei stated: "We do know that this is coming incredibly quickly," and warned that the worst outcome would be if people lacked sufficient opportunity to adapt to the pace of transformation. She also stated that it is "unusual for a technology company to talk so much about all of the things that could go wrong."[^19]

In a February 2026 ABC News interview, she argued that the number of jobs AI could perform without human assistance is "vanishingly small," and that "the ability to have critical thinking skills and learn to interact with people will be more important in the future, rather than less."[^6]

In a February 2026 podcast interview for Sixth Street's *It's Not Magic*, she described Anthropic's leadership culture as built on "100% mutual respect, and the ability to raise tough things and challenge decisions openly," and discussed the pace of model development, regulation, and the tradeoffs between generalist and specialist skills.[^20]

On her working relationship with Dario Amodei, she stated in a Fast Company profile: "I personally think Dario is the most impressive technical visionary in this space," describing her own role as translating that vision "into sets of operating norms."[^21] She has described the sibling co-founder relationship in TIME as: "Since we were kids, we've always felt very aligned."[^18]

### Business Case for Safety

Amodei has publicly argued that safety investments function as commercial advantages rather than operational costs, citing the following mechanisms:

- **Trust and enterprise adoption**: Safety practices build confidence among regulated-industry customers and procurement departments
- **Risk mitigation**: Proactive safety measures reduce liability and reputational exposure
- **Market differentiation**: A safety-first positioning has attracted enterprise customers in sectors where reliability requirements are high

These arguments are contested. Critics from the AI safety research community have characterized elements of Anthropic's approach as "safety theater" — good branding without binding commitments — and some external researchers have specifically questioned whether Anthropic's interpretability research translates into practical safety improvements (see Criticism section below).

## Criticism and Contested Claims

### Safety-Washing Concerns

External AI safety researcher Stephen Casper (MIT) stated on the Alignment Forum in May 2024: "I am beginning to be concerned that Anthropic's recent approach to interpretability research might be better explained by safety washing than practical safety work," arguing that Anthropic had not applied its interpretability techniques to practical tasks competitively and instead focused on "streetlight demos and showing lots of cherry-picked examples."[^22]

### Internal Departures

In February 2026, Anthropic's head of Safeguards Research, Mrinank Sharma, resigned and published a letter warning that "the world is in peril" and that employees "constantly face pressures to set aside what matters most," adding: "Our wisdom must grow in equal measure to our capacity to affect the world."[^23] CNN Business reported this departure alongside broader accounts of researchers at AI labs departing and warning publicly about the pace of development.[^23]

### Commercial Pressure and Safety Commitments

A February 2026 Fortune analysis noted that CEO Dario Amodei acknowledged on the Dwarkesh Podcast: "We're under an incredible amount of commercial pressure and make it even harder for ourselves because we have all this safety stuff we do." The same analysis cited critics who described Anthropic's safety strategy as lacking binding commitments, and noted that some of Anthropic's safeguards had been bypassed by hackers reportedly linked to nation-state actors and criminal organizations.[^24] Meta's chief AI scientist Yann LeCun has publicly accused Anthropic's bioweapon warnings of being designed to influence legislators against open-source AI models.[^24] The Pentagon reportedly considered reducing its engagement with Anthropic due to the company's restrictions on military use of its technology.[^24]

These criticisms are directed at Anthropic as an institution rather than at Daniela Amodei specifically. Her responses to them — beyond the general public statements cited above — are not separately documented in public sources.

## Current Focus Areas

### Commercial AI Safety

As President, Amodei leads Anthropic's commercial operations, including:

- **Enterprise solutions**: Building AI tools with built-in safety guardrails, particularly for regulated industries (healthcare, insurance, regulatory compliance)
- **Partnership strategy**: Overseeing strategic relationships with Amazon, Google, Microsoft, Nvidia, and enterprise customers
- **Market positioning**: Claude for Healthcare and Life Sciences (announced January 11, 2026) reflects the company's stated emphasis on trust and reliability in regulated sectors[^13]

### Policy Engagement

| Area | Involvement | Notes |
|------|-------------|-------|
| AI Safety Institute collaboration | Institutional partnership | Formal agreements with US CAISI (2024) and UK AISI/AI Security Institute (2025); CAISI/AISI evaluated Constitutional Classifiers pre-deployment |
| International forums | Speaker | Presented at Stanford eCorner on Constitutional AI methodology[^15] |
| Industry standards | Participant | Responsible Scaling Policy framework; contributions to AI governance discussion |
| UK government MOU | Institutional signatory | Anthropic signed MOU with UK government to explore Claude for government services and economic modeling[^25] |

## Current Uncertainties

### Commercial vs. Safety Tensions

Key open questions around Anthropic's approach, which Amodei oversees on the commercial side, include:

- **Scaling pressures**: Whether safety priorities will be sustained under competitive market pressure, particularly as Anthropic approaches a potential IPO
- **Measurement challenges**: How safety improvements are quantified and communicated to investors and customers, and whether internal metrics translate to externally verifiable outcomes
- **Binding commitments**: Whether voluntary responsible scaling policies carry meaningful constraints absent regulatory enforcement

### Long-term Impact

- **Industry influence**: Whether Anthropic's commercial model will be replicated by other AI labs, and whether safety-first positioning produces demonstrably different outcomes
- **Policy outcomes**: How effective industry self-regulation has been in shaping AI deployment practices
- **Research translation**: Whether commercial success sustains basic safety research, or whether commercial pressures shift research priorities over time

## Sources & Resources

### Primary Sources

| Type | Resource | Description |
|------|----------|-------------|
| Company materials | [Anthropic Blog](https://www.anthropic.com/news) | Official announcements and perspectives |
| Policy documents | <R id="394ea6d17701b621">Anthropic's Responsible Scaling Policy</R> | Framework development |
| Fundraising | [Anthropic Series A Press Release](https://www.anthropic.com/news/anthropic-raises-124-million-to-build-more-reliable-general-ai-systems) | May 2021, \$124M |
| Fundraising | [Anthropic Series G Press Release](https://www.anthropic.com/news/anthropic-raises-30-billion-series-g-funding-380-billion-post-money-valuation) | February 12, 2026, \$30B |
| Safety collaboration | [Anthropic / US CAISI and UK AISI](https://www.anthropic.com/news/strengthening-our-safeguards-through-collaboration-with-us-caisi-and-uk-aisi) | Safeguard collaboration details |
| Research paper | [Constitutional AI arXiv paper](https://arxiv.org/pdf/2212.08073) | December 2022 |
| NIST | [US AI Safety Institute agreements](https://www.nist.gov/news-events/news/2024/08/us-ai-safety-institute-signs-agreements-regarding-ai-safety-research) | August 2024 |

### Analysis & Commentary

| Source | Focus | Link |
|--------|-------|------|
| CNBC | Commercial strategy, "do more with less" framing | [January 3, 2026 interview](https://www.cnbc.com/2026/01/03/anthropic-daniela-amodei-do-more-with-less-bet.html) |
| Fast Company | Enterprise AI, Claude for Healthcare announcement | [January 2026](https://www.fastcompany.com/91480487/anthropic-cofounder-daniela-amodei-says-that-ai-entreprise-business-can-trust-will-transcend-the-hype-cycle) |
| Fast Company | AI 20 profile | [November 27, 2024](https://www.fastcompany.com/90948058/how-anthropics-daniela-amodei-is-keeping-ai-grounded-in-safety) |
| CNBC | Business customer growth, named enterprise clients | [January 10, 2026](https://www.cnbc.com/2026/01/10/anthropic-amodei-siblings-generative-ai.html) |
| CBS News / 60 Minutes | AI risk and pace of change | [November 2025](https://www.cbsnews.com/news/anthropic-ceo-dario-amodei-warning-of-ai-potential-dangers-60-minutes-transcript/) |
| Fortune | Safety–commerce tensions | [February 17, 2026](https://fortune.com/2026/02/17/anthropic-ceo-dario-amodei-balancing-safety-commercial-pressure-ai-race-openai/) |
| Alignment Forum / MIT | Safety-washing critique | [Stephen Casper, May 2024](https://www.alignmentforum.org/posts/pH6tyhEnngqWAXi9i/eis-xiii-reflections-on-anthropic-s-sae-research-circa-may) |
| CNN Business | Internal departures | [February 11, 2026](https://www.cnn.com/2026/02/11/business/openai-anthropic-departures-nightcap) |
| TIME | TIME100 AI 2023 | [September 2023](https://time.com/collection/time100-ai/6309047/daniela-and-dario-amodei/) |
| Wikipedia | Biographical overview | [Daniela Amodei – Wikipedia](https://en.wikipedia.org/wiki/Daniela_Amodei) |

### Related Profiles

- <EntityLink id="E91" name="dario-amodei">Dario Amodei</EntityLink> - Co-Founder and CEO of Anthropic
- <EntityLink id="E182" name="jan-leike">Jan Leike</EntityLink> - Head of Alignment at Anthropic
- <EntityLink id="E59" name="chris-olah">Chris Olah</EntityLink> - Co-Founder and Head of Interpretability at Anthropic

[^1]: [AI Magazine, "Lifetime of Achievement: Daniela Amodei," 2024](https://aimagazine.com/articles/lifetime-of-achievement-daniela-amodei). Co-founding in December 2020 alongside Dario Amodei and other former OpenAI employees.

[^2]: [AI Magazine, "Lifetime of Achievement: Daniela Amodei," 2024](https://aimagazine.com/articles/lifetime-of-achievement-daniela-amodei). "Left OpenAI in 2020 citing concerns that the company was commercialising AI too quickly and disagreements about safe AI governance."

[^3]: [Anthropic, "Anthropic Raises \$30 Billion in Series G Funding at \$380 Billion Post-Money Valuation," February 12, 2026](https://www.anthropic.com/news/anthropic-raises-30-billion-series-g-funding-380-billion-post-money-valuation).

[^4]: [CNBC, "Anthropic's Amodei Siblings May Hold the Key to Generative AI," January 10, 2026](https://www.cnbc.com/2026/01/10/anthropic-amodei-siblings-generative-ai.html). "Daniela Amodei oversees commercial and operational side of the business... 85% of revenue comes from business customers."

[^5]: [Wikipedia contributors, "Daniela Amodei," updated February 2026](https://en.wikipedia.org/wiki/Daniela_Amodei). Education and early career details sourced here unless otherwise noted.

[^6]: [Fortune, "Anthropic Cofounder Says Studying the Humanities Will Be 'More Important Than Ever,'" February 7, 2026](https://fortune.com/2026/02/07/anthropic-cofounder-daniela-amodei-humanities-majors-soft-skills-hiring-ai-stem/). Quotes sourced from ABC News interview with Daniela Amodei, aired early February 2026.

[^7]: [Grokipedia, "Daniela Amodei," 2025](https://grokipedia.com/page/daniela_amodei). Stripe recruiting metrics and role timeline.

[^8]: [Technology Magazine, "Daniela Amodei," 2024](https://technologymagazine.com/executive/daniela-amodei). "At OpenAI: Engineering Manager + VP of People from October 2018 to May 2020. VP of Safety and Policy from May 2020 to December 2020."

[^9]: [Crunchbase, "Daniela Amodei," 2025](https://www.crunchbase.com/person/daniela-amodei-d7d3). "Co-Founder, President, and member of the Board of Directors at Anthropic."

[^10]: [Tracxn / Next Platform, Anthropic funding data, 2025–2026](https://tracxn.com/d/companies/anthropic/__SzoxXDMin-NK5tKB7ks8yHr6S9Mz68pjVCzFEcGFZ08/funding-and-investors). "Daniela Amodei personally announced the Series B (\$580 million) on X (Twitter) in April 2022."

[^11]: [Bloomberg, "Anthropic Raises \$13B Series F at \$183B Valuation," September 2, 2025](https://bloomberg.com/news/articles/2025-09-02/anthropic-completes-new-funding-round-at-183-billion-valuation). Run-rate revenue approximately \$1 billion at start of 2025, growing to over \$5 billion by August 2025.

[^12]: [Wikipedia contributors, "Anthropic," updated 2026](https://en.wikipedia.org/wiki/Anthropic). Named partnership and investment details including Amazon, Google, Microsoft/Nvidia, and Snowflake.

[^13]: [Fast Company, "Anthropic Cofounder Daniela Amodei Says Trusted Enterprise AI Will Transcend the Hype Cycle," January 2026](https://www.fastcompany.com/91480487/anthropic-cofounder-daniela-amodei-says-that-ai-entreprise-business-can-trust-will-transcend-the-hype-cycle). Includes Claude for Healthcare announcement and quoted statements.

[^14]: [CNBC, "Anthropic's Daniela Amodei on the Company's 'Do More With Less' Bet," January 3, 2026](https://www.cnbc.com/2026/01/03/anthropic-daniela-amodei-do-more-with-less-bet.html).

[^15]: [Stanford University eCorner, "Constitutional AI" (featuring Daniela Amodei), 2023](https://stvp.stanford.edu/clips/constitutional-ai/).

[^16]: [Anthropic Research Team, "Constitutional AI: Harmlessness from AI Feedback," arXiv, December 2022](https://arxiv.org/pdf/2212.08073). Daniela Amodei acknowledged for "help and support"; not listed as a technical author.

[^17]: Research found no public record of Daniela Amodei testifying before Congress or a Senate committee. Congressional testimony from Anthropic has been delivered by CEO Dario Amodei, including before the Senate Judiciary Committee on July 25, 2023.

[^18]: [TIME Magazine, "Dario and Daniela Amodei — TIME100 AI 2023," September 2023](https://time.com/collection/time100-ai/6309047/daniela-and-dario-amodei/).

[^19]: [CBS News / 60 Minutes, Anthropic interview transcript (Anderson Cooper, featuring Dario and Daniela Amodei), November 2025](https://www.cbsnews.com/news/anthropic-ceo-dario-amodei-warning-of-ai-potential-dangers-60-minutes-transcript/).

[^20]: [Sixth Street / It's Not Magic Podcast, "A Conversation with Daniela Amodei," February 19, 2026](https://sixthstreet.com/podcasts/a-conversation-with-daniela-amodei-co-founder-and-president-of-anthropic/).

[^21]: [Fast Company, "How Anthropic's Daniela Amodei Is Keeping AI from Spinning Out of Control," November 27, 2024](https://www.fastcompany.com/90948058/how-anthropics-daniela-amodei-is-keeping-ai-grounded-in-safety).

[^22]: [Stephen Casper (MIT), Alignment Forum, "EIS XIII: Reflections on Anthropic's SAE Research," May 2024](https://www.alignmentforum.org/posts/pH6tyhEnngqWAXi9i/eis-xiii-reflections-on-anthropic-s-sae-research-circa-may).

[^23]: [CNN Business, "AI researchers are sounding the alarm on their way out the door," February 11, 2026](https://www.cnn.com/2026/02/11/business/openai-anthropic-departures-nightcap). Reports Mrinank Sharma's resignation and published letter.

[^24]: [Fortune, "Anthropic was supposed to be a 'safe' alternative to OpenAI," February 17, 2026](https://fortune.com/2026/02/17/anthropic-ceo-dario-amodei-balancing-safety-commercial-pressure-ai-race-openai/).

[^25]: [NIST, "U.S. AI Safety Institute Signs Agreements with Anthropic and OpenAI," August 2024](https://www.nist.gov/news-events/news/2024/08/us-ai-safety-institute-signs-agreements-regarding-ai-safety-research). Includes reference to UK MOU.

