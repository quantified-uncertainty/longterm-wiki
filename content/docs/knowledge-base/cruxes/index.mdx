---
title: Key Cruxes
description: Uncertainties that drive disagreement and prioritization in AI safety
sidebar:
  label: Overview
  order: 0
---
import {EntityLink} from '@components/wiki';


## Overview

Cruxes are key uncertainties where different beliefs lead to substantially different conclusions about AI safety priorities. Identifying and tracking cruxes helps clarify what evidence would be most valuable and where reasonable people disagree.

## Crux Categories

### <EntityLink id="accident-risks">Accident Risk Cruxes</EntityLink>
Uncertainties about unintended AI failures:
- Will advanced AI systems develop misaligned goals?
- Can we detect <EntityLink id="deceptive-alignment">deceptive alignment</EntityLink> before deployment?
- How likely is <EntityLink id="mesa-optimization">mesa-optimization</EntityLink> in large models?
- Will AI systems seek power instrumentally?

### <EntityLink id="misuse-risks">Misuse Risk Cruxes</EntityLink>
Uncertainties about deliberate harmful use:
- How much do AI capabilities "uplift" bioweapon development?
- Will <EntityLink id="autonomous-weapons">autonomous weapons</EntityLink> proliferate faster than defenses?
- Can AI-generated <EntityLink id="disinformation">disinformation</EntityLink> be reliably detected?

### <EntityLink id="structural-risks">Structural Risk Cruxes</EntityLink>
Uncertainties about systemic dynamics:
- Will <EntityLink id="racing-dynamics">racing dynamics</EntityLink> dominate lab behavior?
- Is <EntityLink id="values">value lock-in</EntityLink> a serious concern on realistic timelines?
- How concentrated will AI capabilities become?

### <EntityLink id="epistemic-risks">Epistemic Risk Cruxes</EntityLink>
Uncertainties about knowledge and truth:
- Will AI accelerate or undermine human epistemic capacity?
- Can authentication systems keep pace with generative AI?
- Will <EntityLink id="expertise-atrophy">expertise atrophy</EntityLink> be reversible?

### <EntityLink id="solutions">Solution Cruxes</EntityLink>
Uncertainties about intervention effectiveness:
- Is alignment research on track to succeed?
- Can governance keep pace with capability development?
- Will <EntityLink id="international-coordination">international coordination</EntityLink> be achievable?

## Using Cruxes

Cruxes help:
- **Prioritize research** - Focus on resolving highest-value uncertainties
- **Bridge disagreements** - Identify where people actually differ
- **Track progress** - Monitor how uncertainties resolve over time
- **Inform forecasting** - Structure predictions around key variables
