---
title: Longtermism's Philosophical Credibility After FTX
description: An examination of how the FTX collapse affected longtermism's
  standing as a philosophical movement, including reputational damage, funding
  disruptions, and ongoing debates about the ideology's core claims.
importance: 50
lastEdited: "2026-02-19"
sidebar:
  order: 50
ratings:
  novelty: 4
  rigor: 6
  actionability: 3
  completeness: 7
readerImportance: 58
tacticalValue: 52
quality: 50
llmSummary: "This article examines the dual impact of the FTX collapse on
  longtermism: severe reputational and funding damage (including $160M in lost
  Future Fund commitments and FHI's 2024 closure), alongside pre-existing and
  continuing philosophical critiques about probability cluelessness,
  ends-justify-means reasoning, and power concentration that remain unresolved
  regardless of SBF's misconduct. The article concludes that both the
  reputational and philosophical questions remain genuinely open, with defenders
  maintaining the fraud reflects individual failure rather than ideological
  corruption."
balanceFlags:
  - missing-primary-sources
---
import {EntityLink, R, F, Calc, DataInfoBox, DataExternalLinks} from '@components/wiki';

## Quick Assessment

| Dimension | Assessment |
|-----------|-----------|
| **Philosophical Status** | Contested; core claims remain defended but face renewed scrutiny |
| **Reputational Damage** | Severe in late 2022–2023; partial recovery ongoing |
| **Funding Impact** | \$160M in FTX Future Fund commitments lost; broader EA ecosystem disrupted |
| **Institutional Status** | Mixed; Future of Humanity Institute closed (2024), others persist |
| **Ongoing Credibility** | Defended by MacAskill and Ord; challenged by critics on independent philosophical grounds |

## Key Links

| Source | Link |
|--------|------|
| Radical Philosophy critique | [radicalphilosophy.com](https://www.radicalphilosophy.com/commentary/the-toxic-ideology-of-longtermism) |
| Wikipedia (Effective Altruism) | [en.wikipedia.org](https://en.wikipedia.org/wiki/Effective_altruism) |
| Wikipedia (Longtermism) | [en.wikipedia.org](https://en.wikipedia.org/wiki/Longtermism) |
| 80,000 Hours introduction | [80000hours.org](https://80000hours.org/articles/future-generations/) |
| Émile Torres (Aeon critique) | [aeon.co](https://aeon.co/essays/why-longtermism-is-the-worlds-most-dangerous-secular-credo) |

## Overview

Longtermism is the ethical view that positively influencing the long-term future of humanity constitutes a key moral priority of our time. Developed most prominently by philosophers William MacAskill and Toby Ord within the <EntityLink id="E517">Centre for Effective Altruism</EntityLink> ecosystem, the philosophy holds that future generations deserve equal moral consideration to those alive today, that the potential scale of future human lives dwarfs the present population, and that actions reducing existential risks—such as AI misalignment, engineered pandemics, or nuclear conflict—carry enormous expected value as a result.[^1] Its institutional expression included the <EntityLink id="E140">Future of Humanity Institute</EntityLink> at Oxford, the Global Priorities Institute, and a network of researchers and grantmakers funded substantially through <EntityLink id="E552">Open Philanthropy</EntityLink> and, critically, through Sam Bankman-Fried's <EntityLink id="E855">FTX Future Fund</EntityLink>.[^2]

The collapse of <EntityLink id="E856">FTX</EntityLink> in November 2022 and Bankman-Fried's subsequent conviction on fraud charges precipitated a significant crisis for the longtermist movement. Bankman-Fried had been one of longtermism's most prominent public funders, pledging the bulk of his fortune—which peaked at approximately \$16 billion—to effective altruist and longtermist causes.[^3] The <EntityLink id="E855">FTX Future Fund</EntityLink> had committed \$160 million to longtermist researchers and organizations, funding that became unrecoverable when the exchange filed for bankruptcy.[^4] The scandal prompted intense public debate about whether longtermism's philosophical framework had, in some sense, licensed or enabled the misconduct—or whether the ideology simply suffered guilt by association with a fraudulent donor.

The question of philosophical credibility after FTX thus splits along two axes. The first concerns reputational damage: the movement's public standing, institutional health, and ability to attract funding and talent. The second is more fundamental: whether critics had identified genuine theoretical weaknesses in longtermism that the scandal brought into sharper relief, or whether the philosophy's core arguments remain intact regardless of who funds them. Both debates remain unresolved, and academic scrutiny of longtermism's foundations—including a Leverhulme Trust–funded research project at the University of Bristol announced in 2024—continues to intensify.[^5]

## History and Background

### Origins in Effective Altruism

Longtermism emerged from the effective altruism (EA) movement, which applies utilitarian-influenced reasoning to maximize the good achievable through philanthropy and career choices. Peter Singer's work on the moral obligations of affluent individuals toward distant strangers provided the philosophical foundation, but EA gradually shifted its center of gravity during the 2010s from near-term interventions—global health, poverty alleviation—toward longer-horizon concerns.[^6] MacAskill is credited with coining the term "longtermism" in 2017, and the movement crystallized around two major texts: Toby Ord's *The Precipice* (2020) and MacAskill's *What We Owe the Future* (2022).[^7]

The institutional infrastructure that developed around this philosophical shift was substantial. By 2021, the EA movement had accumulated \$46 billion in dedicated funding, much of it directed toward existential risk research.[^8] The <EntityLink id="E140">Future of Humanity Institute</EntityLink> and the Global Priorities Institute at Oxford served as academic homes for longtermist research, while <EntityLink id="E510">80,000 Hours</EntityLink> steered early-career professionals toward longtermist cause areas including AI safety and biosecurity.

### Sam Bankman-Fried and FTX's Role

Bankman-Fried's relationship with EA began in 2012 when MacAskill advised him to pursue "earning to give"—a strategy of maximizing income in order to donate at scale—as an effective altruistic path.[^9] Bankman-Fried went on to found the cryptocurrency exchange FTX and became one of the movement's most prominent funders. He pledged to donate the overwhelming majority of his fortune to EA and longtermist causes, and established the <EntityLink id="E855">FTX Future Fund</EntityLink> as the vehicle for this giving. He publicly identified his primary commitment as longtermist in character, stating that his interest was not in helping the global poor but in causes aligned with long-run human potential.[^10]

The FTX Future Fund committed \$160 million to longtermist projects before the exchange's collapse.[^4] When FTX filed for bankruptcy in November 2022 amid revelations that customer funds had been misappropriated—allegedly to support affiliated trading firm Alameda Research—the Future Fund team, including its director Nick Beckstead, resigned. FTX's bankruptcy CEO John J. Ray III described the collapse as worse than Enron, citing a complete failure of corporate controls.[^11] Bankman-Fried was subsequently convicted on multiple counts of wire fraud and securities fraud.

## The Reputational Fallout

The immediate consequences for longtermism's public standing were severe. MacAskill, who had been actively promoting *What We Owe the Future* at the time of the collapse, acknowledged the damage directly, stating that if his work had in any way laundered fraudulent conduct, he was ashamed.[^12] <EntityLink id="E510">80,000 Hours</EntityLink> expressed deep regret at having placed trust in Bankman-Fried and acknowledged the organization was grappling with the lessons of the collapse.[^13]

Critics argued the scandal revealed something structural rather than merely incidental. Longtermism's movement had grown to depend on a small number of extremely wealthy donors—a concentration of philanthropic power that left it vulnerable to the ethical failures of individual actors and insulated from the democratic accountability that might otherwise have checked them.[^14] The movement's funding apparatus, observers noted, tended to funnel substantial resources back into EA institution-building and movement growth, raising questions about whether the primary beneficiary of longtermist philanthropy was the longtermist movement itself.[^15]

Some EA leaders received warnings about concerns regarding Bankman-Fried's conduct well before the collapse, yet failed to act decisively on those warnings—a lapse that critics read as evidence of insufficient internal accountability mechanisms within the EA ecosystem.[^16] Peter Singer, whose philosophical work had inspired EA's founding generation, acknowledged that the reputational damage from the FTX collapse was immense and expressed uncertainty about the movement's near-term recovery prospects.[^17]

The <EntityLink id="E140">Future of Humanity Institute</EntityLink>, the most prominent institutional expression of academic longtermism, closed in 2024—though the closure was attributable to a combination of factors including internal difficulties and its relationship with Oxford University, not solely the FTX scandal.

## Philosophical Critiques Independent of FTX

It is important to distinguish between reputational damage arising from association with fraud and substantive philosophical critiques—some of which predate FTX and continue to develop on independent grounds.

### The Prioritization Problem

A central objection to longtermism concerns its treatment of present versus future welfare. Because longtermist calculations assign equal moral weight to future individuals, and because the potential future human population vastly outnumbers those alive today—potentially by ratios of thousands to one if humanity persists for millions of years—longtermist reasoning systematically tends to direct resources toward speculative future risks rather than concrete contemporary suffering.[^6] Critics argue that when this logic is applied consistently, it renders nearly every immediate problem less important than existential risk mitigation, effectively licensing the neglect of poverty, climate change, and other present injustices.[^19]

Philosophers have argued that while care for the future is warranted, the framework imposes demands on present resources that cannot be plausibly justified, and that future people vastly outnumbering the living does not straightforwardly imply their interests should dominate moral decision-making in the ways longtermists suggest.[^19]

### The "Ends Justify Means" Concern

Several critics have argued that longtermism's consequentialist architecture—its insistence that actions be evaluated purely by their expected long-term outcomes—creates insufficient ethical guardrails against harmful behavior in the present. Because Bankman-Fried was, by his own description, a committed consequentialist, some observers raised the question of whether his fraudulent conduct could be rationalized within a framework that prizes outcome maximization.[^21] This is not to say that longtermism endorses fraud; MacAskill and Ord explicitly denied that it does. But critics contended that a philosophy oriented around scale-sensitive expected value calculations may systematically underweight deontological constraints—honesty, informed consent, fiduciary duty—that are not easily quantified.[^22]

Philosopher Alice Crary argued that longtermism's corruption is inseparable from the way its core ideas are put into practice, suggesting the problem is not merely one of bad individual actors but of structural features of the ideology.[^23]

### Theoretical Weaknesses

Beyond the FTX controversy, critics have identified several internal philosophical vulnerabilities. Émile Torres, writing in *Aeon* prior to the FTX collapse, characterized longtermism as the world's most dangerous secular credo, arguing that its emphasis on maximizing the long-run potential of the human species could justify extreme technological acceleration and concentration of power in the present, and that it risks treating current individuals as mere instrumentalities for future value rather than as beings with intrinsic moral worth.[^24]

The probability mathematics underlying longtermist prioritization have also attracted criticism. Longtermist arguments often hold that even very small reductions in extinction probability—on the order of one billionth of one percent—carry more expected value than saving billions of current lives, given the astronomical scale of potential future generations.[^25] Critics argue this reasoning is only as robust as the underlying probability estimates, which are themselves highly uncertain and potentially subject to motivated reasoning by those with institutional interests in existential risk research. Philosophers of ethics have identified "cluelessness"—the difficulty of predicting how present actions will propagate through complex causal chains over long timescales—as a fundamental challenge for any consequentialist framework, including longtermism.[^25]

Separately, a Leverhulme Trust–funded research project at the University of Bristol, led by Professor Richard Pettigrew and announced in 2024, is undertaking a three-year critical examination of longtermism's foundational arguments, specifically scrutinizing the case for prioritizing the interests of trillions of future people over the eight billion currently alive.[^5]

### Internal Incoherence

Some critics have pointed to a potential self-undermining quality in longtermism's demands. If present generations are required to make substantial sacrifices in the service of future flourishing, and if this pattern persists across time, the result may be a history of continuous present-day privation whose benefits accrue only to a final generation—a structure that undermines the philosophy's own goal of ensuring humanity's long-run welfare.[^27]

## Defenders' Responses

Proponents of longtermism have consistently maintained that the FTX scandal reflects the moral failures of an individual, not the validity of a philosophical framework. MacAskill's and Ord's arguments rest on three premises—that future people matter morally, that future populations could be enormous in scale, and that current actions can reliably influence existential outcomes—none of which is touched by what any particular donor did with cryptocurrency exchange funds.[^28]

Defenders also note that longtermism encompasses a range of positions, from MacAskill's more modest claim that long-term impact is *a* key moral priority, to stronger versions holding that it is *the* overwhelming priority. The more cautious formulations explicitly recommend robust actions under uncertainty, including option-preservation, avoidance of irreversible harms, and epistemic humility—recommendations not obviously in tension with conventional ethical constraints.[^29]

On the question of present neglect, some defenders argue that longtermism is compatible with significant near-term intervention and that its critics set up a false opposition. Pandemic preparedness, for instance, serves both near-term public health and long-run existential risk reduction; AI safety research is relevant both to current harms from deployed systems and to hypothetical future catastrophe.[^30]

The movement also retains substantial institutional support. Elon Musk has publicly characterized longtermism as closely matching his own philosophical commitments.[^31] <EntityLink id="E552">Open Philanthropy</EntityLink> continues to fund existential risk research, and academic interest in the field persists despite the loss of FTX-linked funding.

## Criticisms and Concerns

### Association with Undemocratic Power Concentration

One of the most persistent criticisms concerns longtermism's relationship to concentrated private wealth. The movement's philanthropic infrastructure has historically depended on a small number of extremely wealthy technology entrepreneurs who exercise significant influence over research agendas and institutional priorities without meaningful democratic oversight.[^14] Critics characterize this as wealth-derived power operating in the public sphere with minimal civic accountability, and argue that the FTX scandal exemplified the risks inherent in such concentration.

### Ethics Washing

The FTX collapse led critics to argue that longtermist and EA identity functioned as a form of ethics washing—presenting a philanthropic persona that provided social legitimacy and political access while underlying financial practices were deeply problematic. Bankman-Fried's congressional testimony emphasized his philanthropic commitments even as his exchange allegedly misused customer funds.[^32] Whether this represents a systemic feature of longtermist culture or an individual's cynical exploitation of it remains contested.

### The Absence of Actionable Interventions

A practical critique that has gained traction in philosophical forums concerns the difficulty of identifying concrete, tractable interventions that reliably reduce existential risk by meaningful amounts. Critics note that despite longtermism's claimed priority, no clearly promising longtermist interventions have emerged that meet the movement's own standards for evidence-based impact—a gap that raises questions about whether the framework generates useful action-guidance or primarily functions as a reputational and funding ecosystem.[^33]

## Key Uncertainties

Several significant questions remain open:

- **Philosophical independence from scandal**: Whether the core philosophical arguments of longtermism can be evaluated cleanly apart from their institutional context and funding history is disputed. Critics like Crary argue the ideas and their implementation are inseparable; defenders maintain the opposite.
- **Probability and cluelessness**: The degree to which existential risk estimates are tractable versus speculative remains unresolved. If longtermist calculations depend on probabilities that cannot be reliably estimated, the expected-value case for prioritizing existential risk over near-term interventions becomes substantially weaker.
- **Institutional recovery**: Whether EA and longtermist institutions will recover funding and public credibility comparable to their pre-2022 levels is unclear. The closure of the <EntityLink id="E140">Future of Humanity Institute</EntityLink> and the loss of FTX funding represent significant institutional setbacks.
- **Philosophical response**: How longtermism's academic defenders will respond to the growing body of philosophical criticism—including the Bristol Foundations of Longtermism project—remains to be seen. No consensus shift in the philosophy's core commitments has occurred to date.

## Sources

[^1]: [Longtermism - Wikipedia](https://en.wikipedia.org/wiki/Longtermism)
[^2]: [Longtermism: A Philosophy to Last a Lifetime or Two - Oxford Political Review](https://www.oxjournal.org/longtermism-a-philosophy-to-last-a-lifetime-or-two/)
[^3]: [OK, WTF Is Longtermism? - VICE](https://www.vice.com/en/article/ok-wtf-is-longtermism-the-tech-elite-ideology-that-led-to-the-ftx-collapse/)
[^4]: [Effective Altruism and Longtermism: The Elite Tech Ideologies Damaged by FTX - The Week](https://theweek.com/cryptocurrencies/958633/effective-altruism-and-longtermism-the-elite-tech-ideologies-damaged-by)
[^5]: [Who Else Belongs to My Moral Circle? The Foundations of Longtermism - University of Bristol](https://artsmatter.blogs.bristol.ac.uk/2024/11/21/who-else-belongs-to-my-moral-circle-the-foundations-of-longtermism/)
[^6]: [Long-termism: An Ethical Trojan Horse - Carnegie Council](https://www.carnegiecouncil.org/media/article/long-termism-ethical-trojan-horse)
[^7]: [Centre for Effective Altruism - Longtermism](https://www.centreforeffectivealtruism.org/longtermism)
[^8]: [Longtermism: A Philosophy to Last a Lifetime or Two - Oxford Political Review](https://www.oxjournal.org/longtermism-a-philosophy-to-last-a-lifetime-or-two/)
[^9]: [Sam Bankman-Fried, Effective Altruism, and Alameda - TIME](https://time.com/6262810/sam-bankman-fried-effective-altruism-alameda-ftx/)
[^10]: [OK, WTF Is Longtermism? - VICE](https://www.vice.com/en/article/ok-wtf-is-longtermism-the-tech-elite-ideology-that-led-to-the-ftx-collapse/)
[^11]: [What the FTX Collapse Teaches Us About Ethics - Principia Advisory](https://www.principia-advisory.com/2023/03/24/what-the-ftx-collapse-teaches-us-about-ethics/)
[^12]: [Effective Altruism and Longtermism: The Elite Tech Ideologies Damaged by FTX - The Week](https://theweek.com/cryptocurrencies/958633/effective-altruism-and-longtermism-the-elite-tech-ideologies-damaged-by)
[^13]: [Wrong Lessons from the FTX Catastrophe - EA Forum](https://forum.effectivealtruism.org/posts/DB9ggzc5u9RMBosoz/wrong-lessons-from-the-ftx-catastrophe)
[^14]: [The Toxic Ideology of Longtermism - Radical Philosophy](https://www.radicalphilosophy.com/commentary/the-toxic-ideology-of-longtermism)
[^15]: [Why Effective Altruism and Longtermism Are Toxic Ideologies - Current Affairs](https://www.currentaffairs.org/news/2023/05/why-effective-altruism-and-longtermism-are-toxic-ideologies)
[^16]: [Sam Bankman-Fried, Effective Altruism, and Alameda - TIME](https://time.com/6262810/sam-bankman-fried-effective-altruism-alameda-ftx/)
[^17]: [The Toxic Ideology of Longtermism - Radical Philosophy](https://www.radicalphilosophy.com/commentary/the-toxic-ideology-of-longtermism)
[^19]: [Why Longtermism Is the World's Most Dangerous Secular Credo - Aeon](https://aeon.co/essays/why-longtermism-is-the-worlds-most-dangerous-secular-credo)
[^21]: [FTX, EA Principles, and the Longtermist EA Community - EA Forum](https://forum.effectivealtruism.org/posts/st59vLvsorvQhqvBr/ftx-ea-principles-and-the-longtermist-ea-community)
[^22]: [Back to Virtue: Effective Altruism After FTX - MercatorNet](https://www.mercatornet.com/back-to-virtue-effective-altruism-after-ftx)
[^23]: [The Toxic Ideology of Longtermism - Radical Philosophy](https://www.radicalphilosophy.com/commentary/the-toxic-ideology-of-longtermism)
[^24]: [Why Longtermism Is the World's Most Dangerous Secular Credo - Aeon](https://aeon.co/essays/why-longtermism-is-the-worlds-most-dangerous-secular-credo)
[^25]: [Longtermism - Wikipedia](https://en.wikipedia.org/wiki/Longtermism)
[^27]: [On the Fundamental Incoherence of Longtermism - Mind Your Metaphysics (Substack)](https://mindyourmetaphysics.substack.com/p/on-the-fundamental-incoherence-of)
[^28]: [Centre for Effective Altruism - Longtermism](https://www.centreforeffectivealtruism.org/longtermism)
[^29]: [Longtermism - 80,000 Hours](https://80000hours.org/articles/future-generations/)
[^30]: [What Will FTX's Collapse Mean for Global Health and Development? - Devex](https://www.devex.com/news/what-will-ftx-s-collapse-mean-for-global-health-and-development-104480)
[^31]: [Effective Altruism and Longtermism: The Elite Tech Ideologies Damaged by FTX - The Week](https://theweek.com/cryptocurrencies/958633/effective-altruism-and-longtermism-the-elite-tech-ideologies-damaged-by)
[^32]: [What the FTX Collapse Teaches Us About Ethics - Principia Advisory](https://www.principia-advisory.com/2023/03/24/what-the-ftx-collapse-teaches-us-about-ethics/)
[^33]: [Why Haven't We Seen a Promising Longtermist Intervention Yet? - EA Forum](https://forum.effectivealtruism.org/posts/LSfZKPFHzwJgdhF5f/why-haven-t-we-seen-a-promising-longtermist-intervention-yet)
