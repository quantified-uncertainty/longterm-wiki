---
title: History
description: Timeline of AI safety as a field
sidebar:
  label: Overview
  order: 0
---
import {EntityLink} from '@components/wiki';


## Overview

This section traces the development of AI safety as a field, from early theoretical concerns to the current mainstream recognition of AI risks. Understanding this history helps contextualize current debates and institutional structures.

## Historical Eras

### <EntityLink id="miri-era">MIRI Era (2000-2015)</EntityLink>
The field's founding period, dominated by the <EntityLink id="miri">Machine Intelligence Research Institute</EntityLink>:
- <EntityLink id="eliezer-yudkowsky">Eliezer Yudkowsky</EntityLink>'s early writings on AI risk
- Founding of SIAI (later MIRI) in 2000
- Development of foundational concepts (orthogonality thesis, <EntityLink id="instrumental-convergence">instrumental convergence</EntityLink>)
- *Superintelligence* (2014) brings ideas to academic attention

### <EntityLink id="deep-learning-era">Deep Learning Era (2015-2022)</EntityLink>
Deep learning breakthroughs reshape the landscape:
- AlphaGo (2016) demonstrates superhuman capability
- GPT-2 (2019) shows language model potential
- <EntityLink id="anthropic">Anthropic</EntityLink> founded (2021) by former <EntityLink id="openai">OpenAI</EntityLink> safety team
- Growing recognition in ML community

### <EntityLink id="early-warnings">Early Warnings (2022-2023)</EntityLink>
AI safety enters public consciousness:
- ChatGPT (Nov 2022) captures public attention
- Pause letter (March 2023) signed by prominent researchers
- <EntityLink id="geoffrey-hinton">Geoffrey Hinton</EntityLink> leaves Google to speak freely about risks
- Congressional hearings on AI safety

### <EntityLink id="mainstream-era">Mainstream Era (2023-Present)</EntityLink>
AI safety becomes a policy priority:
- Biden Executive Order on AI (Oct 2023)
- Bletchley Park AI Safety Summit (Nov 2023)
- <EntityLink id="ai-safety-institutes">AI Safety Institutes</EntityLink> established globally
- Major labs adopt <EntityLink id="rsp">responsible scaling policies</EntityLink>

## Key Milestones

| Year | Event | Significance |
|------|-------|--------------|
| 2000 | SIAI founded | First AI safety organization |
| 2014 | *Superintelligence* published | Brought ideas to academia |
| 2017 | Asilomar Principles | Early multi-stakeholder agreement |
| 2022 | ChatGPT released | Public awareness breakthrough |
| 2023 | UK AI Safety Summit | First major government summit |
| 2024 | <EntityLink id="eu-ai-act">EU AI Act</EntityLink> enacted | First comprehensive AI regulation |
