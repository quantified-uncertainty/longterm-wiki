---
title: LAWS Proliferation Model
description: This model tracks lethal autonomous weapons proliferation. It projects 50% of militarily capable nations will have LAWS by 2030, proliferating 4-6x faster than nuclear weapons and reaching non-state actors by 2030-2032.
sidebar:
  order: 24
quality: 60
lastEdited: "2025-12-26"
ratings:
  focus: 8.5
  novelty: 5
  rigor: 6.5
  completeness: 7.5
  concreteness: 7
  actionability: 5.5
importance: 68.5
update_frequency: 90
llmSummary: Quantitative model projects LAWS will proliferate 4-6x faster than nuclear weapons, reaching 60 nations by 2030 and non-state operational use by 2030-2032, with assassination costs dropping from $500K-5M to $1K-10K. Assigns 75% probability to scenarios where control mechanisms fail due to dual-use technology barriers, recommending defensive technology investment ($5-10B annually) and attribution mechanisms over prevention-focused strategies.
todos:
  - Complete 'Quantitative Analysis' section (8 placeholders)
clusters:
  - ai-safety
  - governance
  - cyber
subcategory: domain-models
---
import {DataInfoBox, Mermaid, EntityLink} from '@components/wiki';

<DataInfoBox entityId="autonomous-weapons-proliferation" ratings={frontmatter.ratings} />

## Overview

Lethal <EntityLink id="autonomous-weapons">Autonomous Weapons</EntityLink> Systems (LAWS) represent one of the fastest-proliferating military technologies in history, spreading from advanced militaries to regional powers and increasingly to non-state actors at a pace that dramatically outstrips historical precedents like nuclear weapons. Unlike nuclear technology, which requires rare materials, massive infrastructure, and generates detectable signatures, autonomous weapons rely entirely on dual-use commercial technology—artificial intelligence models, computer vision systems, and consumer drones—that proliferates through normal economic channels and cannot be meaningfully restricted without crippling civilian industries. This creates a fundamentally different <EntityLink id="proliferation">proliferation</EntityLink> dynamic where barriers to entry drop exponentially as AI capabilities improve and commercial hardware becomes more sophisticated.

This model analyzes LAWS diffusion through five distinct proliferation stages, from great power development to mass individual access, and projects that by 2030, approximately 60 nations will possess autonomous weapons capabilities, with non-state actors achieving regular operational use by the mid-2030s. The central question is whether any form of proliferation control remains feasible given the dual-use nature of enabling technologies, or whether the global security community must accept widespread LAWS proliferation as inevitable and focus instead on damage limitation, defensive countermeasures, and attribution mechanisms.

The key insight emerging from quantitative proliferation modeling is that LAWS follow an S-curve diffusion pattern similar to civilian technologies rather than the linear, barrier-constrained progression of nuclear weapons, suggesting that the 2025-2030 period represents a critical inflection point where proliferation accelerates dramatically and opportunities for control narrow to near-zero. This matters because once autonomous weapons reach widespread availability among both state and non-state actors, the risks of assassination-at-scale, authoritarian repression, and lowered thresholds for violence become structural features of the international system rather than manageable threats.

## Conceptual Framework

The proliferation of autonomous weapons follows a five-stage diffusion model that parallels technology adoption curves but proceeds at unprecedented speed due to the dual-use nature of enabling technologies. Each stage is characterized by distinct actor types, capability levels, and deployment patterns, with the transition between stages driven primarily by three factors: declining cost of AI and hardware, increasing availability of technical knowledge through open-source channels, and weakening of export control mechanisms as commercial applications overwhelm <EntityLink id="regulatory-capacity">regulatory capacity</EntityLink>.

<Mermaid chart={`
flowchart TD
    A[Great Power R&D] --> B{Technology Maturation}
    B -->|Export Sales| C[Regional Power Adoption]
    B -->|Commercial Dual-Use| D[Widespread State Access]
    C --> E{Control Mechanisms Effective?}
    D --> E
    E -->|No| F[Non-State Actor Access]
    E -->|Yes| G[Limited Proliferation]
    F --> H[Mass Availability]
    H --> I[Assassination-at-Scale Capability]

    style A fill:#e1f5ff
    style C fill:#fff4e1
    style D fill:#fff4e1
    style F fill:#ffe1e1
    style H fill:#ff9999
    style I fill:#ff6666
`} />

The diagram illustrates how proliferation proceeds through multiple parallel pathways—direct military-to-military technology transfer and commercial dual-use diffusion—that converge to enable non-state access unless effective control mechanisms are established during the regional adoption phase. The critical branching point occurs at Stage 3-4 transition, where the window for meaningful proliferation control effectively closes.

### Five-Stage Proliferation Model

| Stage | Timeline | Actor Type | Access Method | Capability Level | Current Status |
|-------|----------|------------|---------------|------------------|----------------|
| Stage 1: Great Power Development | 2015-2023 | U.S., China, Russia, Israel | Indigenous R&D | Advanced autonomy, military-grade | Complete (100%) |
| Stage 2: Regional Power Adoption | 2020-2026 | Turkey, Iran, UK, France, India, S. Korea | Licensed/adapted systems | Mid-tier autonomy | Ongoing (70%) |
| Stage 3: Widespread State Access | 2024-2030 | 30-50 nations | Commercial/export | Variable sophistication | Emerging (30%) |
| Stage 4: Non-State Actor Access | 2026-2032 | Militant groups, terrorist orgs | Commercial drones + DIY | Basic-to-moderate autonomy | Early signs (8%) |
| Stage 5: Mass Availability | 2030+ | Individuals with technical skills | Consumer hardware mods | Basic autonomy | Not reached (2%) |

The table quantifies the progression through proliferation stages, showing that as of 2025, the world is simultaneously in three overlapping stages, with great power capabilities fully mature while non-state access is beginning to emerge. The compression of timelines—Stage 1 through Stage 4 occurring within just 10-15 years—contrasts sharply with nuclear proliferation, which took over 60 years to reach nine state actors and has never achieved non-state access at scale.

## Current Proliferation State (2025)

### Nations with Documented LAWS Programs

**Tier 1 (Advanced, Deployed):**
- **United States:** Loyal Wingman drones, Autonomous Air Defense
- **China:** Extensive autonomous drone programs, swarming capabilities
- **Israel:** Harpy/Harop loitering munitions, autonomous defense systems
- **Turkey:** Kargu-2, STM Kargu (documented autonomous use in Libya)
- **Russia:** Claimed autonomous systems (verification difficult)

**Tier 2 (Developing, Testing):**
- **Ukraine:** AI-enabled FPV drones, autonomous targeting (4M annual production capacity)
- **Iran:** Shahed drones with increasing autonomy
- **UK, France, Germany:** Collaborative European programs
- **South Korea:** DMZ autonomous sentry guns
- **India:** Development programs

**Tier 3 (Early Research/Procurement):**
- 20-30 additional nations with announced programs

**Total:** ~40-50 nations with some level of autonomous weapons capability

### Technology Diffusion Pathways

**1. Direct Military Development**
Nations with advanced AI capabilities develop indigenous systems
- High cost, high capability
- Examples: U.S., China

**2. Technology Transfer & Sales**
Advanced nations sell or license systems to allies
- Medium cost, high capability
- Examples: Israeli systems sold internationally

**3. Commercial Adaptation**
Military adaptation of commercial drone/AI technology
- Low cost, medium capability
- Examples: Ukraine's modified commercial drones

**4. Reverse Engineering**
Captured or crashed systems reverse-engineered
- Medium cost, medium capability
- Examples: Iran's drone programs

**5. Open-Source AI + Commercial Hardware**
Public AI models combined with readily available drones
- Very low cost, low-medium capability
- Examples: DIY autonomous targeting systems

## Comparative Proliferation Analysis

The speed at which autonomous weapons proliferate can be quantified by comparing proliferation milestones to historical precedents. Nuclear weapons provide the most relevant comparison as the last major weapons technology subject to international control efforts, though the comparison reveals how fundamentally different LAWS proliferation dynamics operate.

### Nuclear vs. Autonomous Weapons Proliferation Timelines

| Technology | 5 Nations | 10 Nations | 20 Nations | 50 Nations | Non-State Access |
|------------|-----------|------------|------------|------------|------------------|
| Nuclear Weapons | 19 years | Never reached | Never reached | Never reached | Never achieved |
| Autonomous Weapons | 3-5 years | 5-7 years | 7-10 years (projected) | 10-15 years (projected) | 10-15 years (projected) |
| Proliferation Rate Multiplier | **4-6x faster** | **∞ (nuclear never reached)** | Not comparable | Not comparable | Unique to LAWS |

The table reveals that autonomous weapons proliferate at 4-6 times the rate of nuclear weapons in early stages, but the comparison breaks down entirely at higher proliferation levels because nuclear weapons never achieved widespread state proliferation and never reached non-state actors at scale. LAWS are projected to reach more nations by 2032 than nuclear weapons have reached in 80 years, while simultaneously becoming accessible to non-state actors—a proliferation outcome that nuclear weapons control successfully prevented.

### Structural Barriers Comparison

Understanding why LAWS proliferate faster requires analyzing the structural barriers that slow or enable diffusion. The following table quantifies the relative difficulty across five critical barrier categories:

| Barrier Type | Nuclear Weapons | Autonomous Weapons | LAWS Advantage Factor |
|--------------|-----------------|-------------------|----------------------|
| Material Requirements | Enriched uranium/plutonium (extremely rare) | Computer chips, sensors, cameras (commodity hardware) | 1000x easier |
| Infrastructure Cost | \$5B-\$50B for weapons program | \$50K-\$5M for basic capability | 10,000x cheaper |
| Technical Knowledge | Highly classified, restricted | Published in journals, open-source | 100x more accessible |
| Dual-Use Legitimacy | Very low (enrichment primarily military) | Very high (AI/drones overwhelmingly civilian) | Impossible to restrict |
| Detection/Verification | Satellite imagery, radiation signatures | Indistinguishable from civilian activity | 1000x harder to verify |

This barrier analysis explains the divergent proliferation trajectories. Nuclear weapons face compounding barriers—rare materials AND high costs AND classification AND detectability—that multiply to create extremely high total barriers. LAWS face diminishing barriers—each enabling technology becomes cheaper, more accessible, and more legitimately dual-use over time—creating a proliferation environment where barriers approach zero asymptotically. The cost advantage alone (10,000x cheaper) makes LAWS accessible to actors that could never contemplate nuclear weapons development, while the verification impossibility means that even moderately effective control regimes cannot be constructed around detection mechanisms.

## Quantitative Proliferation Model

The diffusion of autonomous weapons can be modeled using a logistic growth function adapted from technology adoption theory and epidemiological modeling. This approach captures the S-curve pattern observed in technology proliferation, where adoption starts slowly among early adopters, accelerates rapidly during a growth phase, then saturates as the market approaches capacity.

### Mathematical Formulation

$$
N(t) = \frac{K}{1 + e^{-r(t - t_0)}}
$$

Where:
- $N(t)$ = Number of nations with operational LAWS capability at time $t$
- $K$ = Maximum potential adopters (saturation point)
- $r$ = Proliferation rate parameter (controls steepness of adoption curve)
- $t_0$ = Inflection point (year when adoption growth rate peaks)
- $t$ = Time in years since 2015 (baseline year)

### Parameter Estimates

| Parameter | Best Estimate | Range | Confidence | Justification |
|-----------|--------------|-------|------------|---------------|
| $K$ (Max adopters) | 120 nations | 100-140 | High | Excludes smallest states lacking military capacity |
| $r$ (Growth rate) | 0.35 per year | 0.28-0.45 | Medium | Faster than conventional military tech (0.15-0.25), slower than pure commercial tech (0.5-0.8) |
| $t_0$ (Inflection year) | 2025 | 2024-2027 | Medium | Observable acceleration in procurement and deployment |
| Current adopters (2025) | 20 nations | 15-25 | High | Based on documented programs |

The parameter estimates reflect LAWS' hybrid nature: proliferation proceeds faster than traditional military technology due to dual-use characteristics but slower than purely commercial technology due to remaining institutional and policy barriers. The relatively high $r$ value of 0.35 captures the acceleration effect of improving AI capabilities and declining hardware costs, while the inflection point at 2025 reflects the current transition from early adopter phase to mass adoption phase.

### Proliferation Projections

| Year | Nations with LAWS | % of Potential Adopters | Confidence Level | New Adopters per Year |
|------|-------------------|------------------------|------------------|----------------------|
| 2020 | 5 | 4% | High (observed) | 1-2 |
| 2025 | 20 | 17% | High (observed) | 3-4 |
| 2030 | 60 | 50% | Medium | 8-10 |
| 2035 | 95 | 79% | Low | 7-8 |
| 2040 | 110 | 92% | Very Low | 3-4 |

The projections indicate that 2025-2030 represents the maximum growth rate period, with 8-10 new nations achieving LAWS capability annually during the peak proliferation years. By 2030, half of all militarily capable nations will possess autonomous weapons—a proliferation outcome that transforms LAWS from a specialized capability of great powers to a standard military technology. The slowdown after 2035 reflects saturation effects as the remaining non-adopters are primarily nations with limited military capacity or strong normative commitments against autonomous weapons.

### Non-State Actor Timeline

Non-state proliferation follows a different trajectory than state adoption, driven by the lag between commercial technology availability and the technical sophistication required to weaponize it. Historical precedent from commercial drone weaponization provides calibration data for projecting autonomous weapons timelines.

| Capability Milestone | Commercial Drones (2014-2020) | Autonomous Weapons (Projected) | Time Lag Explanation |
|---------------------|-------------------------------|-------------------------------|---------------------|
| Initial weaponization | 2014 (ISIS drops grenades) | 2020-2022 (basic autonomous targeting) | Requires AI integration, more complex than mechanical mods |
| Sophisticated tactical use | 2017 (coordinated swarms) | 2025-2027 (autonomous assassination attempts) | 3-5 year lag for AI models to become accessible |
| Regular operational capability | 2020 (routine in conflicts) | 2030-2032 (well-funded groups deploy routinely) | 10-12 year lag from state capabilities to non-state access |
| Mass availability | Not yet reached | 2035-2040 (small groups, potentially individuals) | Depends on open-source AI advancement rate |

The progression from initial weaponization to operational capability took approximately six years for commercial drones. Autonomous weapons are projected to follow a similar but somewhat delayed timeline, with the critical transition to regular use by non-state actors occurring around 2030-2032—roughly 10-12 years behind state-level capabilities. This lag is shorter than the nuclear weapons case (where non-state access never materialized) but longer than the commercial drone case due to the additional technical complexity of integrating AI targeting systems.

### Non-State Access Probability Drivers

| Factor | Impact on Timeline | Current Trend | 2030 Projection |
|--------|-------------------|---------------|-----------------|
| Open-source AI model capabilities | High acceleration | Rapidly improving | Models sufficient for basic autonomous targeting widely available |
| Commercial drone sophistication | Medium acceleration | Steady improvement | Consumer drones with high-res cameras, long range, payload capacity |
| Legal restrictions on sales | Low deceleration | Weak enforcement | Minimal effectiveness due to dual-use nature |
| Technical knowledge barriers | Medium deceleration | Declining rapidly | Basic autonomous targeting within reach of moderately skilled individuals |
| **Net effect** | **Accelerating access** | **Barriers declining** | **Non-state operational capability highly likely** |

The key uncertainty centers on whether truly lone actors (not just small groups) will gain practical access to autonomous weapons. This depends critically on the trajectory of open-source AI models and the availability of weaponization guides, both of which are currently trending toward increased accessibility with no effective control mechanisms in place.

## Proliferation Control Mechanisms

The international community has attempted various control mechanisms to slow LAWS proliferation, with uniformly disappointing results. The dual-use nature of enabling technologies makes traditional arms control approaches—which rely on restricting access to specialized materials or equipment—essentially ineffective. This section evaluates both implemented and proposed control mechanisms across three dimensions: technical feasibility, political feasibility, and potential impact.

### Control Mechanism Effectiveness Analysis

| Mechanism | Technical Feasibility | Political Feasibility | Potential Impact | Overall Effectiveness | Current Status |
|-----------|---------------------|---------------------|------------------|---------------------|----------------|
| Export controls (Wassenaar) | Low | Medium | Low | **5%** - Easily circumvented | Implemented, largely ineffective |
| International treaty (CCW) | Medium | Very Low | High (if universal) | **10%** - No major power buy-in | Years of negotiations, no result |
| Corporate self-regulation | High | Low | Very Low | **8%** - State actors unaffected | Voluntary, limited participation |
| Technical safeguards (kill switches) | Medium | Medium | Low | **15%** - Bypassed by military systems | Commercial only |
| AI model export controls | Low | Low | Very Low | **3%** - Models recreatable | Proposed, likely ineffective |
| Component-level restrictions | Very Low | Very Low | Negligible | **1%** - Too many civilian uses | Not seriously pursued |
| Attribution mechanisms | Medium-High | Medium | Medium | **35%** - Best feasible option | Early development |
| Defensive technology focus | High | High | Medium | **40%** - Most promising | Underfunded but growing |
| Stigmatization campaign | N/A (normative) | Medium | Medium-High | **25%** - Partial effect possible | Ongoing, mixed reception |

The effectiveness percentages represent estimated reduction in proliferation rate or risk if mechanisms were fully implemented. The highest-impact options—international treaties requiring meaningful human control—face insurmountable political obstacles due to major power opposition. The most feasible options—defensive technology and attribution—offer only partial risk reduction. Critically, no combination of these mechanisms appears capable of preventing proliferation beyond 60+ nations by 2030.

### Why Control Mechanisms Fail

Traditional arms control succeeds when technologies have three characteristics: identifiable specialized components, limited civilian applications, and detectable development signatures. LAWS possess none of these characteristics, creating a proliferation control environment fundamentally more challenging than any previous weapons technology including nuclear, chemical, and biological weapons.

The dual-use problem is particularly acute. Restricting AI model development would require shutting down the entire AI research enterprise. Restricting drone sales would eliminate agricultural, delivery, inspection, and emergency response applications worth hundreds of billions of dollars. Restricting sensor technology would cripple consumer electronics. No state will accept these economic costs to slow military proliferation by a few years at most, especially when competitors can gain advantages by defecting from restrictions.

Verification challenges compound these problems. Nuclear weapons programs generate heat signatures, consume enormous amounts of electricity, and require visible enrichment facilities. LAWS development occurs in ordinary office buildings running ordinary computers doing work indistinguishable from civilian AI research. International inspectors cannot determine whether an AI lab is developing autonomous targeting systems or optimizing package delivery routes—and even if they could, the knowledge required transfers instantly once discovered.

## Scenario Analysis

Future proliferation trajectories depend primarily on two uncertain variables: the success of international control efforts and the relative pace of offensive versus defensive technology development. Four distinct scenarios capture the plausible outcome space, with probabilities assigned based on current trends and historical precedents.

### Scenario Probability Matrix

| Scenario | Probability | 2030 State Proliferation | 2035 Non-State Access | Key Driver | Risk Level |
|----------|-------------|--------------------------|----------------------|------------|------------|
| Uncontrolled Proliferation | 40% | 60-70 nations | Routine operational use | Control mechanisms fail | Very High |
| Partial Control | 35% | 40-50 nations | Limited but growing | Weak international norms | High |
| Effective Control | 15% | 20-30 nations | Rare/prevented | Strong treaty regime | Medium |
| Defensive Dominance | 10% | 60+ nations but ineffective | Irrelevant (weapons don't work) | Counter-LAWS breakthrough | Low |

The scenario probabilities reflect the base rate of arms control failure (75% probability that control mechanisms are weak or ineffective) combined with a small probability (10%) that technological development favors defense so strongly that proliferation becomes strategically irrelevant. The most likely outcome remains uncontrolled or weakly controlled proliferation.

### Scenario 1: Uncontrolled Proliferation (40% probability)

This scenario represents the current default trajectory absent major policy interventions or technological surprises. International control negotiations continue to stall on verification and enforcement mechanisms, while dual-use technology continues to improve and diffuse through commercial channels. By 2030, LAWS capabilities reach 60-70 nations across all regions, with no meaningful technical barriers preventing non-state acquisition.

**Proliferation timeline:** Following the logistic growth curve with $r = 0.40$ (slightly faster than base case due to complete absence of control friction). State proliferation reaches 70 nations by 2030, 100+ by 2035. Non-state actors begin routine operational use by 2032, with well-funded groups possessing capabilities rivaling smaller nations. Individual access becomes feasible by 2038 as open-source AI models and commercial drones converge.

**Security consequences:** Assassination costs drop from millions of dollars (current professional operations) to thousands or hundreds of dollars (autonomous systems), making targeted killing accessible to actors who previously lacked such capabilities. Authoritarian regimes deploy LAWS for internal security, creating surveillance-to-strike infrastructure that operates at machine speed. Terrorist organizations shift from mass casualty attacks (difficult to execute, high probability of interdiction) to high-confidence targeted strikes against specific individuals. Democratic societies face persistent threats from autonomous weapons that can be pre-positioned and activated remotely, fundamentally changing security trade-offs around civil liberties versus protection.

**Likelihood assessment:** This scenario receives 40% probability because it requires only continuation of current trends—no diplomatic breakthroughs needed, no major technical surprises, no dramatic public opinion shifts. The primary uncertainty is whether some external shock (catastrophic LAWS incident, major power conflict) triggers rapid norm formation, but historical precedent suggests such shocks more often accelerate proliferation than constrain it.

### Scenario 2: Partial Control (35% probability)

International norms emerge around LAWS use but lack universal adherence and enforcement mechanisms. Major powers sign treaties with significant loopholes or reservations that preserve their own programs while nominally supporting restrictions. A two-tier system develops where advanced militaries maintain LAWS capabilities under various legal fictions (human-in-the-loop requirements that can be waived, autonomous systems classified as defensive, etc.) while smaller nations and non-state actors face restrictions with uneven enforcement.

**Proliferation timeline:** International norms slow diffusion by approximately 30%, reducing $r$ to 0.25 in the logistic growth model. State proliferation reaches 45 nations by 2030, 75 by 2035. Non-state access occurs but through black markets and state sponsorship rather than direct commercial acquisition, delaying routine operational use to 2034-2036. Export controls reduce but do not eliminate availability.

**Security consequences:** The two-tier system creates strategic asymmetries where major powers possess capabilities that regional competitors cannot legally acquire, increasing incentives for covert development and international tensions. Black markets develop for autonomous weapons components and expertise, with state sponsors (Iran, North Korea, others) providing LAWS to proxy forces. Periodic norm violations occur when nations caught face limited consequences, gradually eroding the stigma. Democratic nations face difficult trade-offs between maintaining technological superiority and supporting international norms.

**Likelihood assessment:** 35% probability reflects this as the most likely "successful" control outcome—meaningful norms emerge but fall short of preventing proliferation. This mirrors historical outcomes for cluster munitions (treaty with major power abstentions) and landmines (treaty with incomplete participation). The scenario requires modest diplomatic success but not the transformative breakthroughs needed for effective control.

### Scenario 3: Effective Control (15% probability)

A strong international treaty establishes meaningful human control requirements for lethal autonomous systems, with major power buy-in and credible verification mechanisms. Proliferation slows dramatically as normative, legal, and technical barriers combine to prevent widespread LAWS deployment. Development focuses on defensive systems and human-supervised applications.

**Proliferation timeline:** Treaty constraints reduce proliferation rate to $r = 0.12$, approaching rates for heavily regulated military technologies. State proliferation limited to 25-30 nations by 2030, reaching only 45 nations by 2035. Non-state access effectively prevented through combination of export controls, technical safeguards, and attribution mechanisms. Individual access remains infeasible through 2040.

**Security consequences:** Military AI development proceeds along supervised and defensive pathways, maintaining human decision-making for lethal force. International security benefits from reduced assassination risks and lower conflict escalation probabilities. However, tensions persist around verification and compliance, with periodic crises when states are suspected of covert development. Some military advantages potentially ceded to non-compliant actors, creating pressure for treaty withdrawal.

**Likelihood assessment:** Only 15% probability due to the substantial diplomatic and technical barriers. Requires unprecedented major power cooperation on military technology—the U.S., China, and Russia would all need to agree that autonomous weapons risks outweigh military advantages and commit to intrusive verification. No historical precedent exists for this level of great power cooperation on militarily relevant technology. Would likely require a catalyst event (catastrophic LAWS incident) combined with unusual political leadership.

### Scenario 4: Defensive Technology Victory (10% probability)

Counter-LAWS technology advances faster than offensive capabilities, creating a defender's advantage where autonomous weapons become tactically ineffective. Detection systems identify autonomous platforms, jamming disrupts their operation, and active defenses defeat them at high rates. Proliferation continues but military value of LAWS declines sharply.

**Proliferation timeline:** Follows uncontrolled proliferation curve for acquisition (many nations obtain LAWS) but deployment and operational use remain limited because systems prove unreliable in contested environments. By 2030, 60+ nations possess LAWS but rarely deploy them operationally. Non-state actors acquire systems but find them ineffective against defended targets.

**Security consequences:** LAWS shift from game-changing weapons to niche capabilities useful only against undefended targets. Arms race dynamics redirect to counter-LAWS measures. Assassination risks increase against soft targets lacking defenses but decrease for protected individuals and installations. Overall risk level substantially lower than proliferation scenarios because weapons don't function as feared.

**Likelihood assessment:** 10% probability reflects significant technical uncertainty about offense-defense balance. While possible, historical precedent suggests offense-defense races rarely end in decisive defensive victory—more commonly they create continued cycles of measure and countermeasure. Defensive dominance requires not just good counter-LAWS technology but fundamental asymmetries favoring defense, which seems unlikely given the diversity of autonomous weapons platforms and attack modes.

## Risk Implications by Proliferation Level

Proliferation level determines the nature and magnitude of autonomous weapons risks. As capabilities spread from great powers to regional states to non-state actors, the risk profile shifts from interstate strategic considerations to diffuse threats against individuals and small groups.

| Proliferation Level | Timeline | Primary Risks | Risk Magnitude | Control Feasibility | Key Threshold Crossed |
|---------------------|----------|---------------|----------------|---------------------|---------------------|
| Great powers only (5-8 nations) | 2015-2020 | Strategic instability, arms race | Medium | High - small number of actors | Military AI integration begins |
| Regional powers (20-30 nations) | 2020-2027 | Regional conflicts, proxy use | Medium-High | Medium - norms still formable | Routine battlefield deployment |
| Widespread state (60+ nations) | 2027-2032 | Ubiquitous military capability | High | Low - too many actors | LAWS become standard military technology |
| Non-state operational (100+ groups) | 2030-2035 | Terrorism, assassination-at-scale | Very High | Very Low - impossible to monitor | Killing capability democratized |
| Individual access (1000+ individuals) | 2035-2040 | Lone-wolf attacks, vigilantism | Extreme | None - completely uncontrollable | Point of no return |

The table identifies five critical thresholds in the proliferation trajectory. The most dangerous transition occurs between widespread state access and non-state operational capability, where autonomous weapons shift from regulated military systems subject to command authority and international law to tools accessible to actors with no accountability to state structures. Once this threshold is crossed, assassination transforms from a capability requiring state resources and risking attribution to an accessible option for well-funded individuals and organizations.

Current assessment places the world in 2025 between the regional powers and widespread state thresholds, with 5-7 years remaining before the high-risk transition to non-state operational capability. This represents a critical window where control mechanisms might still prevent the most dangerous outcomes, though the analysis above suggests low probability of success.

## Policy Implications

### Primary Strategy: Damage Limitation (Recommended for 75% Probability Scenario)

Given the high likelihood that proliferation cannot be prevented, policy should focus on limiting harm in a post-proliferation world rather than attempting to prevent the inevitable. This represents a fundamental strategic reorientation from control to resilience.

**Defensive technology investment:** Prioritize detection systems, jamming capabilities, and active defenses against autonomous weapons. Unlike offensive LAWS development, defensive cooperation faces fewer barriers and provides public goods that reduce everyone's vulnerability. Estimated cost of comprehensive defensive technology program: \$5-10B annually across allied nations. Expected impact: 40-60% reduction in LAWS effectiveness against defended targets.

**Attribution mechanisms:** Develop technical forensics to trace LAWS use to source actors, creating accountability and deterrence. Analogous to nuclear forensics but more challenging due to commercial component ubiquity. Requires international cooperation on component tracking, operating system signatures, and post-incident analysis protocols. Expected impact: Enables retaliation/prosecution in 30-50% of incidents, providing some deterrent effect.

**Civilian protection norms:** Establish strong international prohibitions on LAWS use against civilians, distinct from general LAWS bans that have failed. More achievable politically because it doesn't restrict military capabilities against legitimate targets. Compliance likely incomplete but could reduce civilian casualties by 20-40% through combination of normative pressure and fear of attribution.

**Counter-proliferation targeting:** Accept that universal proliferation prevention is impossible but maintain intelligence and operational capabilities to prevent or delay access by highest-risk actors (designated terrorist organizations, particularly unstable regimes, individuals with assassination/terrorism indicators). Resource-intensive but more tractable than comprehensive control. Can delay high-risk actor access by 3-5 years on average.

### Secondary Strategy: Pursue Control Despite Low Probability (Recommended for 25% Possibility)

Even with low probability of success, the benefits of effective control are sufficiently high to justify continued investment in control mechanisms. Portfolio approach: pursue multiple control pathways simultaneously to maximize chance that at least one succeeds.

**International treaty negotiation:** Continue CCW and other diplomatic processes despite slow progress. Focus on meaningful human control requirements rather than total bans (more politically achievable). Build coalition of committed states even if major powers abstain initially—create template for eventual accession if circumstances change. Expected success probability: 15%, but success would reduce long-term risk by 60-70%.

**Export control strengthening:** Tighten Wassenaar Arrangement and equivalent regimes where possible. Focus on complete weapon systems rather than components (more enforcement-feasible). Expected impact: Delay proliferation to marginal actors by 2-3 years, minimal impact on determined state programs.

**Technical safeguards mandates:** Require kill switches, geofencing, and autonomous operation limitations in commercial drones and AI systems. Effective only against non-state actors using commercial systems, easily bypassed by state military programs. Expected impact: 20-30% reduction in non-state actor capability, no impact on state actors.

**Stigmatization campaign:** Support organizations like Campaign to Stop Killer Robots in creating normative pressure against LAWS development and use. Analogous to landmine and cluster munition campaigns which achieved partial success despite major power abstention. Expected impact: Slow proliferation by 15-25%, reduce willingness to use by 30-40%.

## Strategic Importance

### Magnitude Assessment

| Dimension | Assessment | Quantitative Estimate |
|-----------|------------|----------------------|
| **Potential severity** | High - fundamentally changes cost of political violence | Assassination costs drop from \$500K-5M to \$1K-10K |
| **Probability-weighted importance** | Very High - proliferation trajectory appears nearly certain | 75-85% probability of 60+ nation proliferation by 2030 |
| **Comparative ranking** | Top-tier among weapons proliferation risks | 4-6x faster than nuclear, 10x more actors by 2035 |

### Resource Implications

Current global investment in LAWS control mechanisms: ≈\$50M annually
Estimated investment needed for meaningful defensive capability: \$5-10B annually
Gap factor: **100-200x underfunded**

Priority interventions by cost-effectiveness:
1. Attribution technology R&D (\$500M-1B, 35% risk reduction)
2. Defensive counter-LAWS systems (\$2-5B, 40-60% effectiveness improvement)
3. Civilian protection norm building (\$100M, 25% stigmatization effect)

### Key Cruxes

| Crux | If True | If False | Current Assessment |
|------|---------|----------|-------------------|
| Dual-use restriction is impossible | Focus on damage limitation | Arms control still viable | 85% likely true |
| Non-state access by 2032 | Assassination-at-scale becomes reality | Window for control remains | 70% likely true |
| Defensive technology can dominate | Proliferation becomes less dangerous | Full risk realization | 10% likely |
| Major incident triggers norms | Partial control possible | Uncontrolled proliferation | 25% dependent on events |

## Limitations

This model faces several fundamental constraints that limit confidence in specific quantitative projections while preserving confidence in directional conclusions and relative comparisons.

**Technology trajectory uncertainty:** The model assumes AI capabilities and commercial drone sophistication continue improving at current rates, but breakthrough advances or unexpected plateaus could substantially alter proliferation timelines. If AI progress slows due to algorithmic limits or compute constraints, the projected 2030-2035 timeline for non-state operational capability could extend by 5-10 years. Conversely, rapid advances in open-source AI models could accelerate timelines by 3-5 years. The logistic growth model captures smooth diffusion but cannot predict discontinuous technology jumps that might rapidly enable or prevent certain proliferation pathways.

**Historical analogy limitations:** The model relies heavily on nuclear weapons proliferation as a comparison case, but LAWS represent an unprecedented combination of characteristics—dual-use technology, low cost, impossible verification—that may produce dynamics with no historical precedent. The commercial drone weaponization timeline provides more recent calibration data but spans only 10 years and involves simpler technologies. No historical case perfectly matches LAWS proliferation dynamics, creating irreducible uncertainty in projections beyond 10 years.

**Non-state actor modeling challenges:** State proliferation can be tracked through public announcements, observable procurement, and intelligence reporting. Non-state actor capabilities remain largely invisible until used operationally, creating severe measurement problems. The model projects non-state timelines based on technology availability and historical weapon adoption rates, but actual access depends on factors difficult to quantify—criminal network evolution, state sponsorship decisions, availability of technical expertise in underground markets. Confidence intervals for non-state projections are at least 2x wider than for state proliferation.

**Control mechanism effectiveness:** The model assigns effectiveness percentages to various control mechanisms based on expert judgment rather than empirical validation. No controlled experiments exist for LAWS proliferation control, and historical arms control outcomes provide limited guidance due to the unique dual-use challenges. The assigned probabilities to different scenarios (40% uncontrolled, 35% partial control, etc.) represent informed estimates but lack rigorous empirical grounding. Different expert panels might assign substantially different probabilities while agreeing on directional conclusions.

**Second-order effects omitted:** The model focuses narrowly on proliferation dynamics and does not capture important second-order effects that might alter trajectories. Public backlash after a catastrophic incident could shift political feasibility of control mechanisms. Major power conflict could either accelerate proliferation (arms race dynamics) or enable cooperation (mutual threat recognition). Economic shocks affecting AI industry could slow or redirect technology development. These potential discontinuities are acknowledged but not formally modeled, limiting the model's ability to predict outcomes in turbulent geopolitical environments.

## Related Models

- <EntityLink id="autonomous-weapons-escalation" /> - Analyzes conflict dynamics and escalation risks when autonomous weapons become widespread
- <EntityLink id="flash-dynamics-threshold" /> - Examines speed implications and machine-timescale decision-making at scale

## Sources

- Carnegie Endowment for International Peace. "Mapping LAWS Development Globally"
- Campaign to Stop Killer Robots. Annual reports
- UN CCW Group of Governmental Experts reports
- SIPRI. "Autonomous Weapons Systems and International Humanitarian Law"
- Academic literature on weapons proliferation dynamics
