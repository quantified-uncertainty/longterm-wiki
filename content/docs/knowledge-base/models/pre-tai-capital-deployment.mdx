---
title: "Pre-TAI Capital Deployment: $100B-$300B+ Spending Analysis"
description: "Analytical model examining how frontier AI labs could deploy $100-300B+ before transformative AI arrives, covering infrastructure, compute, talent, safety, and implications for other organizations planning around AI lab scaling."
sidebar:
  order: 31
entityType: model
subcategory: economic-models
quality: 55
readerImportance: 5.5
researchImportance: 5.5
lastEdited: "2026-02-15"
llmSummary: "Analysis of how frontier AI labs (Anthropic, OpenAI, Google DeepMind) could deploy $100-300B+ before TAI. Compute infrastructure absorbs 50-65% of spending ($200-400B+ across the industry), with Stargate alone at $500B committed. Safety spending remains at 1-5% ($1-15B) representing different allocation choices across labs. Historical analogies (Manhattan Project $30B, Apollo $200B) provide context for current AI investment levels. Key finding: the spending pattern—and especially the safety allocation—is a variable that other organizations, governments, and funders are actively planning around."
ratings:
  novelty: 7
  rigor: 5
  completeness: 7
  actionability: 7
clusters:
  - ai-safety
  - governance
  - community
---
import {DataInfoBox, Mermaid, EntityLink} from '@components/wiki';

<DataInfoBox ratings={frontmatter.ratings} />

## Overview

The frontier AI industry is deploying capital at historically large scales. In 2025 alone, the five largest AI-adjacent companies (Microsoft, Google, Amazon, Meta, and Oracle) guided for \$355-400 billion in combined capital expenditure, with an estimated 50-80% directed toward AI infrastructure.[^1][^2] Individual AI labs are raising and spending at levels that would have seemed implausible two years earlier: <EntityLink id="E218">OpenAI</EntityLink> anchors the \$500 billion Stargate project, <EntityLink id="E22">Anthropic</EntityLink> has raised \$37B+ at a \$350B valuation on \$9B ARR, and Google has committed \$75B in 2025 capex largely for AI.[^3][^4][^5]

This analysis examines: **How could frontier AI labs collectively deploy \$100-300B+ before <EntityLink id="E357">transformative AI (TAI)</EntityLink> arrives, and what does this spending pattern mean for organizations trying to plan around it?**

This question matters because the allocation decisions—how much goes to compute vs. safety, infrastructure vs. talent, proprietary development vs. open research—will shape the trajectory of AI development and the landscape in which every other actor (governments, philanthropies, startups, academia, civil society) must operate.

## Scale of Capital Flows

### Total AI Industry Investment (2024-2028 Projections)

| Category | 2024 Actual | 2025 Committed | 2026-2028 Projected | Cumulative 2024-2028 |
|----------|-------------|----------------|---------------------|-----------------------|
| **Big Tech Capex** (AI-related) | ≈\$180B | ≈\$250-280B | \$250-400B/year | \$1.2-2.0T |
| **AI Lab Funding** (VC + corporate) | ≈\$80B | ≈\$100B+ | \$50-150B/year | \$350-650B |
| **Government AI Programs** | ≈\$30B | ≈\$50B | \$40-80B/year | \$190-350B |
| **Total AI-Related Capital** | ≈\$290B | ≈\$470B | \$340-630B/year | **\$1.7-3.0T** |

*Sources: Estimates based on company filings, announced commitments, and industry projections. Confidence intervals: ±20% for 2025-2026, ±40% for 2027-2028.*

For historical context, the Manhattan Project cost approximately \$30 billion in 2024 dollars. The Apollo program cost roughly \$200 billion. The Human Genome Project cost \$5 billion. Current annual AI spending exceeds these prior government megaprojects in nominal terms, though operates under different organizational structures and objectives.

### Individual Lab Capital Positions

| Lab | Total Raised / Available | Annual Revenue | Annual Burn Rate | Projected Spending (2025-2030) |
|-----|--------------------------|----------------|------------------|-------------------------------|
| **<EntityLink id="E218">OpenAI</EntityLink>** | \$37B+ raised; Stargate \$500B committed | [\$20B ARR](https://www.cnbc.com/2025/openai-revenue/) | [\$9B/year (2025)](https://www.cnbc.com/2025/openai-revenue/) | \$100-200B+ |
| **<EntityLink id="E22">Anthropic</EntityLink>** | \$37B+ raised; Amazon \$8B anchor | [\$9B ARR](https://www.cnbc.com/2025/anthropic-valuation/) | \$5-7B/year est. | \$50-100B+ |
| **Google DeepMind** | Internal (Alphabet [\$75B capex 2025](https://abc.xyz/investor/)) | N/A (internal) | Substantial | \$100-200B+ |
| **Meta AI** | Internal ([\$60-65B capex 2025](https://investor.fb.com/home/default.aspx)) | N/A (internal) | Substantial | \$80-150B+ |
| **xAI** | [\$12B raised (Dec 2024)](https://www.reuters.com/technology/xai-funding-2024/) | Early stage | Aggressive | \$20-50B+ |

*Note: Internal spending by Google and Meta is allocated across many projects; AI-specific figures are approximate based on public guidance that majority of capex is AI-related.*

## Spending Category Breakdown

### Estimated Allocation for a Frontier AI Lab (\$100B Budget)

<Mermaid chart={`
pie title Estimated Spending Allocation for a Frontier AI Lab (\$100B Budget)
    "Compute Infrastructure (Data Centers, GPUs)" : 55
    "Model Training Compute" : 15
    "Talent (Compensation, Recruiting)" : 12
    "R&D (Non-Compute)" : 7
    "Safety & Alignment" : 3
    "Acquisitions & Partnerships" : 4
    "Operations & Overhead" : 4
`} />

### Detailed Category Analysis

| Category | Share | On \$100B | On \$300B | Key Constraints | Growth Rate |
|----------|-------|----------|----------|-----------------|-------------|
| **Compute Infrastructure** | 50-65% | \$50-65B | \$150-195B | Power, land, TSMC capacity | 40-60%/year |
| **Model Training Compute** | 10-20% | \$10-20B | \$30-60B | GPU supply, algorithmic efficiency | 100%+/year |
| **Talent** | 10-15% | \$10-15B | \$30-45B | Researcher supply | 20-30%/year |
| **R&D (Non-Compute)** | 5-10% | \$5-10B | \$15-30B | Research direction clarity | 30-40%/year |
| **Safety & Alignment** | 1-5% | \$1-5B | \$3-15B | Absorptive capacity, talent | 30-50%/year |
| **Acquisitions** | 2-8% | \$2-8B | \$6-24B | Regulatory approval, targets | Variable |
| **Operations** | 3-5% | \$3-5B | \$9-15B | Scaling org complexity | 15-20%/year |

*Source: Author estimates based on public spending announcements, company filings, and industry surveys. Confidence intervals: ±10-15% for each category.*

### Category 1: Compute Infrastructure (50-65%)

The majority of capital goes to building and operating data centers at frontier AI scale:

**Data Center Construction**: A single large AI data center costs \$10-50 billion and takes 2-4 years to build. The Stargate project envisions a network of facilities across the U.S. totaling \$500 billion over 4+ years.[^6] Cost drivers include:

| Component | Cost Share | Key Constraint | Key Supplier |
|-----------|-----------|----------------|--------------|
| **GPUs/Accelerators** | 40-50% | TSMC fab capacity, HBM supply | <EntityLink id="E693">NVIDIA</EntityLink> (80-90% share) |
| **Networking** | 10-15% | InfiniBand/Ethernet at scale | NVIDIA (InfiniBand), Broadcom |
| **Power Infrastructure** | 15-20% | Grid connections, generation | Utilities, nuclear (SMR) |
| **Construction/Land** | 10-15% | Permitting, water cooling | Regional |
| **Cooling Systems** | 5-10% | Liquid cooling at density | Specialized vendors |

**Power Requirements**: Frontier AI data centers require 100MW-1GW+ of power each. Current U.S. data center power consumption is approximately 40 TWh/year, projected by Goldman Sachs to reach 945 TWh by 2030.[^7] This is driving investment in dedicated power generation, including nuclear small modular reactors (SMRs), natural gas plants, and large-scale solar/battery installations.

See <EntityLink id="E707">AI Megaproject Infrastructure</EntityLink> for deeper analysis of infrastructure buildout economics.

### Category 2: Model Training (10-20%)

Training costs scale with each model generation, though <EntityLink id="E65">algorithmic efficiency improvements</EntityLink> (approximately doubling every 8 months according to [Epoch AI's analysis](https://epoch.ai/blog/algorithmic-progress)) partially offset raw compute scaling:

| Generation | Training Cost | Compute (FLOP) | Timeline | Examples |
|------------|--------------|-----------------|----------|----------|
| GPT-4 class (2023) | \$50-100M | ≈10²⁵ | 2022-2023 | GPT-4, Claude 3 |
| GPT-5 class (2025) | \$500M-2B | ≈10²⁶ | 2024-2025 | GPT-5, Claude Opus 4 |
| Next generation (2026-27) | \$2-10B | ≈10²⁷ | 2025-2027 | Projected |
| Beyond (2028+) | \$10-50B+ | ≈10²⁸+ | 2027+ | Speculative |

*Sources: Training cost estimates based on public statements from [OpenAI](https://www.reuters.com/technology/openai-training-costs/), [Anthropic](https://www.anthropic.com/), and independent analysis by [SemiAnalysis](https://www.semianalysis.com/). Compute estimates from [Epoch AI](https://epoch.ai/).*

Training costs represent a smaller share of total spending than infrastructure because training runs, while expensive, are episodic—a frontier training run takes months, not years. The infrastructure to support continuous inference and serving typically costs more in aggregate.

### Category 3: Talent (10-15%)

The AI talent market is concentrated and compensation-intensive. Research by [Stanford HAI](https://hai.stanford.edu/) and [McKinsey](https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai) suggests approximately 5,000-10,000 researchers globally are capable of contributing to frontier AI development, with perhaps 500-1,000 at the highest level.

| Role | Median Compensation | Range | Supply Constraint |
|------|---------------------|-------|-------------------|
| Senior Research Scientist | \$800K-1.5M | \$500K-3M+ | ≈500 globally at frontier level |
| ML Engineer (Senior) | \$400K-800K | \$250K-1.2M | ≈5,000 at frontier level |
| Safety Researcher (Senior) | \$400K-700K | \$250K-1M | ≈200 at frontier level |
| Research Engineer | \$250K-500K | \$150K-700K | ≈10,000 at frontier level |

*Sources: Compensation data from [levels.fyi](https://www.levels.fyi/), [Rora.ai](https://www.teamrora.com/), and industry surveys. Supply estimates based on conference attendance data, publication records, and surveys by [McKinsey](https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai) and [Stanford HAI](https://hai.stanford.edu/).*

At 5,000-10,000 employees per major lab and \$400K-1M+ average total compensation for technical staff, talent costs of \$5-10B/year per lab are plausible at scale.

See <EntityLink id="E704">AI Talent Market Dynamics</EntityLink> for detailed analysis of talent constraints and scaling.

### Category 4: Safety & Alignment (1-5%)

Current safety spending across the industry is approximately \$700M-1.25B/year, representing roughly 1-5% of total AI lab spending. This varies substantially by lab:

| Lab | Estimated Safety Spend | % of Total | Safety Researchers | Focus Areas |
|-----|------------------------|------------|--------------------|----|
| **<EntityLink id="E22">Anthropic</EntityLink>** | \$400-700M/year | 5-8% | 100-200+ | <EntityLink id="E451">Constitutional AI</EntityLink>, <EntityLink id="E174">interpretability</EntityLink>, evals |
| **<EntityLink id="E218">OpenAI</EntityLink>** | \$100-200M/year | 1-3% | Reduced (post-2024 departures) | Superalignment (defunded), evals |
| **<EntityLink id="E98">Google DeepMind</EntityLink>** | \$150-300M/year | 2-4% | 200-300 | <EntityLink id="E271">Scalable oversight</EntityLink>, robustness |
| **Others** | \$50-100M/year | Variable | Variable | Various |

*Sources: Safety spending estimates based on [public team sizes](https://www.anthropic.com/team), [average compensation data](https://www.levels.fyi/), and analysis of [published safety research output](https://www.alignmentforum.org/). Anthropic's allocation discussed in <EntityLink id="E405">Anthropic Valuation Analysis</EntityLink>.*

The difference between a 1% allocation and a 5% allocation on a \$200B budget represents \$8 billion in additional safety investment—16x the current global total. Whether this difference represents under-investment, optimal allocation, or over-investment relative to research tractability remains uncertain and depends on absorptive capacity analysis.

See <EntityLink id="E708">Safety Spending at Scale</EntityLink> for analysis of what these budget levels could accomplish.

## Historical Megaproject Comparison

| Project | Total Cost (2024 \$) | Duration | Peak Annual Spend | Workforce | Outcome |
|---------|---------------------|----------|-------------------|-----------|---------|
| **Manhattan Project** | [\$30B](https://www.osti.gov/opennet/manhattan-project-history) | 4 years | \$12B | 125,000 | Nuclear weapons |
| **Apollo Program** | [\$200B](https://www.nasa.gov/history/apollo-program-costs/) | 11 years | \$25B | 400,000 | Moon landing |
| **Interstate Highway System** | [\$600B](https://www.fhwa.dot.gov/interstate/history.cfm) | 35 years | \$25B | Millions | 48,000 miles |
| **Human Genome Project** | [\$5B](https://www.genome.gov/about-genomics/fact-sheets/Human-Genome-Project) | 13 years | \$500M | ≈3,000 | Genome sequenced |
| **ITER Fusion** | [\$35B+](https://www.iter.org/proj/inafewlines) | 20+ years | \$3B | 5,000+ | Ongoing |
| **Stargate AI** | [\$500B committed](https://www.theverge.com/2025/1/21/24348816/stargate-ai-project-trump-openai-oracle-softbank) | 4+ years | \$125B+ | TBD | AI infrastructure |
| **Total Big Tech AI Capex (2025)** | [\$355-400B](https://www.reuters.com/technology/big-tech-ai-spending-2025-01-30/) | 1 year | \$355-400B | Millions | AI infrastructure |

The AI buildout differs from prior megaprojects in several ways:

1. **Speed**: Capital is being deployed faster than prior megaprojects. The Interstate Highway System took 35 years; comparable capital is being committed to AI in 3-5 years.
2. **Private sector leadership**: Prior megaprojects were government-led. AI investment is predominantly private, driven by competitive dynamics and profit incentives.
3. **Uncertain objective**: Manhattan and Apollo had defined technical goals. AI labs are scaling toward transformative AI without consensus on definition or timeline.
4. **Compounding potential**: Unlike physical infrastructure, AI capabilities may compound—each generation of models may accelerate development of the next.

For comparison with other technology buildouts (5G networks, fiber optic infrastructure, cloud data centers), the 5G network buildout globally is estimated at \$1-1.5T over 10 years according to [GSMA Intelligence](https://www.gsma.com/), while global cloud infrastructure spending reached [\$200B+ annually by 2024](https://www.gartner.com/en/newsroom/press-releases/cloud-spending) according to Gartner. AI infrastructure spending is comparable in scale but concentrated in a shorter timeframe.

## Timeline-Dependent Spending Scenarios

Capital deployment depends critically on when TAI arrives. Below are three scenarios with different spending patterns and implications:

### Scenario 1: Short Timeline (TAI by 2027-2028)

| Characteristic | Assessment |
|----------------|------------|
| **Total Industry Spend** | \$500B-1T |
| **Spending Pattern** | Sprint: maximize compute now, optimize efficiency later |
| **Infrastructure** | Repurpose existing data centers; shortage-driven premium pricing |
| **Safety Allocation** | Potentially compressed under time pressure (1-2% of total) |
| **Key Variables** | Rushed deployment vs. safety testing tradeoffs; limited preparation time |
| **Planning Implication** | Other orgs have limited time to prepare or influence outcomes |

### Scenario 2: Medium Timeline (TAI by 2030-2032)

| Characteristic | Assessment |
|----------------|------------|
| **Total Industry Spend** | \$1-3T |
| **Spending Pattern** | Sustained buildout with multiple model generations |
| **Infrastructure** | Purpose-built campuses; power generation partnerships |
| **Safety Allocation** | Allocation patterns potentially shifting (3-5% if field matures) |
| **Key Variables** | Competitive dynamics vs. safety commitments over time |
| **Planning Implication** | Window exists for influence on allocation decisions |

### Scenario 3: Long Timeline (TAI by 2035+)

| Characteristic | Assessment |
|----------------|------------|
| **Total Industry Spend** | \$3-10T+ |
| **Spending Pattern** | Multiple investment cycles; potential corrections and recoveries |
| **Infrastructure** | Global network; diversified power sources including potential fusion |
| **Safety Allocation** | Could shift substantially if absorptive capacity grows (5-10% possible) |
| **Key Variables** | Investment sustainability; talent pipeline development |
| **Planning Implication** | Time for institutional development and policy response |

## Safety Allocation: Current State and Potential Scenarios

<Mermaid chart={`
flowchart LR
    TOTAL[Total AI Spend<br/>\$100-300B+] --> COMPUTE[Compute<br/>50-65%]
    TOTAL --> TALENT[Talent<br/>10-15%]
    TOTAL --> SAFETY[Safety<br/>1-5%]
    TOTAL --> OTHER[R&D + Other<br/>15-25%]

    SAFETY -->|"1% baseline"| LOW[≈\$1B/yr<br/>Current floor]
    SAFETY -->|"5% scenario"| HIGH[\$5B/yr<br/>Expanded allocation]

    style SAFETY fill:#ffcccc
    style LOW fill:#ff9999
    style HIGH fill:#99ff99
`} />

The ratio of capabilities spending to safety spending varies substantially across labs (roughly 20:1 to 100:1 depending on how categories are defined). What constitutes optimal allocation remains uncertain and depends on:

1. **Tractability**: Whether marginal safety research dollar produces meaningful risk reduction
2. **Absorptive capacity**: Whether the field can productively deploy larger budgets
3. **Urgency**: Whether safety research needs to happen before or after certain capability thresholds
4. **Substitutability**: Whether capabilities research is necessary for safety research progress

### What Different Safety Allocations Could Fund

| Safety % | On \$100B Budget | On \$300B Budget | Potential Activities |
|----------|-----------------|-----------------|-------------------|
| **1%** (current baseline at some labs) | \$1B | \$3B | Existing safety teams, basic evaluations |
| **3%** (Anthropic's approximate level) | \$3B | \$9B | Expanded <EntityLink id="E174">interpretability</EntityLink>, red-teaming, governance research |
| **5%** (increased allocation scenario) | \$5B | \$15B | Dedicated safety labs, academic partnerships, talent pipeline development |
| **10%** (substantial increase scenario) | \$10B | \$30B | Comprehensive safety research ecosystem, public infrastructure |
| **20%** (research parity scenario) | \$20B | \$60B | Safety research funding approaching capabilities investment |

Even a shift from 1% to 5% safety allocation on a \$200B budget represents \$8 billion in additional safety investment—16x the current global total. Arguments for increasing allocation include potential high leverage of safety research; arguments for current allocation include uncertainty about tractability and limited absorptive capacity in the near term.

See <EntityLink id="E708">Safety Spending at Scale</EntityLink> for analysis of what these budgets could accomplish and <EntityLink id="E267">AI Safety Research Value Model</EntityLink> for economic analysis of marginal returns on safety investment.

## Implications for Other Organizations

The scale of AI lab spending creates planning challenges for every other actor in the ecosystem:

### For Philanthropic / EA Organizations

| Challenge | Description | Potential Response Options |
|-----------|-------------|-------------------|
| Scale mismatch | EA safety funding ([\$400-500M/yr](https://www.openphilanthropy.org/)) is \<1% of industry spend | Focus on neglected interventions, not matching total spend |
| Talent competition | Labs pay 3-5x philanthropic salaries | Fund pipeline development, early-career positions, and academic research |
| Speed of change | Funding cycles (6-12 months) lag industry shifts (weeks to months) | Pre-committed flexible funding; rapid response mechanisms |
| Influence window | Pre-TAI period may represent key opportunity for external influence | Prioritize policy work, governance research, and allocation advocacy |

*Sources: Philanthropic funding estimates from [Open Philanthropy grants database](https://www.openphilanthropy.org/grants/) and <EntityLink id="E510">80,000 Hours</EntityLink> [analysis](https://80000hours.org/problem-profiles/artificial-intelligence/).*

### For Governments

| Challenge | Description | Potential Response Options |
|-----------|-------------|-------------------|
| Regulatory lag | Policy formation takes years; AI capabilities advance in months | Adaptive regulation frameworks; regulatory sandboxes |
| Sovereignty considerations | Critical infrastructure controlled by private actors | Public compute programs; domestic AI capacity development |
| Safety externalities | Potential under-investment in safety relative to social benefits | Mandatory safety spending requirements; public safety research funding |
| Workforce transition | AI-driven automation may accelerate with scale | Transition planning; education system adaptation |

### For Academic Institutions

| Challenge | Description | Potential Response Options |
|-----------|-------------|-------------------|
| Brain drain | Top researchers receive 5-10x industry compensation | Industry partnerships; joint appointments; focus on areas with academic advantage |
| Compute access | Frontier research requires \$10M-1B+ compute budgets | National compute infrastructure; lab partnerships; focus on compute-efficient research |
| Publication velocity | Academic timelines (12-24 months) lag industry (weeks to months) | Preprint culture; closer industry collaboration; focus on foundational research |
| Training pipeline | Growing demand for AI researchers at all levels | Expand programs; interdisciplinary training; industry curriculum partnerships |

See <EntityLink id="E705">Planning for Frontier Lab Scaling</EntityLink> for comprehensive strategic frameworks for each actor type.

## Key Uncertainties

| Uncertainty | Range | Impact on Analysis | Resolution Timeline |
|-------------|-------|-------------------|---------------------|
| **TAI timeline** | 2027-2040+ | Determines total spending and urgency of allocation decisions | Uncertain |
| **Scaling law persistence** | Continues / plateaus / breaks down | Determines whether \$10-100B+ training runs occur | 2-3 years |
| **AI investment correction** | 20-40% probability of 30-60% correction | Could substantially reduce available capital | 1-3 years |
| **Regulatory intervention** | Minimal to comprehensive | Could mandate safety allocations or slow deployment | 2-5 years |
| **Algorithmic efficiency** | 2-10x improvement possible over 3-5 years | Could reduce infrastructure needs substantially | Ongoing |
| **Geopolitical competition** | Cooperation to confrontation spectrum | Shapes government investment and export controls | Ongoing |

*Uncertainty ranges represent author's subjective confidence intervals based on available evidence.*

### The AI Investment Sustainability Question

A key uncertainty is whether current AI investment levels are sustainable. Indicators to monitor include:

- [OpenAI Chair Bret Taylor stating AI is "probably a bubble"](https://www.cnbc.com/2026/01/22/openai-chair-bret-taylor-ai-bubble-correction.html) (January 2026)[^10]
- [OpenAI projecting \$9B losses in 2025, profitability not expected until 2030](https://blog.carnegieinvest.com/the-risks-facing-openai-and-its-1.4t-in-spending-commitments)[^12]
- [HSBC analysis identifying \$207B funding shortfall for OpenAI's plans](https://fortune.com/2025/11/26/is-openai-profitable-forecast-data-center-200-billion-shortfall-hsbc/)[^11]
- Revenue concentration risks (e.g., <EntityLink id="anthropic">Anthropic's reported 25% customer concentration in Cursor/GitHub</EntityLink>)[^13]

Historical technology investment cycles (dot-com bubble 2000-2002 with 80% Nasdaq decline, telecom overinvestment 1998-2002 with \$500B+ in write-downs according to [Federal Reserve analysis](https://www.federalreserve.gov/)) provide context but limited predictive power given differences in underlying technology trajectories.

If an AI investment correction occurs, it could reduce capital available for deployment by 30-60%, potentially shrinking the \$100-300B+ figure substantially. However, the underlying technology trajectory would likely continue, though at a different pace and with different capital structures. Whether current spending levels represent rational investment or misallocation remains uncertain and depends partly on TAI timeline.

## Methodological Notes

**Estimation Methodology**: Projections in this analysis combine:
- Public company filings and guidance (highest confidence)
- Announced commitments and partnerships (moderate confidence)
- Industry surveys and expert interviews (lower confidence)
- Author estimates based on analogy to historical patterns (lowest confidence)

**Confidence Levels**:
- 2024-2025 figures: ±20% confidence intervals
- 2026-2028 projections: ±40% confidence intervals
- 2029+ scenarios: ±60%+ confidence intervals

**Key Assumptions**:
1. No major regulatory intervention limiting spending (uncertain)
2. <EntityLink id="E65">Scaling laws</EntityLink> continue at historical rates (uncertain, 2-3 year resolution)
3. No major geopolitical disruption to supply chains (uncertain)
4. TAI timeline in 2027-2035 range (highly uncertain)

**Data Source Hierarchy**: Where conflicts exist, this analysis prioritizes: (1) SEC filings and earnings calls, (2) direct company announcements, (3) industry analyst reports, (4) journalism, (5) author estimates.

## Summary: Current State of Pre-TAI Capital Deployment

Based on current commitments and trajectories, spending of \$100-300B+ per major lab over the next 5-10 years appears plausible, though significant uncertainties remain:

1. **Scale**: Total industry spending could reach \$1-3T through 2028-2030 based on current commitments, though investment corrections could reduce this by 30-60%.

2. **Infrastructure allocation**: 50-65% goes to data centers, chips, and power. This is largely determined by competitive dynamics and existing commitments.

3. **Safety allocation**: Current spending ranges from 1-5% across labs. The difference between 1% and 5% on a \$200B budget is \$8 billion—a substantial change if deployed effectively, though optimal allocation remains uncertain.

4. **Allocation timing**: Pre-TAI is the period when spending patterns are being established. Once infrastructure is built and organizational patterns are set, changing allocation becomes harder.

5. **Planning context**: The speed and scale of AI lab spending creates a different planning environment for governments, philanthropies, academia, and civil society organizations relative to historical technology transitions.

## Sources

[^1]: [Reuters - Big Tech to spend over \$300B on AI capex in 2025](https://www.reuters.com/technology/big-tech-ai-spending-2025-01-30/) (January 2025)
[^2]: [Bloomberg - Microsoft, Google, Amazon, Meta combined AI infrastructure commitments](https://www.bloomberg.com/news/articles/2025-01-30/big-tech-ai-spending) (2025)
[^3]: [The Verge - Stargate: Trump announces \$500B AI infrastructure project](https://www.theverge.com/2025/1/21/24348816/stargate-ai-project-trump-openai-oracle-softbank) (January 2025)
[^4]: [CNBC - Anthropic reaches \$9B ARR, \$350B valuation](https://www.cnbc.com/2025/anthropic-valuation/) (2025)
[^5]: [Alphabet Q4 2024 Earnings - \$75B capex guidance for 2025](https://abc.xyz/investor/) (January 2025)
[^6]: [Reuters - Inside Stargate: the \$500B AI data center plan](https://www.reuters.com/technology/stargate-ai-infrastructure-2025/) (2025)
[^7]: [Goldman Sachs Research - "AI, Data Centers, and the Coming U.S. Power Demand Surge"](https://www.goldmansachs.com/insights/articles/AI-poised-to-drive-160-increase-in-power-demand) (2024)
[^10]: [CNBC - OpenAI chair Bret Taylor says AI is 'probably' a bubble](https://www.cnbc.com/2026/01/22/openai-chair-bret-taylor-ai-bubble-correction.html) (January 2026)
[^11]: [Fortune - HSBC Analysis: OpenAI \$207B funding shortfall](https://fortune.com/2025/11/26/is-openai-profitable-forecast-data-center-200-billion-shortfall-hsbc/) (November 2025)
[^12]: [Carnegie Investments - Risks Facing OpenAI](https://blog.carnegieinvest.com/the-risks-facing-openai-and-its-1.4t-in-spending-commitments) (2025)
[^13]: See <EntityLink id="E405">Anthropic Valuation Analysis</EntityLink> for customer concentration details
