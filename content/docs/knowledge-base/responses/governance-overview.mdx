---
numericId: "E822"
title: "AI Governance & Policy (Overview)"
description: "Overview of governance approaches to AI safety, spanning legislation, compute governance, international coordination, and industry self-regulation across multiple jurisdictions."
sidebar:
  label: "Overview"
  order: 0
entityType: "overview"
subcategory: governance
quality: 44
readerImportance: 72.3
tacticalValue: 88
llmSummary: "A structured index/overview of AI governance approaches across jurisdictions, compute governance, international coordination, and industry self-regulation as of early 2026, identifying key tensions (speed vs. thoroughness, national vs. international, voluntary vs. mandatory). Functions primarily as a navigation hub with minimal original analysis or sourced claims."
ratings:
  focus: 8.5
  novelty: 2.5
  rigor: 3.5
  completeness: 6.5
  concreteness: 5.5
  actionability: 4
  objectivity: 6.5
clusters:
  - ai-safety
  - governance
---
import {EntityLink} from '@components/wiki';

## Overview

AI governance encompasses the policies, regulations, standards, and coordination mechanisms aimed at managing risks from advanced AI systems. The governance landscape is rapidly evolving, with approaches ranging from national legislation to international treaties to voluntary industry commitments. As of early 2026, no single governance framework has achieved comprehensive coverage of frontier AI risks, but multiple overlapping efforts are creating an increasingly dense regulatory environment.

## Legislation and Regulation

Major regulatory frameworks and legislation across jurisdictions:

**International:**
- **EU AI Act**: The world's first comprehensive AI regulation, adopting a risk-based approach to regulate foundation models and general-purpose AI
- **Council of Europe Framework Convention on AI**: First legally binding international AI treaty, establishing human rights standards

**United States:**
- **<EntityLink id="E48">California SB 1047</EntityLink>**: Pioneering state-level frontier AI safety bill (vetoed but influential)
- **California SB 53**: First US state law regulating frontier AI models through transparency requirements
- **<EntityLink id="E366">US Executive Order on AI</EntityLink>**: Federal executive action on AI safety and security
- **<EntityLink id="E216">NIST AI Risk Management Framework</EntityLink>**: Voluntary framework for managing AI risks
- **<EntityLink id="E367">US State AI Legislation</EntityLink>**: Growing landscape of state-level AI regulation
- **New York RAISE Act**: State legislation requiring safety protocols for frontier AI
- **Texas TRAIGA**: Comprehensive AI governance act signed in 2025

**Other jurisdictions:**
- **<EntityLink id="E49">Canada AIDA</EntityLink>**: Canada's Artificial Intelligence and Data Act
- **<EntityLink id="E62">Colorado AI Act</EntityLink>**: State-level AI regulation focused on high-risk systems
- **<EntityLink id="E58">China AI Regulations</EntityLink>**: China's evolving approach to AI governance including generative AI rules

**Analysis:**
- **<EntityLink id="E137">Failed and Stalled AI Policy Proposals</EntityLink>**: Tracking proposals that did not advance and why

## Compute Governance

Technical governance approaches leveraging the physical infrastructure of AI:

- **<EntityLink id="E136">AI Chip Export Controls</EntityLink>**: US policies restricting advanced AI chip exports, particularly to China
- **<EntityLink id="E67">Compute Thresholds</EntityLink>**: Using training compute as a measurable threshold for regulatory triggers
- **<EntityLink id="E66">Compute Monitoring</EntityLink>**: Approaches to tracking and verifying AI training runs
- **Hardware-Enabled Governance**: Technical mechanisms in AI hardware for monitoring and enforcement
- **<EntityLink id="E170">International Compute Regimes</EntityLink>**: Proposals for international coordination on compute governance

## International Coordination

Mechanisms for cross-border cooperation on AI safety:

- **<EntityLink id="E173">International AI Safety Summits</EntityLink>**: Series of international summits on AI safety starting with Bletchley Park (2023)
- **Bletchley Declaration**: First international agreement on AI safety signed by 28 countries
- **<EntityLink id="E279">Seoul Declaration</EntityLink>**: Follow-up international commitment on frontier AI safety
- **International Coordination Mechanisms**: Bilateral dialogues, multilateral treaties, and institutional networks

## Industry Self-Regulation

Voluntary commitments and industry-led safety frameworks:

- **<EntityLink id="E252">Responsible Scaling Policies</EntityLink>**: Framework pioneered by Anthropic tying safety requirements to capability levels
- **<EntityLink id="E369">Voluntary Industry Commitments</EntityLink>**: Commitments secured by the Biden administration from major AI labs
- **Model Registries**: Centralized databases for tracking frontier AI models

## Governance Assessment

- **<EntityLink id="E154">AI Governance and Policy</EntityLink>**: Broader analysis of governance approaches and their effectiveness
- **<EntityLink id="E113">Policy Effectiveness Assessment</EntityLink>**: Evaluating which governance interventions actually reduce risk

## Key Tensions

**Speed vs. thoroughness**: The pace of AI capability development outstrips the pace of legislative and regulatory processes in most jurisdictions.

**National vs. international**: AI development is global but governance is primarily national, creating coordination challenges and regulatory arbitrage risks.

**Voluntary vs. mandatory**: Industry self-regulation (RSPs, voluntary commitments) is faster to implement but lacks enforcement mechanisms. Legislation provides enforcement but is slower and harder to update.

**Compute governance as bottleneck**: Compute is the most governable input to AI development (physical, concentrated, measurable), but effective compute governance requires international coordination that remains elusive.
