---
numericId: E846
title: Safety Responses
description: Interventions and approaches to address AI safety risks
sidebar:
  label: Overview
  order: 0
---
import {EntityLink} from '@components/wiki';


## Overview

This section documents interventions and approaches being developed to address AI safety risks. Responses span technical research, governance mechanisms, institutional development, and public engagement.

## Response Categories

### <EntityLink id="interpretability">Technical Alignment</EntityLink>
Research aimed at ensuring AI systems behave as intended:
- <EntityLink id="interpretability">Mechanistic Interpretability</EntityLink> - Understanding model internals
- <EntityLink id="rlhf">RLHF</EntityLink> - Reinforcement learning from human feedback
- <EntityLink id="constitutional-ai">Constitutional AI</EntityLink> - Training with explicit principles
- <EntityLink id="ai-control">AI Control</EntityLink> - Limiting AI autonomy regardless of alignment
- <EntityLink id="evals">Evaluations</EntityLink> - Testing for dangerous capabilities

### <EntityLink id="thresholds">Governance</EntityLink>
Policy and regulatory approaches:
- <EntityLink id="thresholds">Compute Governance</EntityLink> - Controlling AI through hardware
- <EntityLink id="export-controls">Export Controls</EntityLink> - Restricting chip access
- <EntityLink id="responsible-scaling-policies">Responsible Scaling Policies</EntityLink> - Lab commitments
- <EntityLink id="eu-ai-act">Legislation</EntityLink> - Government regulation

### <EntityLink id="ai-safety-institutes">Institutions</EntityLink>
Organizations and structures for AI safety:
- <EntityLink id="ai-safety-institutes">AI Safety Institutes</EntityLink> - Government research bodies
- <EntityLink id="standards-bodies">Standards Bodies</EntityLink> - Technical standard development

### <EntityLink id="coordination-tech">Epistemic Tools</EntityLink>
Technologies to preserve information integrity:
- <EntityLink id="coordination-tech">Coordination Technologies</EntityLink> - Enabling cooperation
- <EntityLink id="content-authentication">Content Authentication</EntityLink> - Verifying authentic media
- <EntityLink id="prediction-markets">Prediction Markets</EntityLink> - Aggregating forecasts

### <EntityLink id="training-programs">Field Building</EntityLink>
Growing the AI safety research community:
- <EntityLink id="training-programs">Training Programs</EntityLink> - Researcher development
- <EntityLink id="corporate-influence">Corporate Influence</EntityLink> - Engaging industry

### Biosecurity
Interventions addressing AI-enabled biological risks:
- DNA Synthesis Screening - Preventing dangerous pathogen reconstruction (SecureDNA, IBBIS)
- Metagenomic Surveillance - Pathogen-agnostic early warning (NAO/SecureBio)
- Medical Countermeasures - Resilience-based defenses (Red Queen Bio, platform vaccines)
- Far-UVC & Physical Defenses - Environmental pathogen reduction (Blueprint Biosecurity)
- AI Bio-Capability Evaluations - Measuring AI biological uplift (VCT, red-teaming)

## Evaluating Responses

Each response page includes assessments of:
- **Tractability** - How feasible is progress?
- **Neglectedness** - How much attention is it getting?
- **Potential Impact** - How much could it help if successful?

See the <EntityLink id="intervention-portfolio">Intervention Portfolio</EntityLink> for comparative analysis.
