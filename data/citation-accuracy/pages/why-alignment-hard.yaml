- pageId: why-alignment-hard
  footnote: 12
  claimText: '- Empirical support: Khan et al. (ICML 2024 Best Paper) found that optimizing debaters for persuasiveness improved truth-finding, with judges reaching...'
  sourceTitle: On scalable oversight with weak LLMs judging strong LLMs
  url: https://proceedings.neurips.cc/paper_files/paper/2024/hash/899511e37a8e01e1bd6f6f1d377cc250-Abstract-Conference.html
  verdict: inaccurate
  score: 0.3
  issues: |-
    WRONG ATTRIBUTION: The source is attributed to Khan et al. (ICML 2024 Best Paper), but the source is actually titled "On scalable oversight with weak LLMs judging strong LLMs" and does not mention Khan et al.
    WRONG ATTRIBUTION: The source is attributed to Kenton et al. (NeurIPS 2024), but the source does not mention Kenton et al.
    UNSUPPORTED: The source does not mention that optimizing debaters for persuasiveness improved truth-finding, with judges reaching 76â€“88% accuracy compared to ~50% baselines.
    MISLEADING PARAPHRASE: The claim states that debate consistently outperforms consultancy across mathematics, coding, logic, and multimodal reasoning tasks, but the source states that debate outperforms consultancy across all tasks when the consultant is randomly assigned to argue for the correct/incorrect answer.
  difficulty: easy
  checkedAt: '2026-02-20 16:32:51'
