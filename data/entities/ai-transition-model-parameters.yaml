- id: international-coordination
  type: ai-transition-model-parameter
  title: International Coordination
  description: Degree of global cooperation on AI governance and safety, measured through treaty
    participation, shared standards adoption, and institutional network strength.
  customFields:
    - label: Direction
      value: Higher is better
    - label: Current Trend
      value: Mixed (11-country AISI network, but US/UK refused Paris 2025 declaration)
    - label: Key Measurement
      value: Treaty signatories, AISI network participation, shared evaluation standards
  relatedEntries:
    - id: international-summits
      type: approach
      relationship: related
    - id: geopolitics
      type: ai-transition-model-metric
      relationship: measured-by
    - id: racing-dynamics-model
      type: model
      relationship: analyzed-by
    - id: multipolar-trap-dynamics
      type: model
      relationship: analyzed-by
    - id: international-coordination-game
      type: model
      relationship: analyzed-by
  tags:
    - governance
    - international
    - coordination
  lastUpdated: 2025-12
  causeEffectGraph:
    title: What Drives International AI Coordination?
    description: Causal factors affecting global cooperation on AI governance. Based on game theory and
      international relations research.
    primaryNodeId: international-coordination
    nodes:
      - id: shared-threat-perception
        label: Shared Threat Perception
        type: leaf
        color: emerald
        description: Common understanding that AI poses global risks requiring cooperation.
        scores:
          novelty: 3  # Well-known factor in international relations literature
          sensitivity: 7  # Major driver of coordination willingness; shifts here ripple through cooperation
          changeability: 5  # Can shift with salient events (AI incidents) but hard to engineer
          certainty: 6  # Reasonably well-studied in IR theory; some uncertainty about AI-specific dynamics
      - id: us-china-relations
        label: US-China Relations
        type: leaf
        color: red
        description: Geopolitical relationship between leading AI powers. Currently adversarial.
        scores:
          novelty: 2  # Common knowledge that this is the key bilateral relationship
          sensitivity: 9  # Single most important variable for global AI coordination; determines cooperation ceiling
          changeability: 2  # Deep structural factors; unlikely to shift dramatically in 5-10 year horizon
          certainty: 7  # Well-documented current state; future trajectory less certain
      - id: institutional-frameworks
        label: Institutional Frameworks
        type: leaf
        color: blue
        description: Existing international bodies (UN, OECD, G7) that could facilitate coordination.
        scores:
          novelty: 3  # Known that institutions matter; AI-specific adaptation somewhat novel
          sensitivity: 5  # Enables but doesn't determine coordination; more of a channel than driver
          changeability: 4  # New bodies possible (AISI network) but slow to establish legitimacy
          certainty: 6  # Institutional effects well-studied; AI-specific adaptation less certain
      - id: trust-between-nations
        label: Trust Between Nations
        type: intermediate
        color: teal
        description: Confidence that commitments will be honored. Verification reduces need for trust.
        scores:
          novelty: 2  # Core IR concept; well understood as cooperation prerequisite
          sensitivity: 8  # Critical bottleneck; without trust, coordination mechanisms hollow
          changeability: 3  # Builds slowly through repeated interactions; easily destroyed
          certainty: 7  # Strong theoretical and empirical grounding in cooperation theory
      - id: coordination-mechanisms
        label: Coordination Mechanisms
        type: intermediate
        description: Treaties, summits, AI Safety Institute networks, shared standards.
        scores:
          novelty: 4  # Specific AI mechanisms (AISI network) are recent; general concept not novel
          sensitivity: 6  # Important transmission channel; effectiveness depends on underlying trust
          changeability: 6  # Can be built deliberately; AISI expansion shows tractability
          certainty: 5  # Which mechanisms work for AI specifically is still being tested
      - id: verification-technology
        label: Verification Technology
        type: leaf
        color: emerald
        description: Technical means to verify compliance with agreements (compute monitoring, model evaluations).
        scores:
          novelty: 6  # Novel application of monitoring tech to AI governance
          sensitivity: 7  # Enables trust-reduced cooperation; key for overcoming commitment problems
          changeability: 5  # Active R&D area; deployment requires political will
          certainty: 4  # Whether verification is technically feasible for AI is uncertain
      - id: racing-dynamics
        label: Racing Dynamics
        type: leaf
        color: rose
        description: Competitive pressure to advance AI capabilities faster than rivals, reducing cooperation.
        scores:
          novelty: 4  # Known from arms race literature; AI application moderately novel
          sensitivity: 8  # Major obstacle to coordination; creates urgency that undermines deliberation
          changeability: 4  # Structural economic and security incentives; hard to shift
          certainty: 6  # Dynamics well-understood; intensity debated
      - id: domestic-politics
        label: Domestic Politics
        type: leaf
        color: slate
        description: Internal political constraints on international AI commitments (nationalism, industry lobbying).
        scores:
          novelty: 3  # Classic constraint on international cooperation
          sensitivity: 6  # Can veto cooperation even when leaders agree
          changeability: 4  # Depends on elections, public opinion, interest group dynamics
          certainty: 6  # Well-studied in IR; AI-specific pressures emerging
      - id: can-cooperation-survive-capability-gaps
        label: Can cooperation survive capability gaps?
        type: leaf
        color: violet
        description: Key uncertainty whether coordination holds as AI advantages become strategically decisive.
        scores:
          novelty: 5  # Novel question as AI capabilities diverge
          sensitivity: 8  # Fundamental question about coordination viability
          changeability: 3  # Structural tension; hard to engineer around
          certainty: 3  # No historical precedent for this dynamic
      - id: international-coordination
        label: International Coordination
        type: effect
        description: Effective global cooperation on AI safety and governance.
        scores:
          novelty: 3  # Need for coordination is recognized; specific challenges somewhat novel
          sensitivity: 9  # Affects entire trajectory of global AI governance outcomes
          changeability: 4  # Resultant of upstream factors; direct intervention difficult
          certainty: 4  # How much coordination is achievable/needed is debated
    edges:
      - source: shared-threat-perception
        target: coordination-mechanisms
        strength: strong
        effect: increases
      - source: us-china-relations
        target: trust-between-nations
        strength: strong
        effect: increases
      - source: institutional-frameworks
        target: coordination-mechanisms
        strength: medium
        effect: increases
      - source: trust-between-nations
        target: international-coordination
        strength: strong
        effect: increases
      - source: coordination-mechanisms
        target: international-coordination
        strength: strong
        effect: increases
      - source: verification-technology
        target: trust-between-nations
        strength: medium
        effect: increases
      - source: racing-dynamics
        target: international-coordination
        strength: strong
        effect: decreases
      - source: domestic-politics
        target: coordination-mechanisms
        strength: medium
        effect: decreases
      - source: can-cooperation-survive-capability-gaps
        target: international-coordination
        strength: medium
        effect: mixed
- id: societal-trust
  type: ai-transition-model-parameter
  title: Societal Trust
  description: Level of public confidence in institutions, experts, and verification systems. A
    foundational parameter affecting democratic function and collective action.
  customFields:
    - label: Direction
      value: Higher is better
    - label: Current Trend
      value: Declining (77% → 22% government trust since 1964)
    - label: Measurement
      value: Survey data (Pew, Gallup)
  parameterDistinctions:
    focus: Do we trust institutions?
    summary: Confidence in institutions, experts, and verification systems
    distinctFrom:
      - id: epistemic-health
        theirFocus: Can we tell what's true?
        relationship: Epistemic health reveals whether institutions deserve trust
      - id: reality-coherence
        theirFocus: Do we agree on facts?
        relationship: Trust enables acceptance of shared facts; fragmentation erodes trust
  relatedEntries:
    - id: trust-decline
      type: risk
      relationship: decreases
    - id: disinformation
      type: risk
      relationship: decreases
    - id: deepfakes
      type: risk
      relationship: decreases
    - id: content-authentication
      type: approach
      relationship: supports
    - id: epistemic-health
      type: ai-transition-model-parameter
      relationship: related
    - id: information-authenticity
      type: ai-transition-model-parameter
      relationship: related
    - id: public-opinion
      type: ai-transition-model-metric
      relationship: measured-by
    - id: trust-cascade-model
      type: model
      relationship: analyzed-by
    - id: deepfakes-authentication-crisis
      type: model
      relationship: analyzed-by
    - id: sycophancy-feedback-loop
      type: model
      relationship: analyzed-by
    - id: epistemic-collapse-threshold
      type: model
      relationship: analyzed-by
    - id: trust-erosion-dynamics
      type: model
      relationship: analyzed-by
  tags:
    - epistemic
    - governance
    - structural
  lastUpdated: 2025-12
  causeEffectGraph:
    title: What Affects Societal Trust?
    description: Causal factors driving trust in institutions, experts, and verification systems. Trust
      has declined from 77% to 22% since 1964.
    primaryNodeId: societal-trust
    nodes:
      - id: institutional-performance
        label: Institutional Performance
        type: leaf
        color: blue
        description: Track record of institutions delivering on promises. Failures erode trust.
        scores:
          novelty: 2  # Well-established in political science; nothing surprising
          sensitivity: 8  # Primary determinant of warranted trust; failures cascade broadly
          changeability: 4  # Requires sustained institutional reform; slow to improve
          certainty: 8  # Strong empirical evidence linking performance to trust
      - id: deepfake-prevalence
        label: Deepfake Prevalence
        type: leaf
        color: red
        description: AI-generated fake content undermines ability to verify reality.
        scores:
          novelty: 5  # AI-generated content is new threat vector; general concept known
          sensitivity: 7  # Directly undermines verification; affects trust in all media
          changeability: 3  # Driven by AI capability advances; hard to reverse prevalence
          certainty: 5  # Effects still emerging; unclear how severe long-term impact
      - id: media-polarization
        label: Media Polarization
        type: leaf
        color: rose
        description: Fragmented information environment where different groups see different facts.
        scores:
          novelty: 3  # Polarization well-documented; AI amplification aspect moderately novel
          sensitivity: 7  # Fragments shared reality; makes collective action difficult
          changeability: 3  # Deep structural and algorithmic drivers; resistant to intervention
          certainty: 7  # Well-measured trend; mechanisms understood
      - id: verification-capability
        label: Verification Capability
        type: intermediate
        color: emerald
        description: Ability to distinguish authentic from fake content.
        scores:
          novelty: 5  # Content authentication is emerging field; specific techniques novel
          sensitivity: 7  # Determines whether deepfakes actually undermine trust
          changeability: 5  # Technical solutions possible (C2PA); adoption uncertain
          certainty: 4  # Arms race dynamics unclear; which approaches will scale unknown
      - id: shared-reality
        label: Shared Reality
        type: intermediate
        description: Common factual foundation for democratic deliberation.
        scores:
          novelty: 4  # Fragmentation is known; AI acceleration of it moderately novel
          sensitivity: 8  # Foundation for democracy and collective action; erosion cascades
          changeability: 3  # Difficult to rebuild once lost; requires sustained effort
          certainty: 6  # Decline well-documented; recovery mechanisms less understood
      - id: expert-credibility
        label: Expert Credibility
        type: leaf
        color: teal
        description: Public perception of whether experts have reliable knowledge and good incentives.
        scores:
          novelty: 3  # Long-standing sociological concept
          sensitivity: 7  # Key intermediary for science communication and policy uptake
          changeability: 4  # Depends on expert behavior and media portrayal
          certainty: 6  # Well-studied in science communication
      - id: algorithmic-amplification
        label: Algorithmic Amplification
        type: leaf
        color: rose
        description: Social media algorithms that amplify divisive and emotionally engaging content.
        scores:
          novelty: 5  # Relatively new phenomenon; mechanisms increasingly understood
          sensitivity: 7  # Major driver of polarization and distrust
          changeability: 5  # Platform policy and regulation can shift this
          certainty: 6  # Growing empirical evidence on effects
      - id: ai-sycophancy
        label: AI Sycophancy
        type: leaf
        color: violet
        description: AI systems that tell users what they want to hear, reinforcing biases.
        scores:
          novelty: 7  # Emerging concern as AI assistants become widespread
          sensitivity: 6  # Could accelerate filter bubbles and epistemic fragmentation
          changeability: 5  # Training approaches can mitigate; competitive pressure to please users
          certainty: 4  # Effects on trust still speculative
      - id: can-trust-be-rebuilt
        label: Can trust be rebuilt once lost?
        type: leaf
        color: violet
        description: Key uncertainty about whether institutional trust can recover from current lows.
        scores:
          novelty: 4  # Historical precedents exist but AI context novel
          sensitivity: 8  # Determines whether decline is reversible
          changeability: 3  # Structural question; not directly changeable
          certainty: 3  # Limited historical precedent for recovery
      - id: societal-trust
        label: Societal Trust
        type: effect
        description: Confidence in institutions, experts, and verification systems.
        scores:
          novelty: 3  # Trust decline well-documented; AI-specific dynamics add some novelty
          sensitivity: 9  # Foundational for governance, coordination, and social cohesion
          changeability: 3  # Resultant of upstream factors; direct intervention limited
          certainty: 7  # Current levels well-measured; future trajectory uncertain
    edges:
      - source: institutional-performance
        target: societal-trust
        strength: strong
        effect: increases
      - source: deepfake-prevalence
        target: verification-capability
        strength: strong
        effect: decreases
      - source: media-polarization
        target: shared-reality
        strength: strong
        effect: decreases
      - source: verification-capability
        target: societal-trust
        strength: medium
        effect: increases
      - source: shared-reality
        target: societal-trust
        strength: medium
        effect: increases
      - source: expert-credibility
        target: societal-trust
        strength: medium
        effect: increases
      - source: algorithmic-amplification
        target: media-polarization
        strength: strong
        effect: increases
      - source: ai-sycophancy
        target: shared-reality
        strength: medium
        effect: decreases
      - source: can-trust-be-rebuilt
        target: societal-trust
        strength: medium
        effect: mixed
- id: epistemic-health
  type: ai-transition-model-parameter
  title: Epistemic Health
  description: Society's collective ability to distinguish truth from falsehood and form shared
    beliefs about reality. Essential for democratic deliberation and coordinated action.
  customFields:
    - label: Direction
      value: Higher is better
    - label: Current Trend
      value: Declining (50%+ web content AI-generated)
    - label: Measurement
      value: Verification success rates, consensus formation
  parameterDistinctions:
    focus: Can we tell what's true?
    summary: Ability to distinguish truth from falsehood
    distinctFrom:
      - id: societal-trust
        theirFocus: Do we trust institutions?
        relationship: Trust enables verification; epistemic health reveals trustworthiness
      - id: reality-coherence
        theirFocus: Do we agree on facts?
        relationship: Epistemic health is capacity; coherence is the outcome when that capacity is shared
  relatedEntries:
    - id: epistemic-collapse
      type: risk
      relationship: decreases
    - id: disinformation
      type: risk
      relationship: decreases
    - id: consensus-manufacturing
      type: risk
      relationship: decreases
    - id: epistemic-security
      type: approach
      relationship: supports
    - id: societal-trust
      type: ai-transition-model-parameter
      relationship: related
    - id: information-authenticity
      type: ai-transition-model-parameter
      relationship: related
    - id: expert-opinion
      type: ai-transition-model-metric
      relationship: measured-by
    - id: epistemic-collapse-threshold
      type: model
      relationship: analyzed-by
    - id: trust-cascade-model
      type: model
      relationship: analyzed-by
    - id: reality-fragmentation-network
      type: model
      relationship: analyzed-by
    - id: authentication-collapse-timeline
      type: model
      relationship: analyzed-by
  tags:
    - epistemic
    - information-environment
  lastUpdated: 2025-12
  causeEffectGraph:
    title: What Affects Epistemic Health?
    description: Causal factors affecting society's ability to distinguish truth from falsehood.
      AI-generated content now comprises 50%+ of web content.
    primaryNodeId: epistemic-health
    nodes:
      - id: ai-content-generation
        label: AI Content Generation
        type: leaf
        color: red
        description: Cheap, scalable production of synthetic text, images, audio, video.
        scores:
          novelty: 4  # Well-known capability; scale and ease continue to surprise
          sensitivity: 8  # Fundamental driver of information environment change
          changeability: 2  # Capability genie out of bottle; will only increase
          certainty: 8  # Clear trajectory of increasing synthetic content
      - id: fact-checking-capacity
        label: Fact-Checking Capacity
        type: leaf
        color: emerald
        description: Human and automated verification resources. Lags content production.
        scores:
          novelty: 4  # AI-assisted fact-checking is novel; basic concept known
          sensitivity: 5  # Helps but can't scale to match content volume
          changeability: 6  # Can be expanded with investment; AI tools emerging
          certainty: 6  # Current limitations clear; AI augmentation potential uncertain
      - id: media-literacy
        label: Media Literacy
        type: leaf
        color: blue
        description: Population's ability to critically evaluate information sources.
        scores:
          novelty: 3  # Long-standing concept; AI-era requirements moderately novel
          sensitivity: 5  # Individual defense; limited against sophisticated manipulation
          changeability: 5  # Education possible but slow; generational timescales
          certainty: 6  # Effectiveness of literacy programs moderately understood
      - id: content-verification
        label: Content Verification
        type: intermediate
        color: emerald
        description: Systems for authenticating real vs. synthetic content.
        scores:
          novelty: 6  # Technical provenance systems (C2PA) are genuinely new
          sensitivity: 7  # Critical chokepoint; if verification fails, epistemic health declines
          changeability: 5  # Standards exist; adoption is the challenge
          certainty: 4  # Whether verification can stay ahead of generation unclear
      - id: source-credibility
        label: Source Credibility
        type: intermediate
        description: Ability to identify reliable information sources.
        scores:
          novelty: 3  # Journalistic credibility long studied; AI complicates it
          sensitivity: 6  # Important heuristic when content verification fails
          changeability: 4  # Depends on media ecosystem; slow to shift
          certainty: 5  # Traditional signals weakening; new signals emerging
      - id: scientific-consensus-formation
        label: Scientific Consensus Formation
        type: leaf
        color: teal
        description: Processes by which scientific communities reach agreement on facts and theories.
        scores:
          novelty: 4  # Process well-studied; AI impacts moderately novel
          sensitivity: 7  # Upstream of public understanding of science
          changeability: 4  # Depends on academic incentives and norms; slow to shift
          certainty: 6  # Mechanisms understood; AI disruption effects uncertain
      - id: information-asymmetry
        label: Information Asymmetry
        type: leaf
        color: rose
        description: Power imbalance where some actors have much better access to accurate information.
        scores:
          novelty: 4  # Classic economics concept; AI amplification novel
          sensitivity: 6  # Affects who can navigate the information environment
          changeability: 4  # Structural feature; requires deliberate intervention
          certainty: 6  # Well-understood in principle; AI-era dynamics emerging
      - id: coordination-on-truth
        label: Coordination on Truth
        type: intermediate
        color: violet
        description: Collective action to establish and maintain shared factual foundations.
        scores:
          novelty: 5  # Framing somewhat novel; underlies many interventions
          sensitivity: 8  # Determines whether verification efforts succeed at scale
          changeability: 5  # Requires institutional commitment; can be built
          certainty: 4  # Whether such coordination is achievable is uncertain
      - id: can-ai-help-verify-ai-content
        label: Can AI help verify AI content?
        type: leaf
        color: violet
        description: Key uncertainty whether AI detection can keep pace with AI generation.
        scores:
          novelty: 6  # Arms race dynamics novel; specific technical question
          sensitivity: 8  # Determines whether verification strategies can scale
          changeability: 3  # Depends on fundamental technical capabilities
          certainty: 3  # Actively researched but fundamentally uncertain
      - id: epistemic-health
        label: Epistemic Health
        type: effect
        description: Society's collective capacity to form accurate beliefs.
        scores:
          novelty: 4  # Epistemic concerns well-known; AI scale effects newer
          sensitivity: 9  # Foundation for democracy, coordination, and good decisions
          changeability: 3  # Emergent from many factors; hard to directly improve
          certainty: 5  # Current state hard to measure; threshold effects unclear
    edges:
      - source: ai-content-generation
        target: content-verification
        strength: strong
        effect: decreases
      - source: fact-checking-capacity
        target: content-verification
        strength: medium
        effect: increases
      - source: media-literacy
        target: source-credibility
        strength: medium
        effect: increases
      - source: content-verification
        target: epistemic-health
        strength: strong
        effect: increases
      - source: source-credibility
        target: epistemic-health
        strength: strong
        effect: increases
      - source: scientific-consensus-formation
        target: source-credibility
        strength: medium
        effect: increases
      - source: information-asymmetry
        target: epistemic-health
        strength: medium
        effect: decreases
      - source: coordination-on-truth
        target: epistemic-health
        strength: strong
        effect: increases
      - source: can-ai-help-verify-ai-content
        target: content-verification
        strength: medium
        effect: mixed
- id: information-authenticity
  type: ai-transition-model-parameter
  title: Information Authenticity
  description: The degree to which content circulating in society can be verified as genuine—tracing
    to real sources, events, or creators. Currently stressed by AI-generated content and deepfake
    detection challenges.
  customFields:
    - label: Direction
      value: Higher is better
    - label: Current Trend
      value: Declining (human deepfake detection at 55% accuracy)
    - label: Measurement
      value: Verification capability, provenance adoption, detection accuracy
  relatedEntries:
    - id: epistemic-health
      type: ai-transition-model-parameter
      relationship: related
    - id: deepfakes-authentication-crisis
      type: model
      relationship: analyzed-by
    - id: authentication-collapse-timeline
      type: model
      relationship: analyzed-by
    - id: trust-cascade-model
      type: model
      relationship: analyzed-by
  tags:
    - epistemic
    - information-environment
    - verification
  lastUpdated: 2025-12
  causeEffectGraph:
    title: What Affects Information Authenticity?
    description: Causal factors affecting content verification. Human deepfake detection at 55%
      accuracy; AI detection in arms race.
    primaryNodeId: information-authenticity
    nodes:
      - id: generative-ai-quality
        label: Generative AI Quality
        type: leaf
        color: red
        description: Fidelity of synthetic content. Approaching indistinguishable from real.
        scores:
          novelty: 4  # Rapid improvement known; specific capabilities still surprise
          sensitivity: 8  # Directly determines detection difficulty; sets the challenge
          changeability: 2  # Will continue improving; cannot be reversed
          certainty: 8  # Clear trajectory toward photorealism across modalities
      - id: provenance-standards
        label: Provenance Standards
        type: leaf
        color: emerald
        description: C2PA and similar content authenticity initiatives.
        scores:
          novelty: 7  # C2PA relatively new; cryptographic provenance is emerging approach
          sensitivity: 6  # Important if adopted; effectiveness depends on platform uptake
          changeability: 6  # Standards can be developed; adoption requires coordination
          certainty: 4  # Whether provenance approach will scale and be adopted unclear
      - id: detection-technology
        label: Detection Technology
        type: leaf
        color: emerald
        description: AI and human ability to identify synthetic content.
        scores:
          novelty: 5  # Detection methods advancing; arms race dynamics known
          sensitivity: 7  # Key countermeasure to generation; if detection fails, authenticity collapses
          changeability: 5  # Research active but may structurally lose to generation
          certainty: 3  # Whether detection can keep pace fundamentally uncertain
      - id: platform-adoption
        label: Platform Adoption
        type: intermediate
        color: teal
        description: Deployment of authenticity tools by major platforms.
        scores:
          novelty: 5  # Platform role in authenticity emerging; incentives unclear
          sensitivity: 6  # Platforms are key distribution chokepoint; adoption enables verification
          changeability: 5  # Depends on business incentives and regulation; tractable with pressure
          certainty: 4  # Platform willingness and implementation quality uncertain
      - id: detection-effectiveness
        label: Detection Effectiveness
        type: intermediate
        description: Real-world accuracy of authenticity verification.
        scores:
          novelty: 5  # Performance metrics emerging; arms race outcomes novel
          sensitivity: 8  # Directly determines practical authenticity; critical bottleneck
          changeability: 4  # Constrained by technology; may be structurally limited
          certainty: 3  # Current 55% human accuracy concerning; trajectory unclear
      - id: information-authenticity
        label: Information Authenticity
        type: effect
        description: Degree to which circulating content can be verified as genuine.
        scores:
          novelty: 5  # Authenticity crisis emerging; specific dynamics novel
          sensitivity: 8  # Foundation for epistemic health and trust; erosion cascades
          changeability: 3  # Resultant of technology arms race; hard to directly shift
          certainty: 4  # Whether authenticity can be maintained is key open question
    edges:
      - source: generative-ai-quality
        target: detection-effectiveness
        strength: strong
        effect: decreases
      - source: provenance-standards
        target: platform-adoption
        strength: medium
        effect: increases
      - source: detection-technology
        target: detection-effectiveness
        strength: strong
        effect: increases
      - source: platform-adoption
        target: information-authenticity
        strength: medium
        effect: increases
      - source: detection-effectiveness
        target: information-authenticity
        strength: strong
        effect: increases
- id: ai-control-concentration
  type: ai-transition-model-parameter
  title: AI Control Concentration
  description: How concentrated or distributed power over AI development and deployment is across
    actors. Neither extreme concentration nor complete diffusion is optimal.
  customFields:
    - label: Direction
      value: Context-dependent (neither extreme ideal)
    - label: Current Trend
      value: Concentrating (<20 orgs can train frontier models)
    - label: Measurement
      value: Market share, compute access, talent distribution
  relatedEntries:
    - id: concentration-of-power
      type: risk
      relationship: related
    - id: compute-hardware
      type: ai-transition-model-metric
      relationship: measured-by
    - id: winner-take-all-model
      type: model
      relationship: analyzed-by
    - id: winner-take-all-concentration
      type: model
      relationship: analyzed-by
    - id: concentration-of-power-model
      type: model
      relationship: analyzed-by
    - id: international-coordination-game
      type: model
      relationship: analyzed-by
  tags:
    - structural
    - governance
    - market-dynamics
  lastUpdated: 2025-12
  causeEffectGraph:
    title: What Drives AI Control Concentration?
    description: Causal factors affecting power distribution in AI. Currently <20 organizations can
      train frontier models.
    primaryNodeId: ai-control-concentration
    nodes:
      - id: compute-requirements
        label: Compute Requirements
        type: leaf
        description: Training frontier models requires $100M-$1B+ compute. Barrier to entry.
        scores:
          novelty: 3  # Well-documented scaling laws; cost trajectory known
          sensitivity: 8  # Primary barrier to entry; sets concentration floor
          changeability: 4  # Algorithmic efficiency could reduce, but likely to remain high
          certainty: 7  # Current requirements well-measured; future requirements debated
      - id: talent-concentration
        label: Talent Concentration
        type: leaf
        description: Top AI researchers clustered in few labs. Critical bottleneck.
        scores:
          novelty: 3  # Known that ML talent scarce; geographic/org concentration well-documented
          sensitivity: 7  # Key input to frontier capabilities; affects who can compete
          changeability: 5  # Education pipeline can expand; but takes years
          certainty: 7  # Current distribution clear; future diffusion uncertain
      - id: data-advantages
        label: Data Advantages
        type: leaf
        description: Proprietary datasets and feedback loops favor incumbents.
        scores:
          novelty: 4  # Data flywheels known; AI-specific dynamics moderately novel
          sensitivity: 6  # Important but less critical than compute; synthetic data may reduce
          changeability: 4  # Accumulated advantages hard to replicate; open data initiatives possible
          certainty: 5  # Role of data vs compute in future models debated
      - id: capital-barriers
        label: Capital Barriers
        type: intermediate
        description: Financial requirements exclude most potential entrants.
        scores:
          novelty: 3  # Capital barriers to entry well-understood in economics
          sensitivity: 7  # Directly determines who can participate in frontier development
          changeability: 4  # Could reduce with cheaper compute; but requirements growing
          certainty: 7  # Current barriers clear; trajectory depends on compute costs
      - id: network-effects
        label: Network Effects
        type: intermediate
        description: Users, developers, and data create reinforcing advantages.
      - id: ai-control-concentration
        label: AI Control Concentration
        type: effect
        description: Degree to which AI power is concentrated vs distributed.
    edges:
      - source: compute-requirements
        target: capital-barriers
        strength: strong
        effect: increases
      - source: talent-concentration
        target: ai-control-concentration
        strength: strong
        effect: increases
      - source: data-advantages
        target: network-effects
        strength: medium
        effect: increases
      - source: capital-barriers
        target: ai-control-concentration
        strength: strong
        effect: increases
      - source: network-effects
        target: ai-control-concentration
        strength: medium
        effect: increases
- id: human-agency
  type: ai-transition-model-parameter
  title: Human Agency
  description: Degree of meaningful human control over decisions affecting their lives. Includes
    autonomy, oversight capacity, and ability to opt out of AI-mediated systems.
  customFields:
    - label: Direction
      value: Higher is better
    - label: Current Trend
      value: Declining (increasing automation of decisions)
    - label: Measurement
      value: Decision autonomy, opt-out availability, oversight capacity
  relatedEntries:
    - id: erosion-of-agency
      type: risk
      relationship: related
    - id: economic-labor
      type: ai-transition-model-metric
      relationship: measured-by
    - id: economic-disruption-impact
      type: model
      relationship: analyzed-by
    - id: expertise-atrophy-cascade
      type: model
      relationship: analyzed-by
    - id: preference-manipulation-drift
      type: model
      relationship: analyzed-by
    - id: concentration-of-power-model
      type: model
      relationship: analyzed-by
  tags:
    - structural
    - autonomy
    - human-ai-interaction
  lastUpdated: 2025-12
  causeEffectGraph:
    title: What Affects Human Agency?
    description: Causal factors affecting meaningful human control over decisions. Automation
      increasingly replaces human judgment.
    primaryNodeId: human-agency
    nodes:
      - id: automation-scope
        label: Automation Scope
        type: leaf
        description: Range of decisions delegated to AI systems. Expanding rapidly.
        scores:
          novelty: 3 # Well-known concern in automation literature
          sensitivity: 8 # Major driver of downstream effects on skills and oversight
          changeability: 4 # Driven by economic incentives; hard to reverse
          certainty: 7 # Clear empirical trends in automation adoption
      - id: opt-out-availability
        label: Opt-Out Availability
        type: leaf
        description: Ability to choose non-AI alternatives. Declining as AI becomes infrastructure.
        scores:
          novelty: 5 # Underappreciated issue as AI becomes default
          sensitivity: 6 # Important for autonomy but indirect effects
          changeability: 5 # Policy can mandate alternatives but market pressure strong
          certainty: 5 # Trajectory unclear; depends on regulatory choices
      - id: decision-transparency
        label: Decision Transparency
        type: leaf
        description: Understanding of how AI-influenced decisions are made.
        scores:
          novelty: 4 # Active research area; reasonably well-known
          sensitivity: 5 # Enables oversight but effect depends on capacity to act
          changeability: 6 # Technical and regulatory solutions possible
          certainty: 4 # Interpretability progress uncertain
      - id: skill-retention
        label: Skill Retention
        type: intermediate
        description: Maintenance of human capabilities to function without AI.
        scores:
          novelty: 6 # Underappreciated systemic risk
          sensitivity: 7 # Critical for maintaining fallback capability
          changeability: 5 # Requires deliberate practice opportunities
          certainty: 6 # Well-documented in aviation and medicine
      - id: oversight-effectiveness
        label: Oversight Effectiveness
        type: intermediate
        description: Ability to review and override AI decisions.
        scores:
          novelty: 4 # Core AI safety concern; widely discussed
          sensitivity: 8 # Critical mediator of AI impact on agency
          changeability: 5 # Depends on both tech and institutional design
          certainty: 5 # Effectiveness varies by domain and implementation
      - id: human-agency
        label: Human Agency
        type: effect
        description: Meaningful human control over decisions affecting lives.
        scores:
          novelty: 3 # Foundational concept; well-established concern
          sensitivity: 9 # Affects many downstream outcomes for autonomy and wellbeing
          changeability: 4 # Structural forces push toward less agency
          certainty: 5 # Measurement and boundaries debated
    edges:
      - source: automation-scope
        target: skill-retention
        strength: strong
        effect: decreases
      - source: opt-out-availability
        target: human-agency
        strength: medium
        effect: increases
      - source: decision-transparency
        target: oversight-effectiveness
        strength: medium
        effect: increases
      - source: skill-retention
        target: human-agency
        strength: medium
        effect: increases
      - source: oversight-effectiveness
        target: human-agency
        strength: strong
        effect: increases
- id: economic-stability
  type: ai-transition-model-parameter
  title: Economic Stability
  description: Resilience of economic systems to AI-driven changes—including labor market
    adaptability, income distribution, and transition smoothness. Currently declining as 40-60% of
    jobs face AI exposure.
  customFields:
    - label: Direction
      value: Higher is better
    - label: Current Trend
      value: Mixed (productivity gains vs displacement risks)
    - label: Measurement
      value: Employment rates, inequality indices, transition costs
  relatedEntries:
    - id: economic-disruption
      type: risk
      relationship: related
    - id: economic-labor
      type: ai-transition-model-metric
      relationship: measured-by
    - id: economic-disruption-impact
      type: model
      relationship: analyzed-by
    - id: winner-take-all-model
      type: model
      relationship: analyzed-by
    - id: winner-take-all-concentration
      type: model
      relationship: analyzed-by
  relatedContent:
    risks:
      - path: /knowledge-base/risks/economic-disruption/
        title: Economic Disruption
      - path: /knowledge-base/risks/winner-take-all/
        title: Winner-Take-All Dynamics
      - path: /knowledge-base/risks/concentration-of-power/
        title: Concentration of Power
    responses:
      - path: /knowledge-base/responses/labor-transition/
        title: Labor Transition
    models:
      - path: /knowledge-base/models/economic-disruption-impact/
        title: Economic Disruption Impact
  tags:
    - economic
    - labor-market
    - structural
  lastUpdated: 2025-12
  causeEffectGraph:
    title: What Affects Economic Stability?
    description: Causal factors affecting economic resilience during AI transition. 40-60% of jobs face
      AI exposure.
    primaryNodeId: economic-stability
    nodes:
      - id: ai-capability-growth
        label: AI Capability Growth
        type: leaf
        color: rose
        description: Rate of AI improvement in economically relevant tasks.
        scores:
          novelty: 2 # Widely discussed in AI discourse
          sensitivity: 9 # Primary driver of economic disruption timeline
          changeability: 3 # Driven by massive investment; hard to slow
          certainty: 4 # Trajectory highly uncertain beyond 2-3 years
      - id: labor-market-adaptation
        label: Labor Market Adaptation
        type: leaf
        color: emerald
        description: Speed of worker retraining and job creation. Historically slow.
        scores:
          novelty: 4 # Known from past industrial transitions
          sensitivity: 8 # Critical for whether transition is smooth or disruptive
          changeability: 6 # Policy interventions can accelerate adaptation
          certainty: 6 # Historical data available; AI speed unprecedented
      - id: social-safety-nets
        label: Social Safety Nets
        type: leaf
        color: blue
        description: Unemployment support, retraining programs, income support.
        scores:
          novelty: 3 # Standard policy tool; well-understood
          sensitivity: 6 # Important buffer but doesn't address root displacement
          changeability: 7 # Direct policy lever; politically feasible
          certainty: 7 # Well-established mechanisms; effectiveness measurable
      - id: job-displacement-rate
        label: Job Displacement Rate
        type: intermediate
        description: Speed at which AI replaces human workers in various sectors.
        scores:
          novelty: 4 # Active debate with varying estimates
          sensitivity: 9 # Directly determines economic shock magnitude
          changeability: 4 # Depends on AI progress and adoption decisions
          certainty: 3 # Estimates range from 10% to 80% of jobs affected
      - id: income-distribution
        label: Income Distribution
        type: intermediate
        description: How AI productivity gains are distributed across population.
        scores:
          novelty: 5 # Winner-take-all dynamics underappreciated
          sensitivity: 7 # Determines whether AI benefits are shared or concentrated
          changeability: 6 # Policy can redistribute; political will uncertain
          certainty: 4 # Depends on policy responses not yet determined
      - id: economic-stability
        label: Economic Stability
        type: effect
        description: Resilience of economic systems to AI-driven changes.
        scores:
          novelty: 3 # Macroeconomic stability well-understood concept
          sensitivity: 8 # Affects social cohesion, political stability, wellbeing
          changeability: 5 # Depends on multiple interacting factors
          certainty: 4 # Outcome depends on race between disruption and adaptation
    edges:
      - source: ai-capability-growth
        target: job-displacement-rate
        strength: strong
        effect: increases
      - source: labor-market-adaptation
        target: economic-stability
        strength: strong
        effect: increases
      - source: social-safety-nets
        target: economic-stability
        strength: medium
        effect: increases
      - source: job-displacement-rate
        target: economic-stability
        strength: strong
        effect: decreases
      - source: income-distribution
        target: economic-stability
        strength: medium
        effect: increases
- id: human-expertise
  type: ai-transition-model-parameter
  title: Human Expertise
  description: Maintenance of human skills, knowledge, and cognitive capabilities in an AI-augmented
    world. Tracks skill retention, domain mastery, and ability to function without AI assistance.
  customFields:
    - label: Direction
      value: Higher is better
    - label: Current Trend
      value: Declining (36% news avoidance, rising deskilling concerns)
    - label: Measurement
      value: Skill retention, cognitive engagement, domain knowledge depth
  relatedEntries:
    - id: learned-helplessness
      type: risk
      relationship: related
    - id: economic-labor
      type: ai-transition-model-metric
      relationship: measured-by
    - id: expertise-atrophy-progression
      type: model
      relationship: analyzed-by
    - id: expertise-atrophy-cascade
      type: model
      relationship: analyzed-by
    - id: automation-bias-cascade
      type: model
      relationship: analyzed-by
  tags:
    - epistemic
    - human-factors
    - cognitive
  lastUpdated: 2025-12
  causeEffectGraph:
    title: What Affects Human Expertise?
    description: Causal factors affecting skill retention in an AI-augmented world. Rising deskilling
      concerns as AI handles more cognitive tasks.
    primaryNodeId: human-expertise
    nodes:
      - id: ai-task-delegation
        label: AI Task Delegation
        type: leaf
        description: Range of cognitive tasks delegated to AI. Reduces practice opportunities.
        scores:
          novelty: 4 # Known issue but scale accelerating with AI
          sensitivity: 8 # Major driver of deskilling through reduced practice
          changeability: 4 # Convenience benefits drive adoption; hard to reverse
          certainty: 7 # Well-documented in aviation and medicine research
      - id: training-investment
        label: Training Investment
        type: leaf
        description: Resources devoted to maintaining human skills.
        scores:
          novelty: 3 # Standard solution; well-understood
          sensitivity: 6 # Can offset some deskilling but limited reach
          changeability: 6 # Direct lever for organizations and policy
          certainty: 7 # Training effectiveness well-studied
      - id: expertise-incentives
        label: Expertise Incentives
        type: leaf
        description: Economic and social rewards for developing deep expertise.
        scores:
          novelty: 5 # Changing landscape underappreciated
          sensitivity: 7 # Fundamental driver of motivation to develop skills
          changeability: 5 # Market-driven; policy can influence margins
          certainty: 5 # Uncertain how AI changes expertise value
      - id: practice-opportunities
        label: Practice Opportunities
        type: intermediate
        description: Frequency of performing tasks needed to maintain skills.
        scores:
          novelty: 5 # Specific mechanism often overlooked
          sensitivity: 8 # Core link between delegation and skill loss
          changeability: 5 # Requires deliberate effort to maintain
          certainty: 8 # Strong evidence from skill decay research
      - id: motivation-to-learn
        label: Motivation to Learn
        type: intermediate
        description: Incentives to develop and maintain expertise.
        scores:
          novelty: 4 # Standard psychological concept
          sensitivity: 7 # Determines effort invested in skill development
          changeability: 5 # Shaped by economic and social signals
          certainty: 7 # Well-established in learning psychology
      - id: human-expertise
        label: Human Expertise
        type: effect
        description: Maintenance of human skills, knowledge, and cognitive capabilities.
        scores:
          novelty: 5 # AI-specific concerns relatively new
          sensitivity: 8 # Affects oversight capacity, resilience, autonomy
          changeability: 5 # Resultant of upstream factors
          certainty: 5 # Long-term trajectories uncertain
    edges:
      - source: ai-task-delegation
        target: practice-opportunities
        strength: strong
        effect: decreases
      - source: training-investment
        target: human-expertise
        strength: medium
        effect: increases
      - source: expertise-incentives
        target: motivation-to-learn
        strength: strong
        effect: increases
      - source: practice-opportunities
        target: human-expertise
        strength: strong
        effect: increases
      - source: motivation-to-learn
        target: human-expertise
        strength: medium
        effect: increases
- id: human-oversight-quality
  type: ai-transition-model-parameter
  title: Human Oversight Quality
  description: Effectiveness of human review, decision authority, and correction capability over AI
    systems. Essential for maintaining accountability and preventing harmful AI behaviors.
  customFields:
    - label: Direction
      value: Higher is better
    - label: Current Trend
      value: Declining (capability gap widening, automation bias increasing)
    - label: Measurement
      value: Review effectiveness, decision authority, error detection rates
  relatedEntries:
    - id: scalable-oversight
      type: safety-agenda
      relationship: related
    - id: lab-behavior
      type: ai-transition-model-metric
      relationship: measured-by
    - id: expertise-atrophy-progression
      type: model
      relationship: analyzed-by
    - id: deceptive-alignment-decomposition
      type: model
      relationship: analyzed-by
    - id: corrigibility-failure-pathways
      type: model
      relationship: analyzed-by
    - id: automation-bias-cascade
      type: model
      relationship: analyzed-by
  tags:
    - governance
    - human-factors
    - safety
  lastUpdated: 2025-12
  causeEffectGraph:
    title: What Affects Human Oversight Quality?
    description: Causal factors affecting human review and correction of AI systems. Capability gap
      widening as AI surpasses human understanding.
    primaryNodeId: human-oversight-quality
    nodes:
      - id: ai-capability-level
        label: AI Capability Level
        type: leaf
        color: rose
        description: Sophistication of AI outputs. Higher capability makes oversight harder.
        scores:
          novelty: 2 # Core concern widely discussed in AI safety
          sensitivity: 9 # Primary driver of oversight difficulty
          changeability: 2 # Capability growth driven by massive investment
          certainty: 7 # Clear trajectory of increasing capability
      - id: interpretability-tools
        label: Interpretability Tools
        type: leaf
        color: emerald
        description: Methods for understanding AI reasoning. Currently cover <10% of behavior.
        scores:
          novelty: 6 # Active research frontier; new techniques emerging
          sensitivity: 7 # Key enabler of meaningful oversight
          changeability: 6 # Research tractable; major breakthroughs possible
          certainty: 4 # Uncertain if interpretability can keep pace with capability
      - id: reviewer-expertise
        label: Reviewer Expertise
        type: leaf
        description: Human capacity to evaluate AI work. Under pressure from expertise atrophy.
        scores:
          novelty: 5 # Connection to deskilling underappreciated
          sensitivity: 7 # Determines baseline human capacity for oversight
          changeability: 5 # Training possible but expertise atrophy works against it
          certainty: 6 # Well-documented expertise requirements
      - id: oversight-time-pressure
        label: Oversight Time Pressure
        type: leaf
        color: rose
        description: Economic pressure to review AI outputs quickly, reducing thoroughness. Speed-accuracy tradeoff.
        scores:
          novelty: 5 # Underappreciated driver of oversight failure
          sensitivity: 7 # Directly affects review quality
          changeability: 5 # Business pressure vs. safety; policy can influence
          certainty: 7 # Well-documented in human factors research
      - id: decision-authority-design
        label: Decision Authority Design
        type: leaf
        color: blue
        description: Institutional rules about when humans must approve vs. when AI can act autonomously.
        scores:
          novelty: 5 # Novel challenge as AI capabilities expand
          sensitivity: 8 # Determines which decisions get human review at all
          changeability: 7 # Direct policy lever; organizations can mandate
          certainty: 6 # Effects depend on implementation quality
      - id: oversight-tooling
        label: Oversight Tooling
        type: leaf
        color: emerald
        description: Software interfaces and processes designed to support effective human review.
        scores:
          novelty: 6 # Emerging focus area; many designs untested
          sensitivity: 6 # Good tooling enables better oversight
          changeability: 7 # Engineering investment can improve rapidly
          certainty: 5 # Which tools work best still unclear
      - id: can-oversight-scale
        label: Can oversight scale?
        type: leaf
        color: violet
        description: Key uncertainty - can human oversight remain meaningful as AI decisions multiply and complexity grows?
        scores:
          novelty: 7 # Central question for AI governance
          sensitivity: 9 # Determines viability of human-in-the-loop approaches
          changeability: 1 # Intrinsic property; cannot be changed
          certainty: 2 # Fundamental uncertainty about scalability limits
      - id: capability-gap
        label: Capability Gap
        type: intermediate
        color: red
        description: Difference between AI capability and human ability to evaluate.
        scores:
          novelty: 5 # Specific framing moderately novel
          sensitivity: 9 # Central bottleneck for oversight effectiveness
          changeability: 4 # Both sides moving; gap likely to widen
          certainty: 6 # Current gap clear; future trajectory less certain
      - id: automation-bias
        label: Automation Bias
        type: intermediate
        color: rose
        description: Tendency to accept AI outputs without critical evaluation.
        scores:
          novelty: 4 # Known in human factors; AI-specific dynamics newer
          sensitivity: 7 # Undermines oversight even when capability exists
          changeability: 5 # Training can reduce but deeply ingrained
          certainty: 8 # Well-documented psychological phenomenon
      - id: human-oversight-quality
        label: Human Oversight Quality
        type: effect
        description: Effectiveness of human review and correction of AI systems.
        scores:
          novelty: 4 # Core safety concern; widely discussed
          sensitivity: 9 # Critical for maintaining control over AI systems
          changeability: 5 # Requires addressing multiple upstream factors
          certainty: 5 # Measurement difficult; effectiveness contested
    edges:
      - source: ai-capability-level
        target: capability-gap
        strength: strong
        effect: increases
      - source: interpretability-tools
        target: human-oversight-quality
        strength: medium
        effect: increases
      - source: reviewer-expertise
        target: capability-gap
        strength: medium
        effect: decreases
      - source: capability-gap
        target: human-oversight-quality
        strength: strong
        effect: decreases
      - source: automation-bias
        target: human-oversight-quality
        strength: medium
        effect: decreases
      - source: oversight-time-pressure
        target: human-oversight-quality
        strength: medium
        effect: decreases
      - source: decision-authority-design
        target: human-oversight-quality
        strength: medium
        effect: increases
      - source: oversight-tooling
        target: human-oversight-quality
        strength: medium
        effect: increases
      - source: can-oversight-scale
        target: human-oversight-quality
        strength: medium
        effect: mixed
- id: alignment-robustness
  type: ai-transition-model-parameter
  title: Alignment Robustness
  description: How reliably AI systems pursue intended goals across contexts, distribution shifts, and
    adversarial conditions. Measures the stability of alignment under real-world deployment.
  customFields:
    - label: Direction
      value: Higher is better
    - label: Current Trend
      value: Declining relative to capability (1-2% reward hacking in frontier models)
    - label: Key Measurement
      value: Behavioral reliability under distribution shift, reward hacking rates
  relatedEntries:
    - id: reward-hacking
      type: risk
      relationship: decreases
    - id: mesa-optimization
      type: risk
      relationship: decreases
    - id: goal-misgeneralization
      type: risk
      relationship: decreases
    - id: deceptive-alignment
      type: risk
      relationship: decreases
    - id: sycophancy
      type: risk
      relationship: decreases
    - id: interpretability
      type: approach
      relationship: supports
    - id: evals
      type: approach
      relationship: supports
    - id: ai-control
      type: approach
      relationship: supports
    - id: interpretability-coverage
      type: ai-transition-model-parameter
      relationship: related
    - id: safety-capability-gap
      type: ai-transition-model-parameter
      relationship: related
    - id: human-oversight-quality
      type: ai-transition-model-parameter
      relationship: related
    - id: alignment-progress
      type: ai-transition-model-metric
      relationship: measured-by
    - id: deceptive-alignment-decomposition
      type: model
      relationship: analyzed-by
    - id: corrigibility-failure-pathways
      type: model
      relationship: analyzed-by
    - id: safety-capability-tradeoff
      type: model
      relationship: analyzed-by
    - id: racing-dynamics-model
      type: model
      relationship: analyzed-by
  tags:
    - safety
    - technical
    - alignment
  lastUpdated: 2025-12
  causeEffectGraph:
    title: What Affects Alignment Robustness?
    description: Causal factors affecting how reliably AI systems pursue intended goals. 1-2% reward
      hacking rates in frontier models.
    primaryNodeId: alignment-robustness
    nodes:
      - id: training-diversity
        label: Training Diversity
        type: leaf
        color: emerald
        description: Variety of scenarios in training data. More diversity improves generalization.
        scores:
          novelty: 4 # Known technique; scale and approach evolving
          sensitivity: 7 # Important for generalization but not sufficient alone
          changeability: 6 # Tractable through data curation efforts
          certainty: 6 # Relationship to robustness well-established but quantification hard
      - id: alignment-research
        label: Alignment Research
        type: leaf
        color: emerald
        description: Progress on techniques like RLHF, constitutional AI, interpretability.
        scores:
          novelty: 5 # Rapidly evolving field with new techniques emerging
          sensitivity: 8 # Core determinant of alignment quality
          changeability: 6 # Tractable research area; progress being made
          certainty: 4 # Which approaches will scale unclear
      - id: adversarial-testing
        label: Adversarial Testing
        type: leaf
        color: emerald
        description: Red-teaming and stress testing before deployment.
        scores:
          novelty: 4 # Well-established practice; AI-specific methods newer
          sensitivity: 7 # Key for finding failure modes pre-deployment
          changeability: 7 # Directly controllable by labs
          certainty: 6 # Testing value established; coverage always incomplete
      - id: deployment-pressure
        label: Deployment Pressure
        type: leaf
        color: rose
        description: Competitive and market pressure to deploy models before alignment is fully verified.
        scores:
          novelty: 4 # Known dynamic in tech deployment
          sensitivity: 8 # Can override safety considerations
          changeability: 5 # Market forces hard to change; regulation can help
          certainty: 7 # Clear evidence of deployment pressure effects
      - id: goal-specification-quality
        label: Goal Specification Quality
        type: leaf
        color: blue
        description: Clarity and completeness of human preferences encoded in training objectives.
        scores:
          novelty: 6 # Outer alignment is active research area
          sensitivity: 8 # Fundamental determinant of what AI optimizes for
          changeability: 6 # Can be improved with research investment
          certainty: 4 # Difficult to specify complex human values
      - id: reward-hacking-incentive
        label: Reward Hacking Incentive
        type: leaf
        color: rose
        description: Structural incentives for AI to find shortcuts that satisfy metrics without intended behavior.
        scores:
          novelty: 6 # Goodhart's law in AI context is evolving understanding
          sensitivity: 8 # Can undermine even well-designed training
          changeability: 5 # Depends on fundamental properties of optimization
          certainty: 6 # Well-documented phenomenon; specific instances hard to predict
      - id: is-alignment-stable
        label: Is alignment stable at scale?
        type: leaf
        color: violet
        description: Key uncertainty - will alignment techniques that work now continue working as capabilities increase?
        scores:
          novelty: 8 # Core unresolved question in alignment research
          sensitivity: 10 # Determines whether current approaches are sufficient
          changeability: 1 # Intrinsic property; cannot be changed
          certainty: 2 # Fundamental uncertainty about scaling behavior
      - id: generalization-quality
        label: Generalization Quality
        type: intermediate
        color: red
        description: Ability of alignment to hold in new situations.
        scores:
          novelty: 6 # Goal misgeneralization is active research area
          sensitivity: 9 # Determines whether alignment survives distribution shift
          changeability: 5 # Depends on training approach; fundamental challenge
          certainty: 4 # Deep theoretical questions unresolved
      - id: vulnerability-detection
        label: Vulnerability Detection
        type: intermediate
        description: Identification of failure modes before deployment.
        scores:
          novelty: 5 # Evals improving but novel vulnerabilities emerge
          sensitivity: 7 # Enables mitigation if detection occurs
          changeability: 6 # Can be improved with investment in evals
          certainty: 5 # Many vulnerabilities may be undetectable
      - id: alignment-robustness
        label: Alignment Robustness
        type: effect
        description: Reliability of aligned behavior across contexts and adversarial conditions.
        scores:
          novelty: 5 # Core safety property; specific failure modes novel
          sensitivity: 9 # Critical for safe deployment at scale
          changeability: 5 # Requires progress on multiple research fronts
          certainty: 4 # Measurement difficult; unknown unknowns concerning
    edges:
      - source: training-diversity
        target: generalization-quality
        strength: strong
        effect: increases
      - source: alignment-research
        target: alignment-robustness
        strength: strong
        effect: increases
      - source: adversarial-testing
        target: vulnerability-detection
        strength: strong
        effect: increases
      - source: generalization-quality
        target: alignment-robustness
        strength: strong
        effect: increases
      - source: vulnerability-detection
        target: alignment-robustness
        strength: medium
        effect: increases
      - source: deployment-pressure
        target: vulnerability-detection
        strength: medium
        effect: decreases
      - source: goal-specification-quality
        target: alignment-robustness
        strength: strong
        effect: increases
      - source: reward-hacking-incentive
        target: alignment-robustness
        strength: medium
        effect: decreases
      - source: is-alignment-stable
        target: alignment-robustness
        strength: strong
        effect: mixed
- id: safety-capability-gap
  type: ai-transition-model-parameter
  title: Safety-Capability Gap
  description: The lag between AI capability advances and corresponding safety/alignment
    understanding. Measures how far safety research trails behind what frontier systems can do.
  customFields:
    - label: Direction
      value: Lower is better (want safety close to capabilities)
    - label: Current Trend
      value: Widening (safety timelines compressed 70-80% post-ChatGPT)
    - label: Key Measurement
      value: Months/years capabilities lead safety research
  relatedEntries:
    - id: racing-dynamics
      type: risk
      relationship: decreases
    - id: interpretability
      type: approach
      relationship: supports
    - id: alignment-robustness
      type: ai-transition-model-parameter
      relationship: related
    - id: racing-intensity
      type: ai-transition-model-parameter
      relationship: related
    - id: safety-culture-strength
      type: ai-transition-model-parameter
      relationship: related
    - id: alignment-progress
      type: ai-transition-model-metric
      relationship: measured-by
    - id: safety-research
      type: ai-transition-model-metric
      relationship: measured-by
    - id: capabilities
      type: ai-transition-model-metric
      relationship: measured-by
    - id: racing-dynamics-impact
      type: model
      relationship: analyzed-by
    - id: safety-capability-tradeoff
      type: model
      relationship: analyzed-by
  tags:
    - safety
    - technical
    - governance
  lastUpdated: 2025-12
  causeEffectGraph:
    title: What Drives the Safety-Capability Gap?
    description: Causal factors affecting the lag between AI capabilities and safety understanding. Gap
      widening post-ChatGPT.
    primaryNodeId: safety-capability-gap
    nodes:
      - id: racing-pressure
        label: Racing Pressure
        type: leaf
        color: red
        description: Competitive dynamics compressing safety timelines 70-80%.
        scores:
          novelty: 4 # Known dynamic; magnitude post-ChatGPT surprising
          sensitivity: 9 # Primary driver of compressed safety timelines
          changeability: 4 # Hard to change without coordination mechanisms
          certainty: 7 # Clear evidence from timeline compression data
      - id: safety-funding
        label: Safety Funding
        type: leaf
        color: emerald
        description: Resources for safety research. Small fraction of capability funding.
        scores:
          novelty: 3 # Well-known funding disparity
          sensitivity: 7 # Enables more safety research when increased
          changeability: 7 # Direct lever; funders can allocate more
          certainty: 7 # Clear relationship between funding and output
      - id: problem-difficulty
        label: Problem Difficulty
        type: leaf
        color: violet
        description: Intrinsic hardness of safety research. May require breakthroughs.
        scores:
          novelty: 6 # Uncertainty about tractability underappreciated
          sensitivity: 8 # If fundamentally hard, gap may be unavoidable
          changeability: 2 # Intrinsic property; can't be changed directly
          certainty: 3 # Deep uncertainty about whether safety is solvable
      - id: safety-talent-pool
        label: Safety Talent Pool
        type: leaf
        color: emerald
        description: Number of qualified researchers working on safety. Currently a few hundred globally.
        scores:
          novelty: 4 # Known constraint; scale often underappreciated
          sensitivity: 8 # Directly limits safety research throughput
          changeability: 6 # Can be grown with training programs; takes time
          certainty: 7 # Talent counts roughly known
      - id: capability-investment
        label: Capability Investment
        type: leaf
        color: rose
        description: Billions invested in capability research. Far exceeds safety investment.
        scores:
          novelty: 2 # Well-documented investment levels
          sensitivity: 8 # Drives capability velocity
          changeability: 4 # Market-driven; regulation can influence
          certainty: 8 # Investment data publicly available
      - id: coordination-mechanisms
        label: Coordination Mechanisms
        type: leaf
        color: blue
        description: Agreements and institutions that could slow racing or increase safety investment.
        scores:
          novelty: 5 # Some mechanisms emerging; effectiveness unclear
          sensitivity: 7 # Could reduce racing pressure if effective
          changeability: 6 # Policy lever; requires international cooperation
          certainty: 4 # Effectiveness of coordination mechanisms untested
      - id: can-safety-keep-pace
        label: Can safety keep pace?
        type: leaf
        color: violet
        description: Key uncertainty - is it possible for safety research to match capability advances, or is the gap structural?
        scores:
          novelty: 8 # Core unresolved question for AI safety
          sensitivity: 10 # Determines viability of safe AI development path
          changeability: 1 # Intrinsic property; cannot be changed
          certainty: 2 # Fundamental uncertainty about relative progress rates
      - id: capability-velocity
        label: Capability Velocity
        type: intermediate
        color: red
        description: Speed of AI capability improvement. Accelerating.
        scores:
          novelty: 3 # Widely discussed capability trajectory
          sensitivity: 9 # Directly determines how fast gap widens
          changeability: 3 # Massive investment momentum; hard to slow
          certainty: 5 # Near-term clear; long-term trajectory uncertain
      - id: safety-velocity
        label: Safety Velocity
        type: intermediate
        color: emerald
        description: Speed of safety research progress. Limited by talent and funding.
        scores:
          novelty: 5 # Progress rate less tracked than capabilities
          sensitivity: 9 # Directly determines if gap can close
          changeability: 6 # Can be accelerated with resources and talent
          certainty: 4 # Hard to measure safety progress objectively
      - id: safety-capability-gap
        label: Safety-Capability Gap
        type: effect
        description: How far safety understanding trails AI capabilities.
        scores:
          novelty: 5 # Framing increasingly recognized; magnitude surprising
          sensitivity: 9 # Central metric for AI risk trajectory
          changeability: 5 # Can be closed from either side
          certainty: 4 # Current gap hard to quantify; future trajectory uncertain
    edges:
      - source: racing-pressure
        target: capability-velocity
        strength: strong
        effect: increases
      - source: safety-funding
        target: safety-velocity
        strength: strong
        effect: increases
      - source: problem-difficulty
        target: safety-velocity
        strength: medium
        effect: decreases
      - source: capability-velocity
        target: safety-capability-gap
        strength: strong
        effect: increases
      - source: safety-velocity
        target: safety-capability-gap
        strength: strong
        effect: decreases
      - source: safety-talent-pool
        target: safety-velocity
        strength: strong
        effect: increases
      - source: capability-investment
        target: capability-velocity
        strength: strong
        effect: increases
      - source: coordination-mechanisms
        target: racing-pressure
        strength: medium
        effect: decreases
      - source: can-safety-keep-pace
        target: safety-capability-gap
        strength: strong
        effect: mixed
- id: interpretability-coverage
  type: ai-transition-model-parameter
  title: Interpretability Coverage
  description: The percentage of model behavior that can be explained and understood by researchers.
    Measures transparency into AI system internals.
  customFields:
    - label: Direction
      value: Higher is better
    - label: Current Trend
      value: Improving slowly (70% of Claude 3 Sonnet features interpretable, but only ~10% of frontier
        model capacity mapped)
    - label: Key Measurement
      value: Percentage of model behavior explainable, feature coverage
  relatedEntries:
    - id: interpretability
      type: concept
      relationship: related
    - id: alignment-progress
      type: ai-transition-model-metric
      relationship: measured-by
  tags:
    - safety
    - technical
    - interpretability
  lastUpdated: 2025-12
  causeEffectGraph:
    title: What Affects Interpretability Coverage?
    description: Causal factors affecting how much of AI behavior we can understand. Currently <10% of
      frontier model capacity mapped.
    primaryNodeId: interpretability-coverage
    nodes:
      - id: model-complexity
        label: Model Complexity
        type: leaf
        color: rose
        description: Size and sophistication of AI systems. Growing exponentially.
        scores:
          novelty: 2  # Well known that models are getting bigger
          sensitivity: 8  # Major driver of interpretability difficulty
          changeability: 2  # Trend toward larger models hard to reverse
          certainty: 9  # Extremely well documented growth trajectory
      - id: research-investment
        label: Research Investment
        type: leaf
        color: emerald
        description: Resources for interpretability research. ~50 researchers globally.
        scores:
          novelty: 5  # Some surprise at how few researchers work on this
          sensitivity: 7  # More investment could significantly accelerate progress
          changeability: 7  # Funding decisions are changeable with advocacy
          certainty: 6  # Estimates of researcher count vary
      - id: technique-development
        label: Technique Development
        type: leaf
        color: emerald
        description: New methods like sparse autoencoders, activation patching.
        scores:
          novelty: 7  # Recent breakthroughs like SAEs are genuinely surprising
          sensitivity: 8  # New techniques could unlock major progress
          changeability: 4  # Depends on unpredictable research breakthroughs
          certainty: 5  # Unclear which techniques will scale
      - id: lab-cooperation
        label: Lab Cooperation
        type: leaf
        color: blue
        description: Willingness of AI labs to share model internals for interpretability research.
        scores:
          novelty: 5  # Emerging as key constraint
          sensitivity: 7  # Without access, external research limited
          changeability: 6  # Policy and incentives can influence
          certainty: 6  # Current cooperation levels known; future uncertain
      - id: computational-requirements
        label: Computational Requirements
        type: leaf
        color: rose
        description: Computing resources needed to run interpretability methods on frontier models.
        scores:
          novelty: 4  # Known constraint; scale less appreciated
          sensitivity: 6  # Limits who can do interpretability research
          changeability: 5  # Cost declining but model size increasing
          certainty: 7  # Compute requirements well-characterized
      - id: automation-of-interpretability
        label: Automation of Interpretability
        type: leaf
        color: emerald
        description: Using AI to help interpret AI, potentially accelerating progress dramatically.
        scores:
          novelty: 7  # Emerging approach with significant potential
          sensitivity: 8  # Could fundamentally change interpretability pace
          changeability: 5  # Depends on technique development
          certainty: 4  # Unclear if automated approaches will work well
      - id: is-full-interpretability-possible
        label: Is full interpretability possible?
        type: leaf
        color: violet
        description: Key uncertainty - can we ever fully understand frontier AI systems, or are they fundamentally opaque?
        scores:
          novelty: 8  # Core philosophical and empirical question
          sensitivity: 10  # Determines ceiling of interpretability progress
          changeability: 1  # Intrinsic property; cannot be changed
          certainty: 2  # Deep uncertainty about fundamental limits
      - id: scaling-challenge
        label: Scaling Challenge
        type: intermediate
        color: red
        description: Difficulty applying interpretability techniques to larger models.
        scores:
          novelty: 4  # Known that interpretability struggles to scale
          sensitivity: 9  # Critical bottleneck for the field
          changeability: 5  # Partially addressable with new techniques
          certainty: 7  # Clearly established as a major challenge
      - id: feature-identification
        label: Feature Identification
        type: intermediate
        description: Ability to identify and understand model features.
        scores:
          novelty: 6  # Recent progress more than expected
          sensitivity: 8  # Core capability for interpretability
          changeability: 6  # Improvable with research investment
          certainty: 5  # Understanding of features still evolving
      - id: interpretability-coverage
        label: Interpretability Coverage
        type: effect
        description: Percentage of model behavior that can be explained.
        scores:
          novelty: 5  # ~10% coverage is about as expected
          sensitivity: 7  # Affects safety verification, alignment validation
          changeability: 5  # Slowly improvable with sustained effort
          certainty: 4  # Hard to measure coverage precisely
    edges:
      - source: model-complexity
        target: scaling-challenge
        strength: strong
        effect: increases
      - source: research-investment
        target: feature-identification
        strength: strong
        effect: increases
      - source: technique-development
        target: feature-identification
        strength: strong
        effect: increases
      - source: scaling-challenge
        target: interpretability-coverage
        strength: strong
        effect: decreases
      - source: feature-identification
        target: interpretability-coverage
        strength: strong
        effect: increases
      - source: lab-cooperation
        target: feature-identification
        strength: medium
        effect: increases
      - source: computational-requirements
        target: scaling-challenge
        strength: medium
        effect: increases
      - source: automation-of-interpretability
        target: feature-identification
        strength: medium
        effect: increases
      - source: is-full-interpretability-possible
        target: interpretability-coverage
        strength: strong
        effect: mixed
- id: regulatory-capacity
  type: ai-transition-model-parameter
  title: Regulatory Capacity
  description: Ability of governments to effectively understand, evaluate, and regulate AI systems,
    including technical expertise, enforcement capability, and institutional resources.
  customFields:
    - label: Direction
      value: Higher is better
    - label: Current Trend
      value: Growing but constrained (AISI budgets ~\$10-50M vs. \$100B+ industry spending)
    - label: Key Measurement
      value: Agency technical expertise, enforcement actions, evaluation capability
  relatedEntries:
    - id: nist-ai-rmf
      type: policy
      relationship: related
    - id: us-executive-order
      type: policy
      relationship: related
    - id: institutional-adaptation-speed
      type: model
      relationship: analyzed-by
  tags:
    - governance
    - regulation
    - institutions
  lastUpdated: 2025-12
  causeEffectGraph:
    title: What Affects Regulatory Capacity?
    description: Causal factors affecting government ability to regulate AI. AISI budgets ~$10-50M vs
      $100B+ industry spending.
    primaryNodeId: regulatory-capacity
    nodes:
      - id: government-ai-expertise
        label: Government AI Expertise
        type: leaf
        color: rose
        description: Technical staff in agencies. Far below industry levels.
        scores:
          novelty: 4  # Expertise gap is known but magnitude may surprise
          sensitivity: 8  # Key bottleneck for regulatory effectiveness
          changeability: 5  # Can hire but salary competition with industry is fierce
          certainty: 7  # Well-documented gap between government and industry
      - id: regulatory-budgets
        label: Regulatory Budgets
        type: leaf
        color: blue
        description: Resources for AI Safety Institutes and regulators.
        scores:
          novelty: 3  # Budget constraints are well-known
          sensitivity: 6  # Important but not the only bottleneck
          changeability: 6  # Political decisions can shift budgets
          certainty: 8  # Budget figures are public and clear
      - id: industry-transparency
        label: Industry Transparency
        type: leaf
        color: rose
        description: Willingness of labs to share information with regulators.
        scores:
          novelty: 5  # Opacity of AI labs is increasingly discussed
          sensitivity: 7  # Without access, regulation is blind
          changeability: 5  # Voluntary commitments exist but enforcement weak
          certainty: 5  # Hard to assess actual vs stated transparency
      - id: salary-competition
        label: Salary Competition
        type: leaf
        color: red
        description: Industry salaries 3-5x government pay for AI talent.
        scores:
          novelty: 3  # Pay gap is well-known
          sensitivity: 7  # Directly limits hiring capability
          changeability: 3  # Government pay scales rigid; hard to change
          certainty: 8  # Salary data is publicly available
      - id: regulatory-complexity
        label: Regulatory Complexity
        type: leaf
        color: violet
        description: AI systems evolve faster than regulatory frameworks can adapt.
        scores:
          novelty: 6  # AI-specific complexity is emerging challenge
          sensitivity: 7  # Determines whether rules are even enforceable
          changeability: 4  # Fundamental challenge of regulating fast-moving tech
          certainty: 6  # Complexity is evident but hard to quantify
      - id: can-regulators-keep-pace
        label: Can regulators keep pace with AI?
        type: leaf
        color: violet
        description: Key uncertainty about whether government can ever close the capability gap.
        scores:
          novelty: 7  # Core question gaining attention
          sensitivity: 9  # Determines viability of regulation as strategy
          changeability: 4  # Depends on structural factors
          certainty: 3  # Fundamental open question
      - id: evaluation-capability
        label: Evaluation Capability
        type: intermediate
        color: teal
        description: Ability to independently assess AI systems.
        scores:
          novelty: 5  # Growing recognition of evaluation challenges
          sensitivity: 8  # Core regulatory function; affects all decisions
          changeability: 5  # Requires both expertise and access
          certainty: 5  # Evaluation science still developing
      - id: enforcement-tools
        label: Enforcement Tools
        type: intermediate
        color: blue
        description: Legal authority and mechanisms to enforce rules.
        scores:
          novelty: 3  # Standard regulatory toolkit discussion
          sensitivity: 6  # Important but depends on what rules exist
          changeability: 5  # Requires legislation; slow to develop
          certainty: 6  # Legal frameworks are knowable
      - id: regulatory-capacity
        label: Regulatory Capacity
        type: effect
        color: emerald
        description: Government ability to understand and regulate AI.
        scores:
          novelty: 4  # Regulatory gaps are increasingly recognized
          sensitivity: 8  # Affects all downstream governance outcomes
          changeability: 5  # Improvable with sustained investment
          certainty: 5  # Hard to measure overall regulatory effectiveness
    edges:
      - source: government-ai-expertise
        target: evaluation-capability
        strength: strong
        effect: increases
      - source: regulatory-budgets
        target: regulatory-capacity
        strength: medium
        effect: increases
      - source: industry-transparency
        target: evaluation-capability
        strength: medium
        effect: increases
      - source: salary-competition
        target: government-ai-expertise
        strength: strong
        effect: decreases
      - source: regulatory-complexity
        target: enforcement-tools
        strength: medium
        effect: decreases
      - source: can-regulators-keep-pace
        target: regulatory-capacity
        strength: medium
        effect: mixed
      - source: evaluation-capability
        target: regulatory-capacity
        strength: strong
        effect: increases
      - source: enforcement-tools
        target: regulatory-capacity
        strength: medium
        effect: increases
- id: institutional-quality
  type: ai-transition-model-parameter
  title: Institutional Quality
  description: Health and effectiveness of institutions involved in AI governance, including
    independence from capture, expertise retention, and decision-making quality.
  customFields:
    - label: Direction
      value: Higher is better
    - label: Current Trend
      value: Under pressure (regulatory capture concerns, expertise gaps, rapid policy shifts)
    - label: Key Measurement
      value: Independence from industry, expertise retention, decision quality metrics
  relatedEntries:
    - id: institutional-capture
      type: risk
      relationship: related
    - id: institutional-adaptation-speed
      type: model
      relationship: analyzed-by
    - id: trust-erosion-dynamics
      type: model
      relationship: analyzed-by
  tags:
    - governance
    - institutions
    - accountability
  lastUpdated: 2025-12
  causeEffectGraph:
    title: What Affects Institutional Quality?
    description: Causal factors affecting governance institution effectiveness. Under pressure from
      capture and expertise gaps.
    primaryNodeId: institutional-quality
    nodes:
      - id: capture-pressure
        label: Capture Pressure
        type: leaf
        color: red
        description: Industry influence on regulators through lobbying, revolving door.
        scores:
          novelty: 3  # Regulatory capture is well-studied concept
          sensitivity: 8  # Major threat to institutional independence
          changeability: 4  # Structural incentives are hard to change
          certainty: 7  # Well-documented in other sectors; AI-specific less studied
      - id: expertise-retention
        label: Expertise Retention
        type: leaf
        color: rose
        description: Ability to keep skilled staff vs. industry salary competition.
        scores:
          novelty: 4  # Known issue but AI salary gaps may surprise
          sensitivity: 7  # Directly affects decision quality
          changeability: 4  # Government pay scales are rigid
          certainty: 7  # Turnover data available; causation clearer
      - id: political-independence
        label: Political Independence
        type: leaf
        color: blue
        description: Insulation from short-term political pressures.
        scores:
          novelty: 3  # Standard concern in institutional design
          sensitivity: 6  # Affects long-term institutional credibility
          changeability: 3  # Requires constitutional or statutory changes
          certainty: 6  # Independence varies by institution and measure
      - id: revolving-door-dynamics
        label: Revolving Door Dynamics
        type: leaf
        color: rose
        description: Staff cycling between regulator and industry roles.
        scores:
          novelty: 3  # Well-known phenomenon in regulation
          sensitivity: 7  # Affects independence and expertise simultaneously
          changeability: 4  # Requires cooling-off periods, salary reform
          certainty: 7  # Career patterns are observable
      - id: institutional-learning
        label: Institutional Learning
        type: leaf
        color: emerald
        description: Ability to accumulate and apply knowledge over time.
        scores:
          novelty: 5  # AI-specific learning challenges are novel
          sensitivity: 7  # Critical for keeping up with technology
          changeability: 5  # Can be improved with deliberate knowledge management
          certainty: 5  # Hard to measure institutional knowledge
      - id: will-institutions-adapt-in-time
        label: Will institutions adapt in time?
        type: leaf
        color: violet
        description: Key uncertainty about whether governance can keep pace with AI development.
        scores:
          novelty: 6  # Core question for AI governance
          sensitivity: 9  # Determines whether institutions remain relevant
          changeability: 4  # Depends on both institutions and AI trajectory
          certainty: 3  # Fundamental open question
      - id: decision-quality
        label: Decision Quality
        type: intermediate
        color: teal
        description: Quality of institutional choices and policies.
        scores:
          novelty: 4  # AI-specific decision challenges are novel
          sensitivity: 8  # Core outcome that determines institutional value
          changeability: 5  # Improvable with better inputs and processes
          certainty: 4  # Hard to measure decision quality objectively
      - id: public-legitimacy
        label: Public Legitimacy
        type: intermediate
        color: slate
        description: Trust in institutions as fair arbiters.
        scores:
          novelty: 3  # Legitimacy concerns are well-established
          sensitivity: 7  # Affects compliance and cooperation
          changeability: 3  # Slow to build, fast to lose
          certainty: 6  # Survey data exists but is imperfect measure
      - id: institutional-quality
        label: Institutional Quality
        type: effect
        color: emerald
        description: Health and effectiveness of governance institutions.
        scores:
          novelty: 4  # AI governance institutions are new and evolving
          sensitivity: 8  # Determines governance effectiveness overall
          changeability: 4  # Requires sustained reform efforts
          certainty: 5  # Multidimensional construct; hard to assess comprehensively
    edges:
      - source: capture-pressure
        target: decision-quality
        strength: strong
        effect: decreases
      - source: expertise-retention
        target: decision-quality
        strength: strong
        effect: increases
      - source: political-independence
        target: institutional-quality
        strength: medium
        effect: increases
      - source: revolving-door-dynamics
        target: capture-pressure
        strength: medium
        effect: increases
      - source: institutional-learning
        target: decision-quality
        strength: medium
        effect: increases
      - source: will-institutions-adapt-in-time
        target: institutional-quality
        strength: medium
        effect: mixed
      - source: decision-quality
        target: institutional-quality
        strength: strong
        effect: increases
      - source: public-legitimacy
        target: institutional-quality
        strength: medium
        effect: increases
- id: reality-coherence
  type: ai-transition-model-parameter
  title: Reality Coherence
  description: The degree to which different populations share common factual beliefs about basic
    events, evidence, and causal relationships—enabling democratic deliberation and collective
    action.
  customFields:
    - label: Direction
      value: Higher is better
    - label: Current Trend
      value: Declining (cross-partisan news overlap from 47% to 12% since 2010)
    - label: Key Measurement
      value: Cross-partisan factual agreement, shared source overlap, institutional trust
  parameterDistinctions:
    focus: Do we agree on facts?
    summary: Shared factual beliefs across populations
    distinctFrom:
      - id: epistemic-health
        theirFocus: Can we tell what's true?
        relationship: Epistemic health is capacity; coherence is the outcome of that capacity being shared
      - id: societal-trust
        theirFocus: Do we trust institutions?
        relationship: Trust in shared sources enables coherence; fragmentation erodes trust
  relatedEntries:
    - id: reality-fragmentation
      type: risk
      relationship: related
    - id: epistemic-health
      type: ai-transition-model-parameter
      relationship: related
    - id: reality-fragmentation-network
      type: model
      relationship: analyzed-by
    - id: epistemic-collapse-threshold
      type: model
      relationship: analyzed-by
  tags:
    - epistemic
    - information-environment
    - democracy
  lastUpdated: 2025-12
  causeEffectGraph:
    title: What Affects Reality Coherence?
    description: Causal factors affecting shared factual beliefs across populations. Cross-partisan news
      overlap from 47% to 12% since 2010.
    primaryNodeId: reality-coherence
    nodes:
      - id: algorithmic-curation
        label: Algorithmic Curation
        type: leaf
        color: rose
        description: Personalization creates filter bubbles with different facts.
        scores:
          novelty: 4  # Filter bubble concept is known; scale may surprise
          sensitivity: 7  # Shapes what information people encounter
          changeability: 5  # Platform choices can change; regulation possible
          certainty: 6  # Effects documented but magnitude debated
      - id: shared-media-sources
        label: Shared Media Sources
        type: leaf
        color: emerald
        description: Common information sources across groups. Declining.
        scores:
          novelty: 3  # Media fragmentation is well-documented trend
          sensitivity: 8  # Directly enables or undermines shared reality
          changeability: 3  # Structural shift away from broadcast media hard to reverse
          certainty: 8  # Cross-partisan news overlap data is clear (47% to 12%)
      - id: political-polarization
        label: Political Polarization
        type: leaf
        color: red
        description: Partisan identity shapes fact acceptance.
        scores:
          novelty: 2  # Polarization is extremely well-documented
          sensitivity: 8  # Major driver of fact rejection
          changeability: 2  # Deep structural and identity factors; very hard to shift
          certainty: 8  # Strong empirical evidence across multiple measures
      - id: ai-generated-content
        label: AI-Generated Content
        type: leaf
        color: red
        description: Synthetic media and text increasingly indistinguishable from authentic content.
        scores:
          novelty: 7  # Rapidly emerging challenge
          sensitivity: 8  # Could accelerate reality fragmentation dramatically
          changeability: 4  # Detection tech vs generation is arms race
          certainty: 5  # Scale of impact still uncertain
      - id: trust-in-institutions
        label: Trust in Institutions
        type: leaf
        color: rose
        description: Confidence in media, science, and government as truth arbiters.
        scores:
          novelty: 3  # Trust decline is well-documented
          sensitivity: 7  # Without trusted arbiters, facts become tribal
          changeability: 3  # Rebuilding trust is slow multi-generational process
          certainty: 7  # Survey data shows clear trends
      - id: can-shared-reality-survive-ai
        label: Can shared reality survive AI content?
        type: leaf
        color: violet
        description: Key uncertainty about whether coherence can persist when anyone can generate convincing false content.
        scores:
          novelty: 8  # Novel question as AI content proliferates
          sensitivity: 9  # Existential for democratic deliberation
          changeability: 4  # Depends on tech, regulation, and social adaptation
          certainty: 2  # Highly uncertain outcome
      - id: information-exposure
        label: Information Exposure
        type: intermediate
        color: slate
        description: What facts different groups encounter.
        scores:
          novelty: 4  # AI-driven personalization adds novelty to known concept
          sensitivity: 7  # Necessary but not sufficient for coherence
          changeability: 5  # Platform policies and regulation can affect
          certainty: 6  # Exposure can be measured; effects less certain
      - id: fact-acceptance
        label: Fact Acceptance
        type: intermediate
        color: teal
        description: Willingness to accept facts from non-aligned sources.
        scores:
          novelty: 5  # Motivated reasoning research growing; AI angle novel
          sensitivity: 9  # Critical bottleneck; even shared exposure fails without this
          changeability: 3  # Deep psychological and identity factors
          certainty: 7  # Strong research base on motivated reasoning
      - id: reality-coherence
        label: Reality Coherence
        type: effect
        color: emerald
        description: Degree to which populations share common factual beliefs.
        scores:
          novelty: 4  # Fragmentation trend known; AI acceleration moderately novel
          sensitivity: 9  # Foundational for democracy and collective action
          changeability: 3  # Resultant of upstream factors; hard to directly improve
          certainty: 6  # Can measure overlap; causation of decline debated
    edges:
      - source: algorithmic-curation
        target: information-exposure
        strength: strong
        effect: decreases
      - source: shared-media-sources
        target: reality-coherence
        strength: strong
        effect: increases
      - source: political-polarization
        target: fact-acceptance
        strength: strong
        effect: decreases
      - source: ai-generated-content
        target: fact-acceptance
        strength: medium
        effect: decreases
      - source: trust-in-institutions
        target: fact-acceptance
        strength: medium
        effect: increases
      - source: can-shared-reality-survive-ai
        target: reality-coherence
        strength: medium
        effect: mixed
      - source: information-exposure
        target: reality-coherence
        strength: medium
        effect: increases
      - source: fact-acceptance
        target: reality-coherence
        strength: strong
        effect: increases
- id: preference-authenticity
  type: ai-transition-model-parameter
  title: Preference Authenticity
  description: The degree to which human preferences reflect genuine values rather than externally
    shaped desires. Essential for autonomy, democratic legitimacy, and meaningful choice.
  customFields:
    - label: Direction
      value: Higher is better
    - label: Current Trend
      value: Under pressure (AI recommendation systems optimize for engagement, not user wellbeing)
    - label: Key Measurement
      value: Reflective endorsement, preference stability, manipulation exposure
  relatedEntries:
    - id: preference-manipulation
      type: risk
      relationship: related
    - id: human-agency
      type: ai-transition-model-parameter
      relationship: related
    - id: public-opinion
      type: ai-transition-model-metric
      relationship: measured-by
    - id: preference-manipulation-drift
      type: model
      relationship: analyzed-by
    - id: sycophancy-feedback-loop
      type: model
      relationship: analyzed-by
    - id: reality-fragmentation-network
      type: model
      relationship: analyzed-by
  tags:
    - epistemic
    - autonomy
    - human-ai-interaction
  lastUpdated: 2025-12
  causeEffectGraph:
    title: What Affects Preference Authenticity?
    description: Causal factors affecting whether preferences reflect genuine values vs external
      manipulation. AI recommendation systems optimize for engagement.
    primaryNodeId: preference-authenticity
    nodes:
      - id: recommendation-optimization
        label: Recommendation Optimization
        type: leaf
        color: red
        description: AI systems optimizing for engagement over user wellbeing.
        scores:
          novelty: 4  # Engagement optimization is known; scale and sophistication growing
          sensitivity: 8  # Major driver of preference shaping at scale
          changeability: 4  # Business models depend on engagement; hard to shift
          certainty: 7  # Well-documented effects on behavior and attention
      - id: targeted-advertising
        label: Targeted Advertising
        type: leaf
        color: rose
        description: Precision persuasion based on psychological profiles.
        scores:
          novelty: 3  # Targeted ads are well-known; AI enhancement incremental
          sensitivity: 7  # Shapes commercial preferences significantly
          changeability: 4  # Regulatory intervention possible but industry resistance strong
          certainty: 7  # Effects well-studied; magnitude debated
      - id: user-awareness
        label: User Awareness
        type: leaf
        color: emerald
        description: Understanding of how preferences are being shaped.
        scores:
          novelty: 5  # AI manipulation mechanisms are less understood by public
          sensitivity: 6  # Enables but doesn't guarantee resistance
          changeability: 6  # Education and transparency can improve
          certainty: 5  # Hard to measure actual awareness vs claimed
      - id: ai-companionship
        label: AI Companionship
        type: leaf
        color: violet
        description: Emotional relationships with AI systems that may shape preferences toward AI interaction.
        scores:
          novelty: 8  # Emerging phenomenon with character.ai, Replika
          sensitivity: 7  # Could fundamentally alter social preferences
          changeability: 4  # Market demand may be hard to redirect
          certainty: 3  # Long-term effects unknown
      - id: personalized-content-bubbles
        label: Personalized Content Bubbles
        type: leaf
        color: rose
        description: AI curation creating increasingly narrow preference reinforcement loops.
        scores:
          novelty: 5  # Filter bubbles known; AI personalization intensifies
          sensitivity: 7  # Narrows preference formation environment
          changeability: 5  # Platform policy and regulation can affect
          certainty: 6  # Effects documented but long-term trajectory uncertain
      - id: can-preferences-remain-authentic
        label: Can preferences remain authentic at scale?
        type: leaf
        color: violet
        description: Key uncertainty about whether genuine preference formation is possible under pervasive AI influence.
        scores:
          novelty: 7  # Philosophical question with new practical relevance
          sensitivity: 9  # Affects meaning of democracy and autonomy
          changeability: 3  # Structural question; not directly addressable
          certainty: 2  # Deep philosophical uncertainty
      - id: manipulation-exposure
        label: Manipulation Exposure
        type: intermediate
        color: slate
        description: Degree of exposure to preference-shaping systems.
        scores:
          novelty: 4  # Ubiquity of AI systems in daily life increasingly recognized
          sensitivity: 8  # More exposure = more shaping potential
          changeability: 4  # Opt-out increasingly difficult; AI becoming infrastructure
          certainty: 6  # Can measure time on platforms; effect magnitude debated
      - id: reflective-capacity
        label: Reflective Capacity
        type: intermediate
        color: teal
        description: Ability to critically evaluate own preferences.
        scores:
          novelty: 6  # AI-accelerated preference shaping outpacing reflection
          sensitivity: 7  # Key defense against manipulation
          changeability: 5  # Can be cultivated but time-consuming
          certainty: 5  # Philosophical and psychological complexity
      - id: preference-authenticity
        label: Preference Authenticity
        type: effect
        color: emerald
        description: Degree to which preferences reflect genuine values.
        scores:
          novelty: 6  # AI-scale preference manipulation is relatively new concern
          sensitivity: 9  # Affects autonomy, democracy, and human flourishing
          changeability: 4  # Structural forces push toward less authenticity
          certainty: 4  # Fundamental philosophical challenges in defining authenticity
    edges:
      - source: recommendation-optimization
        target: manipulation-exposure
        strength: strong
        effect: increases
      - source: targeted-advertising
        target: manipulation-exposure
        strength: strong
        effect: increases
      - source: user-awareness
        target: reflective-capacity
        strength: medium
        effect: increases
      - source: ai-companionship
        target: manipulation-exposure
        strength: medium
        effect: increases
      - source: personalized-content-bubbles
        target: manipulation-exposure
        strength: medium
        effect: increases
      - source: can-preferences-remain-authentic
        target: preference-authenticity
        strength: medium
        effect: mixed
      - source: manipulation-exposure
        target: preference-authenticity
        strength: strong
        effect: decreases
      - source: reflective-capacity
        target: preference-authenticity
        strength: medium
        effect: increases
- id: racing-intensity
  type: ai-transition-model-parameter
  title: Racing Intensity
  description: The degree of competitive pressure driving AI development speed over safety. High
    intensity leads to safety corner-cutting and premature deployment.
  customFields:
    - label: Direction
      value: Lower is better
    - label: Current Trend
      value: High (safety timelines compressed 70-80% post-ChatGPT)
    - label: Key Measurement
      value: Safety evaluation duration, safety budget allocation, deployment delays
  relatedEntries:
    - id: racing-dynamics
      type: risk
      relationship: related
    - id: safety-research
      type: ai-transition-model-metric
      relationship: measured-by
    - id: lab-behavior
      type: ai-transition-model-metric
      relationship: measured-by
    - id: expert-opinion
      type: ai-transition-model-metric
      relationship: measured-by
    - id: compute-hardware
      type: ai-transition-model-metric
      relationship: measured-by
    - id: racing-dynamics-model
      type: model
      relationship: analyzed-by
    - id: racing-dynamics-impact
      type: model
      relationship: analyzed-by
    - id: multipolar-trap-dynamics
      type: model
      relationship: analyzed-by
    - id: lab-incentives-model
      type: model
      relationship: analyzed-by
  relatedContent:
    risks:
      - path: /knowledge-base/risks/racing-dynamics/
        title: Racing Dynamics
      - path: /knowledge-base/risks/multipolar-trap/
        title: Multipolar Trap
    responses:
      - path: /knowledge-base/responses/pause/
        title: Pause Proposals
      - path: /knowledge-base/responses/coordination-mechanisms/
        title: International Coordination
    models:
      - path: /knowledge-base/models/racing-dynamics-impact/
        title: Racing Dynamics Impact
      - path: /knowledge-base/models/capability-alignment-race/
        title: Capability-Alignment Race
  tags:
    - governance
    - safety
    - market-dynamics
  lastUpdated: 2025-12
  causeEffectGraph:
    title: What Drives Racing Intensity?
    description: Causal factors affecting competitive pressure in AI development. Safety timelines
      compressed 70-80% post-ChatGPT.
    primaryNodeId: racing-intensity
    nodes:
      - id: commercial-competition
        label: Commercial Competition
        type: leaf
        color: red
        description: Market pressures between AI labs for customers and revenue.
        scores:
          novelty: 3  # Commercial competition is well-understood driver
          sensitivity: 8  # Major driver of development speed
          changeability: 3  # Market dynamics are hard to change without coordination
          certainty: 8  # Clear evidence from lab behavior post-ChatGPT
      - id: geopolitical-competition
        label: Geopolitical Competition
        type: leaf
        color: red
        description: US-China dynamics driving national AI programs.
        scores:
          novelty: 3  # US-China AI competition is well-known
          sensitivity: 9  # Single largest driver of racing dynamics at national level
          changeability: 2  # Deeply structural; unlikely to shift soon
          certainty: 8  # Clear policy signals and investment patterns
      - id: coordination-mechanisms
        label: Coordination Mechanisms
        type: leaf
        color: emerald
        description: Agreements and norms that could slow racing. Currently weak.
        scores:
          novelty: 4  # AI-specific coordination mechanisms are evolving
          sensitivity: 7  # Could significantly reduce racing if strengthened
          changeability: 5  # Can be built deliberately; requires sustained effort
          certainty: 5  # Effectiveness of various mechanisms still being tested
      - id: investor-pressure
        label: Investor Pressure
        type: leaf
        color: rose
        description: VC and capital market expectations for rapid returns and competitive wins.
        scores:
          novelty: 3  # Standard startup dynamics
          sensitivity: 7  # Affects resource allocation and urgency
          changeability: 4  # Depends on broader market conditions
          certainty: 7  # Investment dynamics well-understood
      - id: talent-competition
        label: Talent Competition
        type: leaf
        color: rose
        description: Labs competing for limited AI research talent accelerates hiring and projects.
        scores:
          novelty: 4  # AI talent wars increasingly recognized
          sensitivity: 6  # Adds to urgency; researchers want to work on cutting-edge
          changeability: 3  # Structural supply constraint
          certainty: 7  # Salary data and hiring patterns clear
      - id: is-racing-inevitable
        label: Is racing inevitable?
        type: leaf
        color: violet
        description: Key uncertainty about whether coordination can overcome competitive pressures.
        scores:
          novelty: 5  # Game theory question with novel AI context
          sensitivity: 9  # Determines whether slowdown is even possible
          changeability: 4  # Depends on coordination mechanisms and incentives
          certainty: 3  # Structural question with uncertain answer
      - id: first-mover-perception
        label: First-Mover Perception
        type: intermediate
        color: teal
        description: Belief that early leads confer lasting advantages.
        scores:
          novelty: 5  # Accuracy of first-mover beliefs is debated
          sensitivity: 8  # Key driver of urgency and corner-cutting
          changeability: 5  # Perceptions can shift with evidence and arguments
          certainty: 5  # Whether first-mover advantages persist is uncertain
      - id: safety-cost-perception
        label: Safety Cost Perception
        type: intermediate
        color: slate
        description: Perception of safety work as competitive disadvantage.
        scores:
          novelty: 5  # Some labs argue safety is competitive advantage; debated
          sensitivity: 7  # Affects resource allocation to safety
          changeability: 6  # Can be reframed; depends on evidence and incentives
          certainty: 5  # Actual costs vs perceived costs differ by context
      - id: racing-intensity
        label: Racing Intensity
        type: effect
        color: red
        description: Competitive pressure driving speed over safety.
        scores:
          novelty: 4  # Racing dynamics increasingly recognized but specifics debated
          sensitivity: 9  # Major determinant of safety margins in development
          changeability: 4  # Requires coordinated action to reduce
          certainty: 6  # 70-80% timeline compression is documented; future trajectory uncertain
    edges:
      - source: commercial-competition
        target: first-mover-perception
        strength: strong
        effect: increases
      - source: geopolitical-competition
        target: racing-intensity
        strength: strong
        effect: increases
      - source: coordination-mechanisms
        target: racing-intensity
        strength: medium
        effect: decreases
      - source: investor-pressure
        target: first-mover-perception
        strength: medium
        effect: increases
      - source: talent-competition
        target: racing-intensity
        strength: medium
        effect: increases
      - source: is-racing-inevitable
        target: racing-intensity
        strength: medium
        effect: mixed
      - source: first-mover-perception
        target: racing-intensity
        strength: strong
        effect: increases
      - source: safety-cost-perception
        target: racing-intensity
        strength: medium
        effect: increases
- id: safety-culture-strength
  type: ai-transition-model-parameter
  title: Safety Culture Strength
  description: The degree to which AI organizations genuinely prioritize safety in decisions, resource
    allocation, and personnel incentives.
  customFields:
    - label: Direction
      value: Higher is better
    - label: Current Trend
      value: Mixed (some labs lead, others decline under competitive pressure)
    - label: Key Measurement
      value: Safety budget trends, deployment veto authority, incident transparency
  relatedEntries:
    - id: racing-dynamics
      type: risk
      relationship: related
    - id: safety-research
      type: ai-transition-model-metric
      relationship: measured-by
    - id: lab-behavior
      type: ai-transition-model-metric
      relationship: measured-by
    - id: racing-dynamics-model
      type: model
      relationship: analyzed-by
    - id: lab-incentives-model
      type: model
      relationship: analyzed-by
  tags:
    - governance
    - safety
    - organizational
  lastUpdated: 2025-12
  causeEffectGraph:
    title: What Affects Safety Culture Strength?
    description: Causal factors affecting whether AI labs genuinely prioritize safety. Mixed results
      across labs under competitive pressure.
    primaryNodeId: safety-culture-strength
    nodes:
      - id: leadership-commitment
        label: Leadership Commitment
        type: leaf
        color: emerald
        description: Genuine priority placed on safety by executives and founders.
        scores:
          novelty: 3 # Well-known that leadership sets culture
          sensitivity: 8 # Strong downstream effects on safety team authority, resource allocation
          changeability: 5 # Can change with leadership turnover or external pressure
          certainty: 7 # Well-established in organizational behavior research
      - id: competitive-pressure
        label: Competitive Pressure
        type: leaf
        color: rose
        description: Racing dynamics that pressure labs to cut safety corners.
        scores:
          novelty: 4 # Recognized but underappreciated by some
          sensitivity: 9 # Major driver of safety culture erosion
          changeability: 3 # Hard to change without industry-wide coordination
          certainty: 8 # Clear evidence from post-ChatGPT timeline compression
      - id: external-oversight
        label: External Oversight
        type: leaf
        color: blue
        description: Regulatory scrutiny and public accountability.
        scores:
          novelty: 3 # Standard governance mechanism
          sensitivity: 6 # Moderate effect on lab behavior
          changeability: 5 # Depends on political will and regulatory capacity
          certainty: 6 # Mixed evidence on effectiveness in tech sectors
      - id: safety-team-authority
        label: Safety Team Authority
        type: intermediate
        color: emerald
        description: Power of safety teams to delay or block deployments.
        scores:
          novelty: 5 # Often overlooked in policy discussions
          sensitivity: 8 # Key transmission mechanism for safety culture
          changeability: 6 # Can change with org restructuring or new leadership
          certainty: 5 # Varies widely across labs; hard to measure
      - id: resource-allocation
        label: Resource Allocation
        type: intermediate
        description: Budget and staffing devoted to safety work.
        scores:
          novelty: 2 # Obvious that resources matter
          sensitivity: 7 # Direct effect on safety output
          changeability: 6 # Can be adjusted with budget decisions
          certainty: 8 # Clear relationship between resources and output
      - id: safety-talent-retention
        label: Safety Talent Retention
        type: leaf
        color: rose
        description: Ability to retain top safety researchers amid competitive poaching and mission drift.
        scores:
          novelty: 6 # Often overlooked; recent departures highlight importance
          sensitivity: 8 # Loss of key researchers can cripple safety efforts
          changeability: 5 # Depends on compensation, mission clarity, and org culture
          certainty: 6 # Clear cases like OpenAI departures, but hard to generalize
      - id: incident-learning-culture
        label: Incident Learning Culture
        type: intermediate
        color: emerald
        description: Whether near-misses and failures are shared and learned from across the organization.
        scores:
          novelty: 5 # Well-known in safety engineering, less applied to AI
          sensitivity: 7 # Key for preventing repeated mistakes
          changeability: 6 # Can be improved with process changes
          certainty: 7 # Strong precedent from aviation and nuclear industries
      - id: board-governance
        label: Board Governance
        type: leaf
        color: blue
        description: Board composition and authority to enforce safety commitments against management.
        scores:
          novelty: 5 # Highlighted by OpenAI board crisis
          sensitivity: 7 # Can override management decisions
          changeability: 4 # Board changes are rare and often contentious
          certainty: 5 # Limited data on effective AI safety governance
      - id: culture-scaling-question
        label: Can Safety Culture Scale?
        type: leaf
        color: violet
        description: Key uncertainty about whether safety culture persists during rapid growth and commercialization.
        scores:
          novelty: 7 # Underexplored in policy discussions
          sensitivity: 8 # Could determine long-term safety outcomes
          changeability: 3 # Structural challenge, not easily addressed
          certainty: 4 # Limited historical precedent at this scale
      - id: safety-culture-strength
        label: Safety Culture Strength
        type: effect
        description: Genuine organizational prioritization of safety.
        scores:
          novelty: 4 # Increasingly discussed but often vague
          sensitivity: 9 # Major determinant of safety outcomes
          changeability: 4 # Cultures are slow to change
          certainty: 5 # Hard to measure authenticity vs. performance
    edges:
      - source: leadership-commitment
        target: safety-team-authority
        strength: strong
        effect: increases
      - source: competitive-pressure
        target: safety-culture-strength
        strength: strong
        effect: decreases
      - source: external-oversight
        target: safety-culture-strength
        strength: medium
        effect: increases
      - source: safety-team-authority
        target: safety-culture-strength
        strength: strong
        effect: increases
      - source: resource-allocation
        target: safety-culture-strength
        strength: medium
        effect: increases
      - source: safety-talent-retention
        target: safety-culture-strength
        strength: strong
        effect: increases
      - source: leadership-commitment
        target: incident-learning-culture
        strength: medium
        effect: increases
      - source: incident-learning-culture
        target: safety-culture-strength
        strength: medium
        effect: increases
      - source: board-governance
        target: leadership-commitment
        strength: medium
        effect: increases
      - source: culture-scaling-question
        target: safety-culture-strength
        strength: medium
        effect: mixed
- id: coordination-capacity
  type: ai-transition-model-parameter
  title: Coordination Capacity
  description: The degree to which AI stakeholders successfully coordinate on safety standards,
    information sharing, and development practices.
  customFields:
    - label: Direction
      value: Higher is better
    - label: Current Trend
      value: Fragile (voluntary commitments exist but lack enforcement)
    - label: Key Measurement
      value: Commitment compliance, information sharing, standard adoption
  relatedEntries:
    - id: racing-dynamics
      type: risk
      relationship: related
    - id: international-coordination
      type: ai-transition-model-parameter
      relationship: related
    - id: geopolitics
      type: ai-transition-model-metric
      relationship: measured-by
    - id: racing-dynamics-impact
      type: model
      relationship: analyzed-by
    - id: international-coordination-game
      type: model
      relationship: analyzed-by
  tags:
    - governance
    - international
    - coordination
  lastUpdated: 2025-12
  causeEffectGraph:
    title: What Affects Coordination Capacity?
    description: Causal factors influencing stakeholder coordination on AI safety. Based on game theory,
      trust dynamics, and institutional mechanisms.
    primaryNodeId: coordination-capacity
    nodes:
      - id: shared-risk-perception
        label: Shared Risk Perception
        type: leaf
        color: emerald
        description: Common understanding of AI risks. Enables cooperation motivation.
        scores:
          novelty: 4 # Well-known prerequisite for cooperation
          sensitivity: 8 # Strong effect on willingness to coordinate
          changeability: 5 # Can shift with evidence and high-profile incidents
          certainty: 7 # Established in collective action literature
      - id: trust-levels
        label: Trust Between Actors
        type: leaf
        color: teal
        description: Confidence that others will honor commitments. Foundation for cooperation.
        scores:
          novelty: 3 # Fundamental to all cooperation theory
          sensitivity: 9 # Critical determinant of coordination success
          changeability: 4 # Trust builds slowly, breaks quickly
          certainty: 8 # Well-established in game theory
      - id: verification-capability
        label: Verification Capability
        type: leaf
        color: blue
        description: Ability to confirm compliance with agreements. Reduces need for trust.
        scores:
          novelty: 5 # Technical verification for AI is novel challenge
          sensitivity: 7 # Key enabler for enforceable agreements
          changeability: 5 # Depends on technical and institutional development
          certainty: 6 # Unclear what verification is feasible for AI
      - id: communication-channels
        label: Communication Channels
        type: intermediate
        description: Established forums for dialogue between AI stakeholders.
        scores:
          novelty: 3 # Standard institutional feature
          sensitivity: 6 # Enables but doesn't guarantee coordination
          changeability: 6 # Forums can be created with political will
          certainty: 7 # Clear role in facilitating dialogue
      - id: coordination-mechanisms
        label: Coordination Mechanisms
        type: intermediate
        color: blue
        description: Standards bodies, agreements, joint commitments.
        scores:
          novelty: 4 # Well-understood mechanisms, novel AI application
          sensitivity: 8 # Key transmission belt for coordination
          changeability: 5 # Can be built but require buy-in
          certainty: 6 # Effectiveness varies widely by design
      - id: geopolitical-tension
        label: Geopolitical Tension
        type: leaf
        color: rose
        description: US-China competition and broader great power rivalry undermining cooperation.
        scores:
          novelty: 3 # Widely recognized factor
          sensitivity: 9 # Major barrier to international coordination
          changeability: 2 # Structural geopolitical forces are slow to shift
          certainty: 8 # Clear evidence of impact on AI governance talks
      - id: first-mover-incentives
        label: First-Mover Incentives
        type: leaf
        color: rose
        description: Economic and strategic advantages from moving first, creating defection pressure.
        scores:
          novelty: 4 # Recognized in AI race discourse
          sensitivity: 8 # Key driver of racing dynamics
          changeability: 4 # Hard to eliminate without coordination
          certainty: 7 # Consistent with game theory predictions
      - id: information-asymmetries
        label: Information Asymmetries
        type: leaf
        color: slate
        description: Gaps in knowledge about others' capabilities and intentions.
        scores:
          novelty: 4 # Standard in security dilemma literature
          sensitivity: 7 # Creates uncertainty that inhibits cooperation
          changeability: 5 # Can be reduced through transparency measures
          certainty: 7 # Well-established effect on cooperation
      - id: coordination-will-question
        label: Will Major Powers Coordinate?
        type: leaf
        color: violet
        description: Key uncertainty about whether US and China can overcome rivalry to coordinate on AI safety.
        scores:
          novelty: 6 # Central question for AI governance
          sensitivity: 9 # Determines feasibility of global coordination
          changeability: 3 # Depends on deep structural factors
          certainty: 3 # Highly uncertain; could go either way
      - id: coordination-capacity
        label: Coordination Capacity
        type: effect
        description: Effective coordination on safety standards and practices.
        scores:
          novelty: 4 # Concept is familiar, AI application is novel
          sensitivity: 8 # Key determinant of collective safety outcomes
          changeability: 5 # Can be improved with sustained effort
          certainty: 5 # Uncertain how much coordination is achievable
    edges:
      - source: shared-risk-perception
        target: communication-channels
        strength: strong
        effect: increases
      - source: trust-levels
        target: coordination-mechanisms
        strength: strong
        effect: increases
      - source: verification-capability
        target: coordination-mechanisms
        strength: medium
        effect: increases
      - source: communication-channels
        target: coordination-capacity
        strength: medium
        effect: increases
      - source: coordination-mechanisms
        target: coordination-capacity
        strength: strong
        effect: increases
      - source: geopolitical-tension
        target: trust-levels
        strength: strong
        effect: decreases
      - source: first-mover-incentives
        target: coordination-capacity
        strength: strong
        effect: decreases
      - source: information-asymmetries
        target: trust-levels
        strength: medium
        effect: decreases
      - source: verification-capability
        target: information-asymmetries
        strength: medium
        effect: decreases
      - source: coordination-will-question
        target: coordination-capacity
        strength: strong
        effect: mixed
- id: biological-threat-exposure
  type: ai-transition-model-parameter
  title: Biological Threat Exposure
  description: Society's vulnerability to biological threats including AI-enabled bioweapons. Measures
    exposure level—lower means better prevention, detection, and response capacity.
  customFields:
    - label: Direction
      value: Lower is better
    - label: Current Trend
      value: Stressed (DNA screening catches ~25% of threats; AI approaching expert virology)
    - label: Key Measurement
      value: Screening coverage, surveillance capability, response speed
  relatedEntries:
    - id: bioweapons
      type: risk
      relationship: related
    - id: bioweapons-attack-chain
      type: model
      relationship: analyzed-by
    - id: bioweapons-ai-uplift
      type: model
      relationship: analyzed-by
  relatedContent:
    risks:
      - path: /knowledge-base/risks/bioweapons/
        title: AI-Enabled Bioweapons
    models:
      - path: /knowledge-base/models/bioweapons-ai-uplift/
        title: Bioweapons AI Uplift
      - path: /knowledge-base/models/bioweapons-attack-chain/
        title: Bioweapons Attack Chain
      - path: /knowledge-base/models/bioweapons-timeline/
        title: Bioweapons Timeline
  tags:
    - security
    - biosecurity
    - defense
  lastUpdated: 2025-12
  causeEffectGraph:
    title: What Affects Biological Threat Exposure?
    description: Causal factors affecting vulnerability to biological threats. DNA screening catches
      ~25% of threats.
    primaryNodeId: biological-threat-exposure
    nodes:
      - id: ai-bioweapon-capability
        label: AI Bioweapon Capability
        type: leaf
        color: red
        description: AI's ability to assist with pathogen design. Approaching expert level.
        scores:
          novelty: 6 # Emerging capability with limited precedent
          sensitivity: 9 # Could enable catastrophic attacks
          changeability: 3 # Capability is advancing regardless of intent
          certainty: 6 # Active debate on magnitude of AI uplift
      - id: dna-synthesis-controls
        label: DNA Synthesis Controls
        type: leaf
        color: emerald
        description: Screening and verification at synthesis facilities.
        scores:
          novelty: 4 # Established mechanism, expanding coverage
          sensitivity: 8 # Key chokepoint for preventing attacks
          changeability: 6 # Can be mandated with regulatory effort
          certainty: 7 # Clear mechanism, uncertain coverage
      - id: biosurveillance-capacity
        label: Biosurveillance Capacity
        type: leaf
        color: emerald
        description: Early detection systems for biological threats.
        scores:
          novelty: 5 # Advancing with metagenomic sequencing
          sensitivity: 7 # Early detection enables faster response
          changeability: 5 # Requires investment and coordination
          certainty: 6 # Coverage and speed vary widely
      - id: attack-feasibility
        label: Attack Feasibility
        type: intermediate
        color: rose
        description: How easily actors can develop bioweapons.
        scores:
          novelty: 4 # Classic biosecurity framing
          sensitivity: 9 # Direct determinant of threat level
          changeability: 4 # Multiple pathways to attack
          certainty: 5 # Depends on attacker resources and intent
      - id: defense-capability
        label: Defense Capability
        type: intermediate
        color: emerald
        description: Detection, response, and countermeasure capacity.
        scores:
          novelty: 3 # Traditional biosecurity framing
          sensitivity: 8 # Key to reducing harm from attacks
          changeability: 5 # Can be improved with investment
          certainty: 6 # Effectiveness varies by pathogen type
      - id: wet-lab-bottleneck
        label: Wet Lab Bottleneck
        type: leaf
        color: slate
        description: Physical biology skills needed to synthesize and handle pathogens.
        scores:
          novelty: 5 # Key debate point in AI biosecurity
          sensitivity: 7 # If strong, limits AI uplift impact
          changeability: 4 # Training and automation could reduce
          certainty: 5 # Actively debated by experts
      - id: mcm-development-capacity
        label: MCM Development Capacity
        type: leaf
        color: emerald
        description: Ability to rapidly develop medical countermeasures (vaccines, therapeutics).
        scores:
          novelty: 5 # COVID showed importance and limitations
          sensitivity: 8 # Key defense against novel pathogens
          changeability: 6 # Can be improved with investment
          certainty: 6 # Platform technologies advancing
      - id: actor-intent
        label: Malicious Actor Intent
        type: leaf
        color: red
        description: Presence of state or non-state actors motivated to use bioweapons.
        scores:
          novelty: 3 # Classic threat assessment factor
          sensitivity: 9 # Without intent, capability is academic
          changeability: 2 # Difficult to influence motivations
          certainty: 4 # Hard to assess clandestine intentions
      - id: offense-defense-balance-question
        label: Does AI Help Defense More?
        type: leaf
        color: violet
        description: Key uncertainty about whether AI capabilities favor biodefense or biooffense.
        scores:
          novelty: 7 # Central unresolved question
          sensitivity: 9 # Determines net impact of AI on biorisk
          changeability: 5 # Could be shaped by investment priorities
          certainty: 3 # Genuinely uncertain; depends on many factors
      - id: biological-threat-exposure
        label: Biological Threat Exposure
        type: effect
        description: Society's vulnerability to biological threats.
        scores:
          novelty: 4 # Established framing for biosecurity
          sensitivity: 9 # Direct measure of catastrophic risk
          changeability: 5 # Multiple intervention points
          certainty: 5 # Net exposure hard to measure
    edges:
      - source: ai-bioweapon-capability
        target: attack-feasibility
        strength: strong
        effect: increases
      - source: dna-synthesis-controls
        target: attack-feasibility
        strength: medium
        effect: decreases
      - source: biosurveillance-capacity
        target: defense-capability
        strength: strong
        effect: increases
      - source: attack-feasibility
        target: biological-threat-exposure
        strength: strong
        effect: increases
      - source: defense-capability
        target: biological-threat-exposure
        strength: strong
        effect: decreases
      - source: wet-lab-bottleneck
        target: attack-feasibility
        strength: medium
        effect: decreases
      - source: mcm-development-capacity
        target: defense-capability
        strength: strong
        effect: increases
      - source: actor-intent
        target: attack-feasibility
        strength: strong
        effect: increases
      - source: offense-defense-balance-question
        target: biological-threat-exposure
        strength: strong
        effect: mixed
- id: cyber-threat-exposure
  type: ai-transition-model-parameter
  title: Cyber Threat Exposure
  description: Society's vulnerability to cyber attacks including AI-enabled threats. Measures
    exposure level—lower means better defense of critical systems.
  customFields:
    - label: Direction
      value: Lower is better
    - label: Current Trend
      value: Stressed (87% of orgs report AI attacks; 72% year-over-year increase)
    - label: Key Measurement
      value: Detection capability, response time, breach cost reduction
  relatedEntries:
    - id: cyberweapons
      type: risk
      relationship: related
    - id: cyberweapons-offense-defense
      type: model
      relationship: analyzed-by
    - id: cyberweapons-attack-automation
      type: model
      relationship: analyzed-by
  relatedContent:
    risks:
      - path: /knowledge-base/risks/cyberweapons/
        title: AI-Enhanced Cyberweapons
    models:
      - path: /knowledge-base/models/cyberweapons-offense-defense/
        title: Cyber Offense-Defense Balance
      - path: /knowledge-base/models/cyberweapons-attack-automation/
        title: Cyberweapons Attack Automation
  tags:
    - security
    - cybersecurity
    - defense
  lastUpdated: 2025-12
  causeEffectGraph:
    title: What Affects Cyber Threat Exposure?
    description: Causal factors influencing society's vulnerability to AI-enabled cyber attacks.
    primaryNodeId: cyber-threat-exposure
    nodes:
      - id: ai-attack-capabilities
        label: AI Attack Capabilities
        type: leaf
        color: red
        description: AI ability to find vulnerabilities, craft exploits, and automate attacks.
        scores:
          novelty: 5 # Emerging threat with demonstrated capabilities
          sensitivity: 9 # Could dramatically scale attack throughput
          changeability: 3 # Capability advancing with general AI progress
          certainty: 7 # Clear evidence of AI-assisted attacks
      - id: legacy-systems
        label: Legacy System Prevalence
        type: leaf
        color: rose
        description: Continued use of outdated, vulnerable infrastructure.
        scores:
          novelty: 2 # Well-known vulnerability source
          sensitivity: 7 # Persistent attack surface
          changeability: 4 # Slow replacement cycles; costly
          certainty: 8 # Clear link to breaches
      - id: ai-defense-capabilities
        label: AI Defense Capabilities
        type: leaf
        color: emerald
        description: AI-powered threat detection, response, and remediation.
        scores:
          novelty: 5 # Rapidly developing defensive applications
          sensitivity: 8 # Could shift offense-defense balance
          changeability: 6 # Investment can accelerate deployment
          certainty: 6 # Effectiveness varies by deployment
      - id: security-investment
        label: Security Investment
        type: leaf
        color: blue
        description: Resources devoted to cybersecurity across organizations.
        scores:
          novelty: 2 # Standard factor in security posture
          sensitivity: 6 # Enables defensive capabilities
          changeability: 6 # Can be increased with incentives
          certainty: 7 # Clear correlation with breach rates
      - id: attack-surface
        label: Attack Surface
        type: intermediate
        color: rose
        description: Overall vulnerability exposure in critical systems.
        scores:
          novelty: 3 # Standard security concept
          sensitivity: 8 # Direct measure of exposure
          changeability: 5 # Can be reduced but constantly expanding
          certainty: 7 # Well-understood relationship to risk
      - id: critical-infrastructure-exposure
        label: Critical Infrastructure Exposure
        type: leaf
        color: red
        description: Vulnerability of power grids, water systems, and other essential infrastructure to cyber attacks.
        scores:
          novelty: 4 # Recognized concern but often underinvested
          sensitivity: 9 # Could cause widespread physical harm
          changeability: 4 # Slow upgrades to SCADA/ICS systems
          certainty: 7 # Clear attack vectors demonstrated
      - id: cybersecurity-workforce
        label: Cybersecurity Workforce
        type: leaf
        color: slate
        description: Availability of skilled security professionals to defend systems.
        scores:
          novelty: 3 # Well-known talent gap
          sensitivity: 6 # Limits defensive capacity
          changeability: 5 # Training pipelines exist but slow
          certainty: 7 # Documented shortage across sectors
      - id: supply-chain-complexity
        label: Supply Chain Complexity
        type: leaf
        color: rose
        description: Third-party dependencies that introduce vulnerabilities beyond org control.
        scores:
          novelty: 5 # SolarWinds highlighted this vector
          sensitivity: 8 # Amplifies attack reach
          changeability: 4 # Difficult to reduce dependencies
          certainty: 7 # Clear evidence from supply chain attacks
      - id: cyber-offense-defense-question
        label: Will Offense Dominate?
        type: leaf
        color: violet
        description: Key uncertainty about whether AI will shift cyber landscape toward attackers or defenders.
        scores:
          novelty: 7 # Central question for AI cybersecurity
          sensitivity: 9 # Determines net impact direction
          changeability: 5 # May be influenced by investment priorities
          certainty: 3 # Genuinely uncertain; competing dynamics
      - id: cyber-threat-exposure
        label: Cyber Threat Exposure
        type: effect
        description: Net societal vulnerability to cyber attacks.
        scores:
          novelty: 4 # Established security framing
          sensitivity: 9 # Direct measure of digital risk
          changeability: 5 # Multiple intervention points
          certainty: 5 # Net exposure hard to quantify
    edges:
      - source: ai-attack-capabilities
        target: attack-surface
        strength: strong
        effect: increases
      - source: legacy-systems
        target: attack-surface
        strength: strong
        effect: increases
      - source: ai-defense-capabilities
        target: attack-surface
        strength: medium
        effect: decreases
      - source: security-investment
        target: ai-defense-capabilities
        strength: medium
        effect: increases
      - source: attack-surface
        target: cyber-threat-exposure
        strength: strong
        effect: increases
      - source: critical-infrastructure-exposure
        target: cyber-threat-exposure
        strength: strong
        effect: increases
      - source: cybersecurity-workforce
        target: ai-defense-capabilities
        strength: medium
        effect: increases
      - source: supply-chain-complexity
        target: attack-surface
        strength: medium
        effect: increases
      - source: cyber-offense-defense-question
        target: cyber-threat-exposure
        strength: strong
        effect: mixed
- id: societal-resilience
  type: ai-transition-model-parameter
  title: Societal Resilience
  description: Society's ability to maintain essential functions and recover from AI-related failures,
    attacks, or disruptions.
  customFields:
    - label: Direction
      value: Higher is better
    - label: Current Trend
      value: Mixed (increasing AI dependency vs. some redundancy investments)
    - label: Key Measurement
      value: Redundancy levels, recovery capability, human skill maintenance
  relatedEntries:
    - id: economic-disruption
      type: risk
      relationship: related
    - id: defense-in-depth-model
      type: model
      relationship: analyzed-by
  tags:
    - resilience
    - infrastructure
    - structural
  lastUpdated: 2025-12
  causeEffectGraph:
    title: What Affects Societal Resilience?
    description: Causal factors influencing society's ability to maintain functions and recover from AI
      disruptions.
    primaryNodeId: societal-resilience
    nodes:
      - id: system-redundancy
        label: System Redundancy
        type: leaf
        color: emerald
        description: Backup systems and fallback capabilities across infrastructure.
        scores:
          novelty: 3 # Well-known resilience principle
          sensitivity: 8 # Key buffer against single points of failure
          changeability: 5 # Requires investment but achievable
          certainty: 8 # Clear relationship to resilience
      - id: human-skill-maintenance
        label: Human Skill Maintenance
        type: leaf
        color: emerald
        description: Continued human capability to operate without AI assistance.
        scores:
          novelty: 5 # Emerging concern as AI adoption grows
          sensitivity: 8 # Critical for non-AI fallback
          changeability: 4 # Skills erode gradually; hard to reverse
          certainty: 6 # Some evidence from automation literature
      - id: ai-dependency-level
        label: AI Dependency Level
        type: leaf
        color: rose
        description: Extent of critical system reliance on AI.
        scores:
          novelty: 4 # Growing concern but not yet mainstream
          sensitivity: 8 # Higher dependency = greater shock risk
          changeability: 4 # Economic pressures drive adoption
          certainty: 7 # Clear relationship to vulnerability
      - id: recovery-planning
        label: Recovery Planning
        type: leaf
        color: blue
        description: Preparation for AI failures and disruptions.
        scores:
          novelty: 5 # AI-specific planning is nascent
          sensitivity: 6 # Enables faster recovery but doesn't prevent shocks
          changeability: 6 # Can be improved with deliberate effort
          certainty: 6 # Standard planning principles apply
      - id: adaptive-capacity
        label: Adaptive Capacity
        type: intermediate
        color: emerald
        description: Ability to reconfigure and respond to novel challenges.
        scores:
          novelty: 4 # Standard resilience concept
          sensitivity: 8 # Key to surviving unexpected shocks
          changeability: 5 # Can be built with intentional design
          certainty: 7 # Well-established in resilience literature
      - id: institutional-capacity
        label: Institutional Capacity
        type: leaf
        color: blue
        description: Strength of governance institutions to coordinate responses to AI disruptions.
        scores:
          novelty: 4 # Standard governance factor
          sensitivity: 7 # Enables coordinated response
          changeability: 4 # Institutional change is slow
          certainty: 7 # Clear role in crisis response
      - id: economic-diversification
        label: Economic Diversification
        type: leaf
        color: slate
        description: Breadth of economic sectors and employment options reducing concentration risk.
        scores:
          novelty: 3 # Standard resilience principle
          sensitivity: 6 # Limits cascading failures
          changeability: 4 # Structural economic changes are slow
          certainty: 7 # Well-established in economics
      - id: social-cohesion
        label: Social Cohesion
        type: leaf
        color: teal
        description: Trust and cooperation between groups enabling collective response to crises.
        scores:
          novelty: 4 # Recognized but often overlooked in tech policy
          sensitivity: 7 # Determines collective action capacity
          changeability: 4 # Deep social trends are slow to shift
          certainty: 6 # Clear role in historical crises
      - id: resilience-vs-efficiency-question
        label: Will Society Invest in Resilience?
        type: leaf
        color: violet
        description: Key uncertainty about whether economic pressures will allow resilience investment over efficiency gains.
        scores:
          novelty: 6 # Central tension in AI policy
          sensitivity: 8 # Determines long-term vulnerability
          changeability: 5 # Policy could shift incentives
          certainty: 4 # Unknown how this tradeoff will resolve
      - id: societal-resilience
        label: Societal Resilience
        type: effect
        description: Overall ability to withstand and recover from AI-related shocks.
        scores:
          novelty: 4 # Standard resilience framing
          sensitivity: 9 # Key to surviving disruptions
          changeability: 5 # Can be improved with investment
          certainty: 6 # Aggregate measure hard to quantify
    edges:
      - source: system-redundancy
        target: adaptive-capacity
        strength: strong
        effect: increases
      - source: human-skill-maintenance
        target: adaptive-capacity
        strength: strong
        effect: increases
      - source: ai-dependency-level
        target: adaptive-capacity
        strength: medium
        effect: decreases
      - source: recovery-planning
        target: adaptive-capacity
        strength: medium
        effect: increases
      - source: adaptive-capacity
        target: societal-resilience
        strength: strong
        effect: increases
      - source: institutional-capacity
        target: adaptive-capacity
        strength: medium
        effect: increases
      - source: economic-diversification
        target: societal-resilience
        strength: medium
        effect: increases
      - source: social-cohesion
        target: adaptive-capacity
        strength: medium
        effect: increases
      - source: resilience-vs-efficiency-question
        target: societal-resilience
        strength: strong
        effect: mixed
