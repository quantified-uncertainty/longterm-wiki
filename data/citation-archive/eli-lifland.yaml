pageId: eli-lifland
verifiedAt: 2026-02-22
totalCitations: 40
verified: 38
broken: 2
unverifiable: 0
citations:
  - footnote: 1
    url: https://samotsvety.org/track-record/
    linkText: Samotsvety Track Record
    claimContext: '**Eli Lifland** is a forecaster and AI safety researcher who ranks #1 on the RAND Forecasting Initiative all-time leaderboard. He co-leads the <EntityLink id="samotsvety">Samotsvety</EntityLink> forecasting team, which placed first in the CSET-Foretell/INFER competition in 2020, 2021, and 2022.[^1] '
    fetchedAt: 2026-02-22T02:12:51.914Z
    httpStatus: 200
    pageTitle: track record
    contentSnippet: "track record Team achievements The Samotsvety Forecasting team at INFER/CSET-Foretell—composed out of Nuño, Misha, Eli—took: 1st place in 2020 , with a relative score of -0.912 (vs. -0.062 by the 2nd best team). Individually we finished 5th, 6th, and 7th . 1st place in 2021 with a relative score of -3.259 (vs. -0.889 by the 2nd best team and vs. -0.267 by “Pro Forecasters”). Individually we finished 1st, 2nd, 4th and 5th . We still hold 1st, 2nd, 3rd, 4th places in INFER&rsquo;s all time ranking"
    contentLength: 12933
    status: verified
    note: null
  - footnote: 2
    url: https://ai-2027.com/about
    linkText: AI 2027 About Page
    claimContext: Lifland co-founded the <EntityLink id="ai-futures-project">AI Futures Project</EntityLink> alongside Daniel Kokotajlo and Thomas Larsen, and co-authored **AI 2027**, a detailed scenario forecast exploring potential <EntityLink id="agi-development">AGI development</EntityLink> trajectories.[^2][^3] T
    fetchedAt: 2026-02-22T02:12:51.455Z
    httpStatus: 200
    pageTitle: About — AI 2027
    contentSnippet: About — AI 2027 About Us The AI 2027 scenario is the first major release from the AI Futures Project . We’re a new nonprofit forecasting the future of AI. We created this website in collaboration with Lightcone Infrastructure . Get in touch You can reach us at info@ai-futures.org . We look forward to hearing from you. If you would like to run our tabletop exercise (or have us run it for you), please fill in this form . If you would like to get involved in steering toward a positive AGI future, w
    contentLength: 614096
    status: verified
    note: null
  - footnote: 3
    url: https://www.lawfaremedia.org/article/lawfare-daily--daniel-kokotajlo-and-eli-lifland-on-their-ai-2027-report
    linkText: Lawfare Media - Daniel Kokotajlo and Eli Lifland on AI 2027
    claimContext: Lifland co-founded the <EntityLink id="ai-futures-project">AI Futures Project</EntityLink> alongside Daniel Kokotajlo and Thomas Larsen, and co-authored **AI 2027**, a detailed scenario forecast exploring potential <EntityLink id="agi-development">AGI development</EntityLink> trajectories.[^2][^3] T
    fetchedAt: 2026-02-22T02:12:51.668Z
    httpStatus: 200
    pageTitle: "Lawfare Daily: Daniel Kokotajlo and Eli Lifland on Their AI 2027 Report | Lawfare"
    contentSnippet: "Lawfare Daily: Daniel Kokotajlo and Eli Lifland on Their AI 2027 Report | Lawfare Kevin Frazier @kevintfrazier kevintfrazier.bsky.social Daniel Kokotajlo Eli Lifland Jen Patja Meet The Authors Subscribe to Lawfare Daniel Kokotajlo, former OpenAI researcher and Executive Director of the AI Futures Project, and Eli Lifland, a researcher with the AI Futures Project, join Kevin Frazier, AI Innovation and Law Fellow at Texas Law and Contributing Editor at Lawfare , to discuss what AI may look like in"
    contentLength: 109668
    status: verified
    note: null
  - footnote: 4
    url: https://www.elilifland.com
    linkText: Eli Lifland Personal Website
    claimContext: Lifland also co-founded and advises Sage, an organization building interactive AI explainers and forecasting tools, and serves as a guest fund manager at the Long Term Future Fund.[^4] He previously worked on <EntityLink id="elicit">Elicit</EntityLink> at Ought and co-created TextAttack, a Python fr
    fetchedAt: 2026-02-22T02:12:51.237Z
    httpStatus: 200
    pageTitle: Eli Lifland
    contentSnippet: Eli Lifland Me elsewhere Blog Twitter Google Scholar Linkedin Github Anonymous Feedback Career I cofounded the AI Futures Project and work as a researcher there on AGI forecasting and governance. I've worked on the AI 2027 scenario and the AI Futures Model , which predicts AI timelines and takeoff speeds. I advise Sage , an organization that is as of 2026, primarily focused on the AI Village . I led the creation of the 2025 and 2026 AI forecasting surveys . I previously worked as a software engi
    contentLength: 10812
    status: verified
    note: null
  - footnote: 5
    url: https://scholar.google.com/citations?user=Q33DXbEAAAAJ&hl=en
    linkText: Eli Lifland Google Scholar Profile
    claimContext: Lifland also co-founded and advises Sage, an organization building interactive AI explainers and forecasting tools, and serves as a guest fund manager at the Long Term Future Fund.[^4] He previously worked on <EntityLink id="elicit">Elicit</EntityLink> at Ought and co-created TextAttack, a Python fr
    fetchedAt: 2026-02-22T02:12:50.712Z
    httpStatus: 0
    pageTitle: null
    contentSnippet: null
    contentLength: 0
    status: broken
    note: fetch failed
  - footnote: 6
    url: https://ai-futures.org/about/
    linkText: AI Futures Project About Page
    claimContext: Lifland is a co-founder and researcher at the **AI Futures Project**, a 501(c)(3) organization focused on AGI forecasting, scenario planning, and policy engagement.[^6] The organization was co-founded with Daniel Kokotajlo (Executive Director, former <EntityLink id="openai">OpenAI</EntityLink> resea
    fetchedAt: 2026-02-22T02:12:53.475Z
    httpStatus: 200
    pageTitle: About | AI Futures Project
    contentSnippet: "About | AI Futures Project The AI Futures Project is a 501(c)(3) nonprofit research organization (EIN 99-4320292). We are funded entirely by charitable donations and grants. Contact You can reach us at info@ai-futures.org or [firstname]@ai-futures.org. We look forward to hearing from you. Team Daniel Kokotajlo , Executive Director: Daniel oversees our research and policy recommendations. He previously worked as a governance researcher at OpenAI on scenario planning. When he left OpenAI, he calle"
    contentLength: 7418
    status: verified
    note: null
  - footnote: 7
    url: https://ai-futures.org/about/
    linkText: AI Futures Project About Page
    claimContext: Lifland is a co-founder and researcher at the **AI Futures Project**, a 501(c)(3) organization focused on AGI forecasting, scenario planning, and policy engagement.[^6] The organization was co-founded with Daniel Kokotajlo (Executive Director, former <EntityLink id="openai">OpenAI</EntityLink> resea
    fetchedAt: 2026-02-22T02:12:53.476Z
    httpStatus: 200
    pageTitle: About | AI Futures Project
    contentSnippet: "About | AI Futures Project The AI Futures Project is a 501(c)(3) nonprofit research organization (EIN 99-4320292). We are funded entirely by charitable donations and grants. Contact You can reach us at info@ai-futures.org or [firstname]@ai-futures.org. We look forward to hearing from you. Team Daniel Kokotajlo , Executive Director: Daniel oversees our research and policy recommendations. He previously worked as a governance researcher at OpenAI on scenario planning. When he left OpenAI, he calle"
    contentLength: 7418
    status: verified
    note: null
  - footnote: 8
    url: https://ai-2027.com/about
    linkText: AI 2027 About Page
    claimContext: The project's flagship output is **AI 2027**, a detailed scenario forecast released in April 2025 exploring how superintelligence might emerge.[^8] The scenario was co-authored with Scott Alexander (who primarily assisted with rewriting) and Romeo Dean (who contributed supplements on compute and sec
    fetchedAt: 2026-02-22T02:12:53.018Z
    httpStatus: 200
    pageTitle: About — AI 2027
    contentSnippet: About — AI 2027 About Us The AI 2027 scenario is the first major release from the AI Futures Project . We’re a new nonprofit forecasting the future of AI. We created this website in collaboration with Lightcone Infrastructure . Get in touch You can reach us at info@ai-futures.org . We look forward to hearing from you. If you would like to run our tabletop exercise (or have us run it for you), please fill in this form . If you would like to get involved in steering toward a positive AGI future, w
    contentLength: 614096
    status: verified
    note: null
  - footnote: 9
    url: https://ai-2027.com/about
    linkText: AI 2027 About Page
    claimContext: The project's flagship output is **AI 2027**, a detailed scenario forecast released in April 2025 exploring how superintelligence might emerge.[^8] The scenario was co-authored with Scott Alexander (who primarily assisted with rewriting) and Romeo Dean (who contributed supplements on compute and sec
    fetchedAt: 2026-02-22T02:12:53.553Z
    httpStatus: 200
    pageTitle: About — AI 2027
    contentSnippet: About — AI 2027 About Us The AI 2027 scenario is the first major release from the AI Futures Project . We’re a new nonprofit forecasting the future of AI. We created this website in collaboration with Lightcone Infrastructure . Get in touch You can reach us at info@ai-futures.org . We look forward to hearing from you. If you would like to run our tabletop exercise (or have us run it for you), please fill in this form . If you would like to get involved in steering toward a positive AGI future, w
    contentLength: 614096
    status: verified
    note: null
  - footnote: 10
    url: https://ai-2027.com
    linkText: AI 2027 Website
    claimContext: "- Increasingly capable AI agents automating significant portions of AI research and development[^10] - Geopolitical tensions, particularly a US-China AI race, influencing safety decisions and deployment timelines[^11]"
    fetchedAt: 2026-02-22T02:12:53.457Z
    httpStatus: 200
    pageTitle: AI 2027
    contentSnippet: AI 2027 April 3rd 2025 PDF Listen Watch Daniel Kokotajlo, Scott Alexander, Thomas Larsen, Eli Lifland, Romeo Dean We predict that the impact of superhuman AI over the next decade will be enormous, exceeding that of the Industrial Revolution. We wrote a scenario that represents our best guess about what that might look like. 1 It’s informed by trend extrapolations, wargames, expert feedback, experience at OpenAI, and previous forecasting successes. 2 (Added Nov 22 2025, to prevent misunderstandin
    contentLength: 1900943
    status: verified
    note: null
  - footnote: 11
    url: https://controlai.news/p/special-edition-the-future-of-ai
    linkText: ControlAI Newsletter - Future of AI Special Edition
    claimContext: "- Increasingly capable AI agents automating significant portions of AI research and development[^10] - Geopolitical tensions, particularly a US-China AI race, influencing safety decisions and deployment timelines[^11] - Alignment challenges, including exploration of safer model series using chain-of"
    fetchedAt: 2026-02-22T02:12:55.230Z
    httpStatus: 200
    pageTitle: "Special Edition: The Future of AI and Humanity, with Eli Lifland"
    contentSnippet: "Special Edition: The Future of AI and Humanity, with Eli Lifland ControlAI Subscribe Sign in Special Edition: The Future of AI and Humanity, with Eli Lifland We spoke with top forecaster and AI 2027 coauthor Eli Lifland to get his views on the speed and risks of AI development. Tolga Bilge , Eleanor Ruth , and Andrea Miotti Apr 10, 2025 27 1 6 Share Welcome to the ControlAI newsletter! For our first ever interview, we sat down with Eli Lifland to learn about the future of AI. Eli is a coauthor o"
    contentLength: 244139
    status: verified
    note: null
  - footnote: 12
    url: https://ai-2027.com
    linkText: AI 2027 Website
    claimContext: "- Geopolitical tensions, particularly a US-China AI race, influencing safety decisions and deployment timelines[^11] - Alignment challenges, including exploration of safer model series using chain-of-thought reasoning to address failures[^12] - Economic impacts, including widespread job displacement"
    fetchedAt: 2026-02-22T02:12:54.743Z
    httpStatus: 200
    pageTitle: AI 2027
    contentSnippet: AI 2027 April 3rd 2025 PDF Listen Watch Daniel Kokotajlo, Scott Alexander, Thomas Larsen, Eli Lifland, Romeo Dean We predict that the impact of superhuman AI over the next decade will be enormous, exceeding that of the Industrial Revolution. We wrote a scenario that represents our best guess about what that might look like. 1 It’s informed by trend extrapolations, wargames, expert feedback, experience at OpenAI, and previous forecasting successes. 2 (Added Nov 22 2025, to prevent misunderstandin
    contentLength: 1900943
    status: verified
    note: null
  - footnote: 13
    url: https://ai-2027.com
    linkText: AI 2027 Website
    claimContext: "- Alignment challenges, including exploration of safer model series using chain-of-thought reasoning to address failures[^12] - Economic impacts, including widespread job displacement[^13]"
    fetchedAt: 2026-02-22T02:12:55.138Z
    httpStatus: 200
    pageTitle: AI 2027
    contentSnippet: AI 2027 April 3rd 2025 PDF Listen Watch Daniel Kokotajlo, Scott Alexander, Thomas Larsen, Eli Lifland, Romeo Dean We predict that the impact of superhuman AI over the next decade will be enormous, exceeding that of the Industrial Revolution. We wrote a scenario that represents our best guess about what that might look like. 1 It’s informed by trend extrapolations, wargames, expert feedback, experience at OpenAI, and previous forecasting successes. 2 (Added Nov 22 2025, to prevent misunderstandin
    contentLength: 1900943
    status: verified
    note: null
  - footnote: 14
    url: https://www.lawfaremedia.org/article/lawfare-daily--daniel-kokotajlo-and-eli-lifland-on-their-ai-2027-report
    linkText: Lawfare Media - Daniel Kokotajlo and Eli Lifland on AI 2027
    claimContext: The project received significant attention and has been discussed in venues including Lawfare Media, <EntityLink id="controlai">ControlAI</EntityLink>, and a CEPR webinar.[^14][^15][^16]
    fetchedAt: 2026-02-22T02:12:54.969Z
    httpStatus: 200
    pageTitle: "Lawfare Daily: Daniel Kokotajlo and Eli Lifland on Their AI 2027 Report | Lawfare"
    contentSnippet: "Lawfare Daily: Daniel Kokotajlo and Eli Lifland on Their AI 2027 Report | Lawfare Kevin Frazier @kevintfrazier kevintfrazier.bsky.social Daniel Kokotajlo Eli Lifland Jen Patja Meet The Authors Subscribe to Lawfare Daniel Kokotajlo, former OpenAI researcher and Executive Director of the AI Futures Project, and Eli Lifland, a researcher with the AI Futures Project, join Kevin Frazier, AI Innovation and Law Fellow at Texas Law and Contributing Editor at Lawfare , to discuss what AI may look like in"
    contentLength: 109668
    status: verified
    note: null
  - footnote: 15
    url: https://controlai.news/p/special-edition-the-future-of-ai
    linkText: ControlAI Newsletter - Future of AI Special Edition
    claimContext: The project received significant attention and has been discussed in venues including Lawfare Media, <EntityLink id="controlai">ControlAI</EntityLink>, and a CEPR webinar.[^14][^15][^16]
    fetchedAt: 2026-02-22T02:12:55.240Z
    httpStatus: 200
    pageTitle: "Special Edition: The Future of AI and Humanity, with Eli Lifland"
    contentSnippet: "Special Edition: The Future of AI and Humanity, with Eli Lifland ControlAI Subscribe Sign in Special Edition: The Future of AI and Humanity, with Eli Lifland We spoke with top forecaster and AI 2027 coauthor Eli Lifland to get his views on the speed and risks of AI development. Tolga Bilge , Eleanor Ruth , and Andrea Miotti Apr 10, 2025 27 1 6 Share Welcome to the ControlAI newsletter! For our first ever interview, we sat down with Eli Lifland to learn about the future of AI. Eli is a coauthor o"
    contentLength: 244139
    status: verified
    note: null
  - footnote: 16
    url: https://cepr.org/multimedia/cepr-webinar-series-economics-artificial-intelligence-ai-2027-scenario-forecast
    linkText: CEPR Webinar - AI 2027 Scenario Forecast
    claimContext: The project received significant attention and has been discussed in venues including Lawfare Media, <EntityLink id="controlai">ControlAI</EntityLink>, and a CEPR webinar.[^14][^15][^16]
    fetchedAt: 2026-02-22T02:12:58.949Z
    httpStatus: 200
    pageTitle: CEPR Webinar Series on the Economics of Artificial Intelligence - AI 2027 Scenario Forecast | CEPR
    contentSnippet: "CEPR Webinar Series on the Economics of Artificial Intelligence - AI 2027 Scenario Forecast | CEPR Skip to main content Search the site Search Discussion paper DP21083 Embracing GenAI: A Comparison of Italian and US Households David Loschiavo Olivier Armantier Antonio Dalla-Zuanna Leonardo Gambacorta Mirko Moscatelli Ilaria Supino 25 Jan 2026 Artificial Intelligence O33 D10 J24 Discussion paper DP21082 AI Adoption, Productivity and Employment: Evidence from European Firms Inaki Aldasoro Leonardo"
    contentLength: 117931
    status: verified
    note: null
  - footnote: 17
    url: https://blog.ai-futures.org/p/clarifying-how-our-ai-timelines-forecasts
    linkText: AI Futures Blog - Clarifying Timelines Forecasts
    claimContext: The AI Futures Project maintains a quantitative timelines model that generates probability distributions for key AGI milestones such as Automated Coder (AC) and superintelligence (ASI). The model incorporates benchmark tracking, compute availability, algorithmic progress, and other inputs to produce
    fetchedAt: 2026-02-22T02:12:56.694Z
    httpStatus: 200
    pageTitle: Clarifying how our AI timelines forecasts have changed since AI 2027
    contentSnippet: Clarifying how our AI timelines forecasts have changed since AI 2027 AI Futures Project Subscribe Sign in Clarifying how our AI timelines forecasts have changed since AI 2027 Correcting common misunderstandings Eli Lifland , Daniel Kokotajlo , and Brendan Halstead Jan 27, 2026 54 10 7 Share Some recent news articles discuss updates to our AI timelines since AI 2027, most notably our new timelines and takeoff model, the AI Futures Model (see blog post announcement ). 1 While we’re glad to see bro
    contentLength: 247779
    status: verified
    note: null
  - footnote: 18
    url: https://blog.ai-futures.org/p/clarifying-how-our-ai-timelines-forecasts
    linkText: AI Futures Blog - Clarifying Timelines Forecasts
    claimContext: Lifland's personal AGI timeline estimates have shifted as new evidence has emerged. His median TED-AI (a general intelligence milestone) forecast has followed this trajectory:[^18]
    fetchedAt: 2026-02-22T02:12:56.708Z
    httpStatus: 200
    pageTitle: Clarifying how our AI timelines forecasts have changed since AI 2027
    contentSnippet: Clarifying how our AI timelines forecasts have changed since AI 2027 AI Futures Project Subscribe Sign in Clarifying how our AI timelines forecasts have changed since AI 2027 Correcting common misunderstandings Eli Lifland , Daniel Kokotajlo , and Brendan Halstead Jan 27, 2026 54 10 7 Share Some recent news articles discuss updates to our AI timelines since AI 2027, most notably our new timelines and takeoff model, the AI Futures Model (see blog post announcement ). 1 While we’re glad to see bro
    contentLength: 247779
    status: verified
    note: null
  - footnote: 19
    url: https://blog.ai-futures.org/p/clarifying-how-our-ai-timelines-forecasts
    linkText: AI Futures Blog - Clarifying Timelines Forecasts
    claimContext: The AI Futures Project has emphasized that the AI 2027 scenario was never intended as a confident prediction that AGI would arrive in 2027, and that all team members maintain high uncertainty about when AGI and ASI will be built.[^19] The December 2025 model update predicted 3-5 years longer timelin
    fetchedAt: 2026-02-22T02:12:57.073Z
    httpStatus: 200
    pageTitle: Clarifying how our AI timelines forecasts have changed since AI 2027
    contentSnippet: Clarifying how our AI timelines forecasts have changed since AI 2027 AI Futures Project Subscribe Sign in Clarifying how our AI timelines forecasts have changed since AI 2027 Correcting common misunderstandings Eli Lifland , Daniel Kokotajlo , and Brendan Halstead Jan 27, 2026 54 10 7 Share Some recent news articles discuss updates to our AI timelines since AI 2027, most notably our new timelines and takeoff model, the AI Futures Model (see blog post announcement ). 1 While we’re glad to see bro
    contentLength: 247779
    status: verified
    note: null
  - footnote: 20
    url: https://www.marketingaiinstitute.com/blog/moving-back-agi-timeline
    linkText: Marketing AI Institute - Moving Back AGI Timeline
    claimContext: The AI Futures Project has emphasized that the AI 2027 scenario was never intended as a confident prediction that AGI would arrive in 2027, and that all team members maintain high uncertainty about when AGI and ASI will be built.[^19] The December 2025 model update predicted 3-5 years longer timelin
    fetchedAt: 2026-02-22T02:12:56.681Z
    httpStatus: 200
    pageTitle: Moving Back the Timeline for AGI. Here’s Why.
    contentSnippet: Moving Back the Timeline for AGI. Here’s Why. Search Search Toggle Menu Contact Us Facebook Instagram LinkedIn Twitter Youtube Slack Medium 2 Min Read Moving Back the Timeline for AGI. Here’s Why. By Mike Kaput on December 4, 2025 Intro To AI Free Class - Register Now The "AI 2027" report , a project that originally predicted Artificial General Intelligence (AGI) could arrive in two years, has been updated by its authors. The new consensus? It will arrive around 2030. That’s because progress app
    contentLength: 116595
    status: verified
    note: null
  - footnote: 21
    url: https://samotsvety.org/track-record/
    linkText: Samotsvety Track Record
    claimContext: 'Lifland ranks #1 on the RAND Forecasting Initiative (CSET-Foretell/INFER) all-time leaderboard.[^21] On GJOpen, his Brier score of 0.23 outperforms the median of 0.301 (ratio 0.76), and he secured 2nd place in the <EntityLink id="metaculus">Metaculus</EntityLink> Economist 2021 tournament and 1st in'
    fetchedAt: 2026-02-22T02:13:00.874Z
    httpStatus: 200
    pageTitle: track record
    contentSnippet: "track record Team achievements The Samotsvety Forecasting team at INFER/CSET-Foretell—composed out of Nuño, Misha, Eli—took: 1st place in 2020 , with a relative score of -0.912 (vs. -0.062 by the 2nd best team). Individually we finished 5th, 6th, and 7th . 1st place in 2021 with a relative score of -3.259 (vs. -0.889 by the 2nd best team and vs. -0.267 by “Pro Forecasters”). Individually we finished 1st, 2nd, 4th and 5th . We still hold 1st, 2nd, 3rd, 4th places in INFER&rsquo;s all time ranking"
    contentLength: 12933
    status: verified
    note: null
  - footnote: 22
    url: https://samotsvety.org/track-record/
    linkText: Samotsvety Track Record
    claimContext: 'Lifland ranks #1 on the RAND Forecasting Initiative (CSET-Foretell/INFER) all-time leaderboard.[^21] On GJOpen, his Brier score of 0.23 outperforms the median of 0.301 (ratio 0.76), and he secured 2nd place in the <EntityLink id="metaculus">Metaculus</EntityLink> Economist 2021 tournament and 1st in'
    fetchedAt: 2026-02-22T02:13:00.744Z
    httpStatus: 200
    pageTitle: track record
    contentSnippet: "track record Team achievements The Samotsvety Forecasting team at INFER/CSET-Foretell—composed out of Nuño, Misha, Eli—took: 1st place in 2020 , with a relative score of -0.912 (vs. -0.062 by the 2nd best team). Individually we finished 5th, 6th, and 7th . 1st place in 2021 with a relative score of -3.259 (vs. -0.889 by the 2nd best team and vs. -0.267 by “Pro Forecasters”). Individually we finished 1st, 2nd, 4th and 5th . We still hold 1st, 2nd, 3rd, 4th places in INFER&rsquo;s all time ranking"
    contentLength: 12933
    status: verified
    note: null
  - footnote: 23
    url: https://samotsvety.org/track-record/
    linkText: Samotsvety Track Record
    claimContext: As co-lead of the **Samotsvety Forecasting team** (approximately 15 forecasters), Lifland helped guide the team to first-place finishes in the INFER competition in 2020, 2021, and 2022.[^23] In 2020, Samotsvety placed 1st with a relative score of -0.912 compared to -0.062 for 2nd place. In 2021, the
    fetchedAt: 2026-02-22T02:13:01.001Z
    httpStatus: 200
    pageTitle: track record
    contentSnippet: "track record Team achievements The Samotsvety Forecasting team at INFER/CSET-Foretell—composed out of Nuño, Misha, Eli—took: 1st place in 2020 , with a relative score of -0.912 (vs. -0.062 by the 2nd best team). Individually we finished 5th, 6th, and 7th . 1st place in 2021 with a relative score of -3.259 (vs. -0.889 by the 2nd best team and vs. -0.267 by “Pro Forecasters”). Individually we finished 1st, 2nd, 4th and 5th . We still hold 1st, 2nd, 3rd, 4th places in INFER&rsquo;s all time ranking"
    contentLength: 12933
    status: verified
    note: null
  - footnote: 24
    url: https://samotsvety.org/track-record/
    linkText: Samotsvety Track Record
    claimContext: As co-lead of the **Samotsvety Forecasting team** (approximately 15 forecasters), Lifland helped guide the team to first-place finishes in the INFER competition in 2020, 2021, and 2022.[^23] In 2020, Samotsvety placed 1st with a relative score of -0.912 compared to -0.062 for 2nd place. In 2021, the
    fetchedAt: 2026-02-22T02:13:01.131Z
    httpStatus: 200
    pageTitle: track record
    contentSnippet: "track record Team achievements The Samotsvety Forecasting team at INFER/CSET-Foretell—composed out of Nuño, Misha, Eli—took: 1st place in 2020 , with a relative score of -0.912 (vs. -0.062 by the 2nd best team). Individually we finished 5th, 6th, and 7th . 1st place in 2021 with a relative score of -3.259 (vs. -0.889 by the 2nd best team and vs. -0.267 by “Pro Forecasters”). Individually we finished 1st, 2nd, 4th and 5th . We still hold 1st, 2nd, 3rd, 4th places in INFER&rsquo;s all time ranking"
    contentLength: 12933
    status: verified
    note: null
  - footnote: 25
    url: https://forum.effectivealtruism.org/posts/EG9xDM8YRz4JN4wMN/samotsvety-s-ai-risk-forecasts
    linkText: EA Forum - Samotsvety's AI Risk Forecasts
    claimContext: The team has produced public forecasts on critical topics including AI existential risk and nuclear risk.[^25]
    fetchedAt: 2026-02-22T02:13:00.088Z
    httpStatus: 200
    pageTitle: Samotsvety&#x27;s AI risk forecasts — EA Forum
    contentSnippet: Samotsvety&#x27;s AI risk forecasts — EA Forum This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. Hide table of contents Samotsvety&#x27;s AI risk forecasts by elifland , Misha_Yagudin Sep 9 2022 5 min read 30 175 AI safety Forecasting AI forecasting FTX Foundation Samotsvety Forecasting What We Owe the Future Frontpage Samotsvety&#x27;s AI risk forecasts Introduction Forecasts WWOTF questions FTX Foundation questions Wh
    contentLength: 701406
    status: verified
    note: null
  - footnote: 26
    url: https://www.elilifland.com
    linkText: Eli Lifland Personal Website
    claimContext: Lifland co-founded **Sage**, an organization focused on building interactive AI explainers and forecasting tools.[^26] One of Sage's key projects is **AI Digest**, which received \$550,000 from <EntityLink id="open-philanthropy">Coefficient Giving</EntityLink> for its work, with an additional \$550,
    fetchedAt: 2026-02-22T02:13:02.685Z
    httpStatus: 200
    pageTitle: Eli Lifland
    contentSnippet: Eli Lifland Me elsewhere Blog Twitter Google Scholar Linkedin Github Anonymous Feedback Career I cofounded the AI Futures Project and work as a researcher there on AGI forecasting and governance. I've worked on the AI 2027 scenario and the AI Futures Model , which predicts AI timelines and takeoff speeds. I advise Sage , an organization that is as of 2026, primarily focused on the AI Village . I led the creation of the 2025 and 2026 AI forecasting surveys . I previously worked as a software engi
    contentLength: 10812
    status: verified
    note: null
  - footnote: 27
    url: https://manifund.org/projects/ai-digest
    linkText: Manifund - AI Digest Project
    claimContext: Lifland co-founded **Sage**, an organization focused on building interactive AI explainers and forecasting tools.[^26] One of Sage's key projects is **AI Digest**, which received \$550,000 from <EntityLink id="open-philanthropy">Coefficient Giving</EntityLink> for its work, with an additional \$550,
    fetchedAt: 2026-02-22T02:13:08.846Z
    httpStatus: 429
    pageTitle: null
    contentSnippet: null
    contentLength: 0
    status: broken
    note: HTTP 429
  - footnote: 28
    url: https://www.matsprogram.org/mentor/lifland
    linkText: MATS Program - Eli Lifland Mentor Profile
    claimContext: Lifland is active in the AI safety and alignment communities, particularly through <EntityLink id="lesswrong">LessWrong</EntityLink> and the Effective Altruism Forum. He serves as a mentor in the MATS Program (focusing on Strategy & Forecasting, Policy & Governance streams).[^28] He has also been fe
    fetchedAt: 2026-02-22T02:13:03.241Z
    httpStatus: 200
    pageTitle: Eli Lifland - MATS Mentor
    contentSnippet: Eli Lifland - MATS Mentor Research Mentors About About Mid Missouri Region Kansas City Region Apply Research Mentors About About Mentors Eli Lifland AI Futures Project — Researcher Links Share Focus Strategy and Forecasting, Policy and Governance H-index 7 Stream AI Futures Project Eli is working on AI scenario forecasting with the AI Futures Project, where he co-authored AI 2027. He advises Sage, an organization he cofounded that works on AI Digest (interactive AI explainers) and forecasting to
    contentLength: 68055
    status: verified
    note: null
  - footnote: 29
    url: https://forum.effectivealtruism.org/posts/gsKQknEikbERo4Hih/creating-making-god-a-feature-documentary-on-risks-from-agi
    linkText: EA Forum - Making God Documentary
    claimContext: Lifland is active in the AI safety and alignment communities, particularly through <EntityLink id="lesswrong">LessWrong</EntityLink> and the Effective Altruism Forum. He serves as a mentor in the MATS Program (focusing on Strategy & Forecasting, Policy & Governance streams).[^28] He has also been fe
    fetchedAt: 2026-02-22T02:13:02.195Z
    httpStatus: 200
    pageTitle: "Creating &#x27;Making God&#x27;: a Feature Documentary on risks from AGI — EA Forum"
    contentSnippet: "Creating &#x27;Making God&#x27;: a Feature Documentary on risks from AGI — EA Forum This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. Hide table of contents Creating &#x27;Making God&#x27;: a Feature Documentary on risks from AGI by ConnorA Apr 15 2025 9 min read 8 21 AI safety Building effective altruism Opportunities to take action Documentaries Effective altruism art and fiction Announcements and updates Effective al"
    contentLength: 371616
    status: verified
    note: null
  - footnote: 30
    url: https://www.elilifland.com
    linkText: Eli Lifland Personal Website
    claimContext: Lifland has taken the Giving What We Can Pledge, committing to donate 10% of his lifetime income to effective charities.[^30]
    fetchedAt: 2026-02-22T02:13:02.266Z
    httpStatus: 200
    pageTitle: Eli Lifland
    contentSnippet: Eli Lifland Me elsewhere Blog Twitter Google Scholar Linkedin Github Anonymous Feedback Career I cofounded the AI Futures Project and work as a researcher there on AGI forecasting and governance. I've worked on the AI 2027 scenario and the AI Futures Model , which predicts AI timelines and takeoff speeds. I advise Sage , an organization that is as of 2026, primarily focused on the AI Village . I led the creation of the 2025 and 2026 AI forecasting surveys . I previously worked as a software engi
    contentLength: 10812
    status: verified
    note: null
  - footnote: 31
    url: https://www.lesswrong.com/posts/PAYfmG2aRbdb74mEp/a-deep-critique-of-ai-2027-s-bad-timeline-models
    linkText: LessWrong - Deep Critique of AI 2027 Timeline Models
    claimContext: Lifland's work, particularly the AI 2027 timelines model, has faced methodological criticism from community members. In a detailed critique posted to <EntityLink id="lesswrong">LessWrong</EntityLink>, the EA Forum, and Substack, forecaster "titotal" described the model's fundamental structure as "hi
    fetchedAt: 2026-02-22T02:13:10.528Z
    httpStatus: 200
    pageTitle: A deep critique of AI 2027’s bad timeline models — LessWrong
    contentSnippet: "x This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. A deep critique of AI 2027’s bad timeline models — LessWrong AI Timelines Has Diagram Simulation AI Frontpage 2025 Top Fifty: 18 % 375 A deep critique of AI 2027’s bad timeline models by titotal 19th Jun 2025 Linkpost from titotal.substack.com 47 min read 40 375 Thank you to Arepo and Eli Lifland for looking over this article for errors. I am sorry that this article is"
    contentLength: 1189399
    status: verified
    note: null
  - footnote: 32
    url: https://www.lesswrong.com/posts/PAYfmG2aRbdb74mEp/a-deep-critique-of-ai-2027-s-bad-timeline-models
    linkText: LessWrong - Deep Critique of AI 2027 Timeline Models
    claimContext: Lifland's work, particularly the AI 2027 timelines model, has faced methodological criticism from community members. In a detailed critique posted to <EntityLink id="lesswrong">LessWrong</EntityLink>, the EA Forum, and Substack, forecaster "titotal" described the model's fundamental structure as "hi
    fetchedAt: 2026-02-22T02:13:11.115Z
    httpStatus: 200
    pageTitle: A deep critique of AI 2027’s bad timeline models — LessWrong
    contentSnippet: "x This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. A deep critique of AI 2027’s bad timeline models — LessWrong AI Timelines Has Diagram Simulation AI Frontpage 2025 Top Fifty: 18 % 375 A deep critique of AI 2027’s bad timeline models by titotal 19th Jun 2025 Linkpost from titotal.substack.com 47 min read 40 375 Thank you to Arepo and Eli Lifland for looking over this article for errors. I am sorry that this article is"
    contentLength: 1189400
    status: verified
    note: null
  - footnote: 33
    url: https://forum.effectivealtruism.org/posts/fKx6DkWfzJXoycWhE/the-practical-value-of-flawed-models-a-response-to-titotal-s
    linkText: EA Forum - Practical Value of Flawed Models
    claimContext: Critics have also raised concerns about philosophical overconfidence, warning that popularizing flawed models could lead people to make significant life decisions based on shaky forecasts.[^33] Others counter that inaction on short timelines could be costlier if the forecasts prove accurate.[^34]
    fetchedAt: 2026-02-22T02:13:10.092Z
    httpStatus: 200
    pageTitle: "The Practical Value of Flawed Models: A Response to titotal’s AI 2027 Critique — EA Forum"
    contentSnippet: "The Practical Value of Flawed Models: A Response to titotal’s AI 2027 Critique — EA Forum This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. Hide table of contents The Practical Value of Flawed Models: A Response to titotal’s AI 2027 Critique by Michelle_Ma Jun 25 2025 7 min read 1 97 Forecasting AI forecasting AI governance Criticism of work in effective altruism Opinion Frontpage The Practical Value of Flawed Models: A"
    contentLength: 172320
    status: verified
    note: null
  - footnote: 34
    url: https://forum.effectivealtruism.org/posts/fKx6DkWfzJXoycWhE/the-practical-value-of-flawed-models-a-response-to-titotal-s
    linkText: EA Forum - Practical Value of Flawed Models
    claimContext: Critics have also raised concerns about philosophical overconfidence, warning that popularizing flawed models could lead people to make significant life decisions based on shaky forecasts.[^33] Others counter that inaction on short timelines could be costlier if the forecasts prove accurate.[^34]
    fetchedAt: 2026-02-22T02:13:10.377Z
    httpStatus: 200
    pageTitle: "The Practical Value of Flawed Models: A Response to titotal’s AI 2027 Critique — EA Forum"
    contentSnippet: "The Practical Value of Flawed Models: A Response to titotal’s AI 2027 Critique — EA Forum This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. Hide table of contents The Practical Value of Flawed Models: A Response to titotal’s AI 2027 Critique by Michelle_Ma Jun 25 2025 7 min read 1 97 Forecasting AI forecasting AI governance Criticism of work in effective altruism Opinion Frontpage The Practical Value of Flawed Models: A"
    contentLength: 172319
    status: verified
    note: null
  - footnote: 35
    url: https://aifuturesnotes.substack.com/p/response-to-titotals-critique-of
    linkText: AI Futures Notes Substack - Response to Titotal Critique
    claimContext: Lifland responded to these criticisms by acknowledging errors and reviewing titotal's critique for factual accuracy. He agreed to changes in the model write-up and paid \$500 bounties to both titotal and another critic, Peter Johnson, for identifying issues.[^35][^36] The team released a detailed re
    fetchedAt: 2026-02-22T02:13:10.336Z
    httpStatus: 200
    pageTitle: Response to titotal’s critique of our AI 2027 timelines model
    contentSnippet: Response to titotal’s critique of our AI 2027 timelines model AI Futures Research Notes Subscribe Sign in Response to titotal’s critique of our AI 2027 timelines model Eli Lifland and Daniel Kokotajlo Dec 16, 2025 12 4 3 Share Introduction In June, a Substack/LessWrong/EA Forum user named titotal wrote “ A deep critique of AI 2027’s bad timeline models ”. Our original model that they were critiquing can be found here , with a brief overview below. 1 In a nutshell, we disagree with most of titota
    contentLength: 725088
    status: verified
    note: null
  - footnote: 36
    url: https://forum.effectivealtruism.org/posts/fKx6DkWfzJXoycWhE/the-practical-value-of-flawed-models-a-response-to-titotal-s
    linkText: EA Forum - Practical Value of Flawed Models
    claimContext: Lifland responded to these criticisms by acknowledging errors and reviewing titotal's critique for factual accuracy. He agreed to changes in the model write-up and paid \$500 bounties to both titotal and another critic, Peter Johnson, for identifying issues.[^35][^36] The team released a detailed re
    fetchedAt: 2026-02-22T02:13:12.153Z
    httpStatus: 200
    pageTitle: "The Practical Value of Flawed Models: A Response to titotal’s AI 2027 Critique — EA Forum"
    contentSnippet: "The Practical Value of Flawed Models: A Response to titotal’s AI 2027 Critique — EA Forum This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. Hide table of contents The Practical Value of Flawed Models: A Response to titotal’s AI 2027 Critique by Michelle_Ma Jun 25 2025 7 min read 1 97 Forecasting AI forecasting AI governance Criticism of work in effective altruism Opinion Frontpage The Practical Value of Flawed Models: A"
    contentLength: 172319
    status: verified
    note: null
  - footnote: 37
    url: https://aifuturesnotes.substack.com/p/response-to-titotals-critique-of
    linkText: AI Futures Notes Substack - Response to Titotal Critique
    claimContext: Lifland responded to these criticisms by acknowledging errors and reviewing titotal's critique for factual accuracy. He agreed to changes in the model write-up and paid \$500 bounties to both titotal and another critic, Peter Johnson, for identifying issues.[^35][^36] The team released a detailed re
    fetchedAt: 2026-02-22T02:13:12.202Z
    httpStatus: 200
    pageTitle: Response to titotal’s critique of our AI 2027 timelines model
    contentSnippet: Response to titotal’s critique of our AI 2027 timelines model AI Futures Research Notes Subscribe Sign in Response to titotal’s critique of our AI 2027 timelines model Eli Lifland and Daniel Kokotajlo Dec 16, 2025 12 4 3 Share Introduction In June, a Substack/LessWrong/EA Forum user named titotal wrote “ A deep critique of AI 2027’s bad timeline models ”. Our original model that they were critiquing can be found here , with a brief overview below. 1 In a nutshell, we disagree with most of titota
    contentLength: 725088
    status: verified
    note: null
  - footnote: 38
    url: https://controlai.news/p/special-edition-the-future-of-ai
    linkText: ControlAI Newsletter - Future of AI Special Edition
    claimContext: "- **Lack of skeptic engagement**: Some community members felt AI 2027 did not sufficiently address skeptical frameworks or justify its models against competing views[^38] - **Unverifiable predictions**: Concerns that some predictions are difficult to validate empirically[^39]"
    fetchedAt: 2026-02-22T02:13:12.653Z
    httpStatus: 200
    pageTitle: "Special Edition: The Future of AI and Humanity, with Eli Lifland"
    contentSnippet: "Special Edition: The Future of AI and Humanity, with Eli Lifland ControlAI Subscribe Sign in Special Edition: The Future of AI and Humanity, with Eli Lifland We spoke with top forecaster and AI 2027 coauthor Eli Lifland to get his views on the speed and risks of AI development. Tolga Bilge , Eleanor Ruth , and Andrea Miotti Apr 10, 2025 27 1 6 Share Welcome to the ControlAI newsletter! For our first ever interview, we sat down with Eli Lifland to learn about the future of AI. Eli is a coauthor o"
    contentLength: 244285
    status: verified
    note: null
  - footnote: 39
    url: https://ai-2027.com
    linkText: AI 2027 Website
    claimContext: "- **Lack of skeptic engagement**: Some community members felt AI 2027 did not sufficiently address skeptical frameworks or justify its models against competing views[^38] - **Unverifiable predictions**: Concerns that some predictions are difficult to validate empirically[^39]"
    fetchedAt: 2026-02-22T02:13:12.809Z
    httpStatus: 200
    pageTitle: AI 2027
    contentSnippet: AI 2027 April 3rd 2025 PDF Listen Watch Daniel Kokotajlo, Scott Alexander, Thomas Larsen, Eli Lifland, Romeo Dean We predict that the impact of superhuman AI over the next decade will be enormous, exceeding that of the Industrial Revolution. We wrote a scenario that represents our best guess about what that might look like. 1 It’s informed by trend extrapolations, wargames, expert feedback, experience at OpenAI, and previous forecasting successes. 2 (Added Nov 22 2025, to prevent misunderstandin
    contentLength: 1900943
    status: verified
    note: null
  - footnote: 40
    url: https://blog.ai-futures.org/p/clarifying-how-our-ai-timelines-forecasts
    linkText: AI Futures Blog - Clarifying Timelines Forecasts
    claimContext: Lifland has been forthright about forecast misses and has regularly updated his timelines as new evidence emerges.[^40] No major personal controversies or ethical issues have been documented beyond these methodological debates.
    fetchedAt: 2026-02-22T02:13:12.692Z
    httpStatus: 200
    pageTitle: Clarifying how our AI timelines forecasts have changed since AI 2027
    contentSnippet: Clarifying how our AI timelines forecasts have changed since AI 2027 AI Futures Project Subscribe Sign in Clarifying how our AI timelines forecasts have changed since AI 2027 Correcting common misunderstandings Eli Lifland , Daniel Kokotajlo , and Brendan Halstead Jan 27, 2026 54 10 7 Share Some recent news articles discuss updates to our AI timelines since AI 2027, most notably our new timelines and takeoff model, the AI Futures Model (see blog post announcement ). 1 While we’re glad to see bro
    contentLength: 247779
    status: verified
    note: null
