pageId: redwood-research
verifiedAt: 2026-02-22
totalCitations: 45
verified: 44
broken: 1
unverifiable: 0
citations:
  - footnote: 1
    url: https://www.redwoodresearch.org/
    linkText: Redwood Research - Official Website
    claimContext: '|-----------|------------|----------| | **Focus Area** | AI systems acting against developer interests | Primary research on <EntityLink id="ai-control">AI Control</EntityLink> and alignment faking[^1] | | **Funding** | \$25M+ from Coefficient Giving | \$9.4M (2021), \$10.7M (2022), \$5.3M (2023)[^2'
    fetchedAt: 2026-02-22T02:12:32.074Z
    httpStatus: 200
    pageTitle: Redwood Research
    contentSnippet: Redwood Research Home Research Team Careers Blog Pioneering threat assessment and mitigation for AI systems Our Research Redwood Research is a nonprofit AI safety and security research organization In the coming years or decades, AI systems will very plausibly match or exceed human capabilities across most intellectual tasks, fundamentally transforming society. Our research specifically addresses the risks that could arise if these powerful AI systems purposefully act against the interests of th
    contentLength: 36365
    status: verified
    note: null
  - footnote: 2
    url: https://blog.redwoodresearch.org/p/the-inaugural-redwood-research-podcast
    linkText: The inaugural Redwood Research podcast - by Buck Shlegeris — - Funding history details
    claimContext: '| **Focus Area** | AI systems acting against developer interests | Primary research on <EntityLink id="ai-control">AI Control</EntityLink> and alignment faking[^1] | | **Funding** | \$25M+ from Coefficient Giving | \$9.4M (2021), \$10.7M (2022), \$5.3M (2023)[^2] | | **Team Size** | 10 staff (2021),'
    fetchedAt: 2026-02-22T02:12:32.420Z
    httpStatus: 200
    pageTitle: The inaugural Redwood Research podcast - by Buck Shlegeris
    contentSnippet: "The inaugural Redwood Research podcast - by Buck Shlegeris Redwood Research blog Subscribe Sign in Redwood Research Podcast The inaugural Redwood Research podcast 26 13 2 1× 0:00 Current time: 0:00 / Total time: -3:52:01 -3:52:01 Audio playback is not supported on your browser. Please upgrade. The inaugural Redwood Research podcast With Buck Shlegeris and Ryan Greenblatt Buck Shlegeris Jan 04, 2026 26 13 2 Share Transcript After five months of Buck being slow at pushing forward editing this, we’"
    contentLength: 748036
    status: verified
    note: null
  - footnote: 3
    url: https://forum.effectivealtruism.org/posts/xDDggeXYgenAGSTyq/we-re-redwood-research-we-do-applied-alignment-research-ama
    linkText: We're Redwood Research, we do applied alignment research, AMA - EA Forum — - October 2021 team size
    claimContext: "| **Funding** | \\$25M+ from Coefficient Giving | \\$9.4M (2021), \\$10.7M (2022), \\$5.3M (2023)[^2] | | **Team Size** | 10 staff (2021), 6-15 research staff (2023 estimate) | Early team of 10 expanded to research organization[^3][^4] | | **Key Concern** | Research output relative to funding | 2023 cri"
    fetchedAt: 2026-02-22T02:12:31.654Z
    httpStatus: 200
    pageTitle: We&#x27;re Redwood Research, we do applied alignment research, AMA — EA Forum
    contentSnippet: We&#x27;re Redwood Research, we do applied alignment research, AMA — EA Forum This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. We&#x27;re Redwood Research, we do applied alignment research, AMA by Buck Oct 5 2021 2 min read 49 107 Ask Me Anything Redwood Research Frontpage Redwood Research is a longtermist organization working on AI alignment based in Berkeley, California. We&#x27;re going to do an AMA this week; we&#x
    contentLength: 855172
    status: verified
    note: null
  - footnote: 4
    url: https://forum.effectivealtruism.org/posts/DaRvpDHHdaoad9Tfu/critiques-of-prominent-ai-safety-labs-redwood-research
    linkText: "Critiques of prominent AI safety labs: Redwood Research - EA Forum — - 2023 research staff estimate"
    claimContext: "| **Funding** | \\$25M+ from Coefficient Giving | \\$9.4M (2021), \\$10.7M (2022), \\$5.3M (2023)[^2] | | **Team Size** | 10 staff (2021), 6-15 research staff (2023 estimate) | Early team of 10 expanded to research organization[^3][^4] | | **Key Concern** | Research output relative to funding | 2023 cri"
    fetchedAt: 2026-02-22T02:12:31.690Z
    httpStatus: 200
    pageTitle: "Critiques of prominent AI safety labs: Redwood Research — EA Forum"
    contentSnippet: "Critiques of prominent AI safety labs: Redwood Research — EA Forum This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. Hide table of contents Critiques of Prominent AI Safety Labs Critiques of prominent AI safety labs: Redwood Research by Omega Mar 31 2023 24 min read 90 339 AI safety Building effective altruism Existential risk Redwood Research Diversity and inclusion Criticism of effective altruist organizations Critici"
    contentLength: 1500588
    status: verified
    note: null
  - footnote: 5
    url: https://forum.effectivealtruism.org/posts/DaRvpDHHdaoad9Tfu/critiques-of-prominent-ai-safety-labs-redwood-research
    linkText: "Critiques of prominent AI safety labs: Redwood Research - EA Forum — - Research output criticism"
    claimContext: "| **Team Size** | 10 staff (2021), 6-15 research staff (2023 estimate) | Early team of 10 expanded to research organization[^3][^4] | | **Key Concern** | Research output relative to funding | 2023 critics cited limited publications; subsequent ICML, NeurIPS work addressed this[^5] |"
    fetchedAt: 2026-02-22T02:12:31.884Z
    httpStatus: 200
    pageTitle: "Critiques of prominent AI safety labs: Redwood Research — EA Forum"
    contentSnippet: "Critiques of prominent AI safety labs: Redwood Research — EA Forum This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. Hide table of contents Critiques of Prominent AI Safety Labs Critiques of prominent AI safety labs: Redwood Research by Omega Mar 31 2023 24 min read 90 339 AI safety Building effective altruism Existential risk Redwood Research Diversity and inclusion Criticism of effective altruist organizations Critici"
    contentLength: 1500588
    status: verified
    note: null
  - footnote: 6
    url: https://projects.propublica.org/nonprofits/organizations/871702255
    linkText: Redwood Research Group Inc - Nonprofit Explorer - ProPublica — - Tax status and location
    claimContext: Redwood Research is a 501(c)(3) nonprofit AI safety and security research organization founded in 2021 and based in Berkeley, California.[^1][^6] The organization emerged from a prior project that founders decided to discontinue in mid-2021, pivoting to focus specifically on risks arising when power
    fetchedAt: 2026-02-22T02:12:33.686Z
    httpStatus: 200
    pageTitle: Redwood Research Group Inc - Nonprofit Explorer - ProPublica
    contentSnippet: "Redwood Research Group Inc - Nonprofit Explorer - ProPublica Skip to content Menu Menu ProPublica Donate Close Close ProPublica Donate Search ProPublica: Search Search Search Show search box Select the type of search Nonprofits People Filing Text Search for a nonprofit Search Search Redwood Research Group Inc Redwood Research Berkeley, CA Tax-exempt since Sept. 2021 EIN: 87-1702255 Receive an email when new data is available for this organization. Organization summary Type of Nonprofit Designate"
    contentLength: 137675
    status: verified
    note: null
  - footnote: 7
    url: https://blog.redwoodresearch.org/p/the-inaugural-redwood-research-podcast
    linkText: The inaugural Redwood Research podcast - by Buck Shlegeris — - Founding from prior project
    claimContext: Redwood Research is a 501(c)(3) nonprofit AI safety and security research organization founded in 2021 and based in Berkeley, California.[^1][^6] The organization emerged from a prior project that founders decided to discontinue in mid-2021, pivoting to focus specifically on risks arising when power
    fetchedAt: 2026-02-22T02:12:33.523Z
    httpStatus: 200
    pageTitle: The inaugural Redwood Research podcast - by Buck Shlegeris
    contentSnippet: "The inaugural Redwood Research podcast - by Buck Shlegeris Redwood Research blog Subscribe Sign in Redwood Research Podcast The inaugural Redwood Research podcast 26 13 2 1× 0:00 Current time: 0:00 / Total time: -3:52:01 -3:52:01 Audio playback is not supported on your browser. Please upgrade. The inaugural Redwood Research podcast With Buck Shlegeris and Ryan Greenblatt Buck Shlegeris Jan 04, 2026 26 13 2 Share Transcript After five months of Buck being slow at pushing forward editing this, we’"
    contentLength: 748036
    status: verified
    note: null
  - footnote: 8
    url: https://www.redwoodresearch.org/
    linkText: Redwood Research - Official Website — - Partnerships
    claimContext: The organization has established itself as a pioneer in the <EntityLink id="ai-control">AI Control</EntityLink> research field, which examines how to maintain safety guarantees even when AI systems may be attempting to subvert control measures. This work was recognized with an oral presentation at I
    fetchedAt: 2026-02-22T02:12:33.504Z
    httpStatus: 200
    pageTitle: Redwood Research
    contentSnippet: Redwood Research Home Research Team Careers Blog Pioneering threat assessment and mitigation for AI systems Our Research Redwood Research is a nonprofit AI safety and security research organization In the coming years or decades, AI systems will very plausibly match or exceed human capabilities across most intellectual tasks, fundamentally transforming society. Our research specifically addresses the risks that could arise if these powerful AI systems purposefully act against the interests of th
    contentLength: 36365
    status: verified
    note: null
  - footnote: 9
    url: https://forum.effectivealtruism.org/posts/xDDggeXYgenAGSTyq/we-re-redwood-research-we-do-applied-alignment-research-ama
    linkText: We're Redwood Research, we do applied alignment research, AMA - EA Forum — - Prosaic alignment approach and superhuman systems focus
    claimContext: The organization takes a "prosaic alignment" approach, explicitly aiming to align superhuman systems rather than just current models. In their 2021 AMA, they stated they are "interested in thinking about our research from an explicit perspective of wanting to align superhuman systems" and are "espec
    fetchedAt: 2026-02-22T02:12:33.596Z
    httpStatus: 200
    pageTitle: We&#x27;re Redwood Research, we do applied alignment research, AMA — EA Forum
    contentSnippet: We&#x27;re Redwood Research, we do applied alignment research, AMA — EA Forum This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. We&#x27;re Redwood Research, we do applied alignment research, AMA by Buck Oct 5 2021 2 min read 49 107 Ask Me Anything Redwood Research Frontpage Redwood Research is a longtermist organization working on AI alignment based in Berkeley, California. We&#x27;re going to do an AMA this week; we&#x
    contentLength: 855174
    status: verified
    note: null
  - footnote: 10
    url: https://forum.effectivealtruism.org/posts/xDDggeXYgenAGSTyq/we-re-redwood-research-we-do-applied-alignment-research-ama
    linkText: We're Redwood Research, we do applied alignment research, AMA - EA Forum — - Initial leadership
    claimContext: Redwood Research received tax-exempt status in September 2021 and quickly assembled a team of ten staff members.[^6][^3] The initial leadership consisted of Nate Thomas as CEO, Buck Shlegeris as CTO, and Bill Zito as COO, with <EntityLink id="paul-christiano">Paul Christiano</EntityLink> and <Entity
    fetchedAt: 2026-02-22T02:12:33.544Z
    httpStatus: 200
    pageTitle: We&#x27;re Redwood Research, we do applied alignment research, AMA — EA Forum
    contentSnippet: We&#x27;re Redwood Research, we do applied alignment research, AMA — EA Forum This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. We&#x27;re Redwood Research, we do applied alignment research, AMA by Buck Oct 5 2021 2 min read 49 107 Ask Me Anything Redwood Research Frontpage Redwood Research is a longtermist organization working on AI alignment based in Berkeley, California. We&#x27;re going to do an AMA this week; we&#x
    contentLength: 855174
    status: verified
    note: null
  - footnote: 11
    url: https://forum.effectivealtruism.org/posts/xDDggeXYgenAGSTyq/we-re-redwood-research-we-do-applied-alignment-research-ama
    linkText: We're Redwood Research, we do applied alignment research, AMA - EA Forum — - Board members
    claimContext: Redwood Research received tax-exempt status in September 2021 and quickly assembled a team of ten staff members.[^6][^3] The initial leadership consisted of Nate Thomas as CEO, Buck Shlegeris as CTO, and Bill Zito as COO, with <EntityLink id="paul-christiano">Paul Christiano</EntityLink> and <Entity
    fetchedAt: 2026-02-22T02:12:35.052Z
    httpStatus: 200
    pageTitle: We&#x27;re Redwood Research, we do applied alignment research, AMA — EA Forum
    contentSnippet: We&#x27;re Redwood Research, we do applied alignment research, AMA — EA Forum This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. We&#x27;re Redwood Research, we do applied alignment research, AMA by Buck Oct 5 2021 2 min read 49 107 Ask Me Anything Redwood Research Frontpage Redwood Research is a longtermist organization working on AI alignment based in Berkeley, California. We&#x27;re going to do an AMA this week; we&#x
    contentLength: 855174
    status: verified
    note: null
  - footnote: 12
    url: https://blog.redwoodresearch.org/p/the-inaugural-redwood-research-podcast
    linkText: The inaugural Redwood Research podcast - by Buck Shlegeris — - Survival and Flourishing Fund
    claimContext: (footnote definition only, no inline reference found)
    fetchedAt: 2026-02-22T02:12:34.779Z
    httpStatus: 200
    pageTitle: The inaugural Redwood Research podcast - by Buck Shlegeris
    contentSnippet: "The inaugural Redwood Research podcast - by Buck Shlegeris Redwood Research blog Subscribe Sign in Redwood Research Podcast The inaugural Redwood Research podcast 26 13 2 1× 0:00 Current time: 0:00 / Total time: -3:52:01 -3:52:01 Audio playback is not supported on your browser. Please upgrade. The inaugural Redwood Research podcast With Buck Shlegeris and Ryan Greenblatt Buck Shlegeris Jan 04, 2026 26 13 2 Share Transcript After five months of Buck being slow at pushing forward editing this, we’"
    contentLength: 748036
    status: verified
    note: null
  - footnote: 13
    url: https://blog.redwoodresearch.org/p/the-inaugural-redwood-research-podcast
    linkText: The inaugural Redwood Research podcast - by Buck Shlegeris — - MLAB launch
    claimContext: (footnote definition only, no inline reference found)
    fetchedAt: 2026-02-22T02:12:35.181Z
    httpStatus: 200
    pageTitle: The inaugural Redwood Research podcast - by Buck Shlegeris
    contentSnippet: "The inaugural Redwood Research podcast - by Buck Shlegeris Redwood Research blog Subscribe Sign in Redwood Research Podcast The inaugural Redwood Research podcast 26 13 2 1× 0:00 Current time: 0:00 / Total time: -3:52:01 -3:52:01 Audio playback is not supported on your browser. Please upgrade. The inaugural Redwood Research podcast With Buck Shlegeris and Ryan Greenblatt Buck Shlegeris Jan 04, 2026 26 13 2 Share Transcript After five months of Buck being slow at pushing forward editing this, we’"
    contentLength: 748036
    status: verified
    note: null
  - footnote: 14
    url: https://github.com/redwoodresearch/mlab
    linkText: GitHub - redwoodresearch/mlab — - MLAB program structure
    claimContext: (footnote definition only, no inline reference found)
    fetchedAt: 2026-02-22T02:12:35.426Z
    httpStatus: 200
    pageTitle: "GitHub - redwoodresearch/mlab: Machine Learning for Alignment Bootcamp"
    contentSnippet: "GitHub - redwoodresearch/mlab: Machine Learning for Alignment Bootcamp Skip to content You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert {{ message }} redwoodresearch / mlab Public Notifications You must be signed in to change notification settings Fork 41 Star 82 Machine Learning for Alignment Bootcamp 82 s"
    contentLength: 330981
    status: verified
    note: null
  - footnote: 15
    url: https://github.com/redwoodresearch/mlab
    linkText: GitHub - redwoodresearch/mlab — - MLAB curriculum
    claimContext: (footnote definition only, no inline reference found)
    fetchedAt: 2026-02-22T02:12:35.155Z
    httpStatus: 200
    pageTitle: "GitHub - redwoodresearch/mlab: Machine Learning for Alignment Bootcamp"
    contentSnippet: "GitHub - redwoodresearch/mlab: Machine Learning for Alignment Bootcamp Skip to content You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert {{ message }} redwoodresearch / mlab Public Notifications You must be signed in to change notification settings Fork 41 Star 82 Machine Learning for Alignment Bootcamp 82 s"
    contentLength: 330980
    status: verified
    note: null
  - footnote: 16
    url: https://blog.redwoodresearch.org/p/the-inaugural-redwood-research-podcast
    linkText: The inaugural Redwood Research podcast - by Buck Shlegeris — - Adversarial training acknowledgment
    claimContext: The organization's early research included an <EntityLink id="adversarial-training">adversarial training</EntityLink> project focused on injury prevention. Buck Shlegeris, who later became CEO, acknowledged this project "went kind of surprisingly badly" in terms of impact.[^16] This experience influ
    fetchedAt: 2026-02-22T02:12:36.522Z
    httpStatus: 200
    pageTitle: The inaugural Redwood Research podcast - by Buck Shlegeris
    contentSnippet: "The inaugural Redwood Research podcast - by Buck Shlegeris Redwood Research blog Subscribe Sign in Redwood Research Podcast The inaugural Redwood Research podcast 26 13 2 1× 0:00 Current time: 0:00 / Total time: -3:52:01 -3:52:01 Audio playback is not supported on your browser. Please upgrade. The inaugural Redwood Research podcast With Buck Shlegeris and Ryan Greenblatt Buck Shlegeris Jan 04, 2026 26 13 2 Share Transcript After five months of Buck being slow at pushing forward editing this, we’"
    contentLength: 748036
    status: verified
    note: null
  - footnote: 17
    url: https://blog.redwoodresearch.org/p/the-inaugural-redwood-research-podcast
    linkText: The inaugural Redwood Research podcast - by Buck Shlegeris — - Strategic reflection
    claimContext: The organization's early research included an <EntityLink id="adversarial-training">adversarial training</EntityLink> project focused on injury prevention. Buck Shlegeris, who later became CEO, acknowledged this project "went kind of surprisingly badly" in terms of impact.[^16] This experience influ
    fetchedAt: 2026-02-22T02:12:36.542Z
    httpStatus: 200
    pageTitle: The inaugural Redwood Research podcast - by Buck Shlegeris
    contentSnippet: "The inaugural Redwood Research podcast - by Buck Shlegeris Redwood Research blog Subscribe Sign in Redwood Research Podcast The inaugural Redwood Research podcast 26 13 2 1× 0:00 Current time: 0:00 / Total time: -3:52:01 -3:52:01 Audio playback is not supported on your browser. Please upgrade. The inaugural Redwood Research podcast With Buck Shlegeris and Ryan Greenblatt Buck Shlegeris Jan 04, 2026 26 13 2 Share Transcript After five months of Buck being slow at pushing forward editing this, we’"
    contentLength: 748036
    status: verified
    note: null
  - footnote: 18
    url: https://github.com/redwoodresearch/mlab
    linkText: GitHub - redwoodresearch/mlab — - REMIX program
    claimContext: (footnote definition only, no inline reference found)
    fetchedAt: 2026-02-22T02:12:36.498Z
    httpStatus: 200
    pageTitle: "GitHub - redwoodresearch/mlab: Machine Learning for Alignment Bootcamp"
    contentSnippet: "GitHub - redwoodresearch/mlab: Machine Learning for Alignment Bootcamp Skip to content You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert {{ message }} redwoodresearch / mlab Public Notifications You must be signed in to change notification settings Fork 41 Star 82 Machine Learning for Alignment Bootcamp 82 s"
    contentLength: 330981
    status: verified
    note: null
  - footnote: 19
    url: https://projects.propublica.org/nonprofits/organizations/871702255
    linkText: Redwood Research Group Inc - Nonprofit Explorer - ProPublica — - Buck Shlegeris CEO role
    claimContext: By 2024, Buck Shlegeris had transitioned from CTO to CEO and Director, with Ryan Greenblatt serving as Chief Scientist.[^19][^20] This period marked Redwood's emergence as a leader in AI Control research and their landmark collaboration with Anthropic on alignment faking.
    fetchedAt: 2026-02-22T02:12:36.505Z
    httpStatus: 200
    pageTitle: Redwood Research Group Inc - Nonprofit Explorer - ProPublica
    contentSnippet: "Redwood Research Group Inc - Nonprofit Explorer - ProPublica Skip to content Menu Menu ProPublica Donate Close Close ProPublica Donate Search ProPublica: Search Search Search Show search box Select the type of search Nonprofits People Filing Text Search for a nonprofit Search Search Redwood Research Group Inc Redwood Research Berkeley, CA Tax-exempt since Sept. 2021 EIN: 87-1702255 Receive an email when new data is available for this organization. Organization summary Type of Nonprofit Designate"
    contentLength: 137675
    status: verified
    note: null
  - footnote: 20
    url: https://projects.propublica.org/nonprofits/organizations/871702255
    linkText: Redwood Research Group Inc - Nonprofit Explorer - ProPublica — - Ryan Greenblatt Chief Scientist
    claimContext: By 2024, Buck Shlegeris had transitioned from CTO to CEO and Director, with Ryan Greenblatt serving as Chief Scientist.[^19][^20] This period marked Redwood's emergence as a leader in AI Control research and their landmark collaboration with Anthropic on alignment faking.
    fetchedAt: 2026-02-22T02:12:36.618Z
    httpStatus: 200
    pageTitle: Redwood Research Group Inc - Nonprofit Explorer - ProPublica
    contentSnippet: "Redwood Research Group Inc - Nonprofit Explorer - ProPublica Skip to content Menu Menu ProPublica Donate Close Close ProPublica Donate Search ProPublica: Search Search Search Show search box Select the type of search Nonprofits People Filing Text Search for a nonprofit Search Search Redwood Research Group Inc Redwood Research Berkeley, CA Tax-exempt since Sept. 2021 EIN: 87-1702255 Receive an email when new data is available for this organization. Organization summary Type of Nonprofit Designate"
    contentLength: 137675
    status: verified
    note: null
  - footnote: 22
    url: https://www.redwoodresearch.org/
    linkText: Redwood Research - Official Website — - UK AISI collaboration
    claimContext: The organization worked with <EntityLink id="uk-aisi">UK AISI</EntityLink> to develop frameworks for constructing safety arguments despite intentional subversion.[^22][^23][^40]
    fetchedAt: 2026-02-22T02:12:38.182Z
    httpStatus: 200
    pageTitle: Redwood Research
    contentSnippet: Redwood Research Home Research Team Careers Blog Pioneering threat assessment and mitigation for AI systems Our Research Redwood Research is a nonprofit AI safety and security research organization In the coming years or decades, AI systems will very plausibly match or exceed human capabilities across most intellectual tasks, fundamentally transforming society. Our research specifically addresses the risks that could arise if these powerful AI systems purposefully act against the interests of th
    contentLength: 36365
    status: verified
    note: null
  - footnote: 23
    url: https://www.redwoodresearch.org/
    linkText: Redwood Research - Official Website — - Safety case publication
    claimContext: The organization worked with <EntityLink id="uk-aisi">UK AISI</EntityLink> to develop frameworks for constructing safety arguments despite intentional subversion.[^22][^23][^40]
    fetchedAt: 2026-02-22T02:12:38.439Z
    httpStatus: 200
    pageTitle: Redwood Research
    contentSnippet: Redwood Research Home Research Team Careers Blog Pioneering threat assessment and mitigation for AI systems Our Research Redwood Research is a nonprofit AI safety and security research organization In the coming years or decades, AI systems will very plausibly match or exceed human capabilities across most intellectual tasks, fundamentally transforming society. Our research specifically addresses the risks that could arise if these powerful AI systems purposefully act against the interests of th
    contentLength: 36365
    status: verified
    note: null
  - footnote: 24
    url: https://www.redwoodresearch.org/
    linkText: Redwood Research - Official Website — - Alignment faking demonstration
    claimContext: In collaboration with <EntityLink id="anthropic">Anthropic</EntityLink>, Redwood demonstrated that large language models can strategically hide misaligned intentions during training.[^24] Claude 3 Opus was used as the primary test model.[^25][^26]
    fetchedAt: 2026-02-22T02:12:38.436Z
    httpStatus: 200
    pageTitle: Redwood Research
    contentSnippet: Redwood Research Home Research Team Careers Blog Pioneering threat assessment and mitigation for AI systems Our Research Redwood Research is a nonprofit AI safety and security research organization In the coming years or decades, AI systems will very plausibly match or exceed human capabilities across most intellectual tasks, fundamentally transforming society. Our research specifically addresses the risks that could arise if these powerful AI systems purposefully act against the interests of th
    contentLength: 36365
    status: verified
    note: null
  - footnote: 25
    url: https://www.anthropic.com/research/alignment-faking
    linkText: Alignment faking in large language models - Anthropic — - Ryan Greenblatt leadership
    claimContext: In collaboration with <EntityLink id="anthropic">Anthropic</EntityLink>, Redwood demonstrated that large language models can strategically hide misaligned intentions during training.[^24] Claude 3 Opus was used as the primary test model.[^25][^26]
    fetchedAt: 2026-02-22T02:12:38.303Z
    httpStatus: 200
    pageTitle: Alignment faking in large language models \ Anthropic
    contentSnippet: "Alignment Alignment faking in large language models Dec 18, 2024 Read the paper Most of us have encountered situations where someone appears to share our views or values, but is in fact only pretending to do so—a behavior that we might call “alignment faking”. Alignment faking occurs in literature: Consider the character of Iago in Shakespeare’s Othello , who acts as if he’s the eponymous character’s loyal friend while subverting and undermining him. It occurs in real life: Consider a politician"
    contentLength: 139945
    status: verified
    note: null
  - footnote: 26
    url: https://www.anthropic.com/research/alignment-faking
    linkText: Alignment faking in large language models - Anthropic — - Claude 3 Opus test model
    claimContext: In collaboration with <EntityLink id="anthropic">Anthropic</EntityLink>, Redwood demonstrated that large language models can strategically hide misaligned intentions during training.[^24] Claude 3 Opus was used as the primary test model.[^25][^26]
    fetchedAt: 2026-02-22T02:12:37.870Z
    httpStatus: 200
    pageTitle: Alignment faking in large language models \ Anthropic
    contentSnippet: "Alignment Alignment faking in large language models Dec 18, 2024 Read the paper Most of us have encountered situations where someone appears to share our views or values, but is in fact only pretending to do so—a behavior that we might call “alignment faking”. Alignment faking occurs in literature: Consider the character of Iago in Shakespeare’s Othello , who acts as if he’s the eponymous character’s loyal friend while subverting and undermining him. It occurs in real life: Consider a politician"
    contentLength: 139945
    status: verified
    note: null
  - footnote: 27
    url: https://www.anthropic.com/research/alignment-faking
    linkText: Alignment faking in large language models - Anthropic — - 12% monitored condition result
    claimContext: "|-----------|----------------------|----------| | Monitored (suggested training) | 12% | Harmful content with scratchpad evidence of deliberate faking[^27] | | Actual training applied | 78% | Outwardly compliant but increased faking reasoning[^28] |"
    fetchedAt: 2026-02-22T02:12:40.173Z
    httpStatus: 200
    pageTitle: Alignment faking in large language models \ Anthropic
    contentSnippet: "Alignment Alignment faking in large language models Dec 18, 2024 Read the paper Most of us have encountered situations where someone appears to share our views or values, but is in fact only pretending to do so—a behavior that we might call “alignment faking”. Alignment faking occurs in literature: Consider the character of Iago in Shakespeare’s Othello , who acts as if he’s the eponymous character’s loyal friend while subverting and undermining him. It occurs in real life: Consider a politician"
    contentLength: 139945
    status: verified
    note: null
  - footnote: 28
    url: https://www.anthropic.com/research/alignment-faking
    linkText: Alignment faking in large language models - Anthropic — - 78% training condition result
    claimContext: "| Monitored (suggested training) | 12% | Harmful content with scratchpad evidence of deliberate faking[^27] | | Actual training applied | 78% | Outwardly compliant but increased faking reasoning[^28] |"
    fetchedAt: 2026-02-22T02:12:40.140Z
    httpStatus: 200
    pageTitle: Alignment faking in large language models \ Anthropic
    contentSnippet: "Alignment Alignment faking in large language models Dec 18, 2024 Read the paper Most of us have encountered situations where someone appears to share our views or values, but is in fact only pretending to do so—a behavior that we might call “alignment faking”. Alignment faking occurs in literature: Consider the character of Iago in Shakespeare’s Othello , who acts as if he’s the eponymous character’s loyal friend while subverting and undermining him. It occurs in real life: Consider a politician"
    contentLength: 139945
    status: verified
    note: null
  - footnote: 29
    url: https://www.redwoodresearch.org/
    linkText: Redwood Research - Official Website — - "Strongest concrete evidence" quote
    claimContext: Redwood describes this as "the strongest concrete evidence that LLMs might naturally fake alignment."[^29] This has significant implications for <EntityLink id="deceptive-alignment">deceptive alignment</EntityLink> concerns.
    fetchedAt: 2026-02-22T02:12:39.528Z
    httpStatus: 200
    pageTitle: Redwood Research
    contentSnippet: Redwood Research Home Research Team Careers Blog Pioneering threat assessment and mitigation for AI systems Our Research Redwood Research is a nonprofit AI safety and security research organization In the coming years or decades, AI systems will very plausibly match or exceed human capabilities across most intellectual tasks, fundamentally transforming society. Our research specifically addresses the risks that could arise if these powerful AI systems purposefully act against the interests of th
    contentLength: 36365
    status: verified
    note: null
  - footnote: 30
    url: https://projects.propublica.org/nonprofits/organizations/871702255
    linkText: Redwood Research Group Inc - Nonprofit Explorer - ProPublica — - Financial data
    claimContext: (footnote definition only, no inline reference found)
    fetchedAt: 2026-02-22T02:12:39.507Z
    httpStatus: 200
    pageTitle: Redwood Research Group Inc - Nonprofit Explorer - ProPublica
    contentSnippet: "Redwood Research Group Inc - Nonprofit Explorer - ProPublica Skip to content Menu Menu ProPublica Donate Close Close ProPublica Donate Search ProPublica: Search Search Search Show search box Select the type of search Nonprofits People Filing Text Search for a nonprofit Search Search Redwood Research Group Inc Redwood Research Berkeley, CA Tax-exempt since Sept. 2021 EIN: 87-1702255 Receive an email when new data is available for this organization. Organization summary Type of Nonprofit Designate"
    contentLength: 137675
    status: verified
    note: null
  - footnote: 31
    url: https://forum.effectivealtruism.org/posts/DaRvpDHHdaoad9Tfu/critiques-of-prominent-ai-safety-labs-redwood-research
    linkText: "Critiques of prominent AI safety labs: Redwood Research - EA Forum — - CTO experience criticism"
    claimContext: An anonymous 2023 critique published on the EA Forum raised concerns about the organization's leadership lacking senior ML research experience. Critics noted that the CTO (Buck Shlegeris) had 3 years of software engineering experience with limited ML background, and that the most experienced ML rese
    fetchedAt: 2026-02-22T02:12:39.787Z
    httpStatus: 200
    pageTitle: "Critiques of prominent AI safety labs: Redwood Research — EA Forum"
    contentSnippet: "Critiques of prominent AI safety labs: Redwood Research — EA Forum This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. Hide table of contents Critiques of Prominent AI Safety Labs Critiques of prominent AI safety labs: Redwood Research by Omega Mar 31 2023 24 min read 90 339 AI safety Building effective altruism Existential risk Redwood Research Diversity and inclusion Criticism of effective altruist organizations Critici"
    contentLength: 1500587
    status: verified
    note: null
  - footnote: 32
    url: https://forum.effectivealtruism.org/posts/DaRvpDHHdaoad9Tfu/critiques-of-prominent-ai-safety-labs-redwood-research
    linkText: "Critiques of prominent AI safety labs: Redwood Research - EA Forum — - ML researcher experience"
    claimContext: An anonymous 2023 critique published on the EA Forum raised concerns about the organization's leadership lacking senior ML research experience. Critics noted that the CTO (Buck Shlegeris) had 3 years of software engineering experience with limited ML background, and that the most experienced ML rese
    fetchedAt: 2026-02-22T02:12:41.262Z
    httpStatus: 200
    pageTitle: "Critiques of prominent AI safety labs: Redwood Research — EA Forum"
    contentSnippet: "Critiques of prominent AI safety labs: Redwood Research — EA Forum This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. Hide table of contents Critiques of Prominent AI Safety Labs Critiques of prominent AI safety labs: Redwood Research by Omega Mar 31 2023 24 min read 90 339 AI safety Building effective altruism Existential risk Redwood Research Diversity and inclusion Criticism of effective altruist organizations Critici"
    contentLength: 1500589
    status: verified
    note: null
  - footnote: 33
    url: https://forum.effectivealtruism.org/posts/DaRvpDHHdaoad9Tfu/critiques-of-prominent-ai-safety-labs-redwood-research
    linkText: "Critiques of prominent AI safety labs: Redwood Research - EA Forum — - Jacob Steinhardt defense"
    claimContext: An anonymous 2023 critique published on the EA Forum raised concerns about the organization's leadership lacking senior ML research experience. Critics noted that the CTO (Buck Shlegeris) had 3 years of software engineering experience with limited ML background, and that the most experienced ML rese
    fetchedAt: 2026-02-22T02:12:41.318Z
    httpStatus: 200
    pageTitle: "Critiques of prominent AI safety labs: Redwood Research — EA Forum"
    contentSnippet: "Critiques of prominent AI safety labs: Redwood Research — EA Forum This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. Hide table of contents Critiques of Prominent AI Safety Labs Critiques of prominent AI safety labs: Redwood Research by Omega Mar 31 2023 24 min read 90 339 AI safety Building effective altruism Existential risk Redwood Research Diversity and inclusion Criticism of effective altruist organizations Critici"
    contentLength: 1500589
    status: verified
    note: null
  - footnote: 34
    url: https://forum.effectivealtruism.org/posts/DaRvpDHHdaoad9Tfu/critiques-of-prominent-ai-safety-labs-redwood-research
    linkText: "Critiques of prominent AI safety labs: Redwood Research - EA Forum — - Conference publication count"
    claimContext: The 2023 critique argued that despite \$21 million in funding and an estimated 6-15 research staff, Redwood's output was "underwhelming given the amount of money and staff time invested."[^5] By 2023, only two papers had been accepted at major conferences (NeurIPS 2022 and ICLR 2023), with much work
    fetchedAt: 2026-02-22T02:12:41.348Z
    httpStatus: 200
    pageTitle: "Critiques of prominent AI safety labs: Redwood Research — EA Forum"
    contentSnippet: "Critiques of prominent AI safety labs: Redwood Research — EA Forum This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. Hide table of contents Critiques of Prominent AI Safety Labs Critiques of prominent AI safety labs: Redwood Research by Omega Mar 31 2023 24 min read 90 339 AI safety Building effective altruism Existential risk Redwood Research Diversity and inclusion Criticism of effective altruist organizations Critici"
    contentLength: 1500589
    status: verified
    note: null
  - footnote: 35
    url: https://forum.effectivealtruism.org/posts/DaRvpDHHdaoad9Tfu/critiques-of-prominent-ai-safety-labs-redwood-research
    linkText: "Critiques of prominent AI safety labs: Redwood Research - EA Forum — - Work trial concerns"
    claimContext: The anonymous critique also raised concerns about workplace culture, including extended work trials lasting up to 4 months that created stress and job insecurity.[^35] The critique mentioned high burnout rates and concerns about diversity and workplace atmosphere, though these claims came from anony
    fetchedAt: 2026-02-22T02:12:41.413Z
    httpStatus: 200
    pageTitle: "Critiques of prominent AI safety labs: Redwood Research — EA Forum"
    contentSnippet: "Critiques of prominent AI safety labs: Redwood Research — EA Forum This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. Hide table of contents Critiques of Prominent AI Safety Labs Critiques of prominent AI safety labs: Redwood Research by Omega Mar 31 2023 24 min read 90 339 AI safety Building effective altruism Existential risk Redwood Research Diversity and inclusion Criticism of effective altruist organizations Critici"
    contentLength: 1500589
    status: verified
    note: null
  - footnote: 36
    url: https://arxiv.org/pdf/2312.06942
    linkText: "AI Control: Improving Safety Despite Intentional Subversion - arXiv — - ICML 2024 oral presentation"
    claimContext: The organization has established itself as a pioneer in the <EntityLink id="ai-control">AI Control</EntityLink> research field, which examines how to maintain safety guarantees even when AI systems may be attempting to subvert control measures. This work was recognized with an oral presentation at I
    fetchedAt: 2026-02-22T02:12:41.276Z
    httpStatus: 200
    pageTitle: (PDF document)
    contentSnippet: null
    contentLength: 1102474
    status: verified
    note: null
  - footnote: 37
    url: https://forum.effectivealtruism.org/posts/MGbdhjgd2v6cg3vjv/apply-to-the-redwood-research-mechanistic-interpretability
    linkText: Apply to the Redwood Research Mechanistic Interpretability Experiment (REMIX) - EA Forum — - REMIX program details
    claimContext: (footnote definition only, no inline reference found)
    fetchedAt: 2026-02-22T02:12:42.469Z
    httpStatus: 200
    pageTitle: Apply to the Redwood Research Mechanistic Interpretability Experiment (REMIX), a research program in Berkeley — EA Forum
    contentSnippet: Apply to the Redwood Research Mechanistic Interpretability Experiment (REMIX), a research program in Berkeley — EA Forum This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. Hide table of contents Apply to the Redwood Research Mechanistic Interpretability Experiment (REMIX), a research program in Berkeley by Max Nadeau , Xander123 , Buck , Nate Thomas Oct 27 2022 15 min read 5 97 AI safety Career choice Application announc
    contentLength: 319791
    status: verified
    note: null
  - footnote: 38
    url: https://www.lesswrong.com/posts/JvZhhzycHu2Yd57RN/causal-scrubbing-a-method-for-rigorously-testing
    linkText: "Causal Scrubbing: a method for rigorously testing interpretability hypotheses - LessWrong — - Causal scrubbing methodology"
    claimContext: Redwood developed causal scrubbing, a principled approach for evaluating the quality of mechanistic interpretations through behavior-preserving resampling ablations.[^38] This methodology provides a rigorous way to test interpretability hypotheses by checking whether proposed computational graphs ac
    fetchedAt: 2026-02-22T02:12:43.451Z
    httpStatus: 200
    pageTitle: "Causal Scrubbing: a method for rigorously testing interpretability hypotheses [Redwood Research] — LessWrong"
    contentSnippet: "x This website requires javascript to properly function. Consider activating javascript to get access to all site functionality. Causal Scrubbing: a method for rigorously testing interpretability hypotheses [Redwood Research] — LessWrong [Redwood Research] Causal Scrubbing Redwood Research Causal Scrubbing Interpretability (ML & AI) AI Frontpage 206 Causal Scrubbing: a method for rigorously testing interpretability hypotheses [Redwood Research] by LawrenceC , Adrià Garriga-alonso , Nicholas Gold"
    contentLength: 1599818
    status: verified
    note: null
  - footnote: 39
    url: https://www.alignmentforum.org/posts/kjudfaQazMmC74SbF/causal-scrubbing-results-on-a-paren-balance-checker
    linkText: "Causal scrubbing: results on a paren balance checker - Alignment Forum — - Causal scrubbing applications"
    claimContext: Redwood developed causal scrubbing, a principled approach for evaluating the quality of mechanistic interpretations through behavior-preserving resampling ablations.[^38] This methodology provides a rigorous way to test interpretability hypotheses by checking whether proposed computational graphs ac
    fetchedAt: 2026-02-22T02:12:49.209Z
    httpStatus: 429
    pageTitle: null
    contentSnippet: null
    contentLength: 0
    status: broken
    note: HTTP 429
  - footnote: 40
    url: https://arxiv.org/abs/2501.17315
    linkText: A Sketch of an AI Control Safety Case - arXiv — - January 2025 safety case framework
    claimContext: The organization worked with <EntityLink id="uk-aisi">UK AISI</EntityLink> to develop frameworks for constructing safety arguments despite intentional subversion.[^22][^23][^40]
    fetchedAt: 2026-02-22T02:12:42.454Z
    httpStatus: 200
    pageTitle: "[2501.17315] A sketch of an AI control safety case"
    contentSnippet: "[2501.17315] A sketch of an AI control safety case --> Computer Science > Artificial Intelligence arXiv:2501.17315 (cs) [Submitted on 28 Jan 2025] Title: A sketch of an AI control safety case Authors: Tomek Korbak , Joshua Clymer , Benjamin Hilton , Buck Shlegeris , Geoffrey Irving View a PDF of the paper titled A sketch of an AI control safety case, by Tomek Korbak and Joshua Clymer and Benjamin Hilton and Buck Shlegeris and Geoffrey Irving View PDF HTML (experimental) Abstract: As LLM agents g"
    contentLength: 45678
    status: verified
    note: null
  - footnote: 41
    url: https://arxiv.org/abs/2405.19550
    linkText: Stress-Testing Capability Elicitation With Password-Locked Models - arXiv — - NeurIPS 2024 paper
    claimContext: (footnote definition only, no inline reference found)
    fetchedAt: 2026-02-22T02:12:42.484Z
    httpStatus: 200
    pageTitle: "[2405.19550] Stress-Testing Capability Elicitation With Password-Locked Models"
    contentSnippet: "[2405.19550] Stress-Testing Capability Elicitation With Password-Locked Models --> Computer Science > Machine Learning arXiv:2405.19550 (cs) [Submitted on 29 May 2024] Title: Stress-Testing Capability Elicitation With Password-Locked Models Authors: Ryan Greenblatt , Fabien Roger , Dmitrii Krasheninnikov , David Krueger View a PDF of the paper titled Stress-Testing Capability Elicitation With Password-Locked Models, by Ryan Greenblatt and 3 other authors View PDF HTML (experimental) Abstract: To"
    contentLength: 47693
    status: verified
    note: null
  - footnote: 42
    url: https://arxiv.org/abs/2411.17693
    linkText: Adaptive Deployment of Untrusted LLMs Reduces Distributed Threats - arXiv — - Late 2024 deployment paper
    claimContext: (footnote definition only, no inline reference found)
    fetchedAt: 2026-02-22T02:12:50.308Z
    httpStatus: 200
    pageTitle: "[2411.17693] Adaptive Deployment of Untrusted LLMs Reduces Distributed Threats"
    contentSnippet: "[2411.17693] Adaptive Deployment of Untrusted LLMs Reduces Distributed Threats --> Computer Science > Computation and Language arXiv:2411.17693 (cs) [Submitted on 26 Nov 2024] Title: Adaptive Deployment of Untrusted LLMs Reduces Distributed Threats Authors: Jiaxin Wen , Vivek Hebbar , Caleb Larson , Aryan Bhatt , Ansh Radhakrishnan , Mrinank Sharma , Henry Sleight , Shi Feng , He He , Ethan Perez , Buck Shlegeris , Akbir Khan View a PDF of the paper titled Adaptive Deployment of Untrusted LLMs R"
    contentLength: 47576
    status: verified
    note: null
  - footnote: 43
    url: https://arxiv.org/abs/2504.10374
    linkText: "Ctrl-Z: Controlling AI Agents via Resampling - arXiv — - April 2025 agent control paper"
    claimContext: (footnote definition only, no inline reference found)
    fetchedAt: 2026-02-22T02:12:50.312Z
    httpStatus: 200
    pageTitle: "[2504.10374] Ctrl-Z: Controlling AI Agents via Resampling"
    contentSnippet: "[2504.10374] Ctrl-Z: Controlling AI Agents via Resampling --> Computer Science > Machine Learning arXiv:2504.10374 (cs) [Submitted on 14 Apr 2025] Title: Ctrl-Z: Controlling AI Agents via Resampling Authors: Aryan Bhatt , Cody Rushing , Adam Kaufman , Tyler Tracy , Vasil Georgiev , David Matolcsi , Akbir Khan , Buck Shlegeris View a PDF of the paper titled Ctrl-Z: Controlling AI Agents via Resampling, by Aryan Bhatt and 7 other authors View PDF Abstract: Control evaluations measure whether monit"
    contentLength: 47126
    status: verified
    note: null
  - footnote: 44
    url: https://arxiv.org/abs/2512.15688
    linkText: "BashArena: A Control Setting for Highly Privileged AI Agents - arXiv — - July 2025 benchmark"
    claimContext: (footnote definition only, no inline reference found)
    fetchedAt: 2026-02-22T02:12:50.247Z
    httpStatus: 200
    pageTitle: "[2512.15688] BashArena: A Control Setting for Highly Privileged AI Agents"
    contentSnippet: "[2512.15688] BashArena: A Control Setting for Highly Privileged AI Agents --> Computer Science > Cryptography and Security arXiv:2512.15688 (cs) [Submitted on 17 Dec 2025] Title: BashArena: A Control Setting for Highly Privileged AI Agents Authors: Adam Kaufman , James Lucassen , Tyler Tracy , Cody Rushing , Aryan Bhatt View a PDF of the paper titled BashArena: A Control Setting for Highly Privileged AI Agents, by Adam Kaufman and 4 other authors View PDF HTML (experimental) Abstract: Future AI "
    contentLength: 45860
    status: verified
    note: null
  - footnote: 45
    url: https://blog.redwoodresearch.org/sitemap/2025
    linkText: Redwood Research blog - 2025 sitemap — - Active blog publications
    claimContext: (footnote definition only, no inline reference found)
    fetchedAt: 2026-02-22T02:12:50.697Z
    httpStatus: 200
    pageTitle: Sitemap - 2025 - Redwood Research blog
    contentSnippet: Sitemap - 2025 - Redwood Research blog Redwood Research blog Subscribe Sign in Home Podcast Chat Reading List Archive About Sitemap - 2025 - Redwood Research blog Measuring no CoT math time horizon (single forward pass) Recent LLMs can use filler tokens or problem repeats to improve (no-CoT) math performance BashArena and Control Setting Design The behavioral selection model for predicting AI motivations Will AI systems drift into misalignment? What's up with Anthropic predicting AGI by early 20
    contentLength: 141993
    status: verified
    note: null
  - footnote: 46
    url: https://blog.redwoodresearch.org/p/guide
    linkText: Reading List - Redwood Research blog — - ARC-AGI achievement
    claimContext: (footnote definition only, no inline reference found)
    fetchedAt: 2026-02-22T02:12:50.585Z
    httpStatus: 200
    pageTitle: Reading List - by Buck Shlegeris - Redwood Research blog
    contentSnippet: "Reading List - by Buck Shlegeris - Redwood Research blog Redwood Research blog Subscribe Sign in Home Podcast Chat Reading List Archive About Reading List (Last updated Jul 28th 2025) Section 1 is a quick guide to the key ideas in AI control, aimed at readers who want to get up to speed as quickly as possible. Section 2 is an extensive guide to almost all of our writing on AI risk, aimed at those who want to gain a deep understanding of Redwood’s worldview. 1. Key Ideas in AI Control Papers and "
    contentLength: 190909
    status: verified
    note: null
