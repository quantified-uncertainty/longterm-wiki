# Auto-Update News Sources
#
# RSS/Atom feeds and web sources checked for new AI safety-relevant information.
# The auto-update system fetches these, builds a news digest, and routes
# relevant items to wiki pages for updating.
#
# Fields:
#   id:          Unique identifier for this source
#   name:        Human-readable name
#   type:        rss | atom | web-search
#   url:         Feed URL (for rss/atom types)
#   query:       Search query (for web-search types; uses Exa API if EXA_API_KEY
#                is set, otherwise falls back to Anthropic web_search tool)
#   frequency:   How often to check: daily | twice-daily | weekly
#   categories:  Topic categories this source covers (used for routing)
#   reliability: high | medium | low (affects how aggressively we trust items)
#   enabled:     true/false

sources:
  # ── AI Lab Blogs ──────────────────────────────────────────────────────────

  - id: openai-blog
    name: OpenAI Blog
    type: rss
    url: https://openai.com/blog/rss.xml
    frequency: daily
    categories: [ai-labs, models, safety, policy]
    reliability: high
    enabled: true

  - id: anthropic-blog
    name: Anthropic Blog / Research
    type: web-search
    query: "Anthropic blog new research safety interpretability 2026"
    frequency: daily
    categories: [ai-labs, safety, models, interpretability]
    reliability: high
    enabled: true

  - id: deepmind-blog
    name: Google DeepMind Blog
    type: rss
    url: https://deepmind.google/blog/rss.xml
    frequency: daily
    categories: [ai-labs, models, safety, research]
    reliability: high
    enabled: true

  - id: meta-ai-blog
    name: Meta AI Blog
    type: web-search
    query: "Meta AI blog new models open source Llama 2026"
    frequency: daily
    categories: [ai-labs, models, open-source]
    reliability: high
    enabled: true

  # ── AI Safety / Alignment ─────────────────────────────────────────────────

  - id: alignment-forum
    name: Alignment Forum
    type: rss
    url: https://www.alignmentforum.org/feed.xml
    frequency: daily
    categories: [safety, alignment, research]
    reliability: high
    enabled: true

  - id: lesswrong
    name: LessWrong
    type: rss
    url: https://www.lesswrong.com/feed.xml
    frequency: daily
    categories: [safety, alignment, rationality, research]
    reliability: medium
    enabled: true

  - id: ea-forum
    name: EA Forum
    type: rss
    url: https://forum.effectivealtruism.org/feed.xml
    frequency: daily
    categories: [safety, policy, governance, funding]
    reliability: medium
    enabled: true

  # ── Policy & Governance ───────────────────────────────────────────────────

  - id: aisafety-news-search
    name: AI Safety Policy News
    type: web-search
    query: "AI safety regulation policy governance 2026"
    frequency: daily
    categories: [policy, governance, regulation]
    reliability: medium
    enabled: true

  - id: ai-executive-orders
    name: AI Executive Orders & Legislation
    type: web-search
    query: "AI executive order legislation bill 2026"
    frequency: daily
    categories: [policy, governance, regulation]
    reliability: medium
    enabled: true

  # ── Newsletters & Aggregators ─────────────────────────────────────────────

  - id: import-ai
    name: Import AI Newsletter
    type: rss
    url: https://importai.substack.com/feed
    frequency: daily
    categories: [ai-labs, models, policy, research]
    reliability: high
    enabled: true

  - id: the-gradient
    name: The Gradient
    type: rss
    url: https://thegradient.pub/rss/
    frequency: daily
    categories: [research, models, safety]
    reliability: high
    enabled: true

  - id: ml-safety-newsletter
    name: ML Safety Newsletter
    type: rss
    url: https://newsletter.mlsafety.org/feed
    frequency: daily
    categories: [safety, alignment, research]
    reliability: high
    enabled: true

  - id: zvi-ai
    name: "Zvi Mowshowitz (Don't Worry About the Vase)"
    type: rss
    url: https://thezvi.substack.com/feed
    frequency: daily
    categories: [safety, policy, models, ai-labs, governance]
    reliability: high
    enabled: true

  - id: cais-newsletter
    name: AI Safety Newsletter (CAIS)
    type: rss
    url: https://newsletter.safe.ai/feed
    frequency: daily
    categories: [safety, alignment, policy, research]
    reliability: high
    enabled: true

  - id: last-week-in-ai
    name: Last Week in AI
    type: rss
    url: https://lastweekin.ai/feed
    frequency: daily
    categories: [ai-labs, models, industry, research]
    reliability: medium
    enabled: true

  - id: navigating-ai-risks
    name: Navigating AI Risks
    type: rss
    url: https://www.navigatingrisks.ai/feed
    frequency: daily
    categories: [safety, governance, policy, risk]
    reliability: medium
    enabled: true

  # ── Arxiv ─────────────────────────────────────────────────────────────────

  - id: arxiv-cs-ai
    name: arXiv cs.AI (Artificial Intelligence)
    type: rss
    url: https://arxiv.org/rss/cs.AI
    frequency: daily
    categories: [research, safety, alignment, interpretability]
    reliability: high
    enabled: true

  - id: arxiv-cs-cl
    name: arXiv cs.CL (Computation and Language)
    type: rss
    url: https://arxiv.org/rss/cs.CL
    frequency: daily
    categories: [research, models, capabilities]
    reliability: high
    enabled: true

  # ── Compute & Industry ────────────────────────────────────────────────────

  - id: ai-industry-news
    name: AI Industry News
    type: web-search
    query: "artificial intelligence funding compute GPU chips 2026"
    frequency: daily
    categories: [compute, industry, funding]
    reliability: medium
    enabled: true

# State tracking is stored in data/auto-update/state.yaml (auto-maintained).
# This file is only for source configuration — it is never rewritten by code.
