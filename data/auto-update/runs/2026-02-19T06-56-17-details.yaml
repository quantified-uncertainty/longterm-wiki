digest:
  date: 2026-02-19
  itemCount: 1318
  items:
    - title: Governance of superintelligence
      url: https://openai.com/index/governance-of-superintelligence
      sourceId: openai-blog
      publishedAt: Mon, 22 May 2023 07:00:00 GMT
      summary: Now is a good time to start thinking about the governance of superintelligence—future AI systems dramatically
        more capable than even AGI.
      relevanceScore: 95
      topics:
        - safety-research
        - alignment-progress
        - agi-development
        - structural
      entities:
        - safety-research
        - agi-development
    - title: Our approach to alignment research
      url: https://openai.com/index/our-approach-to-alignment-research
      sourceId: openai-blog
      publishedAt: Wed, 24 Aug 2022 07:00:00 GMT
      summary: We are improving our AI systems’ ability to learn from human feedback and to assist humans at evaluating AI.
        Our goal is to build a sufficiently aligned AI system that can help us solve all other alignment problems.
      relevanceScore: 95
      topics:
        - alignment-progress
        - safety-research
        - human-feedback
        - alignment-robustness-trajectory
      entities:
        - alignment-progress
        - safety-research
    - title: AI and compute
      url: https://openai.com/index/ai-and-compute
      sourceId: openai-blog
      publishedAt: Wed, 16 May 2018 07:00:00 GMT
      summary: "We’re releasing an analysis showing that since 2012, the amount of compute used in the largest AI training
        runs has been increasing exponentially with a 3.4-month doubling time (by comparison, Moore’s Law had a 2-year
        doubling period)[^footnote-correction]. Since 2012, this metric has grown by more than 300,000x (a 2-year
        doubling period would yield only a 7x increase). Improvements in compute have been a key component of AI
        progress, so as long as this trend continues, it’s worth preparing for "
      relevanceScore: 95
      topics:
        - compute-hardware
        - capabilities
        - ai-timelines
        - scaling-debate
        - projecting-compute-spending
      entities:
        - compute-hardware
        - capabilities
        - ai-timelines
        - projecting-compute-spending
    - title: OpenAI and Anthropic share findings from a joint safety evaluation
      url: https://openai.com/index/openai-anthropic-safety-evaluation
      sourceId: openai-blog
      publishedAt: Wed, 27 Aug 2025 10:00:00 GMT
      summary: OpenAI and Anthropic share findings from a first-of-its-kind joint safety evaluation, testing each other’s
        models for misalignment, instruction following, hallucinations, jailbreaking, and more—highlighting progress,
        challenges, and the value of cross-lab collaboration.
      relevanceScore: 90
      topics:
        - safety-evaluation
        - joint-evaluation
        - misalignment
        - jailbreak
        - hallucination
      entities:
        - safety-research
        - eval-types-table
        - deceptive-alignment-decomposition
    - title: Our updated Preparedness Framework
      url: https://openai.com/index/updating-our-preparedness-framework
      sourceId: openai-blog
      publishedAt: Tue, 15 Apr 2025 00:00:00 GMT
      summary: Sharing our updated framework for measuring and protecting against severe harm from frontier AI capabilities.
      relevanceScore: 90
      topics:
        - safety-research
        - governance
        - risk-assessment
        - preparedness
      entities:
        - intervention-effectiveness-matrix
        - eval-types-table
    - title: Superalignment Fast Grants
      url: https://openai.com/index/superalignment-fast-grants
      sourceId: openai-blog
      publishedAt: Thu, 14 Dec 2023 08:00:00 GMT
      summary: We’re launching $10M in grants to support technical research towards the alignment and safety of superhuman AI
        systems, including weak-to-strong generalization, interpretability, scalable oversight, and more.
      relevanceScore: 90
      topics:
        - alignment-progress
        - safety-research
        - interpretability-sufficient
        - scalable-oversight
      entities:
        - alignment-progress
        - safety-research
    - title: "Frontier AI regulation: Managing emerging risks to public safety"
      url: https://openai.com/index/frontier-ai-regulation
      sourceId: openai-blog
      publishedAt: Thu, 06 Jul 2023 07:00:00 GMT
      summary: ""
      relevanceScore: 90
      topics:
        - safety-research
        - alignment-progress
        - structural
        - regulation-debate
      entities:
        - safety-research
    - title: Planning for AGI and beyond
      url: https://openai.com/index/planning-for-agi-and-beyond
      sourceId: openai-blog
      publishedAt: Fri, 24 Feb 2023 08:00:00 GMT
      summary: Our mission is to ensure that artificial general intelligence—AI systems that are generally smarter than
        humans—benefits all of humanity.
      relevanceScore: 90
      topics:
        - agi-development
        - alignment
        - long-term-planning
      entities:
        - agi-development
        - aligned-agi
    - title: Lessons learned on language model safety and misuse
      url: https://openai.com/index/language-model-safety-and-misuse
      sourceId: openai-blog
      publishedAt: Thu, 03 Mar 2022 08:00:00 GMT
      summary: We describe our latest thinking in the hope of helping other AI developers address safety and misuse of
        deployed models.
      relevanceScore: 90
      topics:
        - safety-research
        - misuse-risks
        - alignment-progress
        - lab-behavior
      entities:
        - safety-research
        - misuse-risks
    - title: Aligning language models to follow instructions
      url: https://openai.com/index/instruction-following
      sourceId: openai-blog
      publishedAt: Thu, 27 Jan 2022 08:00:00 GMT
      summary: We’ve trained language models that are much better at following user intentions than GPT-3 while also making
        them more truthful and less toxic, using techniques developed through our alignment research. These InstructGPT
        models, which are trained with humans in the loop, are now deployed as the default language models on our API.
      relevanceScore: 90
      topics:
        - alignment-progress
        - safety-research
        - human-feedback
        - alignment-robustness-trajectory
      entities:
        - alignment-progress
        - safety-research
    - title: AI safety needs social scientists
      url: https://openai.com/index/ai-safety-needs-social-scientists
      sourceId: openai-blog
      publishedAt: Tue, 19 Feb 2019 08:00:00 GMT
      summary: We’ve written a paper arguing that long-term AI safety research needs social scientists to ensure AI alignment
        algorithms succeed when actual humans are involved. Properly aligning advanced AI systems with human values
        requires resolving many uncertainties related to the psychology of human rationality, emotion, and biases. The
        aim of this paper is to spark further collaboration between machine learning and social science researchers, and
        we plan to hire social scientists to work on this full ti
      relevanceScore: 90
      topics:
        - ai-safety
        - alignment
        - social-science
        - human-values
      entities:
        - alignment-progress
        - safety-research
    - title: Preparing for malicious uses of AI
      url: https://openai.com/index/preparing-for-malicious-uses-of-ai
      sourceId: openai-blog
      publishedAt: Tue, 20 Feb 2018 08:00:00 GMT
      summary: We’ve co-authored a paper that forecasts how malicious actors could misuse AI technology, and potential ways we
        can prevent and mitigate these threats. This paper is the outcome of almost a year of sustained work with our
        colleagues at the Future of Humanity Institute, the Centre for the Study of Existential Risk, the Center for a
        New American Security, the Electronic Frontier Foundation, and others.
      relevanceScore: 90
      topics:
        - misuse-risks
        - safety-research
        - solutions
      entities:
        - misuse-risks
        - solutions
    - title: Superintelligence Alignment Seminar (1 month focused upskilling)
      url: https://forum.effectivealtruism.org/posts/X6bHWKQBKoM8heisn/superintelligence-alignment-seminar-1-month-focused
      sourceId: ea-forum
      publishedAt: Tue, 17 Feb 2026 23:22:58 GMT
      summary: "Published on February 17, 2026 11:22 PM GMTApply to Seminar to Study, Explain, and Try to Solve
        Superintelligence AlignmentApplications for the AFFINE Superintelligence Alignment Seminar are now open, and we
        invite you to apply. It will take place in Hostačov, near Prague (Czechia), from 28 April to 28 May.We are
        working on a draft of the learning materials, in consultation with world-experts.KEY INFODates: From 28th April
        to 28th of MayLocation: Hostačov, 582 82 Skryje-Golčův Jeníkov, Czechia \ud83c"
      relevanceScore: 90
      topics:
        - alignment
        - safety-research
        - education
        - superintelligence
      entities:
        - alignment-progress
        - safety-research
        - agi-development
    - title: Let 2026 Be the Year the World Comes Together for AI Safety
      url: https://www.nature.com/articles/d41586-025-04106-0
      sourceId: aisafety-news-search
      publishedAt: 2026-02-19
      summary: " *Nature* (Published December 29, 2025) A scientific editorial calling for global coordination on AI safety.
        Most rules of the European Union's AI Act are expected to come into force in August 2026; in 2024, the African
        Union published continent-wide guidance for AI policymaking; and there are moves to establish a global AI
        cooperation organization, possibly through the United Nations. The piece warns that the U.S. federal government
        is bucking the trend by cancelling AI policy work and challeng"
      relevanceScore: 90
      topics:
        - ai-safety
        - international-coordination
        - governance
      entities:
        - international-coordination-game
        - regulation-debate
        - solutions
    - title: Frontier risk and preparedness
      url: https://openai.com/index/frontier-risk-and-preparedness
      sourceId: openai-blog
      publishedAt: Thu, 26 Oct 2023 07:00:00 GMT
      summary: To support the safety of highly-capable AI systems, we are developing our approach to catastrophic risk
        preparedness, including building a Preparedness team and launching a challenge.
      relevanceScore: 88
      topics:
        - existential-risk
        - early-warnings
        - safety-research
      entities:
        - is-ai-xrisk-real
        - early-warnings
        - safety-research
    - title: Understanding neural networks through sparse circuits
      url: https://openai.com/index/understanding-neural-networks-through-sparse-circuits
      sourceId: openai-blog
      publishedAt: Thu, 13 Nov 2025 10:00:00 GMT
      summary: OpenAI is exploring mechanistic interpretability to understand how neural networks reason. Our new sparse model
        approach could make AI systems more transparent and support safer, more reliable behavior.
      relevanceScore: 85
      topics:
        - interpretability
        - mechanistic-interpretability
        - safety-research
        - transparency
      entities:
        - interpretability-sufficient
    - title: GPT-5 bio bug bounty call
      url: https://openai.com/gpt-5-bio-bug-bounty
      sourceId: openai-blog
      publishedAt: Fri, 05 Sep 2025 08:45:00 GMT
      summary: OpenAI invites researchers to its Bio Bug Bounty. Test GPT-5’s safety with a universal jailbreak prompt and win
        up to $25,000.
      relevanceScore: 85
      topics:
        - safety-evaluation
        - jailbreak
        - bug-bounty
        - security
      entities:
        - safety-research
        - eval-types-table
    - title: "From hard refusals to safe-completions: toward output-centric safety training"
      url: https://openai.com/index/gpt-5-safe-completions
      sourceId: openai-blog
      publishedAt: Thu, 07 Aug 2025 00:00:00 GMT
      summary: Discover how OpenAI's new safe-completions approach in GPT-5 improves both safety and helpfulness in AI
        responses—moving beyond hard refusals to nuanced, output-centric safety training for handling dual-use prompts.
      relevanceScore: 85
      topics:
        - safety
        - alignment
        - output-centric-safety
        - training
        - refusals
      entities:
        - safety-research
        - alignment-progress
        - why-alignment-hard
    - title: Estimating worst case frontier risks of open weight LLMs
      url: https://openai.com/index/estimating-worst-case-frontier-risks-of-open-weight-llms
      sourceId: openai-blog
      publishedAt: Tue, 05 Aug 2025 00:00:00 GMT
      summary: "In this paper, we study the worst-case frontier risks of releasing gpt-oss. We introduce malicious fine-tuning
        (MFT), where we attempt to elicit maximum capabilities by fine-tuning gpt-oss to be as capable as possible in
        two domains: biology and cybersecurity."
      relevanceScore: 85
      topics:
        - open-vs-closed
        - misuse-risks
        - safety-research
        - malicious-fine-tuning
        - frontier-lab-cost-structure
      entities:
        - open-vs-closed
        - misuse-risks
        - safety-research
    - title: "Sycophancy in GPT-4o: what happened and what we’re doing about it"
      url: https://openai.com/index/sycophancy-in-gpt-4o
      sourceId: openai-blog
      publishedAt: Tue, 29 Apr 2025 18:00:00 GMT
      summary: We have rolled back last week’s GPT‑4o update in ChatGPT so people are now using an earlier version with more
        balanced behavior. The update we removed was overly flattering or agreeable—often described as sycophantic.
      relevanceScore: 85
      topics:
        - alignment
        - model-behavior
        - sycophancy
        - safety-incident
      entities:
        - __index__/knowledge-base/incidents
        - reward-hacking-taxonomy
    - title: OpenAI o3-mini System Card
      url: https://openai.com/index/o3-mini-system-card
      sourceId: openai-blog
      publishedAt: Fri, 31 Jan 2025 11:00:00 GMT
      summary: This report outlines the safety work carried out for the OpenAI o3-mini model, including safety evaluations,
        external red teaming, and Preparedness Framework evaluations.
      relevanceScore: 85
      topics:
        - safety-research
        - alignment-progress
        - expert-opinion
      entities:
        - safety-research
        - alignment-progress
    - title: "Deliberative alignment: reasoning enables safer language models"
      url: https://openai.com/index/deliberative-alignment
      sourceId: openai-blog
      publishedAt: Fri, 20 Dec 2024 10:00:00 GMT
      summary: "Deliberative alignment: reasoning enables safer language models Introducing our new alignment strategy for o1
        models, which are directly taught safety specifications and how to reason over them."
      relevanceScore: 85
      topics:
        - alignment-progress
        - safety-research
        - reasoning
      entities:
        - alignment-progress
        - safety-research
        - reasoning
    - title: OpenAI o1 System Card
      url: https://openai.com/index/openai-o1-system-card
      sourceId: openai-blog
      publishedAt: Thu, 05 Dec 2024 10:00:00 GMT
      summary: This report outlines the safety work carried out prior to releasing OpenAI o1 and o1-mini, including external
        red teaming and frontier risk evaluations according to our Preparedness Framework.
      relevanceScore: 85
      topics:
        - safety-research
        - red-teaming
        - safety-evaluation
        - preparedness-framework
        - frontier-risk
      entities:
        - safety-research
        - eval-types-table
    - title: Building an early warning system for LLM-aided biological threat creation
      url: https://openai.com/index/building-an-early-warning-system-for-llm-aided-biological-threat-creation
      sourceId: openai-blog
      publishedAt: Wed, 31 Jan 2024 08:00:00 GMT
      summary: We’re developing a blueprint for evaluating the risk that a large language model (LLM) could aid someone in
        creating a biological threat. In an evaluation involving both biology experts and students, we found that GPT-4
        provides at most a mild uplift in biological threat creation accuracy. While this uplift is not large enough to
        be conclusive, our finding is a starting point for continued research and community deliberation.
      relevanceScore: 85
      topics:
        - bioweapons-ai-uplift
        - bioweapons-attack-chain
        - early-warnings
        - eval-types-table
      entities:
        - bioweapons-ai-uplift
        - bioweapons-attack-chain
        - early-warnings
        - eval-types-table
    - title: Weak-to-strong generalization
      url: https://openai.com/index/weak-to-strong-generalization
      sourceId: openai-blog
      publishedAt: Thu, 14 Dec 2023 00:00:00 GMT
      summary: "We present a new research direction for superalignment, together with promising initial results: can we
        leverage the generalization properties of deep learning to control strong models with weak supervisors?"
      relevanceScore: 85
      topics:
        - alignment-progress
        - safety-research
        - interpretability-sufficient
      entities:
        - alignment-progress
        - safety-research
    - title: OpenAI’s Approach to Frontier Risk
      url: https://openai.com/global-affairs/our-approach-to-frontier-risk
      sourceId: openai-blog
      publishedAt: Thu, 26 Oct 2023 07:00:00 GMT
      summary: An Update for the UK AI Safety Summit
      relevanceScore: 85
      topics:
        - existential-risk
        - governance
        - solutions
      entities:
        - is-ai-xrisk-real
        - solutions
    - title: Moving AI governance forward
      url: https://openai.com/index/moving-ai-governance-forward
      sourceId: openai-blog
      publishedAt: Fri, 21 Jul 2023 07:00:00 GMT
      summary: OpenAI and other leading labs reinforce AI safety, security and trustworthiness through voluntary commitments.
      relevanceScore: 85
      topics:
        - safety-research
        - alignment-progress
        - structural
      entities:
        - safety-research
    - title: Testimony before the U.S. Senate
      url: https://openai.com/global-affairs/testimony-of-sam-altman-before-the-us-senate
      sourceId: openai-blog
      publishedAt: Thu, 22 Jun 2023 00:00:00 GMT
      summary: The following is the written testimony of Sam Altman, Chief Executive Officer of OpenAI, before the U.S. Senate
        Committee on the Judiciary (Subcommittee on Privacy, Technology, & the Law).
      relevanceScore: 85
      topics:
        - safety-research
        - alignment-progress
        - regulation-debate
      entities:
        - safety-research
    - title: Our approach to AI safety
      url: https://openai.com/index/our-approach-to-ai-safety
      sourceId: openai-blog
      publishedAt: Wed, 05 Apr 2023 07:00:00 GMT
      summary: Ensuring that AI systems are built, deployed, and used safely is critical to our mission.
      relevanceScore: 85
      topics:
        - ai-safety
        - alignment
        - safety-culture
      entities:
        - safety-research
        - alignment-progress
    - title: Forecasting potential misuses of language models for disinformation campaigns and how to reduce risk
      url: https://openai.com/index/forecasting-misuse
      sourceId: openai-blog
      publishedAt: Wed, 11 Jan 2023 08:00:00 GMT
      summary: OpenAI researchers collaborated with Georgetown University’s Center for Security and Emerging Technology and
        the Stanford Internet Observatory to investigate how large language models might be misused for disinformation
        purposes. The collaboration included an October 2021 workshop bringing together 30 disinformation researchers,
        machine learning experts, and policy analysts, and culminated in a co-authored report building on more than a
        year of research. This report outlines the threats that lan
      relevanceScore: 85
      topics:
        - disinformation
        - misuse-risks
        - safety-research
      entities:
        - disinformation-detection-race
        - misuse-risks
        - safety-research
    - title: Measuring Goodhart’s law
      url: https://openai.com/index/measuring-goodharts-law
      sourceId: openai-blog
      publishedAt: Wed, 13 Apr 2022 07:00:00 GMT
      summary: "Goodhart’s law famously says: “When a measure becomes a target, it ceases to be a good measure.” Although
        originally from economics, it’s something we have to grapple with at OpenAI when figuring out how to optimize
        objectives that are difficult or costly to measure."
      relevanceScore: 85
      topics:
        - alignment-progress
        - safety-research
        - reward-hacking-taxonomy
        - goal-misgeneralization-probability
      entities:
        - alignment-progress
        - safety-research
    - title: Fine-tuning GPT-2 from human preferences
      url: https://openai.com/index/fine-tuning-gpt-2
      sourceId: openai-blog
      publishedAt: Thu, 19 Sep 2019 07:00:00 GMT
      summary: We’ve fine-tuned the 774M parameter GPT-2 language model using human feedback for various tasks, successfully
        matching the preferences of the external human labelers, though those preferences did not always match our own.
        Specifically, for summarization tasks the labelers preferred sentences copied wholesale from the input (we’d
        only asked them to ensure accuracy), so our models learned to copy. Summarization required 60k human labels;
        simpler tasks which continue text in various styles required
      relevanceScore: 85
      topics:
        - alignment
        - human-feedback
        - language-models
        - RLHF
      entities:
        - aligned-agi
        - language-models
    - title: Why responsible AI development needs cooperation on safety
      url: https://openai.com/index/cooperation-on-safety
      sourceId: openai-blog
      publishedAt: Wed, 10 Jul 2019 07:00:00 GMT
      summary: "We’ve written a policy research paper identifying four strategies that can be used today to improve the
        likelihood of long-term industry cooperation on safety norms in AI: communicating risks and benefits, technical
        collaboration, increased transparency, and incentivizing standards. Our analysis shows that industry cooperation
        on safety will be instrumental in ensuring that AI systems are safe and beneficial, but competitive pressures
        could lead to a collective action problem, potentially causin"
      relevanceScore: 85
      topics:
        - safety-research
        - governance
        - cooperation
        - industry-norms
      entities:
        - safety-research
        - regulation-debate
    - title: Learning complex goals with iterated amplification
      url: https://openai.com/index/learning-complex-goals-with-iterated-amplification
      sourceId: openai-blog
      publishedAt: Mon, 22 Oct 2018 07:00:00 GMT
      summary: We’re proposing an AI safety technique called iterated amplification that lets us specify complicated behaviors
        and goals that are beyond human scale, by demonstrating how to decompose a task into simpler sub-tasks, rather
        than by providing labeled data or a reward function. Although this idea is in its very early stages and we have
        only completed experiments on simple toy algorithmic domains, we’ve decided to present it in its preliminary
        state because we think it could prove to be a scalable a
      relevanceScore: 85
      topics:
        - ai-safety
        - alignment
        - iterated-amplification
        - scalable-oversight
      entities:
        - alignment-progress
        - safety-research
    - title: AI safety via debate
      url: https://openai.com/index/debate
      sourceId: openai-blog
      publishedAt: Thu, 03 May 2018 07:00:00 GMT
      summary: We’re proposing an AI safety technique which trains agents to debate topics with one another, using a human to
        judge who wins.
      relevanceScore: 85
      topics:
        - alignment-progress
        - solutions
        - safety-research
      entities:
        - alignment-progress
        - solutions
    - title: Concrete AI safety problems
      url: https://openai.com/index/concrete-ai-safety-problems
      sourceId: openai-blog
      publishedAt: Tue, 21 Jun 2016 07:00:00 GMT
      summary: We (along with researchers from Berkeley and Stanford) are co-authors on today’s paper led by Google Brain
        researchers, Concrete Problems in AI Safety. The paper explores many research problems around ensuring that
        modern machine learning systems operate as intended.
      relevanceScore: 85
      topics:
        - ai-safety
        - alignment
        - safety-research
      entities:
        - safety-research
        - accident-risks
    - title: "Gemma Scope 2: helping the AI safety community deepen understanding of complex language model behavior"
      url: https://deepmind.google/blog/gemma-scope-2-helping-the-ai-safety-community-deepen-understanding-of-complex-language-model-behavior/
      sourceId: deepmind-blog
      publishedAt: Tue, 16 Dec 2025 10:14:24 +0000
      summary: Open interpretability tools for language models are now available across the entire Gemma 3 family with the
        release of Gemma Scope 2.
      relevanceScore: 85
      topics:
        - interpretability
        - safety-research
        - language-models
      entities:
        - interpretability-sufficient
        - safety-research
        - language-models
    - title: Strengthening our Frontier Safety Framework
      url: https://deepmind.google/blog/strengthening-our-frontier-safety-framework/
      sourceId: deepmind-blog
      publishedAt: Thu, 23 Oct 2025 23:44:10 +0000
      summary: We’re strengthening the Frontier Safety Framework (FSF) to help identify and mitigate severe risks from
        advanced AI models.
      relevanceScore: 85
      topics:
        - safety-research
        - alignment-progress
        - solutions
      entities:
        - safety-research
        - alignment-progress
        - solutions
    - title: Taking a responsible path to AGI
      url: https://deepmind.google/blog/taking-a-responsible-path-to-agi/
      sourceId: deepmind-blog
      publishedAt: Wed, 02 Apr 2025 13:31:00 +0000
      summary: We’re exploring the frontiers of AGI, prioritizing technical safety, proactive risk assessment, and
        collaboration with the AI community.
      relevanceScore: 85
      topics:
        - agi-development
        - alignment-progress
        - safety-research
        - governance
      entities:
        - agi-development
        - alignment-progress
        - safety-research
    - title: Updating the Frontier Safety Framework
      url: https://deepmind.google/blog/updating-the-frontier-safety-framework/
      sourceId: deepmind-blog
      publishedAt: Tue, 04 Feb 2025 16:41:00 +0000
      summary: Our next iteration of the FSF sets out stronger security protocols on the path to AGI
      relevanceScore: 85
      topics:
        - safety-research
        - governance
        - alignment
        - agi-development
      entities:
        - solutions
        - structural-risks
    - title: AI and Nationalism Are a Deadly Combination
      url: https://www.lesswrong.com/posts/M2vymTx2324D6FfG5/ai-and-nationalism-are-a-deadly-combination
      sourceId: lesswrong
      publishedAt: Wed, 18 Feb 2026 21:46:15 GMT
      summary: Published on February 18, 2026 9:46 PM GMTIf the new technology is as dangerous as its makers say, great power
        competition becomes suicidally reckless. Only international cooperation can ensure AI serves humanity instead of
        worsening war.Dario Amodei, the CEO of leading AI company Anthropic, has written a 19,000 word warning that AI
        technology could spell disaster for humanity. While insisting that he and his company are developing AI
        responsibly, Amodei says that we are facing unprecedented ris
      relevanceScore: 85
      topics:
        - geopolitics
        - international-coordination
        - existential-risk
        - multipolar-competition
      entities:
        - international-coordination-game
        - multipolar-trap-dynamics
        - geopolitics
    - title: "2026 Year in Preview: AI Regulatory Developments for Companies to Watch Out For"
      url: https://www.wsgr.com/en/insights/2026-year-in-preview-ai-regulatory-developments-for-companies-to-watch-out-for.html
      sourceId: aisafety-news-search
      publishedAt: 2026-02-19
      summary: " Wilson Sonsini (Law Firm) A comprehensive legal outlook covering major U.S. AI regulatory trends heading into
        2026. In late 2025, two major U.S. states — California and New York — enacted sweeping laws regulating frontier
        AI models, including California's Transparency in Frontier AI Act (S.B. 53) and New York's Responsible AI Safety
        and Education Act. The article also covers new state laws targeting companies deploying AI for consequential
        decisions in financial services, education, employment,"
      relevanceScore: 85
      topics:
        - ai-regulation
        - governance
        - policy
        - compliance
      entities:
        - regulation-debate
        - solutions
    - title: AI Regulations Around the World – 2026
      url: https://www.mindfoundry.ai/blog/ai-regulations-around-the-world
      sourceId: aisafety-news-search
      publishedAt: 2026-02-19
      summary: " Mind Foundry A global overview of AI regulation as of 2026. On January 23, 2025, President Trump signed
        Executive Order 14179, \"Removing Barriers to American Leadership in Artificial Intelligence,\" which eliminated
        key federal AI oversight policies established under President Biden. The article also covers the UK's position,
        noting that as of the start of 2026, a Private Member's Artificial Intelligence (Regulation) Bill was
        reintroduced and is progressing in the House of Lords."
      relevanceScore: 85
      topics:
        - ai-regulation
        - governance
        - global-policy
      entities:
        - regulation-debate
        - solutions
        - geopolitics
    - title: New State AI Laws Are Effective on January 1, 2026, But a New Executive Order Signals Disruption — *King &
        Spalding*
      url: https://www.kslaw.com/news-and-insights/new-state-ai-laws-are-effective-on-january-1-2026-but-a-new-executive-order-signals-disruption
      sourceId: ai-executive-orders
      publishedAt: 2026-02-19
      summary: " This legal client alert examines the tension between newly effective state AI laws and the Trump
        administration's federal executive order. The Executive Order directs the Executive branch to coordinate federal
        action and encourage federal legislation for a uniform standard, while also directing the Attorney General to
        establish an AI Litigation Task Force to challenge state AI laws deemed inconsistent with the Executive Order.
        The order also directs the Secretary of Commerce to publish, by Marc"
      relevanceScore: 85
      topics:
        - ai-regulation
        - governance
        - policy
        - federal-state-tension
      entities:
        - regulation-debate
        - solutions
    - title: President Trump Signs Executive Order Challenging State AI Laws — *Paul Hastings LLP*
      url: https://www.paulhastings.com/insights/client-alerts/president-trump-signs-executive-order-challenging-state-ai-laws
      sourceId: ai-executive-orders
      publishedAt: 2026-02-19
      summary: " A detailed legal analysis of the December 2025 Executive Order and its implications for state AI regulation.
        The Executive Order instructs the Department of Commerce to condition $42 billion in previously allocated
        broadband infrastructure funding under the BEAD program on the repeal of state AI regulations deemed onerous. By
        raising the financial and legal costs and uncertainty associated with enacting and defending state AI laws, the
        Executive Order may create a deterrent effect that discoura"
      relevanceScore: 85
      topics:
        - ai-regulation
        - governance
        - executive-order
        - policy
      entities:
        - regulation-debate
        - solutions
    - title: "State AI Laws Under Federal Scrutiny: Key Takeaways from the Executive Order — *White & Case LLP*"
      url: https://www.whitecase.com/insight-alert/state-ai-laws-under-federal-scrutiny-key-takeaways-executive-order-establishing
      sourceId: ai-executive-orders
      publishedAt: 2026-02-19
      summary: " A thorough breakdown of Executive Order 14365 and its legal mechanisms. On December 11, 2025, President Trump
        signed an executive order titled \"Ensuring a National Policy Framework for Artificial Intelligence,\" which
        establishes a federal policy aimed at addressing the growing number of state-level AI regulations to \"sustain
        and enhance the United States' global AI dominance through a minimally burdensome national policy framework for
        AI.\" The order also directs the FCC to initiate a proceeding"
      relevanceScore: 85
      topics:
        - ai-regulation
        - governance
        - policy
        - legal-analysis
      entities:
        - regulation-debate
        - solutions
    - title: "U.S. Artificial Intelligence Law Update: Navigating the Evolving State and Federal Regulatory Landscape — *Baker
        Botts*"
      url: https://www.bakerbotts.com/thought-leadership/publications/2026/january/us-ai-law-update
      sourceId: ai-executive-orders
      publishedAt: 2026-02-19
      summary: " A comprehensive January 2026 update on the AI regulatory landscape at both state and federal levels. Over
        1,000 AI-related bills were introduced across states in 2025 alone, with over 700 introduced the year before,
        signaling continued legislative momentum at the state level. On May 22, 2025, the U.S. House of Representatives
        passed a provision within a broader budget reconciliation bill that would have barred states and localities from
        enforcing AI-specific regulations for ten years; however, "
      relevanceScore: 85
      topics:
        - ai-regulation
        - governance
        - policy
        - legislative-landscape
      entities:
        - regulation-debate
        - solutions
    - title: "ML Safety Newsletter #15"
      url: https://newsletter.mlsafety.org/p/ml-safety-newsletter-15
      sourceId: ml-safety-newsletter
      publishedAt: Mon, 18 Aug 2025 17:08:04 GMT
      summary: Risks in Agentic Computer Use, Goal Drift, Shutdown Resistance, and Critiques of Scheming Research
      relevanceScore: 85
      topics:
        - agentic-ai
        - goal-drift
        - shutdown-resistance
        - safety-research
        - deceptive-alignment
      entities:
        - agentic-ai
        - safety-research
        - deceptive-alignment-decomposition
        - corrigibility-failure-pathways
    - title: "ML Safety Newsletter #9"
      url: https://newsletter.mlsafety.org/p/ml-safety-newsletter-9
      sourceId: ml-safety-newsletter
      publishedAt: Tue, 11 Apr 2023 15:53:36 GMT
      summary: Verifying large training runs, security risks from LLM access to APIs, why natural selection may favor AIs over
        humans
      relevanceScore: 85
      topics:
        - ai-risk
        - existential-risk
        - natural-selection
        - competition
        - safety-research
      entities:
        - safety-research
        - case-for-xrisk
        - multipolar-trap-dynamics
    - title: "ML Safety Newsletter #8"
      url: https://newsletter.mlsafety.org/p/ml-safety-newsletter-8
      sourceId: ml-safety-newsletter
      publishedAt: Mon, 20 Feb 2023 15:00:53 GMT
      summary: Interpretability, using law to inform AI alignment, scaling laws for proxy gaming
      relevanceScore: 85
      topics:
        - interpretability
        - alignment
        - scaling-laws
        - reward-hacking
      entities:
        - interpretability-sufficient
        - why-alignment-hard
        - scaling-debate
    - title: "ML Safety Newsletter #1"
      url: https://newsletter.mlsafety.org/p/ml-safety-newsletter-1
      sourceId: ml-safety-newsletter
      publishedAt: Mon, 18 Oct 2021 00:03:15 GMT
      summary: ICLR Safety Paper Roundup
      relevanceScore: 82
      topics:
        - safety-research
        - alignment-progress
      entities:
        - safety-research
        - alignment-progress
    - title: "ForesightSafety Bench: A Frontier Risk Evaluation and Governance Framework towards Safe AI"
      url: https://arxiv.org/abs/2602.14135
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.14135v2 Announce Type: replace Abstract: Rapidly evolving AI exhibits increasingly strong autonomy
        and goal-directed capabilities, accompanied by derivative systemic risks that are more unpredictable, difficult
        to control, and potentially irreversible. However, current AI safety evaluation systems suffer from critical
        limitations such as restricted risk dimensions and failed frontier risk detection. The lagging safety benchmarks
        and alignment technologies can hardly address the comple"
      relevanceScore: 82
      topics:
        - safety-research
        - eval-types-table
        - frontier-lab-cost-structure
        - risk-cascade-pathways
      entities:
        - safety-research
        - eval-types-table
        - frontier-lab-cost-structure
    - title: "Addendum to GPT-5.2 System Card: GPT-5.2-Codex"
      url: https://openai.com/index/gpt-5-2-codex-system-card
      sourceId: openai-blog
      publishedAt: Thu, 18 Dec 2025 00:00:00 GMT
      summary: This system card outlines the comprehensive safety measures implemented for GPT‑5.2-Codex. It details both
        model-level mitigations, such as specialized safety training for harmful tasks and prompt injections, and
        product-level mitigations like agent sandboxing and configurable network access.
      relevanceScore: 80
      topics:
        - safety-research
        - misuse-risks
        - cybersecurity
        - alignment-progress
      entities:
        - safety-research
        - misuse-risks
        - alignment-progress
    - title: Strengthening our safety ecosystem with external testing
      url: https://openai.com/index/strengthening-safety-with-external-testing
      sourceId: openai-blog
      publishedAt: Wed, 19 Nov 2025 12:00:00 GMT
      summary: OpenAI works with independent experts to evaluate frontier AI systems. Third-party testing strengthens safety,
        validates safeguards, and increases transparency in how we assess model capabilities and risks.
      relevanceScore: 80
      topics:
        - safety-research
        - eval-types-table
        - lab-behavior
      entities:
        - __index__/knowledge-base/models
    - title: "Understanding prompt injections: a frontier security challenge"
      url: https://openai.com/index/prompt-injections
      sourceId: openai-blog
      publishedAt: Fri, 07 Nov 2025 11:30:00 GMT
      summary: Prompt injections are a frontier security challenge for AI systems. Learn how these attacks work and how OpenAI
        is advancing research, training models, and building safeguards for users.
      relevanceScore: 80
      topics:
        - security
        - prompt-injection
        - adversarial-attacks
        - safety-research
      entities:
        - accident-risks
    - title: gpt-oss-safeguard technical report
      url: https://openai.com/index/gpt-oss-safeguard-technical-report
      sourceId: openai-blog
      publishedAt: Wed, 29 Oct 2025 00:00:00 GMT
      summary: "gpt-oss-safeguard-120b and gpt-oss-safeguard-20b are two open-weight reasoning models post-trained from the
        gpt-oss models and trained to reason from a provided policy in order to label content under that policy. In this
        report, we describe gpt-oss-safeguard’s capabilities and provide our baseline safety evaluations on the
        gpt-oss-safeguard models, using the underlying gpt-oss models as a baseline. For more information about the
        development and architecture of the underlying gpt-oss models, see "
      relevanceScore: 80
      topics:
        - safety-research
        - safety-classification
        - policy-alignment
        - interpretability
      entities:
        - solutions
    - title: Introducing gpt-oss-safeguard
      url: https://openai.com/index/introducing-gpt-oss-safeguard
      sourceId: openai-blog
      publishedAt: Wed, 29 Oct 2025 00:00:00 GMT
      summary: OpenAI introduces gpt-oss-safeguard—open-weight reasoning models for safety classification that let developers
        apply and iterate on custom policies.
      relevanceScore: 80
      topics:
        - safety-research
        - safety-classification
        - policy-alignment
        - open-source
      entities:
        - solutions
    - title: OpenAI and Broadcom announce strategic collaboration to deploy 10 gigawatts of OpenAI-designed AI accelerators
      url: https://openai.com/index/openai-and-broadcom-announce-strategic-collaboration
      sourceId: openai-blog
      publishedAt: Mon, 13 Oct 2025 06:00:00 GMT
      summary: OpenAI and Broadcom announce a multi-year partnership to deploy 10 gigawatts of OpenAI-designed AI
        accelerators, co-developing next-generation systems and Ethernet solutions to power scalable, energy-efficient
        AI infrastructure by 2029.
      relevanceScore: 80
      topics:
        - compute-hardware
        - ai-megaproject-infrastructure
        - frontier-lab-cost-structure
      entities:
        - compute-hardware
        - ai-megaproject-infrastructure
    - title: AMD and OpenAI announce strategic partnership to deploy 6 gigawatts of AMD GPUs
      url: https://openai.com/index/openai-amd-strategic-partnership
      sourceId: openai-blog
      publishedAt: Mon, 06 Oct 2025 06:00:00 GMT
      summary: AMD and OpenAI have announced a multi-year partnership to deploy 6 gigawatts of AMD Instinct GPUs, beginning
        with 1 gigawatt in 2026, to power OpenAI’s next-generation AI infrastructure and accelerate global AI
        innovation.
      relevanceScore: 80
      topics:
        - compute-hardware
        - ai-megaproject-infrastructure
        - frontier-lab-cost-structure
      entities:
        - compute-hardware
        - ai-megaproject-infrastructure
    - title: Why language models hallucinate
      url: https://openai.com/index/why-language-models-hallucinate
      sourceId: openai-blog
      publishedAt: Fri, 05 Sep 2025 10:00:00 GMT
      summary: OpenAI’s new research explains why language models hallucinate. The findings show how improved evaluations can
        enhance AI reliability, honesty, and safety.
      relevanceScore: 80
      topics:
        - hallucination
        - reliability
        - safety
        - language-models
      entities:
        - language-models
        - safety-research
        - epistemic-risks
    - title: "Collective alignment: public input on our Model Spec"
      url: https://openai.com/index/collective-alignment-aug-2025-updates
      sourceId: openai-blog
      publishedAt: Wed, 27 Aug 2025 13:00:00 GMT
      summary: OpenAI surveyed over 1,000 people worldwide on how AI should behave and compared their views to our Model Spec.
        Learn how collective alignment is shaping AI defaults to better reflect diverse human values and perspectives.
      relevanceScore: 80
      topics:
        - alignment
        - model-spec
        - human-values
        - collective-alignment
      entities:
        - alignment-progress
        - why-alignment-hard
    - title: Agent bio bug bounty call
      url: https://openai.com/bio-bug-bounty
      sourceId: openai-blog
      publishedAt: Thu, 17 Jul 2025 00:00:00 GMT
      summary: OpenAI invites researchers to its Bio Bug Bounty. Test the ChatGPT agent’s safety with a universal jailbreak
        prompt and win up to $25,000.
      relevanceScore: 80
      topics:
        - safety-research
        - misuse-risks
        - biological-organoid
        - accident-risks
      entities:
        - safety-research
        - misuse-risks
    - title: Preparing for future AI risks in biology
      url: https://openai.com/index/preparing-for-future-ai-capabilities-in-biology
      sourceId: openai-blog
      publishedAt: Wed, 18 Jun 2025 10:00:00 GMT
      summary: Advanced AI can transform biology and medicine—but also raises biosecurity risks. We’re proactively assessing
        capabilities and implementing safeguards to prevent misuse.
      relevanceScore: 80
      topics:
        - biosecurity
        - misuse-risks
        - safety-research
        - accident-risks
      entities:
        - misuse-risks
        - accident-risks
        - safety-research
    - title: Expanding on what we missed with sycophancy
      url: https://openai.com/index/expanding-on-sycophancy
      sourceId: openai-blog
      publishedAt: Fri, 02 May 2025 08:00:00 GMT
      summary: A deeper dive on our findings, what went wrong, and future changes we’re making.
      relevanceScore: 80
      topics:
        - alignment
        - model-behavior
        - sycophancy
        - safety-research
      entities:
        - reward-hacking-taxonomy
        - model-organisms-of-misalignment
    - title: New funding to build towards AGI
      url: https://openai.com/index/march-funding-updates
      sourceId: openai-blog
      publishedAt: Mon, 31 Mar 2025 15:00:00 GMT
      summary: Today we’re announcing new funding—$40B at a $300B post-money valuation, which enables us to push the frontiers
        of AI research even further, scale our compute infrastructure, and deliver increasingly powerful tools for the
        500 million people who use ChatGPT every week.
      relevanceScore: 80
      topics:
        - compute
        - agi-development
        - capabilities
        - scaling
      entities:
        - agi-development
        - compute-hardware
        - projecting-compute-spending
        - scaling-debate
    - title: Operator System Card
      url: https://openai.com/index/operator-system-card
      sourceId: openai-blog
      publishedAt: Thu, 23 Jan 2025 10:00:00 GMT
      summary: Drawing from OpenAI’s established safety frameworks, this document highlights our multi-layered approach,
        including model and product mitigations we’ve implemented to protect against prompt engineering and jailbreaks,
        protect privacy and security, as well as details our external red teaming efforts, safety evaluations, and
        ongoing work to further refine these safeguards.
      relevanceScore: 80
      topics:
        - safety-research
        - alignment-progress
        - agentic-ai
      entities:
        - safety-research
        - alignment-progress
        - agentic-ai
    - title: Stargate Infrastructure
      url: https://openai.com/form/stargate-infrastructure
      sourceId: openai-blog
      publishedAt: Tue, 21 Jan 2025 13:30:00 GMT
      summary: OpenAI, and our strategic partners, are thrilled about our shared vision for the Infrastructure of AGI. We are
        energized by the challenges we face and are excited by the prospect of partnering with firms across the
        industrial base to deliver against our ambitious mission. Specifically, we want to connect with firms across the
        built data center infrastructure landscape, from power and land to construction to equipment, and everything in
        between.
      relevanceScore: 80
      topics:
        - compute-hardware
        - ai-megaproject-infrastructure
        - agi-development
      entities:
        - ai-megaproject-infrastructure
        - agi-development
        - compute-hardware
    - title: Announcing The Stargate Project
      url: https://openai.com/index/announcing-the-stargate-project
      sourceId: openai-blog
      publishedAt: Tue, 21 Jan 2025 13:30:00 GMT
      summary: Announcing The Stargate Project
      relevanceScore: 80
      topics:
        - compute-hardware
        - ai-megaproject-infrastructure
        - agi-development
      entities:
        - ai-megaproject-infrastructure
        - agi-development
        - compute-hardware
    - title: Advancing red teaming with people and AI
      url: https://openai.com/index/advancing-red-teaming-with-people-and-ai
      sourceId: openai-blog
      publishedAt: Thu, 21 Nov 2024 10:30:00 GMT
      summary: Advancing red teaming with people and AI
      relevanceScore: 80
      topics:
        - red-teaming
        - safety-research
        - safety-evaluation
      entities:
        - safety-research
        - eval-types-table
    - title: OpenAI’s approach to AI and national security
      url: https://openai.com/global-affairs/openais-approach-to-ai-and-national-security
      sourceId: openai-blog
      publishedAt: Thu, 24 Oct 2024 14:00:00 GMT
      summary: OpenAI’s approach to AI and national security
      relevanceScore: 80
      topics:
        - governance
        - national-security
        - policy
        - geopolitics
      entities:
        - geopolitics
    - title: Practices for Governing Agentic AI Systems
      url: https://openai.com/index/practices-for-governing-agentic-ai-systems
      sourceId: openai-blog
      publishedAt: Thu, 14 Dec 2023 08:00:00 GMT
      summary: ""
      relevanceScore: 80
      topics:
        - agentic-ai
        - governance
        - solutions
      entities:
        - agentic-ai
        - solutions
    - title: Frontier Model Forum updates
      url: https://openai.com/index/frontier-model-forum-updates
      sourceId: openai-blog
      publishedAt: Wed, 25 Oct 2023 07:00:00 GMT
      summary: Together with Anthropic, Google, and Microsoft, we’re announcing the new Executive Director of the Frontier
        Model Forum and a new $10 million AI Safety Fund.
      relevanceScore: 80
      topics:
        - governance
        - safety-research
        - international-coordination-game
      entities:
        - solutions
        - international-coordination-game
    - title: Frontier Model Forum
      url: https://openai.com/index/frontier-model-forum
      sourceId: openai-blog
      publishedAt: Wed, 26 Jul 2023 07:00:00 GMT
      summary: "We’re forming a new industry body to promote the safe and responsible development of frontier AI systems:
        advancing AI safety research, identifying best practices and standards, and facilitating information sharing
        among policymakers and industry."
      relevanceScore: 80
      topics:
        - safety-research
        - alignment-progress
        - structural
      entities:
        - safety-research
    - title: Questions for the Record
      url: https://openai.com/global-affairs/sam-altman-senate-questions-for-the-record
      sourceId: openai-blog
      publishedAt: Thu, 22 Jun 2023 00:00:00 GMT
      summary: The following are the Questions for the Record following Sam Altman's testimony before the U.S. Senate
        Committee on the Judiciary (Subcommittee on Privacy, Technology, & the Law).
      relevanceScore: 80
      topics:
        - safety-research
        - alignment-progress
        - regulation-debate
      entities:
        - safety-research
    - title: Democratic inputs to AI
      url: https://openai.com/index/democratic-inputs-to-ai
      sourceId: openai-blog
      publishedAt: Thu, 25 May 2023 07:00:00 GMT
      summary: Our nonprofit organization, OpenAI, Inc., is launching a program to award ten $100,000 grants to fund
        experiments in setting up a democratic process for deciding what rules AI systems should follow, within the
        bounds defined by the law.
      relevanceScore: 80
      topics:
        - safety-research
        - alignment-progress
        - structural
      entities:
        - safety-research
    - title: How should AI systems behave, and who should decide?
      url: https://openai.com/index/how-should-ai-systems-behave
      sourceId: openai-blog
      publishedAt: Thu, 16 Feb 2023 08:00:00 GMT
      summary: We’re clarifying how ChatGPT’s behavior is shaped and our plans for improving that behavior, allowing more user
        customization, and getting more public input into our decision-making in these areas.
      relevanceScore: 80
      topics:
        - alignment
        - value-alignment
        - governance
        - public-input
      entities:
        - alignment-progress
    - title: A hazard analysis framework for code synthesis large language models
      url: https://openai.com/index/a-hazard-analysis-framework-for-code-synthesis-large-language-models
      sourceId: openai-blog
      publishedAt: Mon, 25 Jul 2022 07:00:00 GMT
      summary: ""
      relevanceScore: 80
      topics:
        - safety-research
        - misuse-risks
        - coding
        - accident-risks
      entities:
        - safety-research
        - misuse-risks
        - coding
    - title: OpenAI Microscope
      url: https://openai.com/index/microscope
      sourceId: openai-blog
      publishedAt: Tue, 14 Apr 2020 07:00:00 GMT
      summary: We’re introducing OpenAI Microscope, a collection of visualizations of every significant layer and neuron of
        eight vision “model organisms” which are often studied in interpretability. Microscope makes it easier to
        analyze the features that form inside these neural networks, and we hope it will help the research community as
        we move towards understanding these complicated systems.
      relevanceScore: 80
      topics:
        - interpretability
        - model-organisms
        - safety-research
      entities:
        - model-organisms-of-misalignment
        - interpretability-sufficient
    - title: Safety Gym
      url: https://openai.com/index/safety-gym
      sourceId: openai-blog
      publishedAt: Thu, 21 Nov 2019 08:00:00 GMT
      summary: We’re releasing Safety Gym, a suite of environments and tools for measuring progress towards reinforcement
        learning agents that respect safety constraints while training.
      relevanceScore: 80
      topics:
        - safety-research
        - reinforcement-learning
        - safety-constraints
      entities:
        - safety-research
    - title: Learning from human preferences
      url: https://openai.com/index/learning-from-human-preferences
      sourceId: openai-blog
      publishedAt: Tue, 13 Jun 2017 07:00:00 GMT
      summary: One step towards building safe AI systems is to remove the need for humans to write goal functions, since using
        a simple proxy for a complex goal, or getting the complex goal a bit wrong, can lead to undesirable and even
        dangerous behavior. In collaboration with DeepMind’s safety team, we’ve developed an algorithm which can infer
        what humans want by being told which of two proposed behaviors is better.
      relevanceScore: 80
      topics:
        - human-feedback
        - reward-learning
        - alignment
        - safety
        - goal-specification
      entities:
        - alignment-progress
        - safety-research
        - why-alignment-hard
    - title: OpenAI technical goals
      url: https://openai.com/index/openai-technical-goals
      sourceId: openai-blog
      publishedAt: Mon, 20 Jun 2016 07:00:00 GMT
      summary: OpenAI’s mission is to build safe AI, and ensure AI’s benefits are as widely and evenly distributed as possible.
      relevanceScore: 80
      topics:
        - ai-safety
        - alignment
        - governance
      entities:
        - safety-research
    - title: Anthropic's Recommendations to OSTP for the U.S. AI Action Plan
      url: https://www.anthropic.com/news/anthropic-s-recommendations-ostp-u-s-ai-action-plan
      sourceId: anthropic-blog
      publishedAt: 2026-02-19
      summary: " Anthropic submitted policy recommendations to the White House's Office of Science and Technology Policy
        (OSTP), noting that powerful AI systems are expected to emerge in late 2026 or early 2027, with intellectual
        capabilities matching or exceeding Nobel Prize winners across most disciplines."
      relevanceScore: 80
      topics:
        - agi-timeline
        - regulation-debate
        - geopolitics
      entities:
        - agi-timeline
        - regulation-debate
        - geopolitics
    - title: Deepening our partnership with the UK AI Security Institute
      url: https://deepmind.google/blog/deepening-our-partnership-with-the-uk-ai-security-institute/
      sourceId: deepmind-blog
      publishedAt: Thu, 11 Dec 2025 00:06:40 +0000
      summary: Google DeepMind and UK AI Security Institute (AISI) strengthen collaboration on critical AI safety and security
        research
      relevanceScore: 80
      topics:
        - safety-research
        - governance
        - geopolitics
      entities:
        - safety-research
        - geopolitics
    - title: Introducing the Gemini 2.5 Computer Use model
      url: https://deepmind.google/blog/introducing-the-gemini-25-computer-use-model/
      sourceId: deepmind-blog
      publishedAt: Thu, 23 Oct 2025 18:40:34 +0000
      summary: Available in preview via the API, our Computer Use model is a specialized model built on Gemini 2.5 Pro’s
        capabilities to power agents that can interact with user interfaces.
      relevanceScore: 80
      topics:
        - agentic-ai
        - tool-use
        - capabilities
        - computer-vision
      entities:
        - agentic-ai
        - tool-use
        - capabilities
    - title: Evaluating potential cybersecurity threats of advanced AI
      url: https://deepmind.google/blog/evaluating-potential-cybersecurity-threats-of-advanced-ai/
      sourceId: deepmind-blog
      publishedAt: Wed, 02 Apr 2025 13:30:00 +0000
      summary: Our framework enables cybersecurity experts to identify which defenses are necessary—and how to prioritize them
      relevanceScore: 80
      topics:
        - misuse-risks
        - cyberweapons-attack-automation
        - safety-research
        - governance
      entities:
        - misuse-risks
        - cyberweapons-attack-automation
        - safety-research
    - title: Review of If Anyone Builds It, Everyone Dies
      url: https://www.lesswrong.com/posts/6qsdJBZD8wGmjdpu7/review-of-if-anyone-builds-it-everyone-dies
      sourceId: lesswrong
      publishedAt: Thu, 19 Feb 2026 01:56:25 GMT
      summary: Published on February 19, 2026 1:53 AM GMTCrosspost of my blog article.Over the past five years, we’ve seen
        extraordinary advancements in AI capabilities, with LLMs going from producing nonsensical text in 2021 to
        becoming people’s therapists and automating complex tasks in 2025. Given such advancement, it’s only natural to
        wonder what further advancement in AI could mean for society. If this technology’s intelligence continues to
        scale at the rate it has been, it seems more likely than not that
      relevanceScore: 80
      topics:
        - existential-risk
        - case-for-xrisk
        - capabilities
      entities:
        - case-for-xrisk
        - capabilities
    - title: Building Technology to Drive AI Governance
      url: https://forum.effectivealtruism.org/posts/WLd4one35GpDL6EwQ/building-technology-to-drive-ai-governance
      sourceId: ea-forum
      publishedAt: Wed, 18 Feb 2026 22:35:32 GMT
      summary: "Published on February 18, 2026 10:35 PM GMTTechnically skilled people who care about AI going well often ask
        me: how should I spend my time if I think AI governance is important? By governance, I mean the constraints,
        incentives, and oversight that govern how AI is developed.One option is to focus on technical work that solves
        problems at the point of production, such as alignment research or safeguards. Another common instinct is to get
        directly involved in policy: switching to a policy role, f"
      relevanceScore: 80
      topics:
        - ai-governance
        - regulation
        - policy
      entities:
        - regulation-debate
        - solutions
    - title: "2026 Outlook: Artificial Intelligence"
      url: https://www.gtlaw.com/en/insights/2025/12/2026-outlook-artificial-intelligence
      sourceId: aisafety-news-search
      publishedAt: 2026-02-19
      summary: " Greenberg Traurig LLP (Law Firm) A detailed regulatory outlook from a major law firm. California's AI Safety
        Act, effective January 1, 2026, establishes protections for employees from retaliation for reporting AI-related
        risks and establishes the CalCompute public AI cloud consortium. The piece also notes that Colorado postponed
        implementation of its AI Act from February 1, 2026 to June 30, 2026, establishing requirements for developers of
        \"high-risk\" AI systems including risk-management, discl"
      relevanceScore: 80
      topics:
        - ai-regulation
        - governance
        - policy
      entities:
        - regulation-debate
        - solutions
    - title: New Privacy, Data Protection and AI Laws in 2026
      url: https://www.pearlcohen.com/new-privacy-data-protection-and-ai-laws-in-2026/
      sourceId: aisafety-news-search
      publishedAt: 2026-02-19
      summary: "Pearl Cohen (Law Firm, Published December 31, 2025) A practical legal summary of new AI laws taking effect in
        2026. Effective January 1, 2026, California is imposing comprehensive safety requirements on AI companion
        chatbots under Senate Bill 243, targeting AI systems that provide adaptive, human-like social interactions. It
        also covers the federal dimension: President Trump signed an executive order establishing federal policy to
        preempt state AI regulations deemed to obstruct national competit"
      relevanceScore: 80
      topics:
        - ai-regulation
        - privacy
        - governance
        - compliance
      entities:
        - regulation-debate
        - solutions
    - title: "AI Legislation in the U.S.: A 2026 Overview — *Software Improvement Group (SIG)*"
      url: https://www.softwareimprovementgroup.com/blog/us-ai-legislation-overview/
      sourceId: ai-executive-orders
      publishedAt: 2026-02-19
      summary: "A broad, regularly updated overview of the current U.S. AI legislative landscape for business leaders. Since
        Donald Trump began his second term in 2025, federal policy has emphasized \"innovation-first\" approaches while
        states continue to pass enforceable AI rules that start taking effect in 2026. America's AI Action Plan
        (released July 2025) remains a key roadmap for federal \"innovation-first\" actions; in 2026, it's increasingly
        important to treat it as a directional policy signal — influencing "
      relevanceScore: 80
      topics:
        - ai-regulation
        - governance
        - policy
        - innovation
      entities:
        - regulation-debate
        - solutions
    - title: "MLSN #17: Measuring General AI Abilities and Mitigating Deception"
      url: https://newsletter.mlsafety.org/p/mlsn-17-measuring-general-ai-abilities
      sourceId: ml-safety-newsletter
      publishedAt: Wed, 19 Nov 2025 20:00:57 GMT
      summary: Measuring General AI Abilities
      relevanceScore: 80
      topics:
        - ai-capabilities
        - deceptive-alignment
        - measurement
        - safety-research
      entities:
        - safety-research
        - deceptive-alignment-decomposition
        - capabilities
    - title: "ML Safety Newsletter #14"
      url: https://newsletter.mlsafety.org/p/ml-safety-newsletter-14
      sourceId: ml-safety-newsletter
      publishedAt: Wed, 07 May 2025 16:02:03 GMT
      summary: Resisting Prompt Injection, Evaluating Cyberattack Capabilities, and SafeBench Winners
      relevanceScore: 80
      topics:
        - prompt-injection
        - security
        - cyberattacks
        - safety-research
      entities:
        - safety-research
        - cyberweapons-attack-automation
    - title: "ML Safety Newsletter #13"
      url: https://newsletter.mlsafety.org/p/ml-safety-newsletter-13-march-2025
      sourceId: ml-safety-newsletter
      publishedAt: Wed, 02 Apr 2025 17:00:47 GMT
      summary: Chain-of-Thought Monitoring, Distinguishing Honesty from Accuracy, and Emergent Misalignment
      relevanceScore: 80
      topics:
        - interpretability
        - honesty
        - emergent-misalignment
        - safety-research
      entities:
        - safety-research
        - interpretability-sufficient
        - model-organisms-of-misalignment
    - title: "ML Safety Newsletter #11"
      url: https://newsletter.mlsafety.org/p/ml-safety-newsletter-11
      sourceId: ml-safety-newsletter
      publishedAt: Thu, 14 Dec 2023 17:24:33 GMT
      summary: Top Safety Papers of 2023
      relevanceScore: 80
      topics:
        - safety-research
        - ml-safety
        - research-overview
      entities:
        - safety-research
    - title: "ML Safety Newsletter #7"
      url: https://newsletter.mlsafety.org/p/ml-safety-newsletter-7
      sourceId: ml-safety-newsletter
      publishedAt: Mon, 09 Jan 2023 15:30:20 GMT
      summary: Making model dishonesty harder, making grokking more interpretable, an example of an emergent internal optimizer
      relevanceScore: 80
      topics:
        - deceptive-alignment
        - interpretability
        - emergent-optimization
        - mesa-optimization
      entities:
        - deceptive-alignment-decomposition
        - mesa-optimization-analysis
        - interpretability-sufficient
    - title: "ML Safety Newsletter #5"
      url: https://newsletter.mlsafety.org/p/ml-safety-newsletter-5
      sourceId: ml-safety-newsletter
      publishedAt: Mon, 26 Sep 2022 21:55:02 GMT
      summary: Safety competitions with more than $1 million in prizes
      relevanceScore: 80
      topics:
        - safety-research
        - alignment-progress
        - competitions
      entities:
        - safety-research
        - alignment-progress
    - title: "AI Safety Newsletter #67: Trump’s preemption executive order"
      url: https://newsletter.safe.ai/p/ai-safety-newsletter-67-trumps-preemption
      sourceId: cais-newsletter
      publishedAt: Wed, 17 Dec 2025 19:32:35 GMT
      summary: "Also: H200s go to China and new frontier AI models from OpenAI and DeepSeek."
      relevanceScore: 80
      topics:
        - geopolitics
        - compute-hardware
        - frontier-models
        - regulation
        - preemption
      entities:
        - geopolitics
        - compute-hardware
        - regulation-debate
    - title: "AI Safety Newsletter #64: New AGI Definition and Senate Bill Would Establish Liability for AI Harms"
      url: https://newsletter.safe.ai/p/ai-safety-newsletter-63-new-agi-definition
      sourceId: cais-newsletter
      publishedAt: Thu, 16 Oct 2025 15:56:30 GMT
      summary: Welcome to the AI Safety Newsletter by the Center for AI Safety. We discuss developments in AI and AI safety.
        No technical background required.
      relevanceScore: 80
      topics:
        - agi-definition
        - regulation
        - liability
        - governance
      entities:
        - regulation-debate
        - agi-development
    - title: "Targeting Alignment: Extracting Safety Classifiers of Aligned LLMs"
      url: https://arxiv.org/abs/2501.16534
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2501.16534v5 Announce Type: replace-cross Abstract: Alignment in large language models (LLMs) is used to
        enforce guidelines such as safety. Yet, alignment fails in the face of jailbreak attacks that modify inputs to
        induce unsafe outputs. In this paper, we introduce and evaluate a new technique for jailbreak attacks. We
        observe that alignment embeds a safety classifier in the LLM responsible for deciding between refusal and
        compliance, and seek to extract an approximation of this classifie"
      relevanceScore: 80
      topics:
        - alignment
        - safety-research
        - interpretability-sufficient
        - deceptive-alignment-decomposition
      entities:
        - alignment
        - safety-research
        - interpretability-sufficient
    - title: "ML Safety Newsletter #4"
      url: https://newsletter.mlsafety.org/p/ml-safety-newsletter-4
      sourceId: ml-safety-newsletter
      publishedAt: Fri, 03 Jun 2022 01:15:35 GMT
      summary: Many New Interpretability Papers, Virtual Logit Matching, Rationalization Helps Robustness
      relevanceScore: 78
      topics:
        - interpretability
        - robustness
        - adversarial-training
      entities:
        - interpretability-sufficient
    - title: "ML Safety Newsletter #2"
      url: https://newsletter.mlsafety.org/p/ml-safety-newsletter-2
      sourceId: ml-safety-newsletter
      publishedAt: Thu, 09 Dec 2021 16:40:04 GMT
      summary: Adversarial Training, Feature Visualization, and Machine Ethics
      relevanceScore: 78
      topics:
        - adversarial-training
        - robustness
        - machine-ethics
        - alignment
      entities:
        - why-alignment-hard
    - title: "AI Safety Newsletter #66: Evaluating Frontier Models, New Gemini and Claude, Preemption is Back"
      url: https://newsletter.safe.ai/p/ai-safety-newsletter-66-aisn-66-evaluating
      sourceId: cais-newsletter
      publishedAt: Tue, 02 Dec 2025 01:35:41 GMT
      summary: Welcome to the AI Safety Newsletter by the Center for AI Safety. We discuss developments in AI and AI safety.
        No technical background required.
      relevanceScore: 78
      topics:
        - frontier-models
        - evaluation
        - capabilities
        - governance
      entities:
        - capabilities
        - frontier-lab-cost-structure
    - title: "AI Safety Newsletter #63: California’s SB-53 Passes the Legislature"
      url: https://newsletter.safe.ai/p/ai-safety-newsletter-63-californias
      sourceId: cais-newsletter
      publishedAt: Wed, 24 Sep 2025 16:10:49 GMT
      summary: Welcome to the AI Safety Newsletter by the Center for AI Safety. We discuss developments in AI and AI safety.
        No technical background required.
      relevanceScore: 78
      topics:
        - regulation
        - governance
        - california-policy
      entities:
        - regulation-debate
    - title: "AI Safety Newsletter #55: Trump Administration Rescinds AI Diffusion Rule, Allows Chip Sales to Gulf States"
      url: https://newsletter.safe.ai/p/ai-safety-newsletter-55-trump-administration
      sourceId: cais-newsletter
      publishedAt: Tue, 20 May 2025 14:43:03 GMT
      summary: Plus, Bills on Whistleblower Protections, Chip Location Verification, and State Preemption
      relevanceScore: 78
      topics:
        - geopolitics
        - compute-hardware
        - regulation
        - policy
      entities:
        - geopolitics
        - compute-hardware
        - regulation-debate
    - title: Measuring Mid-2025 LLM-Assistance on Novice Performance in Biology
      url: https://arxiv.org/abs/2602.16703
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16703v1 Announce Type: cross Abstract: Large language models (LLMs) perform strongly on biological
        benchmarks, raising concerns that they may help novice actors acquire dual-use laboratory skills. Yet, whether
        this translates to improved human performance in the physical laboratory remains unclear. To address this, we
        conducted a pre-registered, investigator-blinded, randomized controlled trial (June-August 2025; n = 153)
        evaluating whether LLMs improve novice performance in tasks tha"
      relevanceScore: 78
      topics:
        - misuse-risks
        - dual-use
        - capabilities
        - safety-research
      entities:
        - misuse-risks
        - capabilities
        - safety-research
    - title: "AI Safety Newsletter #60: The AI Action Plan"
      url: https://newsletter.safe.ai/p/ai-safety-newsletter-60-the-ai-action
      sourceId: cais-newsletter
      publishedAt: Thu, 31 Jul 2025 17:43:20 GMT
      summary: "Plus: ChatGPT Agent and IMO Gold"
      relevanceScore: 76
      topics:
        - ai-policy
        - governance
        - agentic-ai
      entities:
        - agentic-ai
        - regulation-debate
    - title: "AI Safety Newsletter #52: An Expert Virology Benchmark"
      url: https://newsletter.safe.ai/p/ai-safety-newsletter-52-an-expert
      sourceId: cais-newsletter
      publishedAt: Tue, 22 Apr 2025 16:08:14 GMT
      summary: Plus, AI-Enabled Coups
      relevanceScore: 76
      topics:
        - bioweapons
        - ai-capabilities
        - misuse-risks
        - benchmarking
      entities:
        - bioweapons-timeline
        - misuse-risks
    - title: Introducing Lockdown Mode and Elevated Risk labels in ChatGPT
      url: https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt
      sourceId: openai-blog
      publishedAt: Fri, 13 Feb 2026 10:00:00 GMT
      summary: Introducing Lockdown Mode and Elevated Risk labels in ChatGPT to help organizations defend against prompt
        injection and AI-driven data exfiltration.
      relevanceScore: 75
      topics:
        - safety-research
        - misuse-risks
        - tool-use
      entities:
        - misuse-risks
        - solutions
    - title: Keeping your data safe when an AI agent clicks a link
      url: https://openai.com/index/ai-agent-link-safety
      sourceId: openai-blog
      publishedAt: Wed, 28 Jan 2026 00:00:00 GMT
      summary: Learn how OpenAI protects user data when AI agents open links, preventing URL-based data exfiltration and
        prompt injection with built-in safeguards.
      relevanceScore: 75
      topics:
        - safety-research
        - misuse-risks
        - agentic-ai
      entities:
        - misuse-risks
        - agentic-ai
    - title: Evaluating chain-of-thought monitorability
      url: https://openai.com/index/evaluating-chain-of-thought-monitorability
      sourceId: openai-blog
      publishedAt: Thu, 18 Dec 2025 12:00:00 GMT
      summary: OpenAI introduces a new framework and evaluation suite for chain-of-thought monitorability, covering 13
        evaluations across 24 environments. Our findings show that monitoring a model’s internal reasoning is far more
        effective than monitoring outputs alone, offering a promising path toward scalable control as AI systems grow
        more capable.
      relevanceScore: 75
      topics:
        - interpretability
        - reasoning
        - monitoring
        - safety-research
      entities:
        - interpretability-sufficient
        - reasoning
        - safety-research
    - title: Measuring AI’s capability to accelerate biological research
      url: https://openai.com/index/accelerating-biological-research-in-the-wet-lab
      sourceId: openai-blog
      publishedAt: Tue, 16 Dec 2025 08:00:00 GMT
      summary: OpenAI introduces a real-world evaluation framework to measure how AI can accelerate biological research in the
        wet lab. Using GPT-5 to optimize a molecular cloning protocol, the work explores both the promise and risks of
        AI-assisted experimentation.
      relevanceScore: 75
      topics:
        - capabilities
        - scientific-research
        - misuse-risks
      entities:
        - capabilities
        - scientific-research
        - misuse-risks
    - title: "Update to GPT-5 System Card: GPT-5.2"
      url: https://openai.com/index/gpt-5-system-card-update-gpt-5-2
      sourceId: openai-blog
      publishedAt: Thu, 11 Dec 2025 00:00:00 GMT
      summary: GPT-5.2 is the latest model family in the GPT-5 series. The comprehensive safety mitigation approach for these
        models is largely the same as that described in the GPT-5 System Card and GPT-5.1 System Card. Like OpenAI’s
        other models, the GPT-5.2 models were trained on diverse datasets, including information that is publicly
        available on the internet, information that we partner with third parties to access, and information that our
        users or human trainers and researchers provide or generate.
      relevanceScore: 75
      topics:
        - safety-research
        - alignment-progress
      entities:
        - safety-research
        - alignment-progress
    - title: Strengthening cyber resilience as AI capabilities advance
      url: https://openai.com/index/strengthening-cyber-resilience
      sourceId: openai-blog
      publishedAt: Wed, 10 Dec 2025 12:00:00 GMT
      summary: OpenAI is investing in stronger safeguards and defensive capabilities as AI models become more powerful in
        cybersecurity. We explain how we assess risk, limit misuse, and work with the security community to strengthen
        cyber resilience.
      relevanceScore: 75
      topics:
        - safety-research
        - misuse-risks
        - cybersecurity
      entities:
        - safety-research
        - misuse-risks
    - title: How confessions can keep language models honest
      url: https://openai.com/index/how-confessions-can-keep-language-models-honest
      sourceId: openai-blog
      publishedAt: Wed, 03 Dec 2025 10:00:00 GMT
      summary: OpenAI researchers are testing “confessions,” a method that trains models to admit when they make mistakes or
        act undesirably, helping improve AI honesty, transparency, and trust in model outputs.
      relevanceScore: 75
      topics:
        - alignment-progress
        - safety-research
        - epistemic-risks
      entities:
        - __index__/knowledge-base/cruxes
    - title: OpenAI and Foxconn collaborate to strengthen U.S. manufacturing across the AI supply chain
      url: https://openai.com/index/openai-and-foxconn-collaborate
      sourceId: openai-blog
      publishedAt: Thu, 20 Nov 2025 14:50:00 GMT
      summary: OpenAI and Foxconn are collaborating to design and manufacture next-generation AI infrastructure hardware in
        the U.S. The partnership will develop multiple generations of data-center systems, strengthen U.S. supply
        chains, and build key components domestically to accelerate advanced AI infrastructure.
      relevanceScore: 75
      topics:
        - compute-hardware
        - ai-megaproject-infrastructure
        - geopolitics
      entities:
        - __index__/knowledge-base/metrics
    - title: GPT-5.1-Codex-Max System Card
      url: https://openai.com/index/gpt-5-1-codex-max-system-card
      sourceId: openai-blog
      publishedAt: Wed, 19 Nov 2025 00:00:00 GMT
      summary: This system card outlines the comprehensive safety measures implemented for GPT‑5.1-CodexMax. It details both
        model-level mitigations, such as specialized safety training for harmful tasks and prompt injections, and
        product-level mitigations like agent sandboxing and configurable network access.
      relevanceScore: 75
      topics:
        - safety-research
        - lab-behavior
        - misuse-risks
      entities:
        - __index__/knowledge-base/models
    - title: GPT-5.1 Instant and GPT-5.1 Thinking System Card Addendum
      url: https://openai.com/index/gpt-5-system-card-addendum-gpt-5-1
      sourceId: openai-blog
      publishedAt: Wed, 12 Nov 2025 00:00:00 GMT
      summary: This GPT-5 system card addendum provides updated safety metrics for GPT-5.1 Instant and Thinking, including new
        evaluations for mental health and emotional reliance.
      relevanceScore: 75
      topics:
        - safety-research
        - safety-metrics
        - mental-health-risks
        - epistemic-risks
      entities:
        - epistemic-risks
    - title: AWS and OpenAI announce multi-year strategic partnership
      url: https://openai.com/index/aws-and-openai-partnership
      sourceId: openai-blog
      publishedAt: Mon, 03 Nov 2025 06:00:00 GMT
      summary: OpenAI and AWS have entered a multi-year, $38 billion partnership to scale advanced AI workloads. AWS will
        provide world-class infrastructure and compute capacity to power OpenAI’s next generation of models.
      relevanceScore: 75
      topics:
        - compute-hardware
        - infrastructure
        - ai-megaproject-infrastructure
        - geopolitics
      entities:
        - compute-hardware
        - ai-megaproject-infrastructure
        - geopolitics
    - title: "Introducing Aardvark: OpenAI’s agentic security researcher"
      url: https://openai.com/index/introducing-aardvark
      sourceId: openai-blog
      publishedAt: Thu, 30 Oct 2025 11:00:00 GMT
      summary: OpenAI introduces Aardvark, an AI-powered security researcher that autonomously finds, validates, and helps fix
        software vulnerabilities at scale. The system is in private beta—sign up to join early testing.
      relevanceScore: 75
      topics:
        - agentic-ai
        - security-research
        - autonomous-agents
        - safety-research
      entities:
        - agentic-ai
        - tool-use
    - title: "Addendum to GPT-5 System Card: Sensitive conversations"
      url: https://openai.com/index/gpt-5-system-card-sensitive-conversations
      sourceId: openai-blog
      publishedAt: Mon, 27 Oct 2025 10:00:00 GMT
      summary: This system card details GPT-5’s improvements in handling sensitive conversations, including new benchmarks for
        emotional reliance, mental health, and jailbreak resistance.
      relevanceScore: 75
      topics:
        - safety-research
        - alignment-progress
        - jailbreak-resistance
        - emotional-reliance
      entities:
        - language-models
        - safety-research
    - title: "Disrupting malicious uses of AI: October 2025"
      url: https://openai.com/global-affairs/disrupting-malicious-uses-of-ai-october-2025
      sourceId: openai-blog
      publishedAt: Tue, 07 Oct 2025 03:00:00 GMT
      summary: Discover how OpenAI is detecting and disrupting malicious uses of AI in our October 2025 report. Learn how
        we’re countering misuse, enforcing policies, and protecting users from real-world harms.
      relevanceScore: 75
      topics:
        - safety-research
        - misuse-risks
        - lab-behavior
      entities:
        - safety-research
        - misuse-risks
    - title: Samsung and SK join OpenAI’s Stargate initiative to advance global AI infrastructure
      url: https://openai.com/index/samsung-and-sk-join-stargate
      sourceId: openai-blog
      publishedAt: Wed, 01 Oct 2025 03:00:00 GMT
      summary: Samsung and SK join OpenAI’s Stargate initiative to expand global AI infrastructure, scaling advanced memory
        chip production and building next-gen data centers in Korea.
      relevanceScore: 75
      topics:
        - compute-hardware
        - ai-megaproject-infrastructure
        - geopolitics
      entities:
        - compute-hardware
        - ai-megaproject-infrastructure
        - geopolitics
    - title: Launching Sora responsibly
      url: https://openai.com/index/launching-sora-responsibly
      sourceId: openai-blog
      publishedAt: Tue, 30 Sep 2025 00:00:00 GMT
      summary: To address the novel safety challenges posed by a state-of-the-art video model as well as a new social creation
        platform, we’ve built Sora 2 and the Sora app with safety at the foundation. Our approach is anchored in
        concrete protections.
      relevanceScore: 75
      topics:
        - safety-research
        - alignment-progress
        - misuse-risks
      entities:
        - safety-research
        - misuse-risks
    - title: Detecting and reducing scheming in AI models
      url: https://openai.com/index/detecting-and-reducing-scheming-in-ai-models
      sourceId: openai-blog
      publishedAt: Wed, 17 Sep 2025 00:00:00 GMT
      summary: Apollo Research and OpenAI developed evaluations for hidden misalignment (“scheming”) and found behaviors
        consistent with scheming in controlled tests across frontier models. The team shared concrete examples and
        stress tests of an early method to reduce scheming.
      relevanceScore: 75
      topics:
        - deceptive-alignment-decomposition
        - mesa-optimization-analysis
        - alignment-progress
        - safety-research
      entities:
        - deceptive-alignment-decomposition
        - mesa-optimization-analysis
        - alignment-progress
        - safety-research
    - title: Statement on OpenAI’s Nonprofit and PBC
      url: https://openai.com/index/statement-on-openai-nonprofit-and-pbc
      sourceId: openai-blog
      publishedAt: Thu, 11 Sep 2025 14:00:00 GMT
      summary: OpenAI reaffirms its nonprofit leadership with a new structure granting equity in its PBC, enabling over $100B
        in resources to advance safe, beneficial AI for humanity.
      relevanceScore: 75
      topics:
        - governance
        - nonprofit-structure
        - alignment
        - lab-behavior
      entities:
        - anthropic-impact
        - alignment-progress
    - title: OpenAI’s letter to Governor Newsom on harmonized regulation
      url: https://openai.com/global-affairs/letter-to-governor-newsom-on-harmonized-regulation
      sourceId: openai-blog
      publishedAt: Tue, 12 Aug 2025 00:00:00 GMT
      summary: We’ve just sent a letter to Gov. Gavin Newsom calling for California to lead the way in harmonizing state-based
        AI regulation with national—and, by virtue of US leadership, emerging global—standards.
      relevanceScore: 75
      topics:
        - regulation
        - governance
        - policy
        - state-regulation
      entities:
        - regulation-debate
    - title: ChatGPT agent System Card
      url: https://openai.com/index/chatgpt-agent-system-card
      sourceId: openai-blog
      publishedAt: Thu, 17 Jul 2025 10:00:00 GMT
      summary: "ChatGPT agent System Card: OpenAI’s agentic model unites research, browser automation, and code tools with
        safeguards under the Preparedness Framework."
      relevanceScore: 75
      topics:
        - agentic-ai
        - safety-research
        - eval-types-table
        - accident-risks
      entities:
        - agentic-ai
        - safety-research
        - eval-types-table
    - title: Toward understanding and preventing misalignment generalization
      url: https://openai.com/index/emergent-misalignment
      sourceId: openai-blog
      publishedAt: Wed, 18 Jun 2025 10:00:00 GMT
      summary: We study how training on incorrect responses can cause broader misalignment in language models and identify an
        internal feature driving this behavior—one that can be reversed with minimal fine-tuning.
      relevanceScore: 75
      topics:
        - alignment
        - interpretability
        - misalignment
        - safety-research
      entities:
        - interpretability-sufficient
        - why-alignment-hard
        - safety-research
    - title: Evolving OpenAI’s structure
      url: https://openai.com/index/evolving-our-structure
      sourceId: openai-blog
      publishedAt: Mon, 05 May 2025 11:00:00 GMT
      summary: An update from the OpenAI board on transitioning its for-profit entity to a Public Benefit Corporation,
        reinforcing its mission-driven structure under nonprofit oversight while enabling greater impact and long-term
        alignment with the public good.
      relevanceScore: 75
      topics:
        - governance
        - nonprofit-structure
        - organizational-alignment
      entities:
        - anthropic-impact
    - title: OpenAI o3 and o4-mini System Card
      url: https://openai.com/index/o3-o4-mini-system-card
      sourceId: openai-blog
      publishedAt: Wed, 16 Apr 2025 10:00:00 GMT
      summary: OpenAI o3 and OpenAI o4-mini combine state-of-the-art reasoning with full tool capabilities—web browsing,
        Python, image and file analysis, image generation, canvas, automations, file search, and memory.
      relevanceScore: 75
      topics:
        - capabilities
        - safety-evaluation
        - reasoning
        - tool-use
      entities:
        - reasoning
        - tool-use
        - agentic-ai
        - eval-types-table
    - title: "PaperBench: Evaluating AI’s Ability to Replicate AI Research"
      url: https://openai.com/index/paperbench
      sourceId: openai-blog
      publishedAt: Wed, 02 Apr 2025 10:15:00 GMT
      summary: We introduce PaperBench, a benchmark evaluating the ability of AI agents to replicate state-of-the-art AI
        research.
      relevanceScore: 75
      topics:
        - capabilities
        - agentic-ai
        - evaluation
        - scientific-research
      entities:
        - agentic-ai
        - scientific-research
        - eval-types-table
    - title: Security on the path to AGI
      url: https://openai.com/index/security-on-the-path-to-agi
      sourceId: openai-blog
      publishedAt: Wed, 26 Mar 2025 10:00:00 GMT
      summary: At OpenAI, we proactively adapt, including by building comprehensive security measures directly into our
        infrastructure and models.
      relevanceScore: 75
      topics:
        - safety-research
        - security
        - governance
      entities:
        - defense-in-depth-model
    - title: Deep research System Card
      url: https://openai.com/index/deep-research-system-card
      sourceId: openai-blog
      publishedAt: Tue, 25 Feb 2025 10:00:00 GMT
      summary: This report outlines the safety work carried out prior to releasing deep research including external red
        teaming, frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations
        we built in to address key risk areas.
      relevanceScore: 75
      topics:
        - safety-research
        - interpretability
        - misuse-risks
        - accident-risks
      entities:
        - safety-research
        - interpretability-sufficient
        - misuse-risks
        - accident-risks
    - title: Introducing Operator
      url: https://openai.com/index/introducing-operator
      sourceId: openai-blog
      publishedAt: Thu, 23 Jan 2025 10:00:00 GMT
      summary: A research preview of an agent that can use its own browser to perform tasks for you. Available to Pro users in
        the U.S.
      relevanceScore: 75
      topics:
        - agentic-ai
        - tool-use
        - capabilities
      entities:
        - agentic-ai
        - tool-use
    - title: Trading inference-time compute for adversarial robustness
      url: https://openai.com/index/trading-inference-time-compute-for-adversarial-robustness
      sourceId: openai-blog
      publishedAt: Wed, 22 Jan 2025 10:00:00 GMT
      summary: Trading Inference-Time Compute for Adversarial Robustness
      relevanceScore: 75
      topics:
        - safety-research
        - alignment-progress
        - adversarial-robustness
      entities:
        - safety-research
        - alignment-progress
    - title: Introducing SimpleQA
      url: https://openai.com/index/introducing-simpleqa
      sourceId: openai-blog
      publishedAt: Wed, 30 Oct 2024 10:00:00 GMT
      summary: A factuality benchmark called SimpleQA that measures the ability for language models to answer short,
        fact-seeking questions.
      relevanceScore: 75
      topics:
        - safety-research
        - factuality
        - benchmarking
        - eval-types
      entities:
        - safety-research
        - eval-types-table
    - title: Evaluating fairness in ChatGPT
      url: https://openai.com/index/evaluating-fairness-in-chatgpt
      sourceId: openai-blog
      publishedAt: Tue, 15 Oct 2024 10:00:00 GMT
      summary: We've analyzed how ChatGPT responds to users based on their name, using AI research assistants to protect
        privacy.
      relevanceScore: 75
      topics:
        - safety-research
        - fairness
        - bias
        - evaluation
      entities:
        - safety-research
        - eval-types-table
    - title: An update on disrupting deceptive uses of AI
      url: https://openai.com/global-affairs/an-update-on-disrupting-deceptive-uses-of-ai
      sourceId: openai-blog
      publishedAt: Wed, 09 Oct 2024 03:30:00 GMT
      summary: OpenAI’s mission is to ensure that artificial general intelligence benefits all of humanity. We are dedicated
        to identifying, preventing, and disrupting attempts to abuse our models for harmful ends.
      relevanceScore: 75
      topics:
        - misuse-risks
        - safety-research
        - deceptive-alignment
      entities:
        - misuse-risks
        - safety-research
    - title: GPT-4o System Card
      url: https://openai.com/index/gpt-4o-system-card
      sourceId: openai-blog
      publishedAt: Thu, 08 Aug 2024 00:00:00 GMT
      summary: This report outlines the safety work carried out prior to releasing GPT-4o including external red teaming,
        frontier risk evaluations according to our Preparedness Framework, and an overview of the mitigations we built
        in to address key risk areas.
      relevanceScore: 75
      topics:
        - safety
        - evaluation
        - red-teaming
        - risk-assessment
        - preparedness
      entities:
        - safety-research
        - eval-types-table
    - title: OpenAI and Los Alamos National Laboratory announce research partnership
      url: https://openai.com/index/openai-and-los-alamos-national-laboratory-work-together
      sourceId: openai-blog
      publishedAt: Wed, 10 Jul 2024 06:30:00 GMT
      summary: OpenAI and Los Alamos National Laboratory are working to develop safety evaluations to assess and measure
        biological capabilities and risks associated with frontier models.
      relevanceScore: 75
      topics:
        - safety-research
        - evaluation
        - biosecurity
        - risk-assessment
      entities:
        - safety-research
        - bioweapons-timeline
    - title: Extracting Concepts from GPT-4
      url: https://openai.com/index/extracting-concepts-from-gpt-4
      sourceId: openai-blog
      publishedAt: Thu, 06 Jun 2024 00:00:00 GMT
      summary: Using new techniques for scaling sparse autoencoders, we automatically identified 16 million patterns in
        GPT-4's computations.
      relevanceScore: 75
      topics:
        - interpretability-sufficient
        - safety-research
        - capabilities
      entities:
        - interpretability-sufficient
        - safety-research
    - title: OpenAI Board Forms Safety and Security Committee
      url: https://openai.com/index/openai-board-forms-safety-and-security-committee
      sourceId: openai-blog
      publishedAt: Tue, 28 May 2024 03:00:00 GMT
      summary: ""
      relevanceScore: 75
      topics:
        - lab-behavior
        - governance
        - safety-research
      entities:
        - lab-behavior
    - title: OpenAI’s comment to the NTIA on open model weights
      url: https://openai.com/global-affairs/openai-s-comment-to-the-ntia-on-open-model-weights
      sourceId: openai-blog
      publishedAt: Wed, 27 Mar 2024 00:00:00 GMT
      summary: OpenAI’s comment to the NTIA on open model weights This comment was submitted by OpenAI in response to NTIA’s
        March 2024 Request for Information on Dual-Use Foundation Models with Widely Available Weights.
      relevanceScore: 75
      topics:
        - regulation-debate
        - open-vs-closed
        - governance
        - structural-risks
      entities:
        - regulation-debate
        - open-vs-closed
        - structural-risks
    - title: Disrupting malicious uses of AI by state-affiliated threat actors
      url: https://openai.com/index/disrupting-malicious-uses-of-ai-by-state-affiliated-threat-actors
      sourceId: openai-blog
      publishedAt: Wed, 14 Feb 2024 08:00:00 GMT
      summary: We terminated accounts associated with state-affiliated threat actors. Our findings show our models offer only
        limited, incremental capabilities for malicious cybersecurity tasks.
      relevanceScore: 75
      topics:
        - misuse-risks
        - cyberweapons-attack-automation
        - lab-behavior
      entities:
        - misuse-risks
        - cyberweapons-attack-automation
        - lab-behavior
    - title: OpenAI Red Teaming Network
      url: https://openai.com/index/red-teaming-network
      sourceId: openai-blog
      publishedAt: Tue, 19 Sep 2023 07:00:00 GMT
      summary: We’re announcing an open call for the OpenAI Red Teaming Network and invite domain experts interested in
        improving the safety of OpenAI’s models to join our efforts.
      relevanceScore: 75
      topics:
        - safety-research
        - lab-behavior
        - alignment-progress
      entities:
        - safety-research
    - title: Comment on NTIA AI Accountability Policy
      url: https://openai.com/global-affairs/comment-on-ntia-ai-accountability-policy
      sourceId: openai-blog
      publishedAt: Mon, 12 Jun 2023 00:00:00 GMT
      summary: The National Telecommunications and Information Administration (NTIA) request for comments on AI Accountability
        policy.
      relevanceScore: 75
      topics:
        - safety-research
        - alignment-progress
        - regulation-debate
      entities:
        - safety-research
    - title: Language models can explain neurons in language models
      url: https://openai.com/index/language-models-can-explain-neurons-in-language-models
      sourceId: openai-blog
      publishedAt: Tue, 09 May 2023 07:00:00 GMT
      summary: We use GPT-4 to automatically write explanations for the behavior of neurons in large language models and to
        score those explanations. We release a dataset of these (imperfect) explanations and scores for every neuron in
        GPT-2.
      relevanceScore: 75
      topics:
        - interpretability
        - mechanistic-understanding
        - language-models
      entities:
        - interpretability-sufficient
        - language-models
    - title: Scaling laws for reward model overoptimization
      url: https://openai.com/index/scaling-laws-for-reward-model-overoptimization
      sourceId: openai-blog
      publishedAt: Wed, 19 Oct 2022 07:00:00 GMT
      summary: ""
      relevanceScore: 75
      topics:
        - reward-hacking
        - alignment
        - safety-research
      entities:
        - reward-hacking-taxonomy
        - safety-research
    - title: DALL·E 2 pre-training mitigations
      url: https://openai.com/index/dall-e-2-pre-training-mitigations
      sourceId: openai-blog
      publishedAt: Tue, 28 Jun 2022 07:00:00 GMT
      summary: In order to share the magic of DALL·E 2 with a broad audience, we needed to reduce the risks associated with
        powerful image generation models. To this end, we put various guardrails in place to prevent generated images
        from violating our content policy.
      relevanceScore: 75
      topics:
        - safety-research
        - misuse-risks
        - accident-risks
        - deployment-architectures-table
      entities:
        - safety-research
        - misuse-risks
    - title: AI-written critiques help humans notice flaws
      url: https://openai.com/index/critiques
      sourceId: openai-blog
      publishedAt: Mon, 13 Jun 2022 07:00:00 GMT
      summary: We trained “critique-writing” models to describe flaws in summaries. Human evaluators find flaws in summaries
        much more often when shown our model’s critiques. Larger models are better at self-critiquing, with scale
        improving critique-writing more than summary-writing. This shows promise for using AI systems to assist human
        supervision of AI systems on difficult tasks.
      relevanceScore: 75
      topics:
        - alignment-progress
        - safety-research
        - interpretability-sufficient
      entities:
        - alignment-progress
        - safety-research
    - title: Understanding the capabilities, limitations, and societal impact of large language models
      url: https://openai.com/index/understanding-the-capabilities-limitations-and-societal-impact-of-large-language-models
      sourceId: openai-blog
      publishedAt: Thu, 04 Feb 2021 08:00:00 GMT
      summary: ""
      relevanceScore: 75
      topics:
        - safety-research
        - capabilities
        - misuse-risks
        - accident-risks
      entities:
        - safety-research
        - misuse-risks
        - accident-risks
    - title: Improving verifiability in AI development
      url: https://openai.com/index/improving-verifiability
      sourceId: openai-blog
      publishedAt: Thu, 16 Apr 2020 07:00:00 GMT
      summary: We’ve contributed to a multi-stakeholder report by 58 co-authors at 30 organizations, including the Centre for
        the Future of Intelligence, Mila, Schwartz Reisman Institute for Technology and Society, Center for Advanced
        Study in the Behavioral Sciences, and Center for Security and Emerging Technologies. This report describes 10
        mechanisms to improve the verifiability of claims made about AI systems. Developers can use these tools to
        provide evidence that AI systems are safe, secure, fair, or pri
      relevanceScore: 75
      topics:
        - interpretability
        - safety-research
        - governance
        - multi-stakeholder
      entities:
        - interpretability-sufficient
    - title: Benchmarking safe exploration in deep reinforcement learning
      url: https://openai.com/index/benchmarking-safe-exploration-in-deep-reinforcement-learning
      sourceId: openai-blog
      publishedAt: Thu, 21 Nov 2019 08:00:00 GMT
      summary: ""
      relevanceScore: 75
      topics:
        - safety-research
        - reinforcement-learning
        - safety-constraints
      entities:
        - safety-research
    - title: Testing robustness against unforeseen adversaries
      url: https://openai.com/index/testing-robustness
      sourceId: openai-blog
      publishedAt: Thu, 22 Aug 2019 07:00:00 GMT
      summary: We’ve developed a method to assess whether a neural network classifier can reliably defend against adversarial
        attacks not seen during training. Our method yields a new metric, UAR (Unforeseen Attack Robustness), which
        evaluates the robustness of a single model against an unanticipated attack, and highlights the need to measure
        performance across a more diverse range of unforeseen attacks.
      relevanceScore: 75
      topics:
        - adversarial-robustness
        - safety-research
        - interpretability
      entities:
        - safety-research
    - title: OpenAI LP
      url: https://openai.com/index/openai-lp
      sourceId: openai-blog
      publishedAt: Mon, 11 Mar 2019 07:00:00 GMT
      summary: We’ve created OpenAI LP, a new “capped-profit” company that allows us to rapidly increase our investments in
        compute and talent while including checks and balances to actualize our mission.
      relevanceScore: 75
      topics:
        - governance
        - lab-structure
        - agi-development
      entities:
        - agi-development
        - lab-behavior
    - title: Introducing Activation Atlases
      url: https://openai.com/index/introducing-activation-atlases
      sourceId: openai-blog
      publishedAt: Wed, 06 Mar 2019 08:00:00 GMT
      summary: We’ve created activation atlases (in collaboration with Google researchers), a new technique for visualizing
        what interactions between neurons can represent. As AI systems are deployed in increasingly sensitive contexts,
        having a better understanding of their internal decision-making processes will let us identify weaknesses and
        investigate failures.
      relevanceScore: 75
      topics:
        - interpretability
        - neural-networks
        - transparency
      entities:
        - interpretability-sufficient
    - title: Gathering human feedback
      url: https://openai.com/index/gathering-human-feedback
      sourceId: openai-blog
      publishedAt: Thu, 03 Aug 2017 07:00:00 GMT
      summary: RL-Teacher is an open-source implementation of our interface to train AIs via occasional human feedback rather
        than hand-crafted reward functions. The underlying technique was developed as a step towards safe AI systems,
        but also applies to reinforcement learning problems with rewards that are hard to specify.
      relevanceScore: 75
      topics:
        - human-feedback
        - reward-learning
        - alignment
        - safety
      entities:
        - alignment-progress
        - safety-research
    - title: Faulty reward functions in the wild
      url: https://openai.com/index/faulty-reward-functions
      sourceId: openai-blog
      publishedAt: Wed, 21 Dec 2016 08:00:00 GMT
      summary: Reinforcement learning algorithms can break in surprising, counterintuitive ways. In this post we’ll explore
        one failure mode, which is where you misspecify your reward function.
      relevanceScore: 75
      topics:
        - reward-hacking
        - alignment
        - misalignment
      entities:
        - reward-hacking-taxonomy
        - why-alignment-hard
    - title: Introducing OpenAI
      url: https://openai.com/index/introducing-openai
      sourceId: openai-blog
      publishedAt: Fri, 11 Dec 2015 08:00:00 GMT
      summary: OpenAI is a non-profit artificial intelligence research company. Our goal is to advance digital intelligence in
        the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial
        return. Since our research is free from financial obligations, we can better focus on a positive human impact.
      relevanceScore: 75
      topics:
        - agi-development
        - alignment
        - lab-behavior
      entities:
        - agi-development
        - lab-behavior
    - title: Anthropic's Response to Governor Newsom's AI Working Group Draft Report
      url: https://anthropic.com/news/anthropic-s-response-to-governor-newsom-s-ai-working-group-draft-report
      sourceId: anthropic-blog
      publishedAt: 2026-02-19
      summary: ' In this response, Anthropic expressed its belief that powerful AI systems will arrive soon — "perhaps as
        early as the end of 2026" — and emphasized the importance of building a policy regime focused on transparency
        around safety and security protocols.'
      relevanceScore: 75
      topics:
        - agi-timeline
        - regulation-debate
        - policy
      entities:
        - agi-timeline
        - regulation-debate
    - title: "FACTS Benchmark Suite: Systematically evaluating the factuality of large language models"
      url: https://deepmind.google/blog/facts-benchmark-suite-systematically-evaluating-the-factuality-of-large-language-models/
      sourceId: deepmind-blog
      publishedAt: Tue, 09 Dec 2025 11:29:03 +0000
      summary: Systematically evaluating the factuality of large language models with the FACTS Benchmark Suite.
      relevanceScore: 75
      topics:
        - safety-research
        - language-models
        - eval-types-table
      entities:
        - safety-research
        - language-models
        - eval-types-table
    - title: A new era of intelligence with Gemini 3
      url: https://deepmind.google/blog/a-new-era-of-intelligence-with-gemini-3/
      sourceId: deepmind-blog
      publishedAt: Tue, 18 Nov 2025 16:06:41 +0000
      summary: ""
      relevanceScore: 75
      topics:
        - capabilities
        - language-models
        - large-language-models
      entities:
        - large-language-models
        - capabilities
    - title: Gemini Robotics 1.5 brings AI agents into the physical world
      url: https://deepmind.google/blog/gemini-robotics-15-brings-ai-agents-into-the-physical-world/
      sourceId: deepmind-blog
      publishedAt: Thu, 23 Oct 2025 23:33:58 +0000
      summary: We’re powering an era of physical agents — enabling robots to perceive, plan, think, use tools and act to
        better solve complex, multi-step tasks.
      relevanceScore: 75
      topics:
        - agentic-ai
        - tool-use
        - capabilities
      entities:
        - agentic-ai
        - tool-use
        - capabilities
    - title: "VaultGemma: The world's most capable differentially private LLM"
      url: https://deepmind.google/blog/vaultgemma-the-worlds-most-capable-differentially-private-llm/
      sourceId: deepmind-blog
      publishedAt: Thu, 23 Oct 2025 18:42:54 +0000
      summary: We introduce VaultGemma, the most capable model trained from scratch with differential privacy.
      relevanceScore: 75
      topics:
        - differential-privacy
        - language-models
        - safety-research
        - capabilities
      entities:
        - large-language-models
        - safety-research
    - title: Advancing Gemini's security safeguards
      url: https://deepmind.google/blog/advancing-geminis-security-safeguards/
      sourceId: deepmind-blog
      publishedAt: Tue, 20 May 2025 09:45:00 +0000
      summary: We’ve made Gemini 2.5 our most secure model family to date.
      relevanceScore: 75
      topics:
        - safety-research
        - alignment-progress
        - capabilities
      entities:
        - safety-research
        - alignment-progress
        - capabilities
    - title: Our vision for building a universal AI assistant
      url: https://deepmind.google/blog/our-vision-for-building-a-universal-ai-assistant/
      sourceId: deepmind-blog
      publishedAt: Tue, 20 May 2025 09:45:00 +0000
      summary: We’re extending Gemini to become a world model that can make plans and imagine new experiences by simulating
        aspects of the world.
      relevanceScore: 75
      topics:
        - world-models
        - agentic-ai
        - reasoning
        - capabilities
      entities:
        - world-models
        - agentic-ai
        - reasoning
        - capabilities
    - title: Power Laws Are Not Enough
      url: https://www.lesswrong.com/posts/5x54xhX3K2TNY2L3T/power-laws-are-not-enough
      sourceId: lesswrong
      publishedAt: Thu, 19 Feb 2026 04:31:48 GMT
      summary: Published on February 19, 2026 4:31 AM GMTThis is a linkpost for work done as part of MATS 9.0 under the
        mentorship of Richard Ngo. Loss scaling laws are among the most important empirical findings in deep learning.
        This post synthesises evidence that, though important in practice, loss-scaling per se is a straightforward
        consequence of very low-order properties of natural data. The covariance spectrum of natural data generally
        follows a power-law decay - the marginal value of representing the n
      relevanceScore: 75
      topics:
        - scaling-debate
        - capabilities
        - safety-research
      entities:
        - scaling-debate
        - capabilities
    - title: What AI-safely topics are missing from the mainstream media? What underreported but underestimated issues need to
        be addressed? This is your chance to collaborate with filmmakers & have your worries addressed.
      url: https://www.lesswrong.com/posts/GAyD6vHe7bNjq89yz/what-ai-safely-topics-are-missing-from-the-mainstream-media
      sourceId: lesswrong
      publishedAt: Thu, 19 Feb 2026 01:55:47 GMT
      summary: Published on February 19, 2026 1:30 AM GMTWho Let The Docs Out launched their AI Safety Grant yesterday (linked
        here), which was aptly named ‘The Automation & Humanity Documentary Fund’.This granting fund was established to
        provide early-stage research funding ($8,000) to filmmakers creating documentary projects that focus on
        AI-safety; specifically the risks, unintended consequences and the ethical implications of artificial
        intelligence, with a focus on the impacts to animals, humans and our c
      relevanceScore: 75
      topics:
        - safety-research
        - public-opinion
        - governance
      entities:
        - safety-research
        - public-opinion
    - title: "MLSN #18: Adversarial Diffusion, Activation Oracles, Weird Generalization"
      url: https://newsletter.mlsafety.org/p/mlsn-18-adversarial-diffusion-activation
      sourceId: ml-safety-newsletter
      publishedAt: Tue, 20 Jan 2026 17:01:52 GMT
      summary: Diffusion LLMs for Adversarial Attack Generation
      relevanceScore: 75
      topics:
        - adversarial-robustness
        - interpretability
        - safety-research
        - diffusion-models
      entities:
        - safety-research
        - interpretability-sufficient
    - title: "ML Safety Newsletter #16"
      url: https://newsletter.mlsafety.org/p/ml-safety-newsletter-16
      sourceId: ml-safety-newsletter
      publishedAt: Fri, 12 Sep 2025 16:30:32 GMT
      summary: Automated Forecasting, Pretraining Data Filtering, and Security Red Teaming
      relevanceScore: 75
      topics:
        - safety-research
        - forecasting
        - security
        - data-filtering
      entities:
        - safety-research
        - __index__/knowledge-base/forecasting
    - title: "ML Safety Newsletter #12: February 2025"
      url: https://newsletter.mlsafety.org/p/ml-safety-newsletter-12-february
      sourceId: ml-safety-newsletter
      publishedAt: Thu, 27 Feb 2025 22:48:03 GMT
      summary: ML Safety Newsletter Relaunch
      relevanceScore: 75
      topics:
        - safety-research
        - ml-safety
      entities:
        - safety-research
    - title: "ML Safety Newsletter #10"
      url: https://newsletter.mlsafety.org/p/ml-safety-newsletter-10
      sourceId: ml-safety-newsletter
      publishedAt: Wed, 13 Sep 2023 16:57:43 GMT
      summary: Adversarial attacks against language and vision models, improving LLM honesty, and tracing the influence of LLM
        training data
      relevanceScore: 75
      topics:
        - adversarial-robustness
        - language-models
        - interpretability
        - safety-research
      entities:
        - safety-research
        - language-models
        - interpretability-sufficient
    - title: "ML Safety Newsletter #6"
      url: https://newsletter.mlsafety.org/p/ml-safety-newsletter-6
      sourceId: ml-safety-newsletter
      publishedAt: Thu, 13 Oct 2022 14:00:56 GMT
      summary: Transparency survey, provable robustness, models that predict the future
      relevanceScore: 75
      topics:
        - interpretability
        - robustness
        - transparency
        - world-models
      entities:
        - interpretability-sufficient
        - provable-safe
        - world-models
    - title: "ML Safety Newsletter #3"
      url: https://newsletter.mlsafety.org/p/ml-safety-newsletter-3
      sourceId: ml-safety-newsletter
      publishedAt: Tue, 08 Mar 2022 12:00:40 GMT
      summary: Transformer adversarial robustness, fractals, preference learning
      relevanceScore: 75
      topics:
        - adversarial-robustness
        - preference-learning
        - alignment
      entities:
        - why-alignment-hard
    - title: "AI Safety Newsletter #68: Moltbook Exposes Risky AI Behavior"
      url: https://newsletter.safe.ai/p/ai-safety-newsletter-68-moltbook
      sourceId: cais-newsletter
      publishedAt: Mon, 02 Feb 2026 15:37:46 GMT
      summary: "Plus: The Pentagon Accelerates AI and GPT-5.2 solves open mathematics problems."
      relevanceScore: 75
      topics:
        - ai-safety
        - model-behavior
        - frontier-models
        - capabilities
      entities:
        - capabilities
        - frontier-lab-cost-structure
    - title: "AI Safety Newsletter #65: Measuring Automation and Superintelligence Moratorium Letter"
      url: https://newsletter.safe.ai/p/ai-safety-newsletter-65-measuring
      sourceId: cais-newsletter
      publishedAt: Wed, 29 Oct 2025 16:01:51 GMT
      summary: Welcome to the AI Safety Newsletter by the Center for AI Safety. We discuss developments in AI and AI safety.
        No technical background required.
      relevanceScore: 75
      topics:
        - automation
        - superintelligence
        - governance
        - moratorium
      entities:
        - pause-debate
        - agi-development
    - title: "AI Safety Newsletter #61: OpenAI Releases GPT-5"
      url: https://newsletter.safe.ai/p/ai-safety-newsletter-61-openai-releases
      sourceId: cais-newsletter
      publishedAt: Tue, 12 Aug 2025 17:09:49 GMT
      summary: Welcome to the AI Safety Newsletter by the Center for AI Safety. We discuss developments in AI and AI safety.
        No technical background required.
      relevanceScore: 75
      topics:
        - frontier-models
        - capabilities
        - gpt-5
      entities:
        - capabilities
        - frontier-lab-cost-structure
    - title: "AI Safety Newsletter #57: The RAISE Act"
      url: https://newsletter.safe.ai/p/ai-safety-newsletter-57-the-raise
      sourceId: cais-newsletter
      publishedAt: Tue, 17 Jun 2025 16:30:41 GMT
      summary: Welcome to the AI Safety Newsletter by the Center for AI Safety. We discuss developments in AI and AI safety.
        No technical background required.
      relevanceScore: 75
      topics:
        - regulation
        - governance
        - policy
      entities:
        - regulation-debate
    - title: "AI Safety Newsletter #50: AI Action Plan Responses"
      url: https://newsletter.safe.ai/p/ai-safety-newsletter-50-ai-action
      sourceId: cais-newsletter
      publishedAt: Mon, 31 Mar 2025 14:54:12 GMT
      summary: Plus, Detecting Misbehavior in Reasoning Models
      relevanceScore: 75
      topics:
        - governance
        - policy
        - reasoning-models
        - misbehavior-detection
      entities:
        - reasoning
    - title: "Last Week in AI #329 - GPT 5.2, GenAI.mil, Disney in Sora"
      url: https://lastweekin.ai/p/last-week-in-ai-329-gpt-52-genaimil
      sourceId: last-week-in-ai
      publishedAt: Tue, 16 Dec 2025 07:45:13 GMT
      summary: GPT-5.2 is OpenAI&#8217;s latest move in the agentic AI battle, Google is powering a new US military AI
        platform, Trump Moves to Stop States From Regulating AI
      relevanceScore: 75
      topics:
        - agentic-ai
        - capabilities
        - regulation-debate
        - geopolitics
      entities:
        - agentic-ai
        - regulation-debate
        - geopolitics
    - title: Optimization Instability in Autonomous Agentic Workflows for Clinical Symptom Detection
      url: https://arxiv.org/abs/2602.16037
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16037v1 Announce Type: new Abstract: Autonomous agentic workflows that iteratively refine their own
        behavior hold considerable promise, yet their failure modes remain poorly characterized. We investigate
        optimization instability, a phenomenon in which continued autonomous improvement paradoxically degrades
        classifier performance, using Pythia, an open-source framework for automated prompt optimization. Evaluating
        three clinical symptoms with varying prevalence (shortness of breath at "
      relevanceScore: 75
      topics:
        - agentic-ai
        - accident-risks
        - alignment-progress
      entities:
        - agentic-ai
        - accident-risks
    - title: "Toward Scalable Verifiable Reward: Proxy State-Based Evaluation for Multi-turn Tool-Calling LLM Agents"
      url: https://arxiv.org/abs/2602.16246
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16246v1 Announce Type: new Abstract: Interactive large language model (LLM) agents operating via
        multi-turn dialogue and multi-step tool calling are increasingly used in production. Benchmarks for these agents
        must both reliably compare models and yield on-policy training data. Prior agentic benchmarks (e.g., tau-bench,
        tau2-bench, AppWorld) rely on fully deterministic backends, which are costly to build and iterate. We propose
        Proxy State-Based Evaluation, an LLM-driven simulation fr"
      relevanceScore: 75
      topics:
        - agentic-ai
        - alignment-progress
        - tool-use
        - interpretability-sufficient
      entities:
        - agentic-ai
        - alignment-progress
        - tool-use
    - title: Verifiable Semantics for Agent-to-Agent Communication
      url: https://arxiv.org/abs/2602.16424
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16424v1 Announce Type: new Abstract: Multiagent AI systems require consistent communication, but we
        lack methods to verify that agents share the same understanding of the terms used. Natural language is
        interpretable but vulnerable to semantic drift, while learned protocols are efficient but opaque. We propose a
        certification protocol based on the stimulus-meaning model, where agents are tested on shared observable events
        and terms are certified if empirical disagreement falls below a"
      relevanceScore: 75
      topics:
        - agentic-ai
        - alignment-progress
        - interpretability-sufficient
      entities:
        - agentic-ai
        - alignment-progress
    - title: "Recursive language models for jailbreak detection: a procedural defense for tool-augmented agents"
      url: https://arxiv.org/abs/2602.16520
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16520v1 Announce Type: cross Abstract: Jailbreak prompts are a practical and evolving threat to
        large language models (LLMs), particularly in agentic systems that execute tools over untrusted content. Many
        attacks exploit long-context hiding, semantic camouflage, and lightweight obfuscations that can evade
        single-pass guardrails. We present RLM-JB, an end-to-end jailbreak detection framework built on Recursive
        Language Models (RLMs), in which a root model orchestrates a bounded analys"
      relevanceScore: 75
      topics:
        - safety-research
        - misuse-risks
        - agentic-ai
        - tool-use
      entities:
        - safety-research
        - misuse-risks
        - agentic-ai
        - tool-use
    - title: Policy Compiler for Secure Agentic Systems
      url: https://arxiv.org/abs/2602.16708
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16708v1 Announce Type: cross Abstract: LLM-based agents are increasingly being deployed in contexts
        requiring complex authorization policies: customer service protocols, approval workflows, data access
        restrictions, and regulatory compliance. Embedding these policies in prompts provides no enforcement guarantees.
        We present PCAS, a Policy Compiler for Agentic Systems that provides deterministic policy enforcement. Enforcing
        such policies requires tracking information flow across agent"
      relevanceScore: 75
      topics:
        - agentic-ai
        - alignment
        - safety-research
        - deployment-architectures
      entities:
        - agentic-ai
        - deployment-architectures-table
        - safety-research
    - title: Surgical Activation Steering via Generative Causal Mediation
      url: https://arxiv.org/abs/2602.16080
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16080v1 Announce Type: new Abstract: Where should we intervene in a language model (LM) to control
        behaviors that are diffused across many tokens of a long-form response? We introduce Generative Causal Mediation
        (GCM), a procedure for selecting model components, e.g., attention heads, to steer a binary concept (e.g., talk
        in verse vs. talk in prose) from contrastive long-form responses. In GCM, we first construct a dataset of
        contrasting inputs and responses. Then, we quantify how ind"
      relevanceScore: 75
      topics:
        - interpretability
        - mechanistic understanding
        - control
        - steering
      entities:
        - language-models
        - interpretability-sufficient
    - title: "Helpful to a Fault: Measuring Illicit Assistance in Multi-Turn, Multilingual LLM Agents"
      url: https://arxiv.org/abs/2602.16346
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16346v1 Announce Type: new Abstract: LLM-based agents execute real-world workflows via tools and
        memory. These affordances enable ill-intended adversaries to also use these agents to carry out complex misuse
        scenarios. Existing agent misuse benchmarks largely test single-prompt instructions, leaving a gap in measuring
        how agents end up helping with harmful or illegal tasks over multiple turns. We introduce STING (Sequential
        Testing of Illicit N-step Goal execution), an automated red-t"
      relevanceScore: 75
      topics:
        - misuse
        - dual-use
        - agent safety
        - illicit assistance
      entities:
        - agentic-ai
        - language-models
        - misuse-risks
    - title: Mechanistic Indicators of Steering Effectiveness in Large Language Models
      url: https://arxiv.org/abs/2602.01716
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.01716v2 Announce Type: replace Abstract: Activation-based steering enables Large Language Models
        (LLMs) to exhibit targeted behaviors by intervening on intermediate activations without retraining. Despite its
        widespread use, the mechanistic factors that govern when steering succeeds or fails remain poorly understood, as
        prior work has relied primarily on black-box outputs or LLM-based judges. In this study, we investigate whether
        the reliability of steering can be diagnosed using inte"
      relevanceScore: 75
      topics:
        - interpretability
        - steering
        - activation-based-intervention
        - control
      entities:
        - interpretability-sufficient
        - language-models
    - title: Random Scaling of Emergent Capabilities
      url: https://arxiv.org/abs/2502.17356
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: 'arXiv:2502.17356v5 Announce Type: replace Abstract: Language models famously improve under a smooth scaling
        law, but some specific capabilities exhibit sudden breakthroughs in performance. Advocates of "emergence" view
        these capabilities as unlocked at a specific scale, but others attribute breakthroughs to superficial metric
        thresholding effects. We propose that breakthroughs are instead driven by continuous changes in the probability
        distribution of training outcomes when performance is bimoda'
      relevanceScore: 75
      topics:
        - scaling-laws
        - emergent-capabilities
        - language-models
      entities:
        - scaling-debate
        - capabilities
        - language-models
    - title: "AI Safety Newsletter #59: EU Publishes General-Purpose AI Code of Practice"
      url: https://newsletter.safe.ai/p/ai-safety-newsletter-59-eu-publishes
      sourceId: cais-newsletter
      publishedAt: Tue, 15 Jul 2025 18:04:57 GMT
      summary: "Plus: Meta Superintelligence Labs"
      relevanceScore: 74
      topics:
        - governance
        - regulation
        - eu-policy
      entities:
        - regulation-debate
    - title: "AI Safety Newsletter #54: OpenAI Updates Restructure Plan"
      url: https://newsletter.safe.ai/p/ai-safety-newsletter-54-openai-updates
      sourceId: cais-newsletter
      publishedAt: Tue, 13 May 2025 15:52:07 GMT
      summary: Plus, AI Safety Collaboration in Singapore
      relevanceScore: 74
      topics:
        - governance
        - international-coordination
        - ai-safety
      entities:
        - international-coordination-game
    - title: "AI Safety Newsletter #49: Superintelligence Strategy"
      url: https://newsletter.safe.ai/p/ai-safety-newsletter-49-superintelligence
      sourceId: cais-newsletter
      publishedAt: Thu, 06 Mar 2025 16:04:44 GMT
      summary: Plus, Measuring AI Honesty
      relevanceScore: 74
      topics:
        - superintelligence
        - strategy
        - governance
        - honesty
      entities:
        - agi-development
    - title: "AI Safety Newsletter #56: Google Releases Veo 3"
      url: https://newsletter.safe.ai/p/ai-safety-newsletter-56-google-releases
      sourceId: cais-newsletter
      publishedAt: Wed, 28 May 2025 15:02:07 GMT
      summary: Plus, Opus 4 Demonstrates the Fragility of Voluntary Governance
      relevanceScore: 73
      topics:
        - frontier-models
        - governance
        - voluntary-governance
      entities:
        - frontier-lab-cost-structure
    - title: "AI Safety Newsletter #62: Big Tech Launches $100 Million pro-AI Super PAC"
      url: https://newsletter.safe.ai/p/ai-safety-newsletter-62-big-tech
      sourceId: cais-newsletter
      publishedAt: Wed, 27 Aug 2025 16:29:19 GMT
      summary: "Plus: Meta&#8217;s Chatbot Policies Prompt Backlash Amid AI Reorganization; China Reverses Course on Nvidia
        H20 Purchases"
      relevanceScore: 72
      topics:
        - geopolitics
        - compute-hardware
        - policy
        - corporate-behavior
      entities:
        - geopolitics
        - compute-hardware
        - lab-behavior
    - title: "AI Safety Newsletter #58: Senate Removes State AI Regulation Moratorium"
      url: https://newsletter.safe.ai/p/ai-safety-newsletter-58-senate-removes
      sourceId: cais-newsletter
      publishedAt: Thu, 03 Jul 2025 16:23:06 GMT
      summary: "Plus: Judges Split on Whether Training AI on Copyrighted Material is Fair Use"
      relevanceScore: 72
      topics:
        - regulation
        - governance
        - copyright
        - training-data
      entities:
        - regulation-debate
    - title: "AI Safety Newsletter #53: An Open Letter Attempts to Block OpenAI Restructuring"
      url: https://newsletter.safe.ai/p/an-open-letter-attempts-to-block
      sourceId: cais-newsletter
      publishedAt: Tue, 29 Apr 2025 15:11:16 GMT
      summary: Plus, SafeBench Winners
      relevanceScore: 72
      topics:
        - governance
        - corporate-structure
        - safety-culture
      entities:
        - safety-culture-equilibrium
        - lab-behavior
    - title: "Calibrate-Then-Act: Cost-Aware Exploration in LLM Agents"
      url: https://arxiv.org/abs/2602.16699
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16699v1 Announce Type: cross Abstract: LLMs are increasingly being used for complex problems which
        are not necessarily resolved in a single response, but require interacting with an environment to acquire
        information. In these scenarios, LLMs must reason about inherent cost-uncertainty tradeoffs in when to stop
        exploring and commit to an answer. For instance, on a programming task, an LLM should test a generated code
        snippet if it is uncertain about the correctness of that code; the c"
      relevanceScore: 72
      topics:
        - agentic-ai
        - tool-use
        - long-horizon
        - reasoning
      entities:
        - agentic-ai
        - tool-use
        - long-horizon
    - title: "VERA-MH: Reliability and Validity of an Open-Source AI Safety Evaluation in Mental Health"
      url: https://arxiv.org/abs/2602.05088
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.05088v3 Announce Type: replace Abstract: Millions now use generative AI chatbots for psychological
        support. Despite the promise related to availability and scale, the single most pressing question in AI for
        mental health is whether these tools are safe. The Validation of Ethical and Responsible AI in Mental Health
        (VERA-MH) evaluation was recently proposed to meet the urgent need for an evidence-based, automated safety
        benchmark. This study aimed to examine the clinical validity and r"
      relevanceScore: 72
      topics:
        - safety-research
        - misuse-risks
        - eval-types-table
      entities:
        - safety-research
        - misuse-risks
        - eval-types-table
    - title: "PromptGuard: Soft Prompt-Guided Unsafe Content Moderation for Text-to-Image Models"
      url: https://arxiv.org/abs/2501.03544
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2501.03544v4 Announce Type: replace-cross Abstract: Recent text-to-image (T2I) models have exhibited
        remarkable performance in generating high-quality images from text descriptions. However, these models are
        vulnerable to misuse, particularly generating not-safe-for-work (NSFW) content, such as sexually explicit,
        violent, political, and disturbing images, raising serious ethical concerns. In this work, we present
        PromptGuard, a novel content moderation technique that draws inspiration from"
      relevanceScore: 72
      topics:
        - safety-research
        - misuse-risks
        - eval-types-table
      entities:
        - safety-research
        - misuse-risks
        - eval-types-table
    - title: A Content-Based Framework for Cybersecurity Refusal Decisions in Large Language Models
      url: https://arxiv.org/abs/2602.15689
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15689v2 Announce Type: replace-cross Abstract: Large language models and LLM-based agents are
        increasingly used for cybersecurity tasks that are inherently dual-use. Existing approaches to refusal, spanning
        academic policy frameworks and commercially deployed systems, often rely on broad topic-based bans or
        offensive-focused taxonomies. As a result, they can yield inconsistent decisions, over-restrict legitimate
        defenders, and behave brittlely under obfuscation or request segmentation"
      relevanceScore: 72
      topics:
        - safety
        - refusal
        - dual-use
        - cybersecurity
        - LLM alignment
      entities:
        - language-models
        - misuse-risks
        - alignment-progress
    - title: Introducing Trusted Access for Cyber
      url: https://openai.com/index/trusted-access-for-cyber
      sourceId: openai-blog
      publishedAt: Thu, 05 Feb 2026 10:00:00 GMT
      summary: OpenAI introduces Trusted Access for Cyber, a trust-based framework that expands access to frontier cyber
        capabilities while strengthening safeguards against misuse.
      relevanceScore: 70
      topics:
        - safety-research
        - misuse-risks
        - cyberweapons-attack-automation
      entities:
        - misuse-risks
        - cyberweapons-attack-automation
    - title: GPT-5.3-Codex System Card
      url: https://openai.com/index/gpt-5-3-codex-system-card
      sourceId: openai-blog
      publishedAt: Thu, 05 Feb 2026 00:00:00 GMT
      summary: GPT‑5.3-Codex is the most capable agentic coding model to date, combining the frontier coding performance of
        GPT‑5.2-Codex with the reasoning and professional knowledge capabilities of GPT‑5.2.
      relevanceScore: 70
      topics:
        - agentic-ai
        - coding
        - capabilities
      entities:
        - agentic-ai
        - coding
        - capabilities
    - title: OpenAI and SoftBank Group partner with SB Energy
      url: https://openai.com/index/stargate-sb-energy-partnership
      sourceId: openai-blog
      publishedAt: Fri, 09 Jan 2026 11:00:00 GMT
      summary: OpenAI and SoftBank Group partner with SB Energy to develop multi-gigawatt AI data center campuses, including a
        1.2 GW Texas facility supporting the Stargate initiative.
      relevanceScore: 70
      topics:
        - compute-hardware
        - ai-megaproject-infrastructure
        - geopolitics
      entities:
        - compute-hardware
        - ai-megaproject-infrastructure
        - geopolitics
    - title: Continuously hardening ChatGPT Atlas against prompt injection
      url: https://openai.com/index/hardening-atlas-against-prompt-injection
      sourceId: openai-blog
      publishedAt: Mon, 22 Dec 2025 00:00:00 GMT
      summary: OpenAI is strengthening ChatGPT Atlas against prompt injection attacks using automated red teaming trained with
        reinforcement learning. This proactive discover-and-patch loop helps identify novel exploits early and harden
        the browser agent’s defenses as AI becomes more agentic.
      relevanceScore: 70
      topics:
        - safety-research
        - misuse-risks
        - prompt-injection
      entities:
        - safety-research
    - title: Evaluating AI’s ability to perform scientific research tasks
      url: https://openai.com/index/frontierscience
      sourceId: openai-blog
      publishedAt: Tue, 16 Dec 2025 09:00:00 GMT
      summary: OpenAI introduces FrontierScience, a benchmark testing AI reasoning in physics, chemistry, and biology to
        measure progress toward real scientific research.
      relevanceScore: 70
      topics:
        - capabilities
        - scientific-research
        - reasoning
      entities:
        - capabilities
        - scientific-research
        - reasoning
    - title: Advancing science and math with GPT-5.2
      url: https://openai.com/index/gpt-5-2-for-science-and-math
      sourceId: openai-blog
      publishedAt: Thu, 11 Dec 2025 10:00:00 GMT
      summary: GPT-5.2 is OpenAI’s strongest model yet for math and science, setting new state-of-the-art results on
        benchmarks like GPQA Diamond and FrontierMath. This post shows how those gains translate into real research
        progress, including solving an open theoretical problem and generating reliable mathematical proofs.
      relevanceScore: 70
      topics:
        - capabilities
        - scientific-research
        - reasoning
      entities:
        - capabilities
        - scientific-research
        - reasoning
    - title: OpenAI co-founds Agentic AI Foundation, donates AGENTS.md
      url: https://openai.com/index/agentic-ai-foundation
      sourceId: openai-blog
      publishedAt: Tue, 09 Dec 2025 09:00:00 GMT
      summary: OpenAI co-founds the Agentic AI Foundation under the Linux Foundation and donates AGENTS.md to support open,
        interoperable standards for safe agentic AI.
      relevanceScore: 70
      topics:
        - agentic-ai
        - safety-research
        - alignment-progress
      entities:
        - agentic-ai
        - safety-research
        - alignment-progress
    - title: OpenAI to acquire Neptune
      url: https://openai.com/index/openai-to-acquire-neptune
      sourceId: openai-blog
      publishedAt: Wed, 03 Dec 2025 10:00:00 GMT
      summary: OpenAI is acquiring Neptune to deepen visibility into model behavior and strengthen the tools researchers use
        to track experiments and monitor training.
      relevanceScore: 70
      topics:
        - interpretability-sufficient
        - safety-research
        - lab-behavior
      entities:
        - __index__/knowledge-base/capabilities
    - title: How evals drive the next chapter in AI for businesses
      url: https://openai.com/index/evals-drive-next-chapter-of-ai
      sourceId: openai-blog
      publishedAt: Wed, 19 Nov 2025 11:00:00 GMT
      summary: Learn how evals help businesses define, measure, and improve AI performance—reducing risk, boosting
        productivity, and driving strategic advantage.
      relevanceScore: 70
      topics:
        - eval-types-table
        - safety-research
        - alignment-progress
      entities:
        - __index__/knowledge-base/models
    - title: "Notion’s rebuild for agentic AI: How GPT‑5 helped unlock autonomous workflows"
      url: https://openai.com/index/notion
      sourceId: openai-blog
      publishedAt: Fri, 07 Nov 2025 10:00:00 GMT
      summary: Discover how Notion rebuilt its AI architecture with GPT-5 to create autonomous agents that reason, act, and
        adapt across workflows. Learn how this shift unlocked smarter, faster, and more flexible productivity in Notion
        3.0.
      relevanceScore: 70
      topics:
        - agentic-ai
        - autonomous-agents
        - tool-use
        - reasoning
      entities:
        - agentic-ai
        - tool-use
        - reasoning
    - title: Expanding Stargate to Michigan
      url: https://openai.com/index/expanding-stargate-to-michigan
      sourceId: openai-blog
      publishedAt: Thu, 30 Oct 2025 13:30:00 GMT
      summary: OpenAI is expanding Stargate to Michigan with a new one-gigawatt campus that strengthens America’s AI
        infrastructure. The project will create jobs, drive investment, and support economic growth across the Midwest.
      relevanceScore: 70
      topics:
        - compute-hardware
        - infrastructure
        - ai-megaproject-infrastructure
      entities:
        - compute-hardware
        - ai-megaproject-infrastructure
    - title: Doppel’s AI defense system stops attacks before they spread
      url: https://openai.com/index/doppel
      sourceId: openai-blog
      publishedAt: Tue, 28 Oct 2025 10:00:00 GMT
      summary: Discover how Doppel uses OpenAI’s GPT-5 and reinforcement fine-tuning (RFT) to stop deepfake and impersonation
        attacks before they spread, cutting analyst workloads by 80% and reducing threat response from hours to minutes.
      relevanceScore: 70
      topics:
        - security
        - deepfakes
        - misuse-risks
        - adversarial-attacks
      entities:
        - misuse-risks
    - title: Strengthening ChatGPT’s responses in sensitive conversations
      url: https://openai.com/index/strengthening-chatgpt-responses-in-sensitive-conversations
      sourceId: openai-blog
      publishedAt: Mon, 27 Oct 2025 10:00:00 GMT
      summary: OpenAI collaborated with 170+ mental health experts to improve ChatGPT’s ability to recognize distress, respond
        empathetically, and guide users toward real-world support—reducing unsafe responses by up to 80%. Learn how
        we’re making ChatGPT safer and more supportive in sensitive moments.
      relevanceScore: 70
      topics:
        - safety-research
        - alignment-progress
        - misuse-risks
        - mental-health-safety
      entities:
        - language-models
        - safety-research
    - title: Defining and evaluating political bias in LLMs
      url: https://openai.com/index/defining-and-evaluating-political-bias-in-llms
      sourceId: openai-blog
      publishedAt: Thu, 09 Oct 2025 13:00:00 GMT
      summary: Learn how OpenAI evaluates political bias in ChatGPT through new real-world testing methods that improve
        objectivity and reduce bias.
      relevanceScore: 70
      topics:
        - safety-research
        - alignment-progress
        - epistemic-risks
      entities:
        - safety-research
        - epistemic-risks
    - title: Sora 2 System Card
      url: https://openai.com/index/sora-2-system-card
      sourceId: openai-blog
      publishedAt: Tue, 30 Sep 2025 00:00:00 GMT
      summary: Sora 2 is our new state of the art video and audio generation model. Building on the foundation of Sora, this
        new model introduces capabilities that have been difficult for prior video models to achieve– such as more
        accurate physics, sharper realism, synchronized audio, enhanced steerability, and an expanded stylistic range.
      relevanceScore: 70
      topics:
        - safety-research
        - alignment-progress
        - capabilities
      entities:
        - safety-research
        - capabilities
    - title: Working with US CAISI and UK AISI to build more secure AI systems
      url: https://openai.com/index/us-caisi-uk-aisi-ai-update
      sourceId: openai-blog
      publishedAt: Fri, 12 Sep 2025 12:00:00 GMT
      summary: OpenAI shares progress on the partnership with the US CAISI and UK AISI to strengthen AI safety and security.
      relevanceScore: 70
      topics:
        - safety-research
        - regulation-debate
        - alignment-progress
      entities:
        - safety-research
        - regulation-debate
        - alignment-progress
    - title: Shipping smarter agents with every new model
      url: https://openai.com/index/safetykit
      sourceId: openai-blog
      publishedAt: Tue, 09 Sep 2025 10:00:00 GMT
      summary: Discover how SafetyKit leverages OpenAI GPT-5 to enhance content moderation, enforce compliance, and outpace
        legacy safety systems with greater accuracy .
      relevanceScore: 70
      topics:
        - safety
        - content-moderation
        - capabilities
        - language-models
      entities:
        - language-models
        - safety-research
        - capabilities
    - title: Helping people when they need it most
      url: https://openai.com/index/helping-people-when-they-need-it-most
      sourceId: openai-blog
      publishedAt: Tue, 26 Aug 2025 04:00:00 GMT
      summary: How we think about safety for users experiencing mental or emotional distress, the limits of today’s systems,
        and the work underway to refine them.
      relevanceScore: 70
      topics:
        - safety
        - mental-health
        - user-protection
        - limitations
      entities:
        - safety-research
        - accident-risks
    - title: GPT-5 System Card
      url: https://openai.com/index/gpt-5-system-card
      sourceId: openai-blog
      publishedAt: Thu, 07 Aug 2025 00:00:00 GMT
      summary: This GPT-5 system card explains how a unified model routing system powers fast and smart responses using
        gpt-5-main, gpt-5-thinking, and lightweight versions like gpt-5-thinking-nano, optimized for different tasks and
        developer use.
      relevanceScore: 70
      topics:
        - safety
        - system-card
        - model-architecture
        - capabilities
      entities:
        - language-models
        - capabilities
        - safety-research
    - title: Introducing ChatGPT agent
      url: https://openai.com/index/introducing-chatgpt-agent
      sourceId: openai-blog
      publishedAt: Thu, 17 Jul 2025 10:00:00 GMT
      summary: "Introducing ChatGPT agent: it thinks and acts, using tools to complete tasks like research, bookings, and
        slideshows—all with your guidance."
      relevanceScore: 70
      topics:
        - agentic-ai
        - tool-use
        - long-horizon
        - capabilities
      entities:
        - agentic-ai
        - tool-use
        - long-horizon
    - title: Introducing OpenAI o3 and o4-mini
      url: https://openai.com/index/introducing-o3-and-o4-mini
      sourceId: openai-blog
      publishedAt: Wed, 16 Apr 2025 10:00:00 GMT
      summary: Our smartest and most capable models to date with full tool access
      relevanceScore: 70
      topics:
        - capabilities
        - reasoning
        - agentic-ai
        - tool-use
      entities:
        - reasoning
        - tool-use
        - agentic-ai
        - capabilities
    - title: "BrowseComp: a benchmark for browsing agents"
      url: https://openai.com/index/browsecomp
      sourceId: openai-blog
      publishedAt: Thu, 10 Apr 2025 10:00:00 GMT
      summary: "BrowseComp: a benchmark for browsing agents."
      relevanceScore: 70
      topics:
        - agentic-ai
        - evaluation
        - benchmarking
      entities:
        - agentic-ai
        - eval-types-table
    - title: New commission to provide insight as OpenAI builds the world’s best-equipped nonprofit
      url: https://openai.com/index/nonprofit-commission-guidance
      sourceId: openai-blog
      publishedAt: Wed, 02 Apr 2025 12:00:00 GMT
      summary: "Already a nonprofit, and already using AI to help people solve hard problems, OpenAI aims to build the
        best-equipped nonprofit the world has ever seen—combining potentially historic financial resources with
        something even more powerful: technology that can scale human ingenuity itself."
      relevanceScore: 70
      topics:
        - governance
        - nonprofit-structure
        - organizational-alignment
      entities:
        - anthropic-impact
    - title: Detecting misbehavior in frontier reasoning models
      url: https://openai.com/index/chain-of-thought-monitoring
      sourceId: openai-blog
      publishedAt: Mon, 10 Mar 2025 10:00:00 GMT
      summary: Frontier reasoning models exploit loopholes when given the chance. We show we can detect exploits using an LLM
        to monitor their chains-of-thought. Penalizing their “bad thoughts” doesn’t stop the majority of misbehavior—it
        makes them hide their intent.
      relevanceScore: 70
      topics:
        - safety-research
        - interpretability
        - misalignment
        - reasoning
      entities:
        - interpretability-sufficient
        - reasoning
        - safety-research
    - title: OpenAI o3-mini
      url: https://openai.com/index/openai-o3-mini
      sourceId: openai-blog
      publishedAt: Fri, 31 Jan 2025 11:00:00 GMT
      summary: Pushing the frontier of cost-effective reasoning.
      relevanceScore: 70
      topics:
        - reasoning
        - capabilities
        - compute-hardware
      entities:
        - reasoning
        - capabilities
    - title: Computer-Using Agent
      url: https://openai.com/index/computer-using-agent
      sourceId: openai-blog
      publishedAt: Thu, 23 Jan 2025 10:00:00 GMT
      summary: A universal interface for AI to interact with the digital world.
      relevanceScore: 70
      topics:
        - agentic-ai
        - tool-use
        - capabilities
      entities:
        - agentic-ai
        - tool-use
    - title: OpenAI o1 and new tools for developers
      url: https://openai.com/index/o1-and-new-tools-for-developers
      sourceId: openai-blog
      publishedAt: Tue, 17 Dec 2024 00:00:00 GMT
      summary: Introducing OpenAI o1, Realtime API improvements, a new fine-tuning method and more for developers.
      relevanceScore: 70
      topics:
        - reasoning
        - capabilities
        - tool-use
      entities:
        - reasoning
        - capabilities
        - tool-use
    - title: OpenAI’s comments to the NTIA on data center growth, resilience, and security
      url: https://openai.com/global-affairs/comments-to-the-ntia-on-data-center-growth-resilience-and-security
      sourceId: openai-blog
      publishedAt: Mon, 04 Nov 2024 12:00:00 GMT
      summary: This comment was submitted in response to a request for information from the National Telecommunications and
        Information Administration (NTIA).
      relevanceScore: 70
      topics:
        - compute-hardware
        - infrastructure
        - governance
        - policy
      entities:
        - compute-hardware
        - ai-megaproject-infrastructure
    - title: Solving complex problems with OpenAI o1 models
      url: https://openai.com/business/solving-complex-problems-with-openai-o1-models
      sourceId: openai-blog
      publishedAt: Thu, 17 Oct 2024 00:00:00 GMT
      summary: In this video, we share how the o1 reasoning models can help in domains like coding, strategy, and research.
      relevanceScore: 70
      topics:
        - capabilities
        - reasoning
        - agentic-ai
        - tool-use
      entities:
        - reasoning
        - agentic-ai
        - tool-use
    - title: "MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering"
      url: https://openai.com/index/mle-bench
      sourceId: openai-blog
      publishedAt: Thu, 10 Oct 2024 10:00:00 GMT
      summary: We introduce MLE-bench, a benchmark for measuring how well AI agents perform at machine learning engineering.
      relevanceScore: 70
      topics:
        - agentic-ai
        - benchmarking
        - capabilities
        - eval-types
      entities:
        - agentic-ai
        - eval-types-table
    - title: Upgrading the Moderation API with our new multimodal moderation model
      url: https://openai.com/index/upgrading-the-moderation-api-with-our-new-multimodal-moderation-model
      sourceId: openai-blog
      publishedAt: Thu, 26 Sep 2024 10:00:00 GMT
      summary: We’re introducing a new model built on GPT-4o that is more accurate at detecting harmful text and images,
        enabling developers to build more robust moderation systems.
      relevanceScore: 70
      topics:
        - safety-research
        - misuse-risks
        - solutions
      entities:
        - safety-research
        - misuse-risks
        - solutions
    - title: Zico Kolter Joins OpenAI’s Board of Directors
      url: https://openai.com/index/zico-kolter-joins-openais-board-of-directors
      sourceId: openai-blog
      publishedAt: Thu, 08 Aug 2024 12:00:00 GMT
      summary: Zico Kolter Joins OpenAI’s Board of Directors We’re strengthening our governance with expertise in AI safety
        and alignment. Zico will also join the Safety & Security Committee
      relevanceScore: 70
      topics:
        - governance
        - safety
        - alignment
        - lab-behavior
      entities:
        - lab-behavior
        - alignment-progress
    - title: Improving Model Safety Behavior with Rule-Based Rewards
      url: https://openai.com/index/improving-model-safety-behavior-with-rule-based-rewards
      sourceId: openai-blog
      publishedAt: Wed, 24 Jul 2024 09:00:00 GMT
      summary: We've developed and applied a new method leveraging Rule-Based Rewards (RBRs) that aligns models to behave
        safely without extensive human data collection.
      relevanceScore: 70
      topics:
        - alignment
        - safety
        - training-methods
        - reward-modeling
      entities:
        - alignment-progress
        - safety-research
    - title: OpenAI appoints Retired U.S. Army General Paul M. Nakasone to Board of Directors
      url: https://openai.com/index/openai-appoints-retired-us-army-general
      sourceId: openai-blog
      publishedAt: Thu, 13 Jun 2024 14:00:00 GMT
      summary: Nakasone brings cybersecurity experience to growing Board of Directors; will join the Board’s Safety and
        Security Committee
      relevanceScore: 70
      topics:
        - lab-behavior
        - governance
        - safety-research
      entities:
        - lab-behavior
    - title: OpenAI safety practices
      url: https://openai.com/index/openai-safety-update
      sourceId: openai-blog
      publishedAt: Tue, 21 May 2024 06:00:00 GMT
      summary: Artificial general intelligence has the potential to benefit nearly every aspect of our lives—so it must be
        developed and deployed responsibly.
      relevanceScore: 70
      topics:
        - safety-research
        - alignment-progress
        - governance
      entities:
        - safety-research
        - alignment-progress
    - title: "The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions"
      url: https://openai.com/index/the-instruction-hierarchy
      sourceId: openai-blog
      publishedAt: Fri, 19 Apr 2024 19:00:00 GMT
      summary: Today's LLMs are susceptible to prompt injections, jailbreaks, and other attacks that allow adversaries to
        overwrite a model's original instructions with their own malicious prompts.
      relevanceScore: 70
      topics:
        - safety-research
        - misuse-risks
        - interpretability
        - prompt-injection
      entities:
        - misuse-risks
    - title: "Democratic inputs to AI grant program: lessons learned and implementation plans"
      url: https://openai.com/index/democratic-inputs-to-ai-grant-program-update
      sourceId: openai-blog
      publishedAt: Tue, 16 Jan 2024 08:00:00 GMT
      summary: We funded 10 teams from around the world to design ideas and tools to collectively govern AI. We summarize the
        innovations, outline our learnings, and call for researchers and engineers to join us as we continue this work.
      relevanceScore: 70
      topics:
        - governance
        - solutions
      entities:
        - governance
        - solutions
    - title: "Confidence-Building Measures for Artificial Intelligence: Workshop proceedings"
      url: https://openai.com/index/confidence-building-measures-for-artificial-intelligence
      sourceId: openai-blog
      publishedAt: Tue, 01 Aug 2023 07:00:00 GMT
      summary: ""
      relevanceScore: 70
      topics:
        - safety-research
        - alignment-progress
      entities:
        - safety-research
    - title: Improving mathematical reasoning with process supervision
      url: https://openai.com/index/improving-mathematical-reasoning-with-process-supervision
      sourceId: openai-blog
      publishedAt: Wed, 31 May 2023 07:00:00 GMT
      summary: "We've trained a model to achieve a new state-of-the-art in mathematical problem solving by rewarding each
        correct step of reasoning (“process supervision”) instead of simply rewarding the correct final answer (“outcome
        supervision”). In addition to boosting performance relative to outcome supervision, process supervision also has
        an important alignment benefit: it directly trains the model to produce a chain-of-thought that is endorsed by
        humans."
      relevanceScore: 70
      topics:
        - safety-research
        - alignment-progress
        - reasoning
      entities:
        - safety-research
    - title: "GPTs are GPTs: An early look at the labor market impact potential of large language models"
      url: https://openai.com/index/gpts-are-gpts
      sourceId: openai-blog
      publishedAt: Fri, 17 Mar 2023 07:00:00 GMT
      summary: ""
      relevanceScore: 70
      topics:
        - labor-impact
        - economic-impact
        - capabilities
      entities:
        - economic-labor
        - capabilities
    - title: Reducing bias and improving safety in DALL·E 2
      url: https://openai.com/index/reducing-bias-and-improving-safety-in-dall-e-2
      sourceId: openai-blog
      publishedAt: Mon, 18 Jul 2022 07:00:00 GMT
      summary: Today, we are implementing a new technique so that DALL·E generates images of people that more accurately
        reflect the diversity of the world’s population.
      relevanceScore: 70
      topics:
        - safety-research
        - misuse-risks
        - accident-risks
      entities:
        - safety-research
        - misuse-risks
    - title: Best practices for deploying language models
      url: https://openai.com/index/best-practices-for-deploying-language-models
      sourceId: openai-blog
      publishedAt: Thu, 02 Jun 2022 07:00:00 GMT
      summary: Cohere, OpenAI, and AI21 Labs have developed a preliminary set of best practices applicable to any organization
        developing or deploying large language models.
      relevanceScore: 70
      topics:
        - safety-research
        - deployment-architectures-table
        - lab-behavior
      entities:
        - safety-research
        - deployment-architectures-table
    - title: Teaching models to express their uncertainty in words
      url: https://openai.com/index/teaching-models-to-express-their-uncertainty-in-words
      sourceId: openai-blog
      publishedAt: Sat, 28 May 2022 07:00:00 GMT
      summary: ""
      relevanceScore: 70
      topics:
        - alignment-progress
        - safety-research
        - epistemic-risks
      entities:
        - alignment-progress
        - safety-research
    - title: Summarizing books with human feedback
      url: https://openai.com/index/summarizing-books
      sourceId: openai-blog
      publishedAt: Thu, 23 Sep 2021 07:00:00 GMT
      summary: Scaling human oversight of AI systems for tasks that are difficult to evaluate.
      relevanceScore: 70
      topics:
        - alignment-progress
        - safety-research
        - interpretability-sufficient
      entities:
        - alignment-progress
        - safety-research
    - title: Learning to summarize with human feedback
      url: https://openai.com/index/learning-to-summarize-with-human-feedback
      sourceId: openai-blog
      publishedAt: Fri, 04 Sep 2020 07:00:00 GMT
      summary: We’ve applied reinforcement learning from human feedback to train language models that are better at
        summarization.
      relevanceScore: 70
      topics:
        - alignment-progress
        - safety-research
        - interpretability-sufficient
      entities:
        - alignment-progress
        - safety-research
    - title: Scaling laws for neural language models
      url: https://openai.com/index/scaling-laws-for-neural-language-models
      sourceId: openai-blog
      publishedAt: Thu, 23 Jan 2020 08:00:00 GMT
      summary: ""
      relevanceScore: 70
      topics:
        - scaling-laws
        - capabilities
        - forecasting
      entities:
        - scaling-debate
        - __index__/knowledge-base/forecasting
    - title: Emergent tool use from multi-agent interaction
      url: https://openai.com/index/emergent-tool-use
      sourceId: openai-blog
      publishedAt: Tue, 17 Sep 2019 07:00:00 GMT
      summary: We’ve observed agents discovering progressively more complex tool use while playing a simple game of
        hide-and-seek. Through training in our new simulated hide-and-seek environment, agents build a series of six
        distinct strategies and counterstrategies, some of which we did not know our environment supported. The
        self-supervised emergent complexity in this simple environment further suggests that multi-agent co-adaptation
        may one day produce extremely complex and intelligent behavior.
      relevanceScore: 70
      topics:
        - emergent-behavior
        - multi-agent
        - tool-use
        - capabilities
      entities:
        - tool-use
        - emergent-behavior
    - title: Microsoft invests in and partners with OpenAI to support us building beneficial AGI
      url: https://openai.com/index/microsoft-invests-in-and-partners-with-openai
      sourceId: openai-blog
      publishedAt: Mon, 22 Jul 2019 07:00:00 GMT
      summary: Microsoft is investing $1 billion in OpenAI to support us building artificial general intelligence (AGI) with
        widely distributed economic benefits. We’re partnering to develop a hardware and software platform within
        Microsoft Azure which will scale to AGI. We’ll jointly develop new Azure AI supercomputing technologies, and
        Microsoft will become our exclusive cloud provider—so we’ll be working hard together to further extend Microsoft
        Azure’s capabilities in large-scale AI systems.
      relevanceScore: 70
      topics:
        - agi-development
        - compute-hardware
        - lab-behavior
      entities:
        - agi-development
        - compute-hardware
        - anthropic-impact
    - title: Transfer of adversarial robustness between perturbation types
      url: https://openai.com/index/transfer-of-adversarial-robustness-between-perturbation-types
      sourceId: openai-blog
      publishedAt: Fri, 03 May 2019 07:00:00 GMT
      summary: ""
      relevanceScore: 70
      topics:
        - adversarial-robustness
        - safety-research
      entities:
        - safety-research
    - title: Better language models and their implications
      url: https://openai.com/index/better-language-models
      sourceId: openai-blog
      publishedAt: Thu, 14 Feb 2019 08:00:00 GMT
      summary: We’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves
        state-of-the-art performance on many language modeling benchmarks, and performs rudimentary reading
        comprehension, machine translation, question answering, and summarization—all without task-specific training.
      relevanceScore: 70
      topics:
        - language-models
        - capabilities
        - scaling
      entities:
        - language-models
        - capabilities
    - title: Interpretable machine learning through teaching
      url: https://openai.com/index/interpretable-machine-learning-through-teaching
      sourceId: openai-blog
      publishedAt: Thu, 15 Feb 2018 08:00:00 GMT
      summary: We’ve designed a method that encourages AIs to teach each other with examples that also make sense to humans.
        Our approach automatically selects the most informative examples to teach a concept—for instance, the best
        images to describe the concept of dogs—and experimentally we found our approach to be effective at teaching both
        AIs
      relevanceScore: 70
      topics:
        - interpretability-sufficient
        - alignment-progress
        - safety-research
      entities:
        - interpretability-sufficient
        - alignment-progress
    - title: Dota 2
      url: https://openai.com/index/dota-2
      sourceId: openai-blog
      publishedAt: Fri, 11 Aug 2017 07:00:00 GMT
      summary: We’ve created a bot which beats the world’s top professionals at 1v1 matches of Dota 2 under standard
        tournament rules. The bot learned the game from scratch by self-play, and does not use imitation learning or
        tree search. This is a step towards building AI systems which accomplish well-defined goals in messy,
        complicated situations involving real humans.
      relevanceScore: 70
      topics:
        - self-play
        - game-playing
        - superhuman-performance
        - capabilities
      entities:
        - capabilities
        - compute-hardware
    - title: Expanding Our Use of Google Cloud TPUs and Services
      url: https://www.anthropic.com/news/expanding-our-use-of-google-cloud-tpus-and-services
      sourceId: anthropic-blog
      publishedAt: 2026-02-19
      summary: " Anthropic announced plans to expand its use of Google Cloud technologies, including up to one million TPUs —
        an expansion worth tens of billions of dollars expected to bring well over a gigawatt of capacity online in
        2026."
      relevanceScore: 70
      topics:
        - compute-hardware
        - ai-megaproject-infrastructure
        - frontier-lab-cost-structure
      entities:
        - compute-hardware
        - ai-megaproject-infrastructure
        - frontier-lab-cost-structure
    - title: Introducing the Anthropic National Security and Public Sector Advisory Council
      url: https://www.anthropic.com/news/introducing-the-anthropic-national-security-and-public-sector-advisory-council
      sourceId: anthropic-blog
      publishedAt: 2026-02-19
      summary: This announcement introduces a new advisory council, as part of Anthropic's broader mission to build reliable,
        interpretable, and steerable AI systems for national security and public sector applications. > ⚠️ **Note:** I
        used the search query you provided as closely as possible, but please be aware that standard web search engines
        (including the one powering this tool) do not support the `site:` operator or `OR` boolean logic in the same way
        a direct Google search would. The results above are t
      relevanceScore: 70
      topics:
        - alignment
        - interpretability
        - national-security
      entities:
        - alignment
        - interpretability-sufficient
    - title: Strengthening our partnership with the UK government to support prosperity and security in the AI era
      url: https://deepmind.google/blog/strengthening-our-partnership-with-the-uk-government-to-support-prosperity-and-security-in-the-ai-era/
      sourceId: deepmind-blog
      publishedAt: Wed, 10 Dec 2025 14:59:21 +0000
      summary: Deepening our partnership with the UK government to support prosperity and security in the AI era
      relevanceScore: 70
      topics:
        - governance
        - geopolitics
        - safety-research
      entities:
        - geopolitics
        - safety-research
    - title: "SIMA 2: An Agent that Plays, Reasons, and Learns With You in Virtual 3D Worlds"
      url: https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/
      sourceId: deepmind-blog
      publishedAt: Thu, 13 Nov 2025 14:52:18 +0000
      summary: Introducing SIMA 2, a Gemini-powered AI agent that can think, understand, and take actions in interactive
        environments.
      relevanceScore: 70
      topics:
        - agentic-ai
        - reasoning
        - tool-use
        - long-horizon
      entities:
        - agentic-ai
        - reasoning
        - tool-use
        - long-horizon
    - title: Advanced version of Gemini with Deep Think officially achieves gold-medal standard at the International
        Mathematical Olympiad
      url: https://deepmind.google/blog/advanced-version-of-gemini-with-deep-think-officially-achieves-gold-medal-standard-at-the-international-mathematical-olympiad/
      sourceId: deepmind-blog
      publishedAt: Fri, 24 Oct 2025 03:12:29 +0000
      summary: The International Mathematical Olympiad (“IMO”) is the world’s most prestigious competition for young
        mathematicians, and has been held annually since 1959. Each country taking part is represented by six elite,
        pre-university mathematicians who compete to solve six exceptionally difficult problems in algebra,
        combinatorics, geometry, and number theory.
      relevanceScore: 70
      topics:
        - reasoning
        - capabilities
      entities:
        - reasoning
        - capabilities
    - title: Gemini achieves gold-medal level at the International Collegiate Programming Contest World Finals
      url: https://deepmind.google/blog/gemini-achieves-gold-medal-level-at-the-international-collegiate-programming-contest-world-finals/
      sourceId: deepmind-blog
      publishedAt: Fri, 24 Oct 2025 00:22:10 +0000
      summary: Gemini 2.5 Deep Think achieves breakthrough performance at the world’s most prestigious computer programming
        competition, demonstrating a profound leap in abstract problem solving.
      relevanceScore: 70
      topics:
        - reasoning
        - capabilities
        - coding
      entities:
        - reasoning
        - capabilities
        - coding
    - title: Rethinking how we measure AI intelligence
      url: https://deepmind.google/blog/rethinking-how-we-measure-ai-intelligence/
      sourceId: deepmind-blog
      publishedAt: Thu, 23 Oct 2025 18:52:06 +0000
      summary: Game Arena is a new, open-source platform for rigorous evaluation of AI models. It allows for head-to-head
        comparison of frontier systems in environments with clear winning conditions.
      relevanceScore: 70
      topics:
        - eval-types-table
        - capabilities
      entities:
        - eval-types-table
        - capabilities
    - title: Gemini Robotics On-Device brings AI to local robotic devices
      url: https://deepmind.google/blog/gemini-robotics-on-device-brings-ai-to-local-robotic-devices/
      sourceId: deepmind-blog
      publishedAt: Tue, 24 Jun 2025 14:00:00 +0000
      summary: We’re introducing an efficient, on-device robotics model with general-purpose dexterity and fast task adaptation.
      relevanceScore: 70
      topics:
        - robotics
        - agentic-ai
        - autonomous-systems
        - capabilities
      entities:
        - agentic-ai
        - capabilities
    - title: SynthID Detector — a new portal to help identify AI-generated content
      url: https://deepmind.google/blog/synthid-detector--a-new-portal-to-help-identify-ai-generated-content/
      sourceId: deepmind-blog
      publishedAt: Tue, 20 May 2025 09:45:00 +0000
      summary: Learn about the new SynthID Detector portal we announced at I/O to help people understand how the content they
        see online was generated.
      relevanceScore: 70
      topics:
        - deepfakes-authentication-crisis
        - misuse-risks
        - safety-research
      entities:
        - deepfakes-authentication-crisis
        - misuse-risks
        - safety-research
    - title: "AlphaEvolve: A Gemini-powered coding agent for designing advanced algorithms"
      url: https://deepmind.google/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/
      sourceId: deepmind-blog
      publishedAt: Wed, 14 May 2025 14:59:00 +0000
      summary: New AI agent evolves algorithms for math and practical applications in computing by combining the creativity of
        large language models with automated evaluators
      relevanceScore: 70
      topics:
        - agentic-ai
        - coding
        - reasoning
        - capabilities
      entities:
        - agentic-ai
        - coding
        - reasoning
        - capabilities
    - title: "Gemini 2.5: Our most intelligent AI model"
      url: https://deepmind.google/blog/gemini-2-5-our-most-intelligent-ai-model/
      sourceId: deepmind-blog
      publishedAt: Tue, 25 Mar 2025 17:00:36 +0000
      summary: Gemini 2.5 is our most intelligent AI model, now with thinking built in.
      relevanceScore: 70
      topics:
        - language-models
        - reasoning
        - capabilities
      entities:
        - language-models
        - reasoning
        - capabilities
    - title: Gemini Robotics brings AI into the physical world
      url: https://deepmind.google/blog/gemini-robotics-brings-ai-into-the-physical-world/
      sourceId: deepmind-blog
      publishedAt: Wed, 12 Mar 2025 15:00:00 +0000
      summary: Introducing Gemini Robotics and Gemini Robotics-ER, AI models designed for robots to understand, act and react
        to the physical world.
      relevanceScore: 70
      topics:
        - robotics
        - agentic-ai
        - autonomous-systems
        - capabilities
      entities:
        - agentic-ai
        - capabilities
    - title: "FACTS Grounding: A new benchmark for evaluating the factuality of large language models"
      url: https://deepmind.google/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/
      sourceId: deepmind-blog
      publishedAt: Tue, 17 Dec 2024 15:29:00 +0000
      summary: Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground
        their responses in provided source material and avoid hallucinations
      relevanceScore: 70
      topics:
        - safety-research
        - interpretability
        - language-models
        - epistemic-risks
      entities:
        - language-models
        - epistemic-risks
    - title: "Connect 2024: The Responsible Approach We're Taking to Generative AI"
      url: https://ai.meta.com/blog/responsible-ai-connect-2024/
      sourceId: meta-ai-blog
      publishedAt: 2026-02-19
      summary: Discusses Meta's commitment to transparency in the rapidly evolving AI landscape, emphasizing the importance of
        sharing their responsibility and safety approach with everyone. > **Note:** The search query
        `site:ai.meta.com/blog 2026` was executed as requested. However, the results returned are primarily from
        **2024–2025**, as the search engine's index may not yet have surfaced many posts explicitly dated 2026 from that
        domain. The results above are the most relevant ones returned. You may want t
      relevanceScore: 70
      topics:
        - safety-research
        - alignment
        - governance
      entities:
        - solutions
        - structural-risks
    - title: Does GPT-2 Represent Controversy? A Small Mech Interp Investigation
      url: https://www.lesswrong.com/posts/JNjXRBCQJ8RAuqw9n/does-gpt-2-represent-controversy-a-small-mech-interp
      sourceId: lesswrong
      publishedAt: Thu, 19 Feb 2026 01:58:23 GMT
      summary: Published on February 19, 2026 1:36 AM GMTIn thinking about how RLHF-trained models clearly hedge on
        politically controversial topics, I started wondering about if LLMs would encode these politically controversial
        topics differently than topics that are broadly considered controversial but not political. And if they do, to
        understand if the signal is already represented in the base model, or if alignment training may be
        creating/amplifying it.To test this, I assembled a list of 20 prompts, all s
      relevanceScore: 70
      topics:
        - interpretability
        - language-models
        - safety-research
      entities:
        - language-models
        - safety-research
    - title: What to do in a vulnerable universe
      url: https://forum.effectivealtruism.org/posts/N33yGcFsZJnEboSkg/what-to-do-in-a-vulnerable-universe-1
      sourceId: ea-forum
      publishedAt: Thu, 19 Feb 2026 04:58:00 GMT
      summary: 'Published on February 19, 2026 4:58 AM GMTIntroduction to the Vulnerable Universe HypothesisI previously wrote
        about "galactic x-risks" and cautioned on the long-term consequences of interstellar travel on the EA forum in a
        post called “Interstellar travel will probably doom the long-term future”, and this is a follow up to that post.
        The reason for the follow-up is that I outlined a tremendous threat and then left the solutions very open, and I
        was prompted to revisit the solutions as Betham’s '
      relevanceScore: 70
      topics:
        - existential-risk
        - long-term-risks
        - future-projections
      entities:
        - __index__/knowledge-base/future-projections
        - case-for-xrisk
    - title: "AI Safety Newsletter #51: AI Frontiers"
      url: https://newsletter.safe.ai/p/ai-safety-newsletter-51-ai-frontiers
      sourceId: cais-newsletter
      publishedAt: Tue, 15 Apr 2025 14:59:13 GMT
      summary: Plus, AI 2027
      relevanceScore: 70
      topics:
        - ai-development
        - frontier-models
        - agi-timeline
      entities:
        - agi-timeline
        - frontier-lab-cost-structure
    - title: "LWiAI Podcast #228 - GPT 5.2, Scaling Agents, Weird Generalization"
      url: https://lastweekin.ai/p/lwiai-podcast-228-gpt-52-scaling
      sourceId: last-week-in-ai
      publishedAt: Wed, 17 Dec 2025 22:31:17 GMT
      summary: GPT-5.2 is OpenAI&#8217;s latest move in the agentic AI battle, Towards a Science of Scaling Agent Systems, and
        more!
      relevanceScore: 70
      topics:
        - agentic-ai
        - capabilities
        - scaling-debate
      entities:
        - agentic-ai
        - scaling-debate
    - title: Learning Personalized Agents from Human Feedback
      url: https://arxiv.org/abs/2602.16173
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16173v1 Announce Type: new Abstract: Modern AI agents are powerful but often fail to align with the
        idiosyncratic, evolving preferences of individual users. Prior approaches typically rely on static datasets,
        either training implicit preference models on interaction history or encoding user profiles in external memory.
        However, these approaches struggle with new users and with preferences that change over time. We introduce
        Personalized Agents from Human Feedback (PAHF), a framework f"
      relevanceScore: 70
      topics:
        - agentic-ai
        - alignment-progress
        - reward-hacking-taxonomy
      entities:
        - agentic-ai
        - alignment-progress
    - title: Multi-agent cooperation through in-context co-player inference
      url: https://arxiv.org/abs/2602.16301
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: 'arXiv:2602.16301v1 Announce Type: new Abstract: Achieving cooperation among self-interested agents remains a
        fundamental challenge in multi-agent reinforcement learning. Recent work showed that mutual cooperation can be
        induced between "learning-aware" agents that account for and shape the learning dynamics of their co-players.
        However, existing approaches typically rely on hardcoded, often inconsistent, assumptions about co-player
        learning rules or enforce a strict separation between "naive lea'
      relevanceScore: 70
      topics:
        - agentic-ai
        - multi-actor-landscape
        - alignment-progress
      entities:
        - agentic-ai
        - multi-actor-landscape
    - title: A Lightweight Explainable Guardrail for Prompt Safety
      url: https://arxiv.org/abs/2602.15853
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15853v1 Announce Type: cross Abstract: We propose a lightweight explainable guardrail (LEG) method
        for the classification of unsafe prompts. LEG uses a multi-task learning architecture to jointly learn a prompt
        classifier and an explanation classifier, where the latter labels prompt words that explain the safe/unsafe
        overall decision. LEG is trained using synthetic data for explainability, which is generated using a novel
        strategy that counteracts the confirmation biases of LLMs. Last"
      relevanceScore: 70
      topics:
        - safety
        - prompt-safety
        - guardrails
        - alignment
      entities:
        - solutions
        - alignment-progress
        - misuse-risks
    - title: "Anatomy of Capability Emergence: Scale-Invariant Representation Collapse and Top-Down Reorganization in Neural
        Networks"
      url: https://arxiv.org/abs/2602.15997
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15997v1 Announce Type: cross Abstract: Capability emergence during neural network training remains
        mechanistically opaque. We track five geometric measures across five model scales (405K-85M parameters), 120+
        emergence events in eight algorithmic tasks, and three Pythia language models (160M-2.8B). We find: (1) training
        begins with a universal representation collapse to task-specific floors that are scale-invariant across a 210X
        parameter range (e.g., modular arithmetic collapses to R"
      relevanceScore: 70
      topics:
        - capabilities
        - interpretability
        - neural-networks
        - scaling
        - mechanistic-understanding
      entities:
        - capabilities
        - scaling-debate
    - title: "Align Once, Benefit Multilingually: Enforcing Multilingual Consistency for LLM Safety Alignment"
      url: https://arxiv.org/abs/2602.16660
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16660v1 Announce Type: cross Abstract: The widespread deployment of large language models (LLMs)
        across linguistic communities necessitates reliable multilingual safety alignment. However, recent efforts to
        extend alignment to other languages often require substantial resources, either through large-scale,
        high-quality supervision in the target language or through pairwise alignment with high-resource languages,
        which limits scalability. In this work, we propose a resource-efficient m"
      relevanceScore: 70
      topics:
        - alignment-progress
        - safety-research
        - language-models
      entities:
        - alignment-progress
        - safety-research
        - language-models
    - title: "CaveAgent: Transforming LLMs into Stateful Runtime Operators"
      url: https://arxiv.org/abs/2601.01569
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2601.01569v2 Announce Type: replace Abstract: LLM-based agents are increasingly capable of complex task
        execution, yet current agentic systems remain constrained by text-centric paradigms that struggle with
        long-horizon tasks due to fragile multi-turn dependencies and context drift. We present CaveAgent, a framework
        that shifts tool use from ``LLM-as-Text-Generator'' to ``LLM-as-Runtime-Operator.'' CaveAgent introduces a
        dual-stream architecture that inverts the conventional paradigm: rath"
      relevanceScore: 70
      topics:
        - agentic-ai
        - tool-use
        - long-horizon
      entities:
        - agentic-ai
        - tool-use
        - long-horizon
    - title: "AgentNoiseBench: Benchmarking Robustness of Tool-Using LLM Agents Under Noisy Condition"
      url: https://arxiv.org/abs/2602.11348
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.11348v2 Announce Type: replace Abstract: Recent advances in large language models have enabled
        LLM-based agents to achieve strong performance on a variety of benchmarks. However, their performance in
        real-world deployments often that observed on benchmark settings, especially in complex and imperfect
        environments. This discrepancy largely arises because prevailing training and evaluation paradigms are typically
        built on idealized assumptions, overlooking the inherent stochasticity and"
      relevanceScore: 70
      topics:
        - agentic-ai
        - tool-use
        - safety-research
        - robustness
      entities:
        - agentic-ai
        - tool-use
        - safety-research
    - title: "Cocoa: Co-Planning and Co-Execution with AI Agents"
      url: https://arxiv.org/abs/2412.10999
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: 'arXiv:2412.10999v4 Announce Type: replace-cross Abstract: As AI agents take on increasingly long-running tasks
        involving sophisticated planning and execution, there is a corresponding need for novel interaction designs that
        enable deeper human-agent collaboration. However, most prior works leverage human interaction to fix
        "autonomous" workflows that have yet to become fully autonomous or rigidly treat planning and execution as
        separate stages. Based on a formative study with 9 researchers using'
      relevanceScore: 70
      topics:
        - agentic-ai
        - long-horizon
        - planning
      entities:
        - agentic-ai
        - long-horizon
    - title: "PolicyPad: Collaborative Prototyping of LLM Policies"
      url: https://arxiv.org/abs/2509.19680
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2509.19680v2 Announce Type: replace-cross Abstract: As LLMs gain adoption in high-stakes domains like
        mental health, domain experts are increasingly consulted to provide input into policies governing their
        behavior. From an observation of 19 policymaking workshops with 9 experts over 15 weeks, we identified
        opportunities to better support rapid experimentation, feedback, and iteration for collaborative policy design
        processes. We present PolicyPad, an interactive system that facilitates th"
      relevanceScore: 70
      topics:
        - language-models
        - policy
        - alignment
        - governance
      entities:
        - language-models
    - title: Weight space Detection of Backdoors in LoRA Adapters
      url: https://arxiv.org/abs/2602.15195
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15195v2 Announce Type: replace-cross Abstract: LoRA adapters let users fine-tune large language
        models (LLMs) efficiently. However, LoRA adapters are shared through open repositories like Hugging Face Hub
        \\citep{huggingface_hub_docs}, making them vulnerable to backdoor attacks. Current detection methods require
        running the model with test input data -- making them impractical for screening thousands of adapters where the
        trigger for backdoor behavior is unknown. We detect poisoned ada"
      relevanceScore: 70
      topics:
        - language-models
        - security
        - backdoors
        - misuse-risks
        - safety
      entities:
        - misuse-risks
        - safety-research
    - title: Mitigating Gradient Inversion Risks in Language Models via Token Obfuscation
      url: https://arxiv.org/abs/2602.15897
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15897v1 Announce Type: new Abstract: Training and fine-tuning large-scale language models largely
        benefit from collaborative learning, but the approach has been proven vulnerable to gradient inversion attacks
        (GIAs), which allow adversaries to reconstruct private training data from shared gradients. Existing defenses
        mainly employ gradient perturbation techniques, e.g., noise injection or gradient pruning, to disrupt GIAs'
        direct mapping from gradient space to token space. However, th"
      relevanceScore: 70
      topics:
        - privacy
        - security
        - gradient attacks
        - LLM training
      entities:
        - language-models
        - misuse-risks
    - title: "Evolving Language Models without Labels: Majority Drives Selection, Novelty Promotes Variation"
      url: https://arxiv.org/abs/2509.15194
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2509.15194v3 Announce Type: replace-cross Abstract: Large language models (LLMs) are increasingly
        trained with reinforcement learning from verifiable rewards (RLVR), yet real-world deployment demands models
        that can self-improve without labels or external judges. Existing self-improvement approaches primarily rely on
        self-confirmation signals (e.g., confidence, entropy, or consistency) to generate rewards. This reliance drives
        models toward over-confident, majority-favored solutions, causi"
      relevanceScore: 70
      topics:
        - reinforcement-learning
        - training-methods
        - reward-learning
        - alignment
      entities:
        - language-models
        - alignment-progress
    - title: "Error Propagation and Model Collapse in Diffusion Models: A Theoretical Study"
      url: https://arxiv.org/abs/2602.16601
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16601v1 Announce Type: cross Abstract: Machine learning models are increasingly trained or
        fine-tuned on synthetic data. Recursively training on such data has been observed to significantly degrade
        performance in a wide range of tasks, often characterized by a progressive drift away from the target
        distribution. In this work, we theoretically analyze this phenomenon in the setting of score-based diffusion
        models. For a realistic pipeline where each training round uses a combination of"
      relevanceScore: 70
      topics:
        - capabilities
        - model-organisms-of-misalignment
        - reward-hacking-taxonomy
      entities:
        - capabilities
        - model-organisms-of-misalignment
    - title: "Navigating the Deep: End-to-End Extraction on Deep Neural Networks"
      url: https://arxiv.org/abs/2506.17047
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2506.17047v2 Announce Type: replace Abstract: Neural network model extraction has recently emerged as an
        important security concern, as adversaries attempt to recover a network's parameters via black-box queries.
        Carlini et al. proposed in CRYPTO'20 a model extraction approach, consisting of two steps: signature extraction
        and sign extraction. However, in practice this signature-extraction method is limited to very shallow networks
        only, and the proposed sign-extraction method is exponenti"
      relevanceScore: 70
      topics:
        - model-extraction
        - security
        - adversarial-attacks
      entities:
        - misuse-risks
        - safety-research
    - title: Universal Properties of Activation Sparsity in Modern Large Language Models
      url: https://arxiv.org/abs/2509.00454
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2509.00454v2 Announce Type: replace Abstract: Activation sparsity is an intriguing property of deep
        neural networks that has been extensively studied in ReLU-based models, due to its advantages for efficiency,
        robustness, and interpretability. However, methods relying on exact zero activations do not directly apply to
        modern Large Language Models (LLMs), leading to fragmented, model-specific strategies for LLM activation
        sparsity and a gap in its general understanding. In this work, we int"
      relevanceScore: 70
      topics:
        - activation-sparsity
        - large-language-models
        - interpretability
      entities:
        - large-language-models
        - interpretability-sufficient
    - title: "Shrinking the Variance: Shrinkage Baselines for Reinforcement Learning with Verifiable Rewards"
      url: https://arxiv.org/abs/2511.03710
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2511.03710v2 Announce Type: replace Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has
        emerged as a powerful paradigm for post-training large reasoning models (LRMs) using policy-gradient methods
        such as GRPO. To stabilize training, these methods typically center trajectory rewards by subtracting the
        empirical mean reward for each prompt. Statistically, this centering acts as a control variate (baseline),
        reducing the variance of the policy-gradient estimator. In practice,"
      relevanceScore: 70
      topics:
        - reinforcement-learning
        - reward-verification
        - reasoning-models
      entities:
        - reasoning
        - reward-hacking-taxonomy
    - title: Reinforcement Unlearning via Group Relative Policy Optimization
      url: https://arxiv.org/abs/2601.20568
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2601.20568v2 Announce Type: replace Abstract: During pretraining, LLMs inadvertently memorize sensitive
        or copyrighted data, posing significant compliance challenges under legal frameworks like the GDPR and the EU AI
        Act. Fulfilling these mandates demands techniques that can remove information from a deployed model without
        retraining from scratch. Existing unlearning approaches attempt to address this need, but often leak the very
        data they aim to erase, sacrifice fluency and robustness, o"
      relevanceScore: 70
      topics:
        - unlearning
        - data-removal
        - llm-safety
        - copyright-compliance
      entities:
        - safety-research
        - misuse-risks
    - title: Boundary Point Jailbreaking of Black-Box LLMs
      url: https://arxiv.org/abs/2602.15001
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: 'arXiv:2602.15001v2 Announce Type: replace Abstract: Frontier LLMs are safeguarded against attempts to extract
        harmful information via adversarial prompts known as "jailbreaks". Recently, defenders have developed
        classifier-based systems that have survived thousands of hours of human red teaming. We introduce Boundary Point
        Jailbreaking (BPJ), a new class of automated jailbreak attacks that evade the strongest industry-deployed
        safeguards. Unlike previous attacks that rely on white/grey-box assum'
      relevanceScore: 70
      topics:
        - llm-safety
        - adversarial-attacks
        - jailbreaking
        - robustness
      entities:
        - misuse-risks
    - title: "EconEvals: Benchmarks and Litmus Tests for Economic Decision-Making by LLM Agents"
      url: https://arxiv.org/abs/2503.18825
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2503.18825v4 Announce Type: replace Abstract: We develop evaluation methods for measuring the economic
        decision-making capabilities and tendencies of LLMs. First, we develop benchmarks derived from key problems in
        economics -- procurement, scheduling, and pricing -- that test an LLM's ability to learn from the environment in
        context. Second, we develop the framework of litmus tests, evaluations that quantify an LLM's choice behavior on
        a stylized decision-making task with multiple conflict"
      relevanceScore: 68
      topics:
        - agentic-ai
        - reasoning
        - goal-misgeneralization-probability
      entities:
        - agentic-ai
        - reasoning
    - title: Rethinking the Role of Entropy in Optimizing Tool-Use Behaviors for Large Language Model Agents
      url: https://arxiv.org/abs/2602.02050
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.02050v2 Announce Type: replace Abstract: Tool-using agents based on Large Language Models (LLMs)
        excel in tasks such as mathematical reasoning and multi-hop question answering. However, in long trajectories,
        agents often trigger excessive and low-quality tool calls, increasing latency and degrading inference
        performance, making managing tool-use behavior challenging. In this work, we conduct entropy-based pilot
        experiments and observe a strong positive correlation between entropy redu"
      relevanceScore: 68
      topics:
        - agentic-ai
        - tool-use
        - reasoning
      entities:
        - agentic-ai
        - tool-use
        - reasoning
    - title: Evaluating Language Model Agency through Negotiations
      url: https://arxiv.org/abs/2401.04536
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2401.04536v3 Announce Type: replace-cross Abstract: We introduce an approach to evaluate language model
        (LM) agency using negotiation games. This approach better reflects real-world use cases and addresses some of
        the shortcomings of alternative LM benchmarks. Negotiation games enable us to study multi-turn, and cross-model
        interactions, modulate complexity, and side-step accidental evaluation data leakage. We use our approach to test
        six widely used and publicly accessible LMs, evaluating"
      relevanceScore: 68
      topics:
        - agentic-ai
        - persuasion
        - goal-misgeneralization-probability
      entities:
        - agentic-ai
        - persuasion
    - title: Bringing ChatGPT to GenAI.mil
      url: https://openai.com/index/bringing-chatgpt-to-genaimil
      sourceId: openai-blog
      publishedAt: Mon, 09 Feb 2026 11:00:00 GMT
      summary: OpenAI for Government announces the deployment of a custom ChatGPT on GenAI.mil, bringing secure,
        safety-forward AI to U.S. defense teams.
      relevanceScore: 65
      topics:
        - deployment
        - geopolitics
        - autonomous-weapons-proliferation
      entities:
        - geopolitics
        - autonomous-weapons-proliferation
    - title: Introducing GPT-5.3-Codex
      url: https://openai.com/index/introducing-gpt-5-3-codex
      sourceId: openai-blog
      publishedAt: Thu, 05 Feb 2026 00:00:00 GMT
      summary: GPT-5.3-Codex is a Codex-native agent that pairs frontier coding performance with general reasoning to support
        long-horizon, real-world technical work.
      relevanceScore: 65
      topics:
        - agentic-ai
        - coding
        - long-horizon
      entities:
        - agentic-ai
        - coding
        - long-horizon
    - title: Investing in Merge Labs
      url: https://openai.com/index/investing-in-merge-labs
      sourceId: openai-blog
      publishedAt: Thu, 15 Jan 2026 07:00:00 GMT
      summary: OpenAI is investing in Merge Labs to support new brain computer interfaces that bridge biological and
        artificial intelligence to maximize human ability, agency, and experience.
      relevanceScore: 65
      topics:
        - brain-computer-interfaces
        - collective-intelligence
      entities:
        - brain-computer-interfaces
        - collective-intelligence
    - title: OpenAI partners with Cerebras
      url: https://openai.com/index/cerebras-partnership
      sourceId: openai-blog
      publishedAt: Wed, 14 Jan 2026 14:00:00 GMT
      summary: OpenAI partners with Cerebras to add 750MW of high-speed AI compute, reducing inference latency and making
        ChatGPT faster for real-time AI workloads.
      relevanceScore: 65
      topics:
        - compute-hardware
        - capabilities
      entities:
        - compute-hardware
    - title: Introducing GPT-5.2-Codex
      url: https://openai.com/index/introducing-gpt-5-2-codex
      sourceId: openai-blog
      publishedAt: Thu, 18 Dec 2025 00:00:00 GMT
      summary: GPT-5.2-Codex is OpenAI’s most advanced coding model, offering long-horizon reasoning, large-scale code
        transformations, and enhanced cybersecurity capabilities.
      relevanceScore: 65
      topics:
        - capabilities
        - coding
        - long-horizon
        - cybersecurity
      entities:
        - capabilities
        - coding
        - long-horizon
    - title: Introducing GPT-5.2
      url: https://openai.com/index/introducing-gpt-5-2
      sourceId: openai-blog
      publishedAt: Thu, 11 Dec 2025 00:00:00 GMT
      summary: GPT-5.2 is our most advanced frontier model for everyday professional work, with state-of-the-art reasoning,
        long-context understanding, coding, and vision. Use it in ChatGPT and the OpenAI API to power faster, more
        reliable agentic workflows.
      relevanceScore: 65
      topics:
        - capabilities
        - reasoning
        - long-horizon
      entities:
        - capabilities
        - reasoning
        - long-horizon
    - title: Funding grants for new research into AI and mental health
      url: https://openai.com/index/ai-mental-health-research-grants
      sourceId: openai-blog
      publishedAt: Mon, 01 Dec 2025 12:00:00 GMT
      summary: OpenAI is awarding up to $2 million in grants for research at the intersection of AI and mental health. The
        program supports projects that study real-world risks, benefits, and applications to improve safety and
        well-being.
      relevanceScore: 65
      topics:
        - safety-research
        - alignment-progress
        - epistemic-risks
      entities:
        - __index__/knowledge-base/cruxes
    - title: Early experiments in accelerating science with GPT-5
      url: https://openai.com/index/accelerating-science-gpt-5
      sourceId: openai-blog
      publishedAt: Thu, 20 Nov 2025 00:00:00 GMT
      summary: OpenAI introduces the first research cases showing how GPT-5 accelerates scientific progress across math,
        physics, biology, and computer science. Explore how AI and researchers collaborate to generate proofs, uncover
        new insights, and reshape the pace of discovery.
      relevanceScore: 65
      topics:
        - scientific-research
        - capabilities
        - reasoning
      entities:
        - __index__/knowledge-base/capabilities
    - title: Introducing the Teen Safety Blueprint
      url: https://openai.com/index/introducing-the-teen-safety-blueprint
      sourceId: openai-blog
      publishedAt: Thu, 06 Nov 2025 00:00:00 GMT
      summary: Discover OpenAI’s Teen Safety Blueprint—a roadmap for building AI responsibly with safeguards, age-appropriate
        design, and collaboration to protect and empower young people online.
      relevanceScore: 65
      topics:
        - safety-research
        - youth-safety
        - responsible-ai
        - accident-risks
      entities:
        - accident-risks
    - title: Seizing the AI opportunity
      url: https://openai.com/global-affairs/seizing-the-ai-opportunity
      sourceId: openai-blog
      publishedAt: Mon, 27 Oct 2025 12:00:00 GMT
      summary: Meeting the demands of the Intelligence Age will require strategic investment in energy and infrastructure.
        OpenAI’s submission to the White House details how expanding capacity and workforce readiness can sustain U.S.
        leadership in AI and economic growth.
      relevanceScore: 65
      topics:
        - compute-hardware
        - infrastructure
        - ai-megaproject-infrastructure
        - geopolitics
      entities:
        - compute-hardware
        - ai-megaproject-infrastructure
        - geopolitics
    - title: Expert Council on Well-Being and AI
      url: https://openai.com/index/expert-council-on-well-being-and-ai
      sourceId: openai-blog
      publishedAt: Tue, 14 Oct 2025 10:00:00 GMT
      summary: OpenAI’s new Expert Council on Well-Being and AI brings together leading psychologists, clinicians, and
        researchers to guide how ChatGPT supports emotional health, especially for teens. Learn how their insights are
        shaping safer, more caring AI experiences.
      relevanceScore: 65
      topics:
        - safety-research
        - alignment-progress
        - expert-opinion
      entities:
        - safety-research
        - expert-opinion
    - title: Introducing AgentKit, new Evals, and RFT for agents
      url: https://openai.com/index/introducing-agentkit
      sourceId: openai-blog
      publishedAt: Mon, 06 Oct 2025 00:00:00 GMT
      summary: "Today, we’re releasing new tools to help developers go from prototype to production faster: AgentKit, expanded
        evals capabilities, and reinforcement fine-tuning for agents."
      relevanceScore: 65
      topics:
        - agentic-ai
        - safety-research
        - eval-types-table
      entities:
        - agentic-ai
        - safety-research
        - eval-types-table
    - title: OpenAI, Oracle, and SoftBank expand Stargate with five new AI datacenter sites
      url: https://openai.com/index/five-new-stargate-sites
      sourceId: openai-blog
      publishedAt: Tue, 23 Sep 2025 14:00:00 GMT
      summary: OpenAI, Oracle, and SoftBank announce five new Stargate AI datacenter sites, accelerating a $500B, 10-gigawatt
        U.S. infrastructure buildout to power next-generation AI and create tens of thousands of jobs.
      relevanceScore: 65
      topics:
        - compute-hardware
        - ai-megaproject-infrastructure
        - frontier-lab-cost-structure
      entities:
        - compute-hardware
        - ai-megaproject-infrastructure
        - frontier-lab-cost-structure
    - title: A joint statement from OpenAI and Microsoft
      url: https://openai.com/index/joint-statement-from-openai-and-microsoft
      sourceId: openai-blog
      publishedAt: Thu, 11 Sep 2025 14:00:00 GMT
      summary: OpenAI and Microsoft sign a new MOU, reinforcing their partnership and shared commitment to AI safety and
        innovation.
      relevanceScore: 65
      topics:
        - alignment-progress
        - safety-research
      entities:
        - alignment-progress
        - safety-research
    - title: Building more helpful ChatGPT experiences for everyone
      url: https://openai.com/index/building-more-helpful-chatgpt-experiences-for-everyone
      sourceId: openai-blog
      publishedAt: Tue, 02 Sep 2025 04:00:00 GMT
      summary: We’re partnering with experts, strengthening protections for teens with parental controls, and routing
        sensitive conversations to reasoning models in ChatGPT.
      relevanceScore: 65
      topics:
        - safety
        - parental-controls
        - teen-protection
        - sensitive-content
      entities:
        - safety-research
        - language-models
    - title: Introducing GPT-5 for developers
      url: https://openai.com/index/introducing-gpt-5-for-developers
      sourceId: openai-blog
      publishedAt: Thu, 07 Aug 2025 10:00:00 GMT
      summary: Introducing GPT-5 in our API platform—offering high reasoning performance, new controls for devs, and
        best-in-class results on real coding tasks.
      relevanceScore: 65
      topics:
        - capabilities
        - reasoning
        - coding
        - language-models
      entities:
        - language-models
        - capabilities
        - coding
    - title: Introducing gpt-oss
      url: https://openai.com/index/introducing-gpt-oss
      sourceId: openai-blog
      publishedAt: Tue, 05 Aug 2025 00:00:00 GMT
      summary: We’re releasing gpt-oss-120b and gpt-oss-20b—two state-of-the-art open-weight language models that deliver
        strong real-world performance at low cost. Available under the flexible Apache 2.0 license, these models
        outperform similarly sized open models on reasoning tasks, demonstrate strong tool use capabilities, and are
        optimized for efficient deployment on consumer hardware.
      relevanceScore: 65
      topics:
        - open-vs-closed
        - language-models
        - misuse-risks
        - safety-research
      entities:
        - open-vs-closed
        - language-models
        - misuse-risks
    - title: "Disrupting malicious uses of AI: June 2025"
      url: https://openai.com/global-affairs/disrupting-malicious-uses-of-ai-june-2025
      sourceId: openai-blog
      publishedAt: Thu, 05 Jun 2025 02:00:00 GMT
      summary: In our June 2025 update, we outline how we’re disrupting malicious uses of AI—through safety tools that detect
        and counter abuse, support democratic values, and promote responsible AI deployment for the benefit of all.
      relevanceScore: 65
      topics:
        - misuse-risks
        - safety-research
        - governance
      entities:
        - misuse-risks
        - safety-research
    - title: OpenAI’s response to the Department of Energy on AI infrastructure
      url: https://openai.com/global-affairs/response-to-department-of-energy
      sourceId: openai-blog
      publishedAt: Wed, 07 May 2025 18:30:00 GMT
      summary: Why infrastructure is destiny and how the US can seize it.
      relevanceScore: 65
      topics:
        - compute-hardware
        - ai-megaproject-infrastructure
        - governance
        - geopolitics
      entities:
        - compute-hardware
        - ai-megaproject-infrastructure
        - geopolitics
    - title: Thinking with images
      url: https://openai.com/index/thinking-with-images
      sourceId: openai-blog
      publishedAt: Wed, 16 Apr 2025 10:00:00 GMT
      summary: OpenAI o3 and o4-mini represent a significant breakthrough in visual perception by reasoning with images in
        their chain of thought.
      relevanceScore: 65
      topics:
        - capabilities
        - reasoning
        - interpretability
      entities:
        - reasoning
        - interpretability-sufficient
    - title: Introducing GPT-4.1 in the API
      url: https://openai.com/index/gpt-4-1
      sourceId: openai-blog
      publishedAt: Mon, 14 Apr 2025 10:00:00 GMT
      summary: Introducing GPT-4.1 in the API—a new family of models with across-the-board improvements, including major gains
        in coding, instruction following, and long-context understanding. We’re also releasing our first nano model.
        Available to developers worldwide starting today.
      relevanceScore: 65
      topics:
        - capabilities
        - coding
        - reasoning
        - long-context
      entities:
        - coding
        - reasoning
        - long-horizon
        - capabilities
    - title: Moving from intent-based bots to proactive AI agents
      url: https://openai.com/index/zendesk
      sourceId: openai-blog
      publishedAt: Thu, 27 Mar 2025 09:00:00 GMT
      summary: Moving from intent-based bots to proactive AI agents.
      relevanceScore: 65
      topics:
        - agentic-ai
        - capabilities
      entities:
        - agentic-ai
    - title: Introducing GPT-4.5
      url: https://openai.com/index/introducing-gpt-4-5
      sourceId: openai-blog
      publishedAt: Thu, 27 Feb 2025 10:00:00 GMT
      summary: We’re releasing a research preview of GPT‑4.5—our largest and best model for chat yet. GPT‑4.5 is a step
        forward in scaling up pre-training and post-training.
      relevanceScore: 65
      topics:
        - capabilities
        - scaling-debate
        - agi-timeline
      entities:
        - capabilities
        - scaling-debate
        - agi-timeline
    - title: Disrupting malicious uses of AI
      url: https://openai.com/global-affairs/disrupting-malicious-uses-of-ai
      sourceId: openai-blog
      publishedAt: Fri, 21 Feb 2025 06:30:00 GMT
      summary: Ensuring AI benefits humanity by advancing democratic AI, preventing misuse, and protecting against
        authoritarian threats.
      relevanceScore: 65
      topics:
        - misuse-risks
        - safety-research
        - governance
      entities:
        - misuse-risks
        - safety-research
    - title: Introducing deep research
      url: https://openai.com/index/introducing-deep-research
      sourceId: openai-blog
      publishedAt: Sun, 02 Feb 2025 16:00:00 GMT
      summary: An agent that uses reasoning to synthesize large amounts of online information and complete multi-step research
        tasks for you. Available to Pro users today, Plus and Team next.
      relevanceScore: 65
      topics:
        - agentic-ai
        - reasoning
        - long-horizon
        - capabilities
      entities:
        - agentic-ai
        - reasoning
        - long-horizon
    - title: Sora System Card
      url: https://openai.com/index/sora-system-card
      sourceId: openai-blog
      publishedAt: Mon, 09 Dec 2024 00:00:00 GMT
      summary: Sora is OpenAI’s video generation model, designed to take text, image, and video inputs and generate a new
        video as an output. Sora builds on learnings from DALL-E and GPT models, and is designed to give people expanded
        tools for storytelling and creative expression.
      relevanceScore: 65
      topics:
        - capabilities
        - multimodal-models
        - video-generation
        - safety-evaluation
      entities:
        - capabilities
        - safety-research
    - title: An update on our safety & security practices
      url: https://openai.com/index/update-on-safety-and-security-practices
      sourceId: openai-blog
      publishedAt: Mon, 16 Sep 2024 13:00:00 GMT
      summary: An update on our safety & security practices
      relevanceScore: 65
      topics:
        - safety-research
        - lab-behavior
        - solutions
      entities:
        - safety-research
        - lab-behavior
        - solutions
    - title: OpenAI o1 System Card External Testers Acknowledgements
      url: https://openai.com/index/openai-o1-system-card/external-testers-acknowledgements
      sourceId: openai-blog
      publishedAt: Thu, 12 Sep 2024 10:00:00 GMT
      summary: OpenAI o1 system card external testers acknowledgements
      relevanceScore: 65
      topics:
        - safety-research
        - capabilities
      entities:
        - safety-research
        - capabilities
    - title: GPT-4o System Card External Testers Acknowledgements
      url: https://openai.com/index/gpt-4o-system-card/external-testers-acknowledgements
      sourceId: openai-blog
      publishedAt: Thu, 08 Aug 2024 10:00:00 GMT
      summary: GPT-4o system card external testers acknowledgements
      relevanceScore: 65
      topics:
        - safety
        - evaluation
        - red-teaming
        - transparency
      entities:
        - safety-research
    - title: "A Primer on the EU AI Act: What It Means for AI Providers and Deployers"
      url: https://openai.com/global-affairs/a-primer-on-the-eu-ai-act
      sourceId: openai-blog
      publishedAt: Tue, 30 Jul 2024 00:00:00 GMT
      summary: We’re sharing a preliminary overview of the EU AI Act including upcoming deadlines and requirements, with a
        particular focus on prohibited and high-risk use cases
      relevanceScore: 65
      topics:
        - regulation
        - governance
        - policy
        - safety
      entities:
        - regulation-debate
    - title: Prover-Verifier Games improve legibility of language model outputs
      url: https://openai.com/index/prover-verifier-games-improve-legibility
      sourceId: openai-blog
      publishedAt: Wed, 17 Jul 2024 10:00:00 GMT
      summary: Discover how prover-verifier games improve the legibility of language model outputs, making AI solutions
        clearer, easier to verify, and more trustworthy for both humans and machines.
      relevanceScore: 65
      topics:
        - interpretability
        - alignment
        - safety
        - verification
      entities:
        - interpretability-sufficient
    - title: Disrupting deceptive uses of AI by covert influence operations
      url: https://openai.com/index/disrupting-deceptive-uses-of-ai-by-covert-influence-operations
      sourceId: openai-blog
      publishedAt: Thu, 30 May 2024 10:00:00 GMT
      summary: We’ve terminated accounts linked to covert influence operations; no significant audience increase due to our
        services.
      relevanceScore: 65
      topics:
        - misuse-risks
        - disinformation-detection-race
        - safety-research
      entities:
        - misuse-risks
        - disinformation-detection-race
    - title: Introducing the Model Spec
      url: https://openai.com/index/introducing-the-model-spec
      sourceId: openai-blog
      publishedAt: Wed, 08 May 2024 00:00:00 GMT
      summary: ""
      relevanceScore: 65
      topics:
        - safety-research
        - alignment-progress
        - governance
      entities:
        - safety-research
        - alignment-progress
    - title: OpenAI and Elon Musk
      url: https://openai.com/index/openai-elon-musk
      sourceId: openai-blog
      publishedAt: Tue, 05 Mar 2024 08:00:00 GMT
      summary: We are dedicated to the OpenAI mission and have pursued it every step of the way.
      relevanceScore: 65
      topics:
        - governance
        - lab-behavior
        - structural
        - agi-development
      entities:
        - governance
        - lab-behavior
        - structural
        - agi-development
    - title: Video generation models as world simulators
      url: https://openai.com/index/video-generation-models-as-world-simulators
      sourceId: openai-blog
      publishedAt: Thu, 15 Feb 2024 08:00:00 GMT
      summary: "We explore large-scale training of generative models on video data. Specifically, we train text-conditional
        diffusion models jointly on videos and images of variable durations, resolutions and aspect ratios. We leverage
        a transformer architecture that operates on spacetime patches of video and image latent codes. Our largest
        model, Sora, is capable of generating a minute of high fidelity video. Our results suggest that scaling video
        generation models is a promising path towards building general "
      relevanceScore: 65
      topics:
        - world-models
        - capabilities
        - video-generation
      entities:
        - world-models
        - capabilities
    - title: How OpenAI is approaching 2024 worldwide elections
      url: https://openai.com/index/how-openai-is-approaching-2024-worldwide-elections
      sourceId: openai-blog
      publishedAt: Mon, 15 Jan 2024 08:00:00 GMT
      summary: We’re working to prevent abuse, provide transparency on AI-generated content, and improve access to accurate
        voting information.
      relevanceScore: 65
      topics:
        - misuse-risks
        - disinformation-electoral-impact
        - deepfakes-authentication-crisis
      entities:
        - misuse-risks
        - disinformation-electoral-impact
        - deepfakes-authentication-crisis
    - title: OpenAI Cybersecurity Grant Program
      url: https://openai.com/index/openai-cybersecurity-grant-program
      sourceId: openai-blog
      publishedAt: Thu, 01 Jun 2023 07:00:00 GMT
      summary: Our goal is to facilitate the development of AI-powered cybersecurity capabilities for defenders through grants
        and other support.
      relevanceScore: 65
      topics:
        - safety-research
        - alignment-progress
        - misuse-risks
      entities:
        - safety-research
    - title: ChatGPT plugins
      url: https://openai.com/index/chatgpt-plugins
      sourceId: openai-blog
      publishedAt: Thu, 23 Mar 2023 07:00:00 GMT
      summary: We’ve implemented initial support for plugins in ChatGPT. Plugins are tools designed specifically for language
        models with safety as a core principle, and help ChatGPT access up-to-date information, run computations, or use
        third-party services.
      relevanceScore: 65
      topics:
        - tool-use
        - safety-design
        - agentic-ai
      entities:
        - tool-use
        - agentic-ai
    - title: New and improved content moderation tooling
      url: https://openai.com/index/new-and-improved-content-moderation-tooling
      sourceId: openai-blog
      publishedAt: Wed, 10 Aug 2022 07:00:00 GMT
      summary: We are introducing a new and improved content moderation tool. The Moderation endpoint improves upon our
        previous content filter, and is available for free today to OpenAI API developers.
      relevanceScore: 65
      topics:
        - safety-research
        - misuse-risks
        - deployment-architectures-table
      entities:
        - misuse-risks
        - safety-research
    - title: "WebGPT: Improving the factual accuracy of language models through web browsing"
      url: https://openai.com/index/webgpt
      sourceId: openai-blog
      publishedAt: Thu, 16 Dec 2021 08:00:00 GMT
      summary: We’ve fine-tuned GPT-3 to more accurately answer open-ended questions using a text-based web browser.
      relevanceScore: 65
      topics:
        - alignment-progress
        - safety-research
        - epistemic-risks
        - tool-use
      entities:
        - alignment-progress
        - safety-research
    - title: OpenAI’s API now available with no waitlist
      url: https://openai.com/index/api-no-waitlist
      sourceId: openai-blog
      publishedAt: Thu, 18 Nov 2021 08:00:00 GMT
      summary: Wider availability made possible by safety progress.
      relevanceScore: 65
      topics:
        - safety-research
        - capabilities
        - deployment-architectures-table
      entities:
        - safety-research
        - deployment-architectures-table
    - title: Improving language model behavior by training on a curated dataset
      url: https://openai.com/index/improving-language-model-behavior
      sourceId: openai-blog
      publishedAt: Thu, 10 Jun 2021 07:00:00 GMT
      summary: Our latest research finds we can improve language model behavior with respect to specific behavioral values by
        fine-tuning on a small, curated dataset.
      relevanceScore: 65
      topics:
        - alignment-progress
        - safety-research
        - interpretability-sufficient
      entities:
        - alignment-progress
        - safety-research
    - title: AI and efficiency
      url: https://openai.com/index/ai-and-efficiency
      sourceId: openai-blog
      publishedAt: Tue, 05 May 2020 07:00:00 GMT
      summary: We’re releasing an analysis showing that since 2012 the amount of compute needed to train a neural net to the
        same performance on ImageNet classification has been decreasing by a factor of 2 every 16 months. Compared to
        2012, it now takes 44 times less compute to train a neural network to the level of AlexNet (by contrast, Moore’s
        Law would yield an 11x cost improvement over this period). Our results suggest that for AI tasks with high
        levels of recent investment, algorithmic progress has yielde
      relevanceScore: 65
      topics:
        - compute-hardware
        - capabilities
        - scaling-debate
      entities:
        - compute-hardware
        - scaling-debate
    - title: Deep double descent
      url: https://openai.com/index/deep-double-descent
      sourceId: openai-blog
      publishedAt: Thu, 05 Dec 2019 08:00:00 GMT
      summary: "We show that the double descent phenomenon occurs in CNNs, ResNets, and transformers: performance first
        improves, then gets worse, and then improves again with increasing model size, data size, or training time. This
        effect is often avoided through careful regularization. While this behavior appears to be fairly universal, we
        don’t yet fully understand why it happens, and view further study of this phenomenon as an important research
        direction."
      relevanceScore: 65
      topics:
        - scaling-laws
        - deep-learning
        - capabilities
      entities:
        - scaling-debate
        - deep-learning-era
    - title: Generative modeling with sparse transformers
      url: https://openai.com/index/sparse-transformer
      sourceId: openai-blog
      publishedAt: Tue, 23 Apr 2019 07:00:00 GMT
      summary: We’ve developed the Sparse Transformer, a deep neural network which sets new records at predicting what comes
        next in a sequence—whether text, images, or sound. It uses an algorithmic improvement of the attention mechanism
        to extract patterns from sequences 30x longer than possible previously.
      relevanceScore: 65
      topics:
        - scaling-laws
        - sparse-transformers
        - capabilities
      entities:
        - sparse-moe
        - capabilities
    - title: How AI training scales
      url: https://openai.com/index/how-ai-training-scales
      sourceId: openai-blog
      publishedAt: Fri, 14 Dec 2018 08:00:00 GMT
      summary: We’ve discovered that the gradient noise scale, a simple statistical metric, predicts the parallelizability of
        neural network training on a wide range of tasks. Since complex tasks tend to have noisier gradients,
        increasingly large batch sizes are likely to become useful in the future, removing one potential limit to
        further growth of AI systems. More broadly, these results show that neural network training need not be
        considered a mysterious art, but can be rigorized and systematized.
      relevanceScore: 65
      topics:
        - scaling
        - training
        - compute
      entities:
        - compute-hardware
        - capabilities
    - title: Reinforcement learning with prediction-based rewards
      url: https://openai.com/index/reinforcement-learning-with-prediction-based-rewards
      sourceId: openai-blog
      publishedAt: Wed, 31 Oct 2018 07:00:00 GMT
      summary: We’ve developed Random Network Distillation (RND), a prediction-based method for encouraging reinforcement
        learning agents to explore their environments through curiosity, which for the first time exceeds average human
        performance on Montezuma’s Revenge.
      relevanceScore: 65
      topics:
        - reinforcement-learning
        - exploration
        - curiosity
      entities:
        - capabilities
    - title: Improving language understanding with unsupervised learning
      url: https://openai.com/index/language-unsupervised
      sourceId: openai-blog
      publishedAt: Mon, 11 Jun 2018 07:00:00 GMT
      summary: "We’ve obtained state-of-the-art results on a suite of diverse language tasks with a scalable, task-agnostic
        system, which we’re also releasing. Our approach is a combination of two existing ideas: transformers and
        unsupervised pre-training. These results provide a convincing example that pairing supervised learning methods
        with unsupervised pre-training works very well; this is an idea that many have explored in the past, and we hope
        our result motivates further research into applying this idea "
      relevanceScore: 65
      topics:
        - language-models
        - capabilities
        - deep-learning-era
      entities:
        - language-models
        - capabilities
    - title: More on Dota 2
      url: https://openai.com/index/more-on-dota-2
      sourceId: openai-blog
      publishedAt: Wed, 16 Aug 2017 07:00:00 GMT
      summary: Our Dota 2 result shows that self-play can catapult the performance of machine learning systems from far below
        human level to superhuman, given sufficient compute. In the span of a month, our system went from barely
        matching a high-ranked player to beating the top pros and has continued to improve since then. Supervised deep
        learning systems can only be as good as their training datasets, but in self-play systems, the available data
        improves automatically as the agent gets better.
      relevanceScore: 65
      topics:
        - self-play
        - scaling
        - capabilities
        - compute
      entities:
        - capabilities
        - compute-hardware
        - scaling-debate
    - title: Robust adversarial inputs
      url: https://openai.com/index/robust-adversarial-inputs
      sourceId: openai-blog
      publishedAt: Mon, 17 Jul 2017 07:00:00 GMT
      summary: We’ve created images that reliably fool neural network classifiers when viewed from varied scales and
        perspectives. This challenges a claim from last week that self-driving cars would be hard to trick maliciously
        since they capture images from multiple scales, angles, perspectives, and the like.
      relevanceScore: 65
      topics:
        - adversarial-robustness
        - safety
        - robustness
        - misuse-risks
      entities:
        - misuse-risks
        - accident-risks
    - title: Learning to cooperate, compete, and communicate
      url: https://openai.com/index/learning-to-cooperate-compete-and-communicate
      sourceId: openai-blog
      publishedAt: Thu, 08 Jun 2017 07:00:00 GMT
      summary: "Multiagent environments where agents compete for resources are stepping stones on the path to AGI. Multiagent
        environments have two useful properties: first, there is a natural curriculum—the difficulty of the environment
        is determined by the skill of your competitors (and if you’re competing against clones of yourself, the
        environment exactly matches your skill level). Second, a multiagent environment has no stable equilibrium: no
        matter how smart an agent is, there’s always pressure to get sma"
      relevanceScore: 65
      topics:
        - multi-agent
        - cooperation
        - competition
        - communication
        - agi-development
      entities:
        - agentic-ai
        - agi-development
        - multipolar-competition
    - title: Attacking machine learning with adversarial examples
      url: https://openai.com/index/attacking-machine-learning-with-adversarial-examples
      sourceId: openai-blog
      publishedAt: Fri, 24 Feb 2017 08:00:00 GMT
      summary: Adversarial examples are inputs to machine learning models that an attacker has intentionally designed to cause
        the model to make a mistake; they’re like optical illusions for machines. In this post we’ll show how
        adversarial examples work across different mediums, and will discuss why securing systems against them can be
        difficult.
      relevanceScore: 65
      topics:
        - adversarial-examples
        - robustness
        - misuse-risks
      entities:
        - misuse-risks
    - title: A Statement from Dario Amodei on American AI Leadership
      url: https://www.anthropic.com/news/statement-dario-amodei-american-ai-leadership
      sourceId: anthropic-blog
      publishedAt: 2026-02-19
      summary: " This is a statement from Anthropic CEO Dario Amodei on Anthropic's commitment to advancing America's
        leadership in building powerful and beneficial AI."
      relevanceScore: 65
      topics:
        - geopolitics
        - agi-development
        - lab-behavior
      entities:
        - geopolitics
        - agi-development
    - title: Teaching AI to see the world more like we do
      url: https://deepmind.google/blog/teaching-ai-to-see-the-world-more-like-we-do/
      sourceId: deepmind-blog
      publishedAt: Tue, 11 Nov 2025 11:49:13 +0000
      summary: Our new paper analyzes the important ways AI systems organize the visual world differently from humans.
      relevanceScore: 65
      topics:
        - interpretability-sufficient
        - alignment-progress
      entities:
        - interpretability-sufficient
        - alignment-progress
    - title: "Genie 3: A new frontier for world models"
      url: https://deepmind.google/blog/genie-3-a-new-frontier-for-world-models/
      sourceId: deepmind-blog
      publishedAt: Fri, 24 Oct 2025 02:54:30 +0000
      summary: Genie 3 can generate dynamic worlds that you can navigate in real time at 24 frames per second, retaining
        consistency for a few minutes at a resolution of 720p.
      relevanceScore: 65
      topics:
        - world-models
        - capabilities
      entities:
        - world-models
        - capabilities
    - title: "Introducing CodeMender: an AI agent for code security"
      url: https://deepmind.google/blog/introducing-codemender-an-ai-agent-for-code-security/
      sourceId: deepmind-blog
      publishedAt: Thu, 23 Oct 2025 23:05:51 +0000
      summary: Using advanced AI to fix critical software vulnerabilities
      relevanceScore: 65
      topics:
        - safety-research
        - misuse-risks
        - solutions
      entities:
        - safety-research
        - misuse-risks
        - solutions
    - title: "Gemini 2.5: Updates to our family of thinking models"
      url: https://deepmind.google/blog/gemini-25-updates-to-our-family-of-thinking-models/
      sourceId: deepmind-blog
      publishedAt: Tue, 17 Jun 2025 16:00:00 +0000
      summary: "Explore the latest Gemini 2.5 model updates with enhanced performance and accuracy: Gemini 2.5 Pro now stable,
        Flash generally available, and the new Flash-Lite in preview."
      relevanceScore: 65
      topics:
        - language-models
        - reasoning
        - capabilities
      entities:
        - language-models
        - reasoning
        - capabilities
    - title: Introducing Gemini 2.5 Flash
      url: https://deepmind.google/blog/introducing-gemini-2-5-flash/
      sourceId: deepmind-blog
      publishedAt: Thu, 17 Apr 2025 19:02:00 +0000
      summary: Gemini 2.5 Flash is our first fully hybrid reasoning model, giving developers the ability to turn thinking on
        or off.
      relevanceScore: 65
      topics:
        - language-models
        - reasoning
        - capabilities
      entities:
        - language-models
        - reasoning
        - capabilities
    - title: Google DeepMind at NeurIPS 2024
      url: https://deepmind.google/blog/google-deepmind-at-neurips-2024/
      sourceId: deepmind-blog
      publishedAt: Thu, 05 Dec 2024 17:45:00 +0000
      summary: Advancing adaptive AI agents, empowering 3D scene creation, and innovating LLM training for a smarter, safer
        future
      relevanceScore: 65
      topics:
        - safety-research
        - agentic-ai
        - alignment
      entities:
        - agentic-ai
        - solutions
    - title: Be skeptical of milestone announcements by young AI startups
      url: https://www.lesswrong.com/posts/qefrWyeiMvWEFRitN/be-skeptical-of-milestone-announcements-by-young-ai-startups
      sourceId: lesswrong
      publishedAt: Thu, 19 Feb 2026 04:19:10 GMT
      summary: Published on February 19, 2026 4:19 AM GMTAlmost one year ago now, a company named XBOW announced that their AI
        had achieved "rank one" on the HackerOne leaderboard. HackerOne is a crowdsourced "bug bounty" platform, where
        large companies like Anthropic, SalesForce, Uber, and others pay out bounties for disclosures of hacks on their
        products and services. Bug bounty research is a highly competitive sport, and in addition to money it can give a
        security researcher or an engineer excellent profess
      relevanceScore: 65
      topics:
        - lab-behavior
        - expert-opinion
        - safety-research
      entities:
        - lab-behavior
        - expert-opinion
    - title: "LWiAI Podcast #234 - Opus 4.6, GPT-5.3-Codex, Seedance 2.0, GLM-5"
      url: https://lastweekin.ai/p/lwiai-podcast-234-opus-46-gpt-53
      sourceId: last-week-in-ai
      publishedAt: Tue, 17 Feb 2026 04:43:31 GMT
      summary: An action-packed episode!
      relevanceScore: 65
      topics:
        - frontier-models
        - capabilities
        - ai-news
      entities:
        - capabilities
    - title: "Last Week in AI #335 - Opus 4.6, Codex 5.3, Gemini 3 Deep Think, GLM 5, Seedance 2.0"
      url: https://lastweekin.ai/p/last-week-in-ai-335-opus-46-codex
      sourceId: last-week-in-ai
      publishedAt: Mon, 16 Feb 2026 02:00:20 GMT
      summary: A crazy packed edition of Last Week in AI! Plus some small updates.
      relevanceScore: 65
      topics:
        - frontier-models
        - capabilities
        - ai-news
      entities:
        - capabilities
    - title: "LWiAI Podcast #231 - Claude Cowork, Anthropic $10B, Deep Delta Learning"
      url: https://lastweekin.ai/p/lwiai-podcast-231-claude-cowork-anthropic
      sourceId: last-week-in-ai
      publishedAt: Wed, 21 Jan 2026 03:22:53 GMT
      summary: Anthropic&#8217;s new Cowork tool, Anthropic Raising $10 Billion at $350 Billion Value, Deep Delta Learning
      relevanceScore: 65
      topics:
        - capabilities
        - agentic-ai
        - lab-behavior
        - anthropic-impact
      entities:
        - agentic-ai
        - anthropic-impact
    - title: "Last Week in AI #331 - Nvidia announcements, Grok bikini prompts, RAISE Act"
      url: https://lastweekin.ai/p/last-week-in-ai-331-nvidia-announcements
      sourceId: last-week-in-ai
      publishedAt: Tue, 06 Jan 2026 11:56:58 GMT
      summary: Nvidia Details New A.I. Chips and Autonomous Car Project, Grok is undressing anyone, NY passes AI regulation
      relevanceScore: 65
      topics:
        - compute-hardware
        - regulation-debate
        - misuse-risks
      entities:
        - compute-hardware
        - regulation-debate
    - title: "LWiAI Podcast #227 - Jeremie is back! DeepSeek 3.2, TPUs, Nested Learning"
      url: https://lastweekin.ai/p/lwiai-podcast-227-jeremie-is-back
      sourceId: last-week-in-ai
      publishedAt: Tue, 09 Dec 2025 08:41:54 GMT
      summary: "Deepseek 3.2 New AI Model is Faster, Cheaper and Smarter, NVIDIA&#8217;s Partners Are Beginning to Tilt Toward
        Google&#8217;s TPU Ecosystem, Nested Learning: The Illusion of Deep Learning Architecture"
      relevanceScore: 65
      topics:
        - capabilities
        - compute-hardware
        - architecture-scenarios-table
      entities:
        - compute-hardware
        - architecture-scenarios-table
    - title: "EnterpriseGym Corecraft: Training Generalizable Agents on High-Fidelity RL Environments"
      url: https://arxiv.org/abs/2602.16179
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16179v1 Announce Type: new Abstract: We show that training AI agents on high-fidelity reinforcement
        learning environments produces capabilities that generalize beyond the training distribution. We introduce
        \\corecraft{}, the first environment in \\textsc{EnterpriseGym}, Surge AI's suite of agentic RL environments.
        \\corecraft{} is a fully operational enterprise simulation of a customer support organization, comprising over
        2,500 entities across 14 entity types with 23 unique tools, desi"
      relevanceScore: 65
      topics:
        - agentic-ai
        - capabilities
        - long-horizon
      entities:
        - agentic-ai
        - long-horizon
    - title: Towards a Science of AI Agent Reliability
      url: https://arxiv.org/abs/2602.16666
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16666v1 Announce Type: new Abstract: AI agents are increasingly deployed to execute important
        tasks. While rising accuracy scores on standard benchmarks suggest rapid progress, many agents still continue to
        fail in practice. This discrepancy highlights a fundamental limitation of current evaluations: compressing agent
        behavior into a single success metric obscures critical operational flaws. Notably, it ignores whether agents
        behave consistently across runs, withstand perturbations, f"
      relevanceScore: 65
      topics:
        - ai-agent-reliability
        - safety
        - deployment
      entities:
        - agentic-ai
        - solutions
        - deployment-architectures-table
    - title: "ReLoop: Structured Modeling and Behavioral Verification for Reliable LLM-Based Optimization"
      url: https://arxiv.org/abs/2602.15983
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15983v1 Announce Type: cross Abstract: Large language models (LLMs) can translate natural language
        into optimization code, but silent failures pose a critical risk: code that executes and returns solver-feasible
        solutions may encode semantically incorrect formulations, creating a feasibility-correctness gap of up to 90
        percentage points on compositional problems. We introduce ReLoop, addressing silent failures from two
        complementary directions. Structured generation decomposes code pr"
      relevanceScore: 65
      topics:
        - language-models
        - safety-research
        - reliability
        - agentic-ai
        - accident-risks
      entities:
        - language-models
        - safety-research
        - agentic-ai
        - accident-risks
    - title: Retrieval Collapses When AI Pollutes the Web
      url: https://arxiv.org/abs/2602.16136
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16136v1 Announce Type: cross Abstract: The rapid proliferation of AI-generated content on the Web
        presents a structural risk to information retrieval, as search engines and Retrieval-Augmented Generation (RAG)
        systems increasingly consume evidence produced by the Large Language Models (LLMs). We characterize this
        ecosystem-level failure mode as Retrieval Collapse, a two-stage process where (1) AI-generated content dominates
        search results, eroding source diversity, and (2) low-quality"
      relevanceScore: 65
      topics:
        - epistemic-risks
        - structural-risks
        - misuse-risks
      entities:
        - epistemic-risks
        - structural-risks
        - misuse-risks
    - title: "Intra-Fairness Dynamics: The Bias Spillover Effect in Targeted LLM Alignment"
      url: https://arxiv.org/abs/2602.16438
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16438v1 Announce Type: cross Abstract: Conventional large language model (LLM) fairness alignment
        largely focuses on mitigating bias along single sensitive attributes, overlooking fairness as an inherently
        multidimensional and context-specific value. This approach risks creating systems that achieve narrow fairness
        metrics while exacerbating disparities along untargeted attributes, a phenomenon known as bias spillover. While
        extensively studied in machine learning, bias spillover rema"
      relevanceScore: 65
      topics:
        - alignment-progress
        - safety-research
        - misuse-risks
      entities:
        - alignment-progress
        - safety-research
        - misuse-risks
    - title: "Explainable AI: Context-Aware Layer-Wise Integrated Gradients for Explaining Transformer Models"
      url: https://arxiv.org/abs/2602.16608
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16608v1 Announce Type: cross Abstract: Transformer models achieve state-of-the-art performance
        across domains and tasks, yet their deeply layered representations make their predictions difficult to
        interpret. Existing explainability methods rely on final-layer attributions, capture either local token-level
        attributions or global attention patterns without unification, and lack context-awareness of inter-token
        dependencies and structural components. They also fail to capture how releva"
      relevanceScore: 65
      topics:
        - interpretability-sufficient
        - safety-research
      entities:
        - interpretability-sufficient
        - safety-research
    - title: Precise Attribute Intensity Control in Large Language Models via Targeted Representation Editing
      url: https://arxiv.org/abs/2510.12121
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2510.12121v2 Announce Type: replace Abstract: Precise attribute intensity control--generating Large
        Language Model (LLM) outputs with specific, user-defined attribute intensities--is crucial for AI systems
        adaptable to diverse user expectations. Current LLM alignment methods, however, typically provide only
        directional or open-ended guidance, failing to reliably achieve exact attribute intensities. We address this
        limitation with three key designs: (1) reformulating precise attribute inten"
      relevanceScore: 65
      topics:
        - interpretability-sufficient
        - alignment
        - safety-research
      entities:
        - interpretability-sufficient
        - safety-research
    - title: "VerifyBench: Benchmarking Reference-based Reward Systems for Large Language Models"
      url: https://arxiv.org/abs/2505.15801
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2505.15801v4 Announce Type: replace-cross Abstract: Large reasoning models such as OpenAI o1 and
        DeepSeek-R1 have demonstrated remarkable performance in complex reasoning tasks. A critical component of their
        training is the incorporation of reference-based reward systems within reinforcement learning (RL), where model
        outputs are evaluated against ground truth references. However, existing reward benchmarks focus on preference
        comparisons between responses rather than evaluating verificati"
      relevanceScore: 65
      topics:
        - reward-modeling
        - language-models
        - evaluation
        - alignment
      entities:
        - language-models
        - reward-hacking-taxonomy
    - title: "When Models Examine Themselves: Vocabulary-Activation Correspondence in Self-Referential Processing"
      url: https://arxiv.org/abs/2602.11358
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.11358v2 Announce Type: replace-cross Abstract: Large language models produce rich introspective
        language when prompted for self-examination, but whether this language reflects internal computation or
        sophisticated confabulation has remained unclear. We show that self-referential vocabulary tracks concurrent
        activation dynamics, and that this correspondence is specific to self-referential processing. We introduce the
        Pull Methodology, a protocol that elicits extended self-examination t"
      relevanceScore: 65
      topics:
        - language-models
        - interpretability
        - self-awareness
        - introspection
      entities:
        - interpretability-sufficient
        - situational-awareness
    - title: Closing the Distribution Gap in Adversarial Training for LLMs
      url: https://arxiv.org/abs/2602.15238
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15238v2 Announce Type: replace-cross Abstract: Adversarial training for LLMs is one of the most
        promising methods to reliably improve robustness against adversaries. However, despite significant progress,
        models remain vulnerable to simple in-distribution exploits, such as rewriting prompts in the past tense or
        translating them into other languages. We argue that this persistent fragility stems from a fundamental
        limitation in current adversarial training algorithms: they minimize adv"
      relevanceScore: 65
      topics:
        - language-models
        - adversarial-robustness
        - safety
        - alignment
      entities:
        - alignment-progress
        - safety-research
    - title: SecCodeBench-V2 Technical Report
      url: https://arxiv.org/abs/2602.15485
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15485v2 Announce Type: replace-cross Abstract: We introduce SecCodeBench-V2, a publicly released
        benchmark for evaluating Large Language Model (LLM) copilots' capabilities of generating secure code.
        SecCodeBench-V2 comprises 98 generation and fix scenarios derived from Alibaba Group's industrial productions,
        where the underlying security issues span 22 common CWE (Common Weakness Enumeration) categories across five
        programming languages: Java, C, Python, Go, and JavaScript. SecCodeBen"
      relevanceScore: 65
      topics:
        - security
        - LLM capabilities
        - code generation
        - dual-use
      entities:
        - language-models
        - misuse-risks
    - title: "CheckIfExist: Detecting Citation Hallucinations in the Era of AI-Generated Content"
      url: https://arxiv.org/abs/2602.15871
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15871v1 Announce Type: new Abstract: The proliferation of large language models (LLMs) in academic
        workflows has introduced unprecedented challenges to bibliographic integrity, particularly through reference
        hallucination -- the generation of plausible but non-existent citations. Recent investigations have documented
        the presence of AI-hallucinated citations even in papers accepted at premier machine learning conferences such
        as NeurIPS and ICLR, underscoring the urgency of automated "
      relevanceScore: 65
      topics:
        - hallucinations
        - LLM reliability
        - misinformation
      entities:
        - language-models
        - epistemic-risks
    - title: Graph Representation-based Model Poisoning on the Heterogeneous Internet of Agents
      url: https://arxiv.org/abs/2511.07176
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2511.07176v2 Announce Type: replace-cross Abstract: Internet of Agents (IoA) envisions a unified,
        agent-centric paradigm where heterogeneous large language model (LLM) agents can interconnect and collaborate at
        scale. Within this paradigm, federated fine-tuning (FFT) serves as a key enabler that allows distributed LLM
        agents to co-train an intelligent global LLM without centralizing local datasets. However, the FFT-enabled IoA
        systems remain vulnerable to model poisoning attacks, where adv"
      relevanceScore: 65
      topics:
        - model-poisoning
        - adversarial-attacks
        - multi-agent-systems
        - security
      entities:
        - agentic-ai
        - misuse-risks
    - title: Multi-Objective Alignment of Language Models for Personalized Psychotherapy
      url: https://arxiv.org/abs/2602.16053
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16053v1 Announce Type: new Abstract: Mental health disorders affect over 1 billion people
        worldwide, yet access to care remains limited by workforce shortages and cost constraints. While AI systems show
        therapeutic promise, current alignment approaches optimize objectives independently, failing to balance patient
        preferences with clinical safety. We survey 335 individuals with lived mental health experience to collect
        preference rankings across therapeutic dimensions, then develop a m"
      relevanceScore: 65
      topics:
        - alignment
        - multi-objective-alignment
        - language-models
        - applications
      entities:
        - language-models
        - alignment-progress
    - title: Evolutionary Context Search for Automated Skill Acquisition
      url: https://arxiv.org/abs/2602.16113
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16113v1 Announce Type: cross Abstract: Large Language Models cannot reliably acquire new knowledge
        post-deployment -- even when relevant text resources exist, models fail to transform them into actionable
        knowledge without retraining. Retrieval-Augmented Generation attempts to bridge this gap by surfacing relevant
        documents at inference time, yet similarity-based retrieval often fails to identify context that actually
        improves task performance. We introduce Evolutionary Context Search"
      relevanceScore: 65
      topics:
        - language-models
        - capabilities
        - self-improvement
      entities:
        - language-models
        - capabilities
    - title: On the Expressive Power of Mixture-of-Experts for Structured Complex Tasks
      url: https://arxiv.org/abs/2505.24205
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2505.24205v2 Announce Type: replace Abstract: Mixture-of-experts networks (MoEs) have demonstrated
        remarkable efficiency in modern deep learning. Despite their empirical success, the theoretical foundations
        underlying their ability to model complex tasks remain poorly understood. In this work, we conduct a systematic
        study of the expressive power of MoEs in modeling complex tasks with two common structural priors:
        low-dimensionality and sparsity. For shallow MoEs, we prove that they can ef"
      relevanceScore: 65
      topics:
        - mixture-of-experts
        - model-architecture
        - scaling
      entities:
        - sparse-moe
        - capabilities
    - title: "Safe But Not Sorry: Reducing Over-Conservatism in Safety Critics via Uncertainty-Aware Modulation"
      url: https://arxiv.org/abs/2510.18478
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2510.18478v2 Announce Type: replace Abstract: Ensuring the safe exploration of reinforcement learning
        (RL) agents is critical for deployment in real-world systems. Yet existing approaches struggle to strike the
        right balance: methods that tightly enforce safety often cripple task performance, while those that prioritize
        reward leave safety constraints frequently violated, producing diffuse cost landscapes that flatten gradients
        and stall policy improvement. We introduce the Uncertain Safet"
      relevanceScore: 65
      topics:
        - safe-reinforcement-learning
        - safety-constraints
        - deployment
      entities:
        - safety-research
        - deployment-architectures-table
    - title: "Watch Out for the Lifespan: Evaluating Backdoor Attacks Against Federated Model Adaptation"
      url: https://arxiv.org/abs/2511.14406
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2511.14406v2 Announce Type: replace Abstract: Large models adaptation through Federated Learning (FL)
        addresses a wide range of use cases and is enabled by Parameter-Efficient Fine-Tuning techniques such as
        Low-Rank Adaptation (LoRA). However, this distributed learning paradigm faces several security threats,
        particularly to its integrity, such as backdoor attacks that aim to inject malicious behavior during the local
        training steps of certain clients. We present the first analysis of the "
      relevanceScore: 65
      topics:
        - backdoor-attacks
        - federated-learning
        - security
        - model-adaptation
      entities:
        - misuse-risks
        - safety-research
    - title: "Language and Experience: A Computational Model of Social Learning in Complex Tasks"
      url: https://arxiv.org/abs/2509.00074
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2509.00074v2 Announce Type: replace Abstract: The ability to combine linguistic guidance from others
        with direct experience is central to human development, enabling safe and rapid learning in new environments.
        How do people integrate these two sources of knowledge, and how might AI systems? We present a computational
        framework that models social learning as joint probabilistic inference over structured, executable world models
        given sensorimotor and linguistic data. We make this possible "
      relevanceScore: 62
      topics:
        - agentic-ai
        - learning
        - safety-research
      entities:
        - agentic-ai
        - safety-research
    - title: GPT-5.2 derives a new result in theoretical physics
      url: https://openai.com/index/new-result-theoretical-physics
      sourceId: openai-blog
      publishedAt: Fri, 13 Feb 2026 11:00:00 GMT
      summary: A new preprint shows GPT-5.2 proposing a new formula for a gluon amplitude, later formally proved and verified
        by OpenAI and academic collaborators.
      relevanceScore: 60
      topics:
        - capabilities
        - scientific-research
        - reasoning
      entities:
        - capabilities
        - scientific-research
        - reasoning
    - title: Introducing OpenAI Frontier
      url: https://openai.com/index/introducing-openai-frontier
      sourceId: openai-blog
      publishedAt: Thu, 05 Feb 2026 06:00:00 GMT
      summary: OpenAI Frontier is an enterprise platform for building, deploying, and managing AI agents with shared context,
        onboarding, permissions, and governance.
      relevanceScore: 60
      topics:
        - agentic-ai
        - deployment-architectures-table
        - governance
      entities:
        - agentic-ai
        - deployment-architectures-table
    - title: Unrolling the Codex agent loop
      url: https://openai.com/index/unrolling-the-codex-agent-loop
      sourceId: openai-blog
      publishedAt: Fri, 23 Jan 2026 12:00:00 GMT
      summary: A technical deep dive into the Codex agent loop, explaining how Codex CLI orchestrates models, tools, prompts,
        and performance using the Responses API.
      relevanceScore: 60
      topics:
        - agentic-ai
        - tool-use
        - reasoning
      entities:
        - agentic-ai
        - tool-use
        - reasoning
    - title: Strengthening the U.S. AI supply chain through domestic manufacturing
      url: https://openai.com/index/strengthening-the-us-ai-supply-chain
      sourceId: openai-blog
      publishedAt: Thu, 15 Jan 2026 00:00:00 GMT
      summary: OpenAI launches a new RFP to strengthen the U.S. AI supply chain by accelerating domestic manufacturing,
        creating jobs, and scaling AI infrastructure.
      relevanceScore: 60
      topics:
        - compute-hardware
        - ai-megaproject-infrastructure
        - geopolitics
      entities:
        - compute-hardware
        - ai-megaproject-infrastructure
        - geopolitics
    - title: Netomi’s lessons for scaling agentic systems into the enterprise
      url: https://openai.com/index/netomi
      sourceId: openai-blog
      publishedAt: Thu, 08 Jan 2026 13:00:00 GMT
      summary: How Netomi scales enterprise AI agents using GPT-4.1 and GPT-5.2—combining concurrency, governance, and
        multi-step reasoning for reliable production workflows.
      relevanceScore: 60
      topics:
        - agentic-ai
        - reasoning
        - safety-research
      entities:
        - agentic-ai
        - reasoning
    - title: GPT-5 and the future of mathematical discovery
      url: https://openai.com/index/gpt-5-mathematical-discovery
      sourceId: openai-blog
      publishedAt: Mon, 24 Nov 2025 00:00:00 GMT
      summary: UCLA Professor Ernest Ryu and GPT-5 solved a key question in optimization theory, showcasing AI’s role in
        accelerating mathematical discovery.
      relevanceScore: 60
      topics:
        - scientific-research
        - reasoning
        - capabilities
      entities:
        - __index__/knowledge-base/capabilities
    - title: Building more with GPT-5.1-Codex-Max
      url: https://openai.com/index/gpt-5-1-codex-max
      sourceId: openai-blog
      publishedAt: Wed, 19 Nov 2025 00:00:00 GMT
      summary: Introducing GPT-5.1-Codex-Max, a faster, more intelligent agentic coding model for Codex. The model is designed
        for long-running, project-scale work with enhanced reasoning and token efficiency.
      relevanceScore: 60
      topics:
        - coding
        - agentic-ai
        - long-horizon
        - capabilities
      entities:
        - __index__/knowledge-base/capabilities
    - title: AI progress and recommendations
      url: https://openai.com/index/ai-progress-and-recommendations
      sourceId: openai-blog
      publishedAt: Thu, 06 Nov 2025 00:00:00 GMT
      summary: AI is advancing fast. We have the chance to shape its progress—toward discovery, safety, and a better future
        for everyone.
      relevanceScore: 60
      topics:
        - ai-safety
        - governance
        - responsible-ai
      entities:
        - solutions
    - title: The next chapter for UK sovereign AI
      url: https://openai.com/index/the-next-chapter-for-uk-sovereign-ai
      sourceId: openai-blog
      publishedAt: Wed, 22 Oct 2025 16:00:00 GMT
      summary: OpenAI expands its UK partnership with a new Ministry of Justice agreement, bringing ChatGPT to civil servants.
        It also introduces UK data residency for ChatGPT Enterprise, ChatGPT Edu, and the API Platform to support
        trusted and secure AI adoption.
      relevanceScore: 60
      topics:
        - geopolitics
        - regulation-debate
        - agi-development
      entities:
        - geopolitics
        - regulation-debate
    - title: OpenAI announces strategic collaboration with Japan’s Digital Agency
      url: https://openai.com/global-affairs/strategic-collaboration-with-japan-digital-agency
      sourceId: openai-blog
      publishedAt: Thu, 02 Oct 2025 00:00:00 GMT
      summary: OpenAI and Japan’s Digital Agency partner to advance generative AI in public services, support international AI
        governance, and promote safe, trustworthy AI adoption worldwide.
      relevanceScore: 60
      topics:
        - regulation-debate
        - geopolitics
        - safety-research
      entities:
        - regulation-debate
        - geopolitics
        - safety-research
    - title: OpenAI and NVIDIA announce strategic partnership to deploy 10 gigawatts of NVIDIA systems
      url: https://openai.com/index/openai-nvidia-systems-partnership
      sourceId: openai-blog
      publishedAt: Mon, 22 Sep 2025 08:45:00 GMT
      summary: OpenAI and NVIDIA announce a strategic partnership to deploy 10 gigawatts of AI datacenters powered by NVIDIA
        systems, with the first phase launching in 2026.
      relevanceScore: 60
      topics:
        - compute-hardware
        - ai-megaproject-infrastructure
      entities:
        - compute-hardware
        - ai-megaproject-infrastructure
    - title: Accelerating life sciences research
      url: https://openai.com/index/accelerating-life-sciences-research-with-retro-biosciences
      sourceId: openai-blog
      publishedAt: Fri, 22 Aug 2025 08:30:00 GMT
      summary: Discover how a specialized AI model, GPT-4b micro, helped OpenAI and Retro Bio engineer more effective proteins
        for stem cell therapy and longevity research.
      relevanceScore: 60
      topics:
        - capabilities
        - scientific-research
        - protein-engineering
        - life-sciences
      entities:
        - scientific-research
        - capabilities
    - title: GPT-5 and the new era of work
      url: https://openai.com/index/gpt-5-new-era-of-work
      sourceId: openai-blog
      publishedAt: Thu, 07 Aug 2025 10:00:00 GMT
      summary: GPT-5 is OpenAI’s most advanced model—transforming enterprise AI, automation, and workforce productivity in the
        new era of intelligent work.
      relevanceScore: 60
      topics:
        - capabilities
        - enterprise
        - automation
        - workforce
      entities:
        - capabilities
        - economic-labor
    - title: Introducing GPT-5
      url: https://openai.com/index/introducing-gpt-5
      sourceId: openai-blog
      publishedAt: Thu, 07 Aug 2025 00:00:00 GMT
      summary: We are introducing GPT‑5, our best AI system yet. GPT‑5 is a significant leap in intelligence over all our
        previous models, featuring state-of-the-art performance across coding, math, writing, health, visual perception,
        and more.
      relevanceScore: 60
      topics:
        - language-models
        - capabilities
        - reasoning
      entities:
        - language-models
        - capabilities
    - title: Stargate advances with 4.5 GW partnership with Oracle
      url: https://openai.com/index/stargate-advances-with-partnership-with-oracle
      sourceId: openai-blog
      publishedAt: Tue, 22 Jul 2025 00:00:00 GMT
      summary: Oracle and OpenAI have entered an agreement to develop 4.5 gigawatts of additional Stargate data center
        capacity in the U.S. This investment will create new jobs, accelerate America’s reindustrialization, and help
        advance U.S. AI leadership. It also marks a major milestone for Stargate, OpenAI’s AI infrastructure platform
        and long-term vision to deliver the benefits of AI to everyone.
      relevanceScore: 60
      topics:
        - compute-hardware
        - ai-megaproject-infrastructure
        - geopolitics
      entities:
        - compute-hardware
        - ai-megaproject-infrastructure
    - title: Introducing Stargate UAE
      url: https://openai.com/index/introducing-stargate-uae
      sourceId: openai-blog
      publishedAt: Thu, 22 May 2025 00:00:00 GMT
      summary: We’re launching Stargate UAE – the first international deployment of Stargate, OpenAI’s AI infrastructure
        platform.
      relevanceScore: 60
      topics:
        - compute-hardware
        - ai-megaproject-infrastructure
        - geopolitics
      entities:
        - compute-hardware
        - ai-megaproject-infrastructure
        - geopolitics
    - title: Introducing HealthBench
      url: https://openai.com/index/healthbench
      sourceId: openai-blog
      publishedAt: Mon, 12 May 2025 10:30:00 GMT
      summary: HealthBench is a new evaluation benchmark for AI in healthcare which evaluates models in realistic scenarios.
        Built with input from 250+ physicians, it aims to provide a shared standard for model performance and safety in
        health.
      relevanceScore: 60
      topics:
        - safety-research
        - eval-types
        - capabilities
      entities:
        - safety-research
        - eval-types-table
    - title: OpenAI’s EU Economic Blueprint
      url: https://openai.com/global-affairs/openais-eu-economic-blueprint
      sourceId: openai-blog
      publishedAt: Mon, 07 Apr 2025 00:00:00 GMT
      summary: Today, OpenAI is sharing the EU Economic Blueprint—a set of proposals to help Europe seize the promise of
        artificial intelligence, drive sustainable economic growth across the region, and ensure that AI is developed
        and deployed by Europe, in Europe, for Europe.
      relevanceScore: 60
      topics:
        - governance
        - regulation
        - geopolitics
      entities:
        - geopolitics
        - regulation-debate
    - title: "Addendum to GPT-4o System Card: 4o image generation"
      url: https://openai.com/index/gpt-4o-image-generation-system-card-addendum
      sourceId: openai-blog
      publishedAt: Tue, 25 Mar 2025 11:00:00 GMT
      summary: 4o image generation is a new, significantly more capable image generation approach than our earlier DALL·E 3
        series of models. It can create photorealistic output. It can take images as inputs and transform them.
      relevanceScore: 60
      topics:
        - capabilities
        - safety-evaluation
        - image-generation
      entities:
        - eval-types-table
    - title: OpenAI GPT-4.5 System Card
      url: https://openai.com/index/gpt-4-5-system-card
      sourceId: openai-blog
      publishedAt: Thu, 27 Feb 2025 12:00:00 GMT
      summary: We’re releasing a research preview of OpenAI GPT‑4.5, our largest and most knowledgeable model yet.
      relevanceScore: 60
      topics:
        - capabilities
        - safety-research
        - scaling-debate
      entities:
        - capabilities
        - safety-research
        - scaling-debate
    - title: Introducing ChatGPT Gov
      url: https://openai.com/global-affairs/introducing-chatgpt-gov
      sourceId: openai-blog
      publishedAt: Tue, 28 Jan 2025 06:00:00 GMT
      summary: ChatGPT Gov is designed to streamline government agencies’ access to OpenAI’s frontier models.
      relevanceScore: 60
      topics:
        - deployment-architectures-table
        - geopolitics
        - regulation-debate
      entities:
        - deployment-architectures-table
    - title: Simplifying, stabilizing, and scaling continuous-time consistency models
      url: https://openai.com/index/simplifying-stabilizing-and-scaling-continuous-time-consistency-models
      sourceId: openai-blog
      publishedAt: Wed, 23 Oct 2024 10:00:00 GMT
      summary: We’ve simplified, stabilized, and scaled continuous-time consistency models, achieving comparable sample
        quality to leading diffusion models, while using only two sampling steps.
      relevanceScore: 60
      topics:
        - capabilities
        - diffusion-models
        - architecture
        - sampling
      entities:
        - capabilities
    - title: Learning to reason with LLMs
      url: https://openai.com/index/learning-to-reason-with-llms
      sourceId: openai-blog
      publishedAt: Thu, 12 Sep 2024 10:02:00 GMT
      summary: We are introducing OpenAI o1, a new large language model trained with reinforcement learning to perform complex
        reasoning. o1 thinks before it answers—it can produce a long internal chain of thought before responding to the
        user.
      relevanceScore: 60
      topics:
        - reasoning
        - capabilities
        - long-horizon
      entities:
        - reasoning
        - long-horizon
        - capabilities
    - title: Finding GPT-4’s mistakes with GPT-4
      url: https://openai.com/index/finding-gpt4s-mistakes-with-gpt-4
      sourceId: openai-blog
      publishedAt: Thu, 27 Jun 2024 10:00:00 GMT
      summary: CriticGPT, a model based on GPT-4, writes critiques of ChatGPT responses to help human trainers spot mistakes
        during RLHF
      relevanceScore: 60
      topics:
        - alignment
        - safety
        - training-methods
        - evaluation
      entities:
        - alignment-progress
        - safety-research
    - title: Hello GPT-4o
      url: https://openai.com/index/hello-gpt-4o
      sourceId: openai-blog
      publishedAt: Mon, 13 May 2024 10:05:00 GMT
      summary: We’re announcing GPT-4 Omni, our new flagship model which can reason across audio, vision, and text in real time.
      relevanceScore: 60
      topics:
        - capabilities
        - language-models
      entities:
        - capabilities
        - language-models
    - title: Understanding the source of what we see and hear online
      url: https://openai.com/index/understanding-the-source-of-what-we-see-and-hear-online
      sourceId: openai-blog
      publishedAt: Tue, 07 May 2024 00:00:00 GMT
      summary: Today we’re introducing new technology to help researchers identify content created by our tools and joining
        the Coalition for Content Provenance and Authenticity Steering Committee to promote industry standards.
      relevanceScore: 60
      topics:
        - misuse-risks
        - deepfakes-authentication-crisis
        - safety-research
      entities:
        - misuse-risks
        - deepfakes-authentication-crisis
    - title: Review completed & Altman, Brockman to continue to lead OpenAI
      url: https://openai.com/index/review-completed-altman-brockman-to-continue-to-lead-openai
      sourceId: openai-blog
      publishedAt: Fri, 08 Mar 2024 08:00:00 GMT
      summary: New board members named and enhancements to the governance structure introduced
      relevanceScore: 60
      topics:
        - governance
        - lab-behavior
        - structural
      entities:
        - governance
        - lab-behavior
        - structural
    - title: Response to NIST Executive Order on AI
      url: https://openai.com/global-affairs/response-to-nist-executive-order-on-ai
      sourceId: openai-blog
      publishedAt: Fri, 02 Feb 2024 00:00:00 GMT
      summary: The National Institute of Standards and Technology (NIST) request for information related to its assignments
        under sections 4.1, 4.5, and 11 of the Executive Order Concerning Artificial Intelligence
      relevanceScore: 60
      topics:
        - regulation-debate
        - governance
      entities:
        - regulation-debate
    - title: Using GPT-4 for content moderation
      url: https://openai.com/index/using-gpt-4-for-content-moderation
      sourceId: openai-blog
      publishedAt: Tue, 15 Aug 2023 07:00:00 GMT
      summary: We use GPT-4 for content policy development and content moderation decisions, enabling more consistent
        labeling, a faster feedback loop for policy refinement, and less involvement from human moderators.
      relevanceScore: 60
      topics:
        - safety-research
        - misuse-risks
        - capabilities
      entities:
        - language-models
    - title: Announcing OpenAI’s Bug Bounty Program
      url: https://openai.com/index/bug-bounty-program
      sourceId: openai-blog
      publishedAt: Tue, 11 Apr 2023 07:00:00 GMT
      summary: This initiative is essential to our commitment to develop safe and advanced AI. As we create technology and
        services that are secure, reliable, and trustworthy, we need your help.
      relevanceScore: 60
      topics:
        - safety-research
        - security
        - responsible-disclosure
      entities:
        - safety-research
    - title: DALL·E 2 research preview update
      url: https://openai.com/index/dall-e-2-update
      sourceId: openai-blog
      publishedAt: Wed, 18 May 2022 07:00:00 GMT
      summary: Early users have created over 3 million images to date and helped us improve our safety processes. We’re
        excited to begin adding up to 1,000 new users from our waitlist each week.
      relevanceScore: 60
      topics:
        - safety-research
        - misuse-risks
      entities:
        - safety-research
        - misuse-risks
    - title: A research agenda for assessing the economic impacts of code generation models
      url: https://openai.com/index/economic-impacts-research
      sourceId: openai-blog
      publishedAt: Thu, 03 Mar 2022 08:00:00 GMT
      summary: ""
      relevanceScore: 60
      topics:
        - safety-research
        - economic-labor
        - capabilities
      entities:
        - safety-research
        - economic-labor
    - title: "TruthfulQA: Measuring how models mimic human falsehoods"
      url: https://openai.com/index/truthfulqa
      sourceId: openai-blog
      publishedAt: Wed, 08 Sep 2021 07:00:00 GMT
      summary: ""
      relevanceScore: 60
      topics:
        - safety-research
        - interpretability-sufficient
        - epistemic-risks
      entities:
        - safety-research
    - title: Language models are few-shot learners
      url: https://openai.com/index/language-models-are-few-shot-learners
      sourceId: openai-blog
      publishedAt: Thu, 28 May 2020 07:00:00 GMT
      summary: ""
      relevanceScore: 60
      topics:
        - capabilities
        - language-models
        - scaling-debate
      entities:
        - language-models
        - scaling-debate
    - title: "GPT-2: 1.5B release"
      url: https://openai.com/index/gpt-2-1-5b-release
      sourceId: openai-blog
      publishedAt: Tue, 05 Nov 2019 08:00:00 GMT
      summary: As the final model release of GPT-2’s staged release, we’re releasing the largest version (1.5B parameters) of
        GPT-2 along with code and model weights to facilitate detection of outputs of GPT-2 models. While there have
        been larger language models released since August, we’ve continued with our original staged release plan in
        order to provide the community with a test case of a full staged release process. We hope that this test case
        will be useful to developers of future powerful models, and we
      relevanceScore: 60
      topics:
        - language-models
        - capabilities
        - misuse-risks
      entities:
        - language-models
        - misuse-risks
    - title: "Neural MMO: A massively multiagent game environment"
      url: https://openai.com/index/neural-mmo
      sourceId: openai-blog
      publishedAt: Mon, 04 Mar 2019 08:00:00 GMT
      summary: We’re releasing a Neural MMO, a massively multiagent game environment for reinforcement learning agents. Our
        platform supports a large, variable number of agents within a persistent and open-ended task. The inclusion of
        many agents and species leads to better exploration, divergent niche formation, and greater overall competence.
      relevanceScore: 60
      topics:
        - reinforcement-learning
        - multi-agent
        - environment
      entities:
        - agentic-ai
    - title: Quantifying generalization in reinforcement learning
      url: https://openai.com/index/quantifying-generalization-in-reinforcement-learning
      sourceId: openai-blog
      publishedAt: Thu, 06 Dec 2018 08:00:00 GMT
      summary: "We’re releasing CoinRun, a training environment which provides a metric for an agent’s ability to transfer its
        experience to novel situations and has already helped clarify a longstanding puzzle in reinforcement learning.
        CoinRun strikes a desirable balance in complexity: the environment is simpler than traditional platformer games
        like Sonic the Hedgehog but still poses a worthy generalization challenge for state of the art algorithms."
      relevanceScore: 60
      topics:
        - reinforcement-learning
        - generalization
        - transfer-learning
      entities:
        - capabilities
    - title: "Plan online, learn offline: Efficient learning and exploration via model-based control"
      url: https://openai.com/index/plan-online-learn-offline
      sourceId: openai-blog
      publishedAt: Mon, 05 Nov 2018 08:00:00 GMT
      summary: ""
      relevanceScore: 60
      topics:
        - reinforcement-learning
        - model-based
        - planning
      entities:
        - long-horizon
    - title: Large-scale study of curiosity-driven learning
      url: https://openai.com/index/large-scale-study-of-curiosity-driven-learning
      sourceId: openai-blog
      publishedAt: Mon, 13 Aug 2018 07:00:00 GMT
      summary: ""
      relevanceScore: 60
      topics:
        - reinforcement-learning
        - curiosity
        - exploration
      entities:
        - capabilities
    - title: Learning Montezuma’s Revenge from a single demonstration
      url: https://openai.com/index/learning-montezumas-revenge-from-a-single-demonstration
      sourceId: openai-blog
      publishedAt: Wed, 04 Jul 2018 07:00:00 GMT
      summary: "We’ve trained an agent to achieve a high score of 74,500 on Montezuma’s Revenge from a single human
        demonstration, better than any previously published result. Our algorithm is simple: the agent plays a sequence
        of games starting from carefully chosen states from the demonstration, and learns from them by optimizing the
        game score using PPO, the same reinforcement learning algorithm that underpins OpenAI Five."
      relevanceScore: 60
      topics:
        - reinforcement-learning
        - learning-from-demonstrations
        - imitation
      entities:
        - capabilities
    - title: Interpretable and pedagogical examples
      url: https://openai.com/index/interpretable-and-pedagogical-examples
      sourceId: openai-blog
      publishedAt: Thu, 02 Nov 2017 07:00:00 GMT
      summary: ""
      relevanceScore: 60
      topics:
        - interpretability-sufficient
        - alignment-progress
      entities:
        - interpretability-sufficient
    - title: Learning to model other minds
      url: https://openai.com/index/learning-to-model-other-minds
      sourceId: openai-blog
      publishedAt: Thu, 14 Sep 2017 07:00:00 GMT
      summary: We’re releasing an algorithm which accounts for the fact that other agents are learning too, and discovers
        self-interested yet collaborative strategies like tit-for-tat in the iterated prisoner’s dilemma. This
        algorithm, Learning with Opponent-Learning Awareness (LOLA), is a small step towards agents that model other
        minds.
      relevanceScore: 60
      topics:
        - multi-agent
        - game-theory
        - cooperation
        - reasoning
      entities:
        - agentic-ai
        - reasoning
        - instrumental-convergence-framework
    - title: Adversarial attacks on neural network policies
      url: https://openai.com/index/adversarial-attacks-on-neural-network-policies
      sourceId: openai-blog
      publishedAt: Wed, 08 Feb 2017 08:00:00 GMT
      summary: ""
      relevanceScore: 60
      topics:
        - adversarial-attacks
        - robustness
        - safety
      entities: []
    - title: How we’re bringing AI image verification to the Gemini app
      url: https://deepmind.google/blog/how-were-bringing-ai-image-verification-to-the-gemini-app/
      sourceId: deepmind-blog
      publishedAt: Thu, 20 Nov 2025 15:13:19 +0000
      summary: ""
      relevanceScore: 60
      topics:
        - safety-research
        - deepfakes-authentication-crisis
      entities:
        - safety-research
        - deepfakes-authentication-crisis
    - title: "T5Gemma: A new collection of encoder-decoder Gemma models"
      url: https://deepmind.google/blog/t5gemma-a-new-collection-of-encoder-decoder-gemma-models/
      sourceId: deepmind-blog
      publishedAt: Sat, 25 Oct 2025 18:14:00 +0000
      summary: Introducing T5Gemma, a new collection of encoder-decoder LLMs.
      relevanceScore: 60
      topics:
        - language-models
        - architecture-scenarios-table
      entities:
        - language-models
        - architecture-scenarios-table
    - title: Try Deep Think in the Gemini app
      url: https://deepmind.google/blog/try-deep-think-in-the-gemini-app/
      sourceId: deepmind-blog
      publishedAt: Thu, 23 Oct 2025 18:54:19 +0000
      summary: We're rolling out Deep Think in the Gemini app for Google AI Ultra subscribers, and we're giving select
        mathematicians access to the full version of the Gemini 2.5 Deep Think model entered into the IMO competition.
      relevanceScore: 60
      topics:
        - reasoning
        - capabilities
      entities:
        - reasoning
        - capabilities
    - title: We’re expanding our Gemini 2.5 family of models
      url: https://deepmind.google/blog/were-expanding-our-gemini-25-family-of-models/
      sourceId: deepmind-blog
      publishedAt: Tue, 17 Jun 2025 16:00:00 +0000
      summary: Gemini 2.5 Flash and Pro are now generally available, and we’re introducing 2.5 Flash-Lite, our most
        cost-efficient and fastest 2.5 model yet.
      relevanceScore: 60
      topics:
        - language-models
        - capabilities
      entities:
        - language-models
        - capabilities
    - title: "Gemini 2.5: Our most intelligent models are getting even better"
      url: https://deepmind.google/blog/gemini-25-our-world-leading-model-is-getting-even-better/
      sourceId: deepmind-blog
      publishedAt: Tue, 20 May 2025 09:45:00 +0000
      summary: Gemini 2.5 Pro continues to be loved by developers as the best model for coding, and 2.5 Flash is getting even
        better with a new update. We’re bringing new capabilities to our models, including Deep Think, an experimental
        enhanced reasoning mode for 2.5 Pro.
      relevanceScore: 60
      topics:
        - language-models
        - coding
        - capabilities
      entities:
        - language-models
        - coding
        - capabilities
    - title: "Genie 2: A large-scale foundation world model"
      url: https://deepmind.google/blog/genie-2-a-large-scale-foundation-world-model/
      sourceId: deepmind-blog
      publishedAt: Wed, 04 Dec 2024 14:23:00 +0000
      summary: Generating unlimited diverse training environments for future general agents
      relevanceScore: 60
      topics:
        - world-models
        - agentic-ai
        - capabilities
      entities:
        - world-models
        - agentic-ai
    - title: Manifold spin off MNX, a real money decentralized market for AI-related bets. Includes levered prediction
        markets, perpetual futures
      url: https://www.lesswrong.com/posts/2mJ3BzFkvHAWjhqdy/manifold-spin-off-mnx-a-real-money-decentralized-market-for
      sourceId: lesswrong
      publishedAt: Wed, 18 Feb 2026 22:36:24 GMT
      summary: Published on February 18, 2026 10:36 PM GMTTrillions of dollars are flowing into AI, and there is almost
        nowhere to trade it.There’s no exchange for hyperscalers to hedge their $100M training runs. No benchmark
        markets to bet on the speed of AI progress. No public markets on OpenAI despite them being worth more than
        Goldman Sachs.The most important sector in the global economy has less financial infrastructure than soybeans.
        Until now.Announcing MNX, the first exchange to allow trading across th
      relevanceScore: 60
      topics:
        - agi-timeline
        - forecasting
        - geopolitics
      entities:
        - __index__/knowledge-base/forecasting
        - agi-timeline
        - geopolitics
    - title: "Last Week in AI #333 - ChatGPT Ads, Zhipu+Huawei, Drama at Thinking Machines"
      url: https://lastweekin.ai/p/last-week-in-ai-333-chatgpt-ads-zhipuhuawei
      sourceId: last-week-in-ai
      publishedAt: Fri, 23 Jan 2026 05:14:53 GMT
      summary: OpenAI to test ads in ChatGPT as it burns through billions, Sequoia to invest in Anthropic, Zhipu AI breaks US
        chip reliance, The Drama at Thinking Machines Is Riveting Silicon Valley
      relevanceScore: 60
      topics:
        - capabilities
        - geopolitics
        - compute-hardware
        - lab-behavior
      entities:
        - compute-hardware
        - geopolitics
    - title: "Last Week in AI #332 - Apple + Gemini, OpenAI + Cerebras, Claude Cowork"
      url: https://lastweekin.ai/p/last-week-in-ai-332-apple-gemini
      sourceId: last-week-in-ai
      publishedAt: Thu, 15 Jan 2026 07:06:16 GMT
      summary: Google&#8217;s Gemini to power Apple&#8217;s AI features like Siri, OpenAI signs deal worth $10B for compute
        from Cerebras, and more!
      relevanceScore: 60
      topics:
        - capabilities
        - compute-hardware
        - lab-behavior
      entities:
        - compute-hardware
        - lab-behavior
    - title: "Last Week in AI #330 - Groq->Nvidia , ChatGPT Apps, US AI Genesis Mission"
      url: https://lastweekin.ai/p/last-week-in-ai-330-groq-nvidia-chatgpt
      sourceId: last-week-in-ai
      publishedAt: Thu, 25 Dec 2025 08:51:51 GMT
      summary: Nvidia buying AI chip startup Groq&#8217;s assets for about $20 billion in largest deal on record, OpenAI opens
        ChatGPT to third-party apps via its Platform, and more!
      relevanceScore: 60
      topics:
        - compute-hardware
        - capabilities
        - lab-behavior
      entities:
        - compute-hardware
        - lab-behavior
    - title: "Last Week in AI #328 - DeepSeek 3.2, Mistral 3, Trainium3, Runway Gen-4.5"
      url: https://lastweekin.ai/p/last-week-in-ai-328-deepseek-32-mistral
      sourceId: last-week-in-ai
      publishedAt: Mon, 08 Dec 2025 04:44:04 GMT
      summary: DeepSeek Releases New Reasoning Models, Mistral closes in on Big AI rivals with new open-weight frontier and
        small models, and more!
      relevanceScore: 60
      topics:
        - capabilities
        - language-models
        - reasoning
      entities:
        - language-models
        - reasoning
    - title: Building Safe and Deployable Clinical Natural Language Processing under Temporal Leakage Constraints
      url: https://arxiv.org/abs/2602.15852
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15852v1 Announce Type: cross Abstract: Clinical natural language processing (NLP) models have shown
        promise for supporting hospital discharge planning by leveraging narrative clinical documentation. However,
        note-based models are particularly vulnerable to temporal and lexical leakage, where documentation artifacts
        encode future clinical decisions and inflate apparent predictive performance. Such behavior poses substantial
        risks for real-world deployment, where overconfident or tempor"
      relevanceScore: 60
      topics:
        - safety
        - deployment
        - natural-language-processing
        - medical-ai
      entities:
        - solutions
        - deployment-architectures-table
    - title: "NLP Privacy Risk Identification in Social Media (NLP-PRISM): A Survey"
      url: https://arxiv.org/abs/2602.15866
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15866v1 Announce Type: cross Abstract: Natural Language Processing (NLP) is integral to social
        media analytics but often processes content containing Personally Identifiable Information (PII), behavioral
        cues, and metadata raising privacy risks such as surveillance, profiling, and targeted advertising. To
        systematically assess these risks, we review 203 peer-reviewed papers and propose the NLP Privacy Risk
        Identification in Social Media (NLP-PRISM) framework, which evaluates vulnerabi"
      relevanceScore: 60
      topics:
        - privacy
        - safety
        - misuse-risks
        - nlp
      entities:
        - misuse-risks
        - solutions
    - title: Generalized Leverage Score for Scalable Assessment of Privacy Vulnerability
      url: https://arxiv.org/abs/2602.15919
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15919v1 Announce Type: cross Abstract: Can the privacy vulnerability of individual data points be
        assessed without retraining models or explicitly simulating attacks? We answer affirmatively by showing that
        exposure to membership inference attack (MIA) is fundamentally governed by a data point's influence on the
        learned model. We formalize this in the linear setting by establishing a theoretical correspondence between
        individual MIA risk and the leverage score, identifying it as a pri"
      relevanceScore: 60
      topics:
        - privacy
        - safety-research
        - model-security
        - misuse-risks
      entities:
        - safety-research
        - misuse-risks
    - title: "Language Statistics and False Belief Reasoning: Evidence from 41 Open-Weight LMs"
      url: https://arxiv.org/abs/2602.16085
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16085v1 Announce Type: cross Abstract: Research on mental state reasoning in language models (LMs)
        has the potential to inform theories of human social cognition--such as the theory that mental state reasoning
        emerges in part from language exposure--and our understanding of LMs themselves. Yet much published work on LMs
        relies on a relatively small sample of closed-source LMs, limiting our ability to rigorously test psychological
        theories and evaluate LM capacities. Here, we replicate"
      relevanceScore: 60
      topics:
        - language-models
        - reasoning
        - interpretability
        - theory-of-mind
        - epistemic-risks
      entities:
        - language-models
        - reasoning
        - epistemic-risks
    - title: Interpretability-by-Design with Accurate Locally Additive Models and Conditional Feature Effects
      url: https://arxiv.org/abs/2602.16503
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16503v1 Announce Type: cross Abstract: Generalized additive models (GAMs) offer interpretability
        through independent univariate feature effects but underfit when interactions are present in data. GA$^2$Ms add
        selected pairwise interactions which improves accuracy, but sacrifices interpretability and limits model
        auditing. We propose \\emph{Conditionally Additive Local Models} (CALMs), a new model class, that balances the
        interpretability of GAMs with the accuracy of GA$^2$Ms. CALMs all"
      relevanceScore: 60
      topics:
        - interpretability-sufficient
        - safety-research
      entities:
        - interpretability-sufficient
        - safety-research
    - title: "SEISMO: Increasing Sample Efficiency in Molecular Optimization with a Trajectory-Aware LLM Agent"
      url: https://arxiv.org/abs/2602.00663
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.00663v2 Announce Type: replace Abstract: Optimizing the structure of molecules to achieve desired
        properties is a central bottleneck across the chemical sciences, particularly in the pharmaceutical industry
        where it underlies the discovery of new drugs. Since molecular property evaluation often relies on costly and
        rate-limited oracles, such as experimental assays, molecular optimization must be highly sample-efficient. To
        address this, we introduce SEISMO, an LLM agent that performs "
      relevanceScore: 60
      topics:
        - agentic-ai
        - tool-use
        - scientific-research
      entities:
        - agentic-ai
        - tool-use
        - scientific-research
    - title: Do Vision-Language Models Respect Contextual Integrity in Location Disclosure?
      url: https://arxiv.org/abs/2602.05023
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.05023v2 Announce Type: replace-cross Abstract: Vision-language models (VLMs) have demonstrated
        strong performance in image geolocation, a capability further sharpened by frontier multimodal large reasoning
        models (MLRMs). This poses a significant privacy risk, as these widely accessible models can be exploited to
        infer sensitive locations from casually shared photos, often at street-level precision, potentially surpassing
        the level of detail the sharer consented or intended to disclos"
      relevanceScore: 60
      topics:
        - vision-language-models
        - privacy
        - safety
        - misuse-risks
      entities:
        - misuse-risks
        - safety-research
    - title: Does Socialization Emerge in AI Agent Society? A Case Study of Moltbook
      url: https://arxiv.org/abs/2602.14299
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.14299v2 Announce Type: replace-cross Abstract: As large language model agents increasingly populate
        networked environments, a fundamental question arises: do artificial intelligence (AI) agent societies undergo
        convergence dynamics similar to human social systems? Lately, Moltbook approximates a plausible future scenario
        in which autonomous agents participate in an open-ended, continuously evolving online society. We present the
        first large-scale systemic diagnosis of this AI agent so"
      relevanceScore: 60
      topics:
        - ai-agents
        - multi-agent-systems
        - emergent-behavior
        - agentic-ai
      entities:
        - agentic-ai
        - multi-actor-landscape
    - title: "Understanding LLM Failures: A Multi-Tape Turing Machine Analysis of Systematic Errors in Language Model
        Reasoning"
      url: https://arxiv.org/abs/2602.15868
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15868v1 Announce Type: new Abstract: Large language models (LLMs) exhibit failure modes on
        seemingly trivial tasks. We propose a formalisation of LLM interaction using a deterministic multi-tape Turing
        machine, where each tape represents a distinct component: input characters, tokens, vocabulary, model
        parameters, activations, probability distributions, and output text. The model enables precise localisation of
        failure modes to specific pipeline stages, revealing, e.g., how tokenisati"
      relevanceScore: 60
      topics:
        - LLM failures
        - reasoning
        - interpretability
      entities:
        - language-models
        - reasoning
        - interpretability-sufficient
    - title: "Missing-by-Design: Certifiable Modality Deletion for Revocable Multimodal Sentiment Analysis"
      url: https://arxiv.org/abs/2602.16144
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16144v1 Announce Type: new Abstract: As multimodal systems increasingly process sensitive personal
        data, the ability to selectively revoke specific data modalities has become a critical requirement for privacy
        compliance and user autonomy. We present Missing-by-Design (MBD), a unified framework for revocable multimodal
        sentiment analysis that combines structured representation learning with a certifiable parameter-modification
        pipeline. Revocability is critical in privacy-sensitive ap"
      relevanceScore: 60
      topics:
        - privacy
        - data deletion
        - multimodal systems
      entities:
        - language-models
        - misuse-risks
    - title: "MemoryArena: Benchmarking Agent Memory in Interdependent Multi-Session Agentic Tasks"
      url: https://arxiv.org/abs/2602.16313
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16313v1 Announce Type: new Abstract: Existing evaluations of agents with memory typically assess
        memorization and action in isolation. One class of benchmarks evaluates memorization by testing recall of past
        conversations or text but fails to capture how memory is used to guide future decisions. Another class focuses
        on agents acting in single-session tasks without the need for long-term memory. However, in realistic settings,
        memorization and action are tightly coupled: agents acquir"
      relevanceScore: 60
      topics:
        - agentic AI
        - memory
        - agent evaluation
      entities:
        - agentic-ai
        - language-models
    - title: "CAST: Character-and-Scene Episodic Memory for Agents"
      url: https://arxiv.org/abs/2602.06051
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.06051v3 Announce Type: replace Abstract: Episodic memory is a central component of human memory,
        which refers to the ability to recall coherent events grounded in who, when, and where. However, most agent
        memory systems only emphasize semantic recall and treat experience as structures such as key-value, vector, or
        graph, which makes them struggle to represent and retrieve coherent events. To address this challenge, we
        propose a Character-and-Scene based memory architecture(CAST) inspi"
      relevanceScore: 60
      topics:
        - agentic-ai
        - memory
        - agent-architecture
      entities:
        - agentic-ai
        - tool-use
    - title: Empirical Cumulative Distribution Function Clustering for LLM-based Agent System Analysis
      url: https://arxiv.org/abs/2602.16131
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16131v1 Announce Type: cross Abstract: Large language models (LLMs) are increasingly used as agents
        to solve complex tasks such as question answering (QA), scientific debate, and software development. A standard
        evaluation procedure aggregates multiple responses from LLM agents into a single final answer, often via
        majority voting, and compares it against reference answers. However, this process can obscure the quality and
        distributional characteristics of the original responses. In t"
      relevanceScore: 60
      topics:
        - agentic-ai
        - language-models
        - tool-use
      entities:
        - agentic-ai
        - language-models
        - tool-use
    - title: Transformers Provably Learn Algorithmic Solutions for Graph Connectivity, But Only with the Right Data
      url: https://arxiv.org/abs/2510.19753
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2510.19753v2 Announce Type: replace Abstract: Transformers often fail to learn generalizable algorithms,
        instead relying on brittle heuristics. Using graph connectivity as a testbed, we explain this phenomenon both
        theoretically and empirically. We consider a simplified Transformer architecture, the Disentangled Transformer,
        and prove that an $L$-layer model can compute connectivity in graphs with diameters up to $3^L$, implementing an
        algorithm equivalent to computing powers of the adjace"
      relevanceScore: 60
      topics:
        - algorithmic-reasoning
        - generalization
        - transformers
      entities:
        - reasoning
        - language-models
    - title: Introducing GPT-5.3-Codex-Spark
      url: https://openai.com/index/introducing-gpt-5-3-codex-spark
      sourceId: openai-blog
      publishedAt: Thu, 12 Feb 2026 10:00:00 GMT
      summary: Introducing GPT-5.3-Codex-Spark—our first real-time coding model. 15x faster generation, 128k context, now in
        research preview for ChatGPT Pro users.
      relevanceScore: 55
      topics:
        - capabilities
        - coding
        - agentic-ai
      entities:
        - agentic-ai
        - coding
    - title: GPT-5 lowers the cost of cell-free protein synthesis
      url: https://openai.com/index/gpt-5-lowers-protein-synthesis-cost
      sourceId: openai-blog
      publishedAt: Thu, 05 Feb 2026 11:00:00 GMT
      summary: An autonomous lab combining OpenAI’s GPT-5 with Ginkgo Bioworks’ cloud automation cut cell-free protein
        synthesis costs by 40% through closed-loop experimentation.
      relevanceScore: 55
      topics:
        - capabilities
        - scientific-research
        - tool-use
      entities:
        - scientific-research
        - tool-use
    - title: "Unlocking the Codex harness: how we built the App Server"
      url: https://openai.com/index/unlocking-the-codex-harness
      sourceId: openai-blog
      publishedAt: Wed, 04 Feb 2026 13:00:00 GMT
      summary: Learn how to embed the Codex agent using the Codex App Server, a bidirectional JSON-RPC API powering streaming
        progress, tool use, approvals, and diffs.
      relevanceScore: 55
      topics:
        - agentic-ai
        - tool-use
        - coding
      entities:
        - agentic-ai
        - tool-use
        - coding
    - title: Inside OpenAI’s in-house data agent
      url: https://openai.com/index/inside-our-in-house-data-agent
      sourceId: openai-blog
      publishedAt: Thu, 29 Jan 2026 10:00:00 GMT
      summary: How OpenAI built an in-house AI data agent that uses GPT-5, Codex, and memory to reason over massive datasets
        and deliver reliable insights in minutes.
      relevanceScore: 55
      topics:
        - agentic-ai
        - tool-use
        - reasoning
      entities:
        - agentic-ai
        - tool-use
        - reasoning
    - title: How countries can end the capability overhang
      url: https://openai.com/index/how-countries-can-end-the-capability-overhang
      sourceId: openai-blog
      publishedAt: Wed, 21 Jan 2026 01:00:00 GMT
      summary: Our latest report reveals stark differences in advanced AI adoption across countries and outlines new
        initiatives to help nations capture productivity gains from AI.
      relevanceScore: 55
      topics:
        - geopolitics
        - agi-development
        - capabilities
      entities:
        - geopolitics
        - agi-development
    - title: Cisco and OpenAI redefine enterprise engineering with AI agents
      url: https://openai.com/index/cisco
      sourceId: openai-blog
      publishedAt: Tue, 20 Jan 2026 11:00:00 GMT
      summary: Cisco and OpenAI redefine enterprise engineering with Codex, an AI software agent embedded in workflows to
        speed builds, automate defect fixes, and enable AI-native development.
      relevanceScore: 55
      topics:
        - agentic-ai
        - tool-use
        - capabilities
      entities:
        - agentic-ai
        - tool-use
    - title: Updating our Model Spec with teen protections
      url: https://openai.com/index/updating-model-spec-with-teen-protections
      sourceId: openai-blog
      publishedAt: Thu, 18 Dec 2025 11:00:00 GMT
      summary: OpenAI is updating its Model Spec with new Under-18 Principles that define how ChatGPT should support teens
        with safe, age-appropriate guidance grounded in developmental science. The update strengthens guardrails,
        clarifies expected model behavior in higher-risk situations, and builds on our broader work to improve teen
        safety across ChatGPT.
      relevanceScore: 55
      topics:
        - safety-research
        - alignment-progress
      entities:
        - safety-research
        - alignment-progress
    - title: Inside Mirakl's agentic commerce vision
      url: https://openai.com/index/mirakl
      sourceId: openai-blog
      publishedAt: Mon, 01 Dec 2025 22:00:00 GMT
      summary: Mirakl is redefining commerce through AI agents and ChatGPT Enterprise—achieving faster documentation, smarter
        customer support, and building toward agent-native commerce with Mirakl Nexus.
      relevanceScore: 55
      topics:
        - agentic-ai
        - tool-use
        - economic-labor
      entities:
        - __index__/knowledge-base/capabilities
    - title: "Mixpanel security incident: what OpenAI users need to know"
      url: https://openai.com/index/mixpanel-incident
      sourceId: openai-blog
      publishedAt: Wed, 26 Nov 2025 19:00:00 GMT
      summary: OpenAI shares details about a Mixpanel security incident involving limited API analytics data. No API content,
        credentials, or payment details were exposed. Learn what happened and how we’re protecting users.
      relevanceScore: 55
      topics:
        - misuse-risks
        - structural-risks
      entities:
        - __index__/knowledge-base/incidents
    - title: How we built OWL, the new architecture behind our ChatGPT-based browser, Atlas
      url: https://openai.com/index/building-chatgpt-atlas
      sourceId: openai-blog
      publishedAt: Thu, 30 Oct 2025 00:00:00 GMT
      summary: A deep dive into OWL, the new architecture powering ChatGPT Atlas—decoupling Chromium, enabling fast startup,
        rich UI, and agentic browsing with ChatGPT.
      relevanceScore: 55
      topics:
        - architecture
        - agentic-ai
        - tool-use
      entities:
        - architecture-scenarios-table
        - agentic-ai
        - tool-use
    - title: Built to benefit everyone
      url: https://openai.com/index/built-to-benefit-everyone
      sourceId: openai-blog
      publishedAt: Tue, 28 Oct 2025 06:00:00 GMT
      summary: OpenAI’s recapitalization strengthens mission-focused governance, expanding resources to ensure AI benefits
        everyone while advancing innovation responsibly.
      relevanceScore: 55
      topics:
        - governance
        - alignment
        - responsible-ai
        - structural
      entities:
        - solutions
        - structural
    - title: AI in South Korea—OpenAI’s Economic Blueprint
      url: https://openai.com/index/south-korea-economic-blueprint
      sourceId: openai-blog
      publishedAt: Thu, 23 Oct 2025 00:00:00 GMT
      summary: OpenAI's Korea Economic Blueprint outlines how South Korea can scale trusted AI through sovereign capabilities
        and strategic partnerships to drive growth.
      relevanceScore: 55
      topics:
        - geopolitics
        - regulation-debate
        - agi-development
      entities:
        - geopolitics
        - regulation-debate
    - title: AI in Japan—OpenAI’s Japan Economic Blueprint
      url: https://openai.com/index/japan-economic-blueprint
      sourceId: openai-blog
      publishedAt: Wed, 22 Oct 2025 00:00:00 GMT
      summary: OpenAI’s Japan Economic Blueprint outlines how Japan can harness AI to boost innovation, strengthen
        competitiveness, and enable sustainable, inclusive growth.
      relevanceScore: 55
      topics:
        - geopolitics
        - regulation-debate
        - agi-development
      entities:
        - geopolitics
        - regulation-debate
    - title: Accelerating AI adoption in Europe
      url: https://openai.com/global-affairs/accelerating-ai-uptake-in-europe
      sourceId: openai-blog
      publishedAt: Mon, 06 Oct 2025 00:00:00 GMT
      summary: OpenAI and Allied for Startups release the Hacktivate AI report with 20 actionable policy ideas to accelerate
        AI adoption in Europe, boost competitiveness, and empower innovators.
      relevanceScore: 55
      topics:
        - regulation-debate
        - geopolitics
        - agi-development
      entities:
        - regulation-debate
        - geopolitics
    - title: Measuring the performance of our models on real-world tasks
      url: https://openai.com/index/gdpval
      sourceId: openai-blog
      publishedAt: Thu, 25 Sep 2025 09:00:00 GMT
      summary: OpenAI introduces GDPval, a new evaluation that measures model performance on real-world economically valuable
        tasks across 44 occupations.
      relevanceScore: 55
      topics:
        - capabilities
        - eval-types-table
      entities:
        - eval-types-table
        - capabilities
    - title: Introducing Stargate UK
      url: https://openai.com/index/introducing-stargate-uk
      sourceId: openai-blog
      publishedAt: Tue, 16 Sep 2025 14:30:00 GMT
      summary: OpenAI, NVIDIA, and Nscale launch Stargate UK, a sovereign AI infrastructure partnership delivering up to
        50,000 GPUs and the UK’s largest supercomputer to power national AI innovation, public services, and economic
        growth.
      relevanceScore: 55
      topics:
        - compute-hardware
        - geopolitics
        - ai-megaproject-infrastructure
      entities:
        - compute-hardware
        - geopolitics
        - ai-megaproject-infrastructure
    - title: Introducing gpt-realtime and Realtime API updates
      url: https://openai.com/index/introducing-gpt-realtime
      sourceId: openai-blog
      publishedAt: Thu, 28 Aug 2025 10:00:00 GMT
      summary: We’re releasing a more advanced speech-to-speech model and new API capabilities including MCP server support,
        image input, and SIP phone calling support.
      relevanceScore: 55
      topics:
        - capabilities
        - API
        - speech-to-speech
        - language-models
      entities:
        - language-models
        - capabilities
    - title: Scaling domain expertise in complex, regulated domains
      url: https://openai.com/index/blue-j
      sourceId: openai-blog
      publishedAt: Thu, 21 Aug 2025 10:00:00 GMT
      summary: Discover how Blue J is transforming tax research with AI-powered tools built on GPT-4.1. By combining domain
        expertise with Retrieval-Augmented Generation, Blue J delivers fast, accurate, and fully-cited tax
        answers—trusted by professionals across the US, Canada, and the UK.
      relevanceScore: 55
      topics:
        - domain-expertise
        - RAG
        - regulated-domains
        - capabilities
      entities:
        - capabilities
        - tool-use
    - title: Coding and design with GPT-5
      url: https://openai.com/index/gpt-5-coding-design
      sourceId: openai-blog
      publishedAt: Thu, 07 Aug 2025 00:03:00 GMT
      summary: Learn how GPT-5 unlocks new possibilities in coding and design.
      relevanceScore: 55
      topics:
        - capabilities
        - coding
        - design
      entities:
        - coding
        - capabilities
    - title: Medical research with GPT-5
      url: https://openai.com/index/gpt-5-medical-research
      sourceId: openai-blog
      publishedAt: Thu, 07 Aug 2025 00:01:00 GMT
      summary: Learn how GPT-5 is used for medical research.
      relevanceScore: 55
      topics:
        - capabilities
        - scientific-research
        - medical-research
      entities:
        - scientific-research
        - capabilities
    - title: gpt-oss-120b & gpt-oss-20b Model Card
      url: https://openai.com/index/gpt-oss-model-card
      sourceId: openai-blog
      publishedAt: Tue, 05 Aug 2025 00:00:00 GMT
      summary: We introduce gpt-oss-120b and gpt-oss-20b, two open-weight reasoning models available under the Apache 2.0
        license and our gpt-oss usage policy.
      relevanceScore: 55
      topics:
        - language-models
        - safety-research
        - eval-types-table
      entities:
        - language-models
        - eval-types-table
    - title: Introducing Stargate Norway
      url: https://openai.com/index/introducing-stargate-norway
      sourceId: openai-blog
      publishedAt: Thu, 31 Jul 2025 00:00:00 GMT
      summary: We’re launching Stargate Norway—OpenAI’s first AI data center initiative in Europe under our OpenAI for
        Countries program. Stargate is OpenAI’s overarching infrastructure platform and is a critical part of our
        long-term vision to deliver the benefits of AI to everyone.
      relevanceScore: 55
      topics:
        - compute-hardware
        - ai-megaproject-infrastructure
        - geopolitics
      entities:
        - compute-hardware
        - ai-megaproject-infrastructure
    - title: Scaling security with responsible disclosure
      url: https://openai.com/index/scaling-coordinated-vulnerability-disclosure
      sourceId: openai-blog
      publishedAt: Mon, 09 Jun 2025 10:00:00 GMT
      summary: OpenAI introduces its Outbound Coordinated Disclosure Policy to guide how it responsibly reports
        vulnerabilities in third-party software—emphasizing integrity, collaboration, and proactive security at scale.
      relevanceScore: 55
      topics:
        - safety-research
        - governance
        - lab-behavior
      entities:
        - safety-research
        - lab-behavior
    - title: Introducing Codex
      url: https://openai.com/index/introducing-codex
      sourceId: openai-blog
      publishedAt: Fri, 16 May 2025 08:00:00 GMT
      summary: "Introducing Codex: a cloud-based software engineering agent that can work on many tasks in parallel, powered
        by codex-1. With Codex, developers can simultaneously deploy multiple agents to independently handle coding
        tasks such as writing features, answering questions about your codebase, fixing bugs, and proposing pull
        requests for review."
      relevanceScore: 55
      topics:
        - agentic-ai
        - coding
        - long-horizon
        - capabilities
      entities:
        - agentic-ai
        - coding
        - long-horizon
    - title: OpenAI Pioneers Program
      url: https://openai.com/index/openai-pioneers-program
      sourceId: openai-blog
      publishedAt: Wed, 09 Apr 2025 10:00:00 GMT
      summary: Advancing model performance and real world evaluation in applied domains.
      relevanceScore: 55
      topics:
        - capabilities
        - evaluation
        - real-world-deployment
      entities:
        - eval-types-table
    - title: Our response to the UK’s copyright consultation
      url: https://openai.com/global-affairs/response-to-uk-copyright-consultation
      sourceId: openai-blog
      publishedAt: Wed, 02 Apr 2025 07:00:00 GMT
      summary: Recommendations for pro-innovation policies that can help make the UK the AI capital of Europe.
      relevanceScore: 55
      topics:
        - governance
        - regulation
        - policy
      entities:
        - regulation-debate
    - title: OpenAI’s proposals for the U.S. AI Action Plan
      url: https://openai.com/global-affairs/openai-proposals-for-the-us-ai-action-plan
      sourceId: openai-blog
      publishedAt: Thu, 13 Mar 2025 03:00:00 GMT
      summary: Recommendations build on OpenAI’s Economic Blueprint to strengthen America’s AI leadership.
      relevanceScore: 55
      topics:
        - regulation-debate
        - geopolitics
        - governance
      entities:
        - regulation-debate
        - geopolitics
    - title: Sharing the latest Model Spec
      url: https://openai.com/index/sharing-the-latest-model-spec
      sourceId: openai-blog
      publishedAt: Wed, 12 Feb 2025 13:00:00 GMT
      summary: We’ve made updates to the Model Spec based on external feedback and our continued research in shaping desired
        model behavior.
      relevanceScore: 55
      topics:
        - safety-research
        - alignment-progress
      entities:
        - safety-research
        - alignment-progress
    - title: Understanding complex trends with deep research
      url: https://openai.com/index/deep-research
      sourceId: openai-blog
      publishedAt: Sun, 02 Feb 2025 16:00:00 GMT
      summary: How OpenAI deep research helps Bain & Company understand complex industry trends.
      relevanceScore: 55
      topics:
        - agentic-ai
        - reasoning
        - capabilities
      entities:
        - agentic-ai
        - reasoning
    - title: Strengthening America’s AI leadership with the U.S. National Laboratories
      url: https://openai.com/index/strengthening-americas-ai-leadership-with-the-us-national-laboratories
      sourceId: openai-blog
      publishedAt: Thu, 30 Jan 2025 10:00:00 GMT
      summary: OpenAI’s latest line of reasoning models will be used by nation’s leading scientists to drive scientific
        breakthroughs.
      relevanceScore: 55
      topics:
        - scientific-research
        - capabilities
        - geopolitics
      entities:
        - scientific-research
        - capabilities
    - title: Why OpenAI’s structure must evolve to advance our mission
      url: https://openai.com/index/why-our-structure-must-evolve-to-advance-our-mission
      sourceId: openai-blog
      publishedAt: Fri, 27 Dec 2024 00:00:00 GMT
      summary: A stronger non-profit supported by the for-profit’s success.
      relevanceScore: 55
      topics:
        - structural
        - lab-behavior
        - alignment-progress
      entities:
        - structural
        - lab-behavior
    - title: OpenAI and the Lenfest Institute AI Collaborative and Fellowship program
      url: https://openai.com/index/lenfest-institute
      sourceId: openai-blog
      publishedAt: Tue, 22 Oct 2024 06:05:00 GMT
      summary: OpenAI and the Lenfest Institute AI Collaborative and Fellowship program
      relevanceScore: 55
      topics:
        - governance
        - policy
        - media
        - safety-research
      entities:
        - safety-research
    - title: Introducing OpenAI o1
      url: https://openai.com/index/introducing-openai-o1-preview
      sourceId: openai-blog
      publishedAt: Thu, 12 Sep 2024 10:03:00 GMT
      summary: Introducing OpenAI o1
      relevanceScore: 55
      topics:
        - reasoning
        - capabilities
        - language-models
      entities:
        - reasoning
        - language-models
        - capabilities
    - title: Disrupting a covert Iranian influence operation
      url: https://openai.com/index/disrupting-a-covert-iranian-influence-operation
      sourceId: openai-blog
      publishedAt: Fri, 16 Aug 2024 11:00:00 GMT
      summary: We banned accounts linked to a covert Iranian influence operation using ChatGPT to generate website and social
        media content focused on multiple topics, including the U.S. presidential campaign. We have seen no indication
        that this content reached a meaningful audience.
      relevanceScore: 55
      topics:
        - misuse-risks
        - disinformation
        - influence-operations
        - safety
      entities:
        - misuse-risks
        - disinformation-detection-race
    - title: A Holistic Approach to Undesired Content Detection in the Real World
      url: https://openai.com/index/a-holistic-approach-to-undesired-content-detection-in-the-real-world
      sourceId: openai-blog
      publishedAt: Thu, 20 Jun 2024 00:00:00 GMT
      summary: We present a holistic approach to building a robust and useful natural language classification system for
        real-world content moderation.
      relevanceScore: 55
      topics:
        - safety
        - content-moderation
        - misuse-prevention
      entities:
        - misuse-risks
        - safety-research
    - title: Expanding on how Voice Engine works and our safety research
      url: https://openai.com/index/expanding-on-how-voice-engine-works-and-our-safety-research
      sourceId: openai-blog
      publishedAt: Fri, 07 Jun 2024 17:45:00 GMT
      summary: Exploring the technology behind our text-to-speech model.
      relevanceScore: 55
      topics:
        - safety-research
        - capabilities
      entities:
        - safety-research
        - capabilities
    - title: Introducing GPT-4o and more tools to ChatGPT free users
      url: https://openai.com/index/gpt-4o-and-more-tools-to-chatgpt-free
      sourceId: openai-blog
      publishedAt: Mon, 13 May 2024 10:00:00 GMT
      summary: Introducing GPT-4o and more tools to ChatGPT free users We are launching our newest flagship model and making
        more capabilities available for free in ChatGPT.
      relevanceScore: 55
      topics:
        - capabilities
        - language-models
      entities:
        - capabilities
        - language-models
    - title: "OpenAI’s commitment to child safety: adopting safety by design principles"
      url: https://openai.com/index/child-safety-adopting-sbd-principles
      sourceId: openai-blog
      publishedAt: Tue, 23 Apr 2024 00:00:00 GMT
      summary: ""
      relevanceScore: 55
      topics:
        - safety-research
        - misuse-risks
        - accident-risks
      entities:
        - misuse-risks
        - accident-risks
    - title: OpenAI announces new members to board of directors
      url: https://openai.com/index/openai-announces-new-members-to-board-of-directors
      sourceId: openai-blog
      publishedAt: Fri, 08 Mar 2024 08:00:00 GMT
      summary: Dr. Sue Desmond-Hellmann, Nicole Seligman, Fidji Simo join; Sam Altman rejoins board
      relevanceScore: 55
      topics:
        - governance
        - lab-behavior
        - structural
      entities:
        - governance
        - lab-behavior
        - structural
    - title: DALL·E 3 is now available in ChatGPT Plus and Enterprise
      url: https://openai.com/index/dall-e-3-is-now-available-in-chatgpt-plus-and-enterprise
      sourceId: openai-blog
      publishedAt: Thu, 19 Oct 2023 07:00:00 GMT
      summary: We developed a safety mitigation stack to ready DALL·E 3 for wider release and are sharing updates on our
        provenance research.
      relevanceScore: 55
      topics:
        - misuse-risks
        - safety-research
      entities:
        - misuse-risks
        - safety-research
    - title: New AI classifier for indicating AI-written text
      url: https://openai.com/index/new-ai-classifier-for-indicating-ai-written-text
      sourceId: openai-blog
      publishedAt: Tue, 31 Jan 2023 08:00:00 GMT
      summary: We’re launching a classifier trained to distinguish between AI-written and human-written text.
      relevanceScore: 55
      topics:
        - deepfakes
        - detection
        - misuse-risks
      entities:
        - deepfakes-authentication-crisis
        - misuse-risks
    - title: Techniques for training large neural networks
      url: https://openai.com/index/techniques-for-training-large-neural-networks
      sourceId: openai-blog
      publishedAt: Thu, 09 Jun 2022 07:00:00 GMT
      summary: Large neural networks are at the core of many recent advances in AI, but training them is a difficult
        engineering and research challenge which requires orchestrating a cluster of GPUs to perform a single
        synchronized calculation.
      relevanceScore: 55
      topics:
        - capabilities
        - compute-hardware
        - language-models
      entities:
        - language-models
        - compute-hardware
    - title: Economic impacts research at OpenAI
      url: https://openai.com/index/economic-impacts
      sourceId: openai-blog
      publishedAt: Thu, 03 Mar 2022 08:00:00 GMT
      summary: Call for expressions of interest to study the economic impacts of large language models.
      relevanceScore: 55
      topics:
        - safety-research
        - economic-labor
      entities:
        - safety-research
        - economic-labor
    - title: Solving math word problems
      url: https://openai.com/index/solving-math-word-problems
      sourceId: openai-blog
      publishedAt: Fri, 29 Oct 2021 07:00:00 GMT
      summary: "We’ve trained a system that solves grade school math problems with nearly twice the accuracy of a fine-tuned
        GPT-3 model. It solves about 90% as many problems as real kids: a small sample of 9-12 year olds scored 60% on a
        test from our dataset, while our system scored 55% on those same problems."
      relevanceScore: 55
      topics:
        - reasoning
        - capabilities
        - language-models
      entities:
        - reasoning
        - language-models
    - title: OpenAI Codex
      url: https://openai.com/index/openai-codex
      sourceId: openai-blog
      publishedAt: Tue, 10 Aug 2021 07:00:00 GMT
      summary: We’ve created an improved version of OpenAI Codex, our AI system that translates natural language to code, and
        we are releasing it through our API in private beta starting today.
      relevanceScore: 55
      topics:
        - coding
        - tool-use
        - capabilities
      entities:
        - coding
        - tool-use
    - title: Multimodal neurons in artificial neural networks
      url: https://openai.com/index/multimodal-neurons
      sourceId: openai-blog
      publishedAt: Thu, 04 Mar 2021 08:00:00 GMT
      summary: We’ve discovered neurons in CLIP that respond to the same concept whether presented literally, symbolically, or
        conceptually. This may explain CLIP’s accuracy in classifying surprising visual renditions of concepts, and is
        also an important step toward understanding the associations and biases that CLIP and similar models learn.
      relevanceScore: 55
      topics:
        - interpretability-sufficient
        - safety-research
        - world-models
      entities:
        - interpretability-sufficient
    - title: Generative language modeling for automated theorem proving
      url: https://openai.com/index/generative-language-modeling-for-automated-theorem-proving
      sourceId: openai-blog
      publishedAt: Mon, 07 Sep 2020 07:00:00 GMT
      summary: ""
      relevanceScore: 55
      topics:
        - reasoning
        - scientific-research
        - capabilities
      entities:
        - reasoning
        - scientific-research
    - title: "GPT-2: 6-month follow-up"
      url: https://openai.com/index/gpt-2-6-month-follow-up
      sourceId: openai-blog
      publishedAt: Tue, 20 Aug 2019 07:00:00 GMT
      summary: We’re releasing the 774 million parameter GPT-2 language model after the release of our small 124M model in
        February, staged release of our medium 355M model in May, and subsequent research with partners and the AI
        community into the model’s potential for misuse and societal benefit. We’re also releasing an open-source legal
        agreement to make it easier for organizations to initiate model-sharing partnerships with each other, and are
        publishing a technical report about our experience in coordinat
      relevanceScore: 55
      topics:
        - language-models
        - capabilities
      entities:
        - language-models
    - title: Computational limitations in robust classification and win-win results
      url: https://openai.com/index/computational-limitations-in-robust-classification-and-win-win-results
      sourceId: openai-blog
      publishedAt: Mon, 04 Feb 2019 08:00:00 GMT
      summary: ""
      relevanceScore: 55
      topics:
        - robustness
        - classification
        - adversarial
      entities: []
    - title: Learning concepts with energy functions
      url: https://openai.com/index/learning-concepts-with-energy-functions
      sourceId: openai-blog
      publishedAt: Wed, 07 Nov 2018 08:00:00 GMT
      summary: "We’ve developed an energy-based model that can quickly learn to identify and generate instances of concepts,
        such as near, above, between, closest, and furthest, expressed as sets of 2d points. Our model learns these
        concepts after only five demonstrations. We also show cross-domain transfer: we use concepts learned in a 2d
        particle environment to solve tasks on a 3-dimensional physics-based robot."
      relevanceScore: 55
      topics:
        - energy-based-models
        - concept-learning
        - interpretability
      entities: []
    - title: Variational option discovery algorithms
      url: https://openai.com/index/variational-option-discovery-algorithms
      sourceId: openai-blog
      publishedAt: Thu, 26 Jul 2018 07:00:00 GMT
      summary: ""
      relevanceScore: 55
      topics:
        - reinforcement-learning
        - hierarchical-learning
        - options
      entities: []
    - title: "Glow: Better reversible generative models"
      url: https://openai.com/index/glow
      sourceId: openai-blog
      publishedAt: Mon, 09 Jul 2018 07:00:00 GMT
      summary: We introduce Glow, a reversible generative model which uses invertible 1x1 convolutions. It extends previous
        work on reversible generative models and simplifies the architecture. Our model can generate realistic high
        resolution images, supports efficient sampling, and discovers features that can be used to manipulate attributes
        of data. We’re releasing code for the model and an online visualization tool so people can explore and build on
        these results.
      relevanceScore: 55
      topics:
        - generative-models
        - normalizing-flows
        - architecture
      entities:
        - architecture-scenarios-table
    - title: Learning policy representations in multiagent systems
      url: https://openai.com/index/learning-policy-representations-in-multiagent-systems
      sourceId: openai-blog
      publishedAt: Sun, 17 Jun 2018 07:00:00 GMT
      summary: ""
      relevanceScore: 55
      topics:
        - multi-agent
        - reinforcement-learning
        - policy
      entities:
        - agentic-ai
    - title: "GamePad: A learning environment for theorem proving"
      url: https://openai.com/index/gamepad
      sourceId: openai-blog
      publishedAt: Sat, 02 Jun 2018 07:00:00 GMT
      summary: ""
      relevanceScore: 55
      topics:
        - reasoning
        - capabilities
      entities:
        - reasoning
        - capabilities
    - title: Scaling Kubernetes to 2,500 nodes
      url: https://openai.com/index/scaling-kubernetes-to-2500-nodes
      sourceId: openai-blog
      publishedAt: Thu, 18 Jan 2018 08:00:00 GMT
      summary: ""
      relevanceScore: 55
      topics:
        - compute-hardware
        - capabilities
      entities:
        - compute-hardware
    - title: Competitive self-play
      url: https://openai.com/index/competitive-self-play
      sourceId: openai-blog
      publishedAt: Wed, 11 Oct 2017 07:00:00 GMT
      summary: We’ve found that self-play allows simulated AIs to discover physical skills like tackling, ducking, faking,
        kicking, catching, and diving for the ball, without explicitly designing an environment with these skills in
        mind. Self-play ensures that the environment is always the right difficulty for an AI to improve. Taken
        alongside our Dota 2 self-play results, we have increasing confidence that self-play will be a core part of
        powerful AI systems in the future.
      relevanceScore: 55
      topics:
        - self-play
        - reinforcement-learning
        - multi-agent
        - emergent-behavior
      entities:
        - agentic-ai
        - reasoning
    - title: Learning with opponent-learning awareness
      url: https://openai.com/index/learning-with-opponent-learning-awareness
      sourceId: openai-blog
      publishedAt: Wed, 13 Sep 2017 07:00:00 GMT
      summary: ""
      relevanceScore: 55
      topics:
        - multi-agent
        - learning-dynamics
        - game-theory
      entities:
        - agentic-ai
        - reasoning
    - title: OpenAI and Microsoft
      url: https://openai.com/index/openai-and-microsoft
      sourceId: openai-blog
      publishedAt: Tue, 15 Nov 2016 08:00:00 GMT
      summary: We’re working with Microsoft to start running most of our large-scale experiments on Azure.
      relevanceScore: 55
      topics:
        - compute-hardware
        - infrastructure
      entities:
        - compute-hardware
    - title: Infrastructure for deep learning
      url: https://openai.com/index/infrastructure-for-deep-learning
      sourceId: openai-blog
      publishedAt: Mon, 29 Aug 2016 07:00:00 GMT
      summary: Deep learning is an empirical science, and the quality of a group’s infrastructure is a multiplier on progress.
        Fortunately, today’s open-source ecosystem makes it possible for anyone to build great deep learning
        infrastructure.
      relevanceScore: 55
      topics:
        - compute-hardware
        - infrastructure
      entities:
        - compute-hardware
    - title: We’re expanding our presence in Singapore to advance AI in the Asia-Pacific region
      url: https://deepmind.google/blog/were-expanding-our-presence-in-singapore-to-advance-ai-in-the-asia-pacific-region/
      sourceId: deepmind-blog
      publishedAt: Tue, 18 Nov 2025 17:00:00 +0000
      summary: Google DeepMind opens a new Singapore research lab, accelerating AI progress in the Asia-Pacific region.
      relevanceScore: 55
      topics:
        - agi-development
        - geopolitics
        - lab-behavior
      entities:
        - agi-development
        - geopolitics
        - lab-behavior
    - title: "MedGemma: Our most capable open models for health AI development"
      url: https://deepmind.google/blog/medgemma-our-most-capable-open-models-for-health-ai-development/
      sourceId: deepmind-blog
      publishedAt: Sat, 25 Oct 2025 18:02:50 +0000
      summary: We’re announcing new multimodal models in the MedGemma collection, our most capable open models for health AI
        development.
      relevanceScore: 55
      topics:
        - language-models
        - capabilities
      entities:
        - language-models
        - capabilities
    - title: Gemini 2.5 Flash-Lite is now ready for scaled production use
      url: https://deepmind.google/blog/gemini-25-flash-lite-is-now-ready-for-scaled-production-use/
      sourceId: deepmind-blog
      publishedAt: Sat, 25 Oct 2025 17:34:32 +0000
      summary: Gemini 2.5 Flash-Lite, previously in preview, is now stable and generally available. This cost-efficient model
        provides high quality in a small size, and includes 2.5 family features like a 1 million-token context window
        and multimodality.
      relevanceScore: 55
      topics:
        - language-models
        - capabilities
      entities:
        - language-models
        - capabilities
    - title: Discovering new solutions to century-old problems in fluid dynamics
      url: https://deepmind.google/blog/discovering-new-solutions-to-century-old-problems-in-fluid-dynamics/
      sourceId: deepmind-blog
      publishedAt: Fri, 24 Oct 2025 00:02:06 +0000
      summary: Our new method could help mathematicians leverage AI techniques to tackle long-standing challenges in
        mathematics, physics and engineering.
      relevanceScore: 55
      topics:
        - reasoning
        - capabilities
        - scientific-research
      entities:
        - reasoning
        - capabilities
        - scientific-research
    - title: "Introducing Gemma 3 270M: The compact model for hyper-efficient AI"
      url: https://deepmind.google/blog/introducing-gemma-3-270m-the-compact-model-for-hyper-efficient-ai/
      sourceId: deepmind-blog
      publishedAt: Thu, 23 Oct 2025 18:50:11 +0000
      summary: "Today, we're adding a new, highly specialized tool to the Gemma 3 toolkit: Gemma 3 270M, a compact,
        270-million parameter model."
      relevanceScore: 55
      topics:
        - language-models
        - capabilities
      entities:
        - language-models
        - capabilities
    - title: "Announcing Gemma 3n preview: Powerful, efficient, mobile-first AI"
      url: https://deepmind.google/blog/announcing-gemma-3n-preview-powerful-efficient-mobile-first-ai/
      sourceId: deepmind-blog
      publishedAt: Tue, 20 May 2025 09:45:00 +0000
      summary: Gemma 3n is a cutting-edge open model designed for fast, multimodal AI on devices, featuring optimized
        performance, unique flexibility with a 2-in-1 model, and expanded multimodal understanding with audio,
        empowering developers to build live, interactive applications and sophisticated audio-centric experiences.
      relevanceScore: 55
      topics:
        - language-models
        - capabilities
      entities:
        - language-models
        - capabilities
    - title: "Gemini 2.5 Pro Preview: even better coding performance"
      url: https://deepmind.google/blog/gemini-25-pro-preview-even-better-coding-performance/
      sourceId: deepmind-blog
      publishedAt: Tue, 06 May 2025 15:06:55 +0000
      summary: We’ve seen developers doing amazing things with Gemini 2.5 Pro, so we decided to release an updated version a
        couple of weeks early to get into developers hands sooner.
      relevanceScore: 55
      topics:
        - language-models
        - coding
        - capabilities
      entities:
        - language-models
        - coding
        - capabilities
    - title: Introducing Gemma 3
      url: https://deepmind.google/blog/introducing-gemma-3/
      sourceId: deepmind-blog
      publishedAt: Wed, 12 Mar 2025 08:00:00 +0000
      summary: The most capable model you can run on a single GPU or TPU.
      relevanceScore: 55
      topics:
        - language-models
        - capabilities
      entities:
        - language-models
        - capabilities
    - title: "The AI for Science Forum: A new era of discovery"
      url: https://deepmind.google/blog/the-ai-for-science-forum-a-new-era-of-discovery/
      sourceId: deepmind-blog
      publishedAt: Mon, 18 Nov 2024 19:57:00 +0000
      summary: The AI Science Forum highlights AI's present and potential role in revolutionizing scientific discovery and
        solving global challenges, emphasizing collaboration between the scientific community, policymakers, and
        industry leaders.
      relevanceScore: 55
      topics:
        - scientific-research
        - safety-research
        - governance
      entities:
        - scientific-research
        - solutions
    - title: "The Llama 4 Herd: The Beginning of a New Era of Natively Multimodal AI Innovation"
      url: https://ai.meta.com/blog/llama-4-multimodal-intelligence/
      sourceId: meta-ai-blog
      publishedAt: 2026-02-19
      summary: "  Introduces Llama 4 Scout and Llama 4 Maverick — the first open-weight, natively multimodal models with
        unprecedented context support, and Meta's first models built using a mixture-of-experts (MoE) architecture."
      relevanceScore: 55
      topics:
        - capabilities
        - language-models
        - sparse-moe
      entities:
        - language-models
        - sparse-moe
    - title: Managed vs Unmanaged Agency
      url: https://forum.effectivealtruism.org/posts/DauhnYiuSSLjE8nWX/managed-vs-unmanaged-agency
      sourceId: ea-forum
      publishedAt: Wed, 18 Feb 2026 15:24:26 GMT
      summary: "Published on February 18, 2026 3:24 PM GMTtl;dr: Some subagents are more closely managed, which makes them to
        an extent instruments of the superagent, giving rise to what looks like instrumental/terminal goals. Selection
        on trust avoids the difficulties that normally come with this, like inability to do open-ended truth-seeking and
        free-ranging agency.(reply to Richard Ngo on the confused-ness of Instrumental vs Terminal goals that seemed
        maybe worth a quick top-level post based on @the gears to"
      relevanceScore: 55
      topics:
        - agency
        - alignment
        - instrumental-convergence
      entities:
        - instrumental-convergence-framework
        - alignment-progress
    - title: "LWiAI Podcast #232 - ChatGPT Ads, Thinking Machines Drama, STEM"
      url: https://lastweekin.ai/p/lwiai-podcast-232-chatgpt-ads-thinking
      sourceId: last-week-in-ai
      publishedAt: Wed, 28 Jan 2026 09:51:53 GMT
      summary: "OpenAI to test ads in ChatGPT as it burns through billions, The Drama at Thinking Machines, STEM: Scaling
        Transformers with Embedding Modules"
      relevanceScore: 55
      topics:
        - capabilities
        - language-models
        - compute-hardware
        - lab-behavior
      entities:
        - language-models
        - compute-hardware
    - title: "LWiAI Podcast #230 - 2025 Retrospective, Nvidia buys Groq, GLM 4.7, METR"
      url: https://lastweekin.ai/p/lwiai-podcast-230-2025-retrospective
      sourceId: last-week-in-ai
      publishedAt: Wed, 07 Jan 2026 06:59:29 GMT
      summary: Nvidia buying AI chip startup Groq for about $20 billion, Meta Buys AI Startup Manus, Z.AI launches GLM-4.7
      relevanceScore: 55
      topics:
        - compute-hardware
        - lab-behavior
        - ai-acceleration-tradeoff
      entities:
        - compute-hardware
        - lab-behavior
    - title: "LWiAI Podcast #226 - Gemini 3, Claude Opus 4.5, Nano Banana Pro, LeJEPA"
      url: https://lastweekin.ai/p/lwiai-podcast-226-gemini-3-claude
      sourceId: last-week-in-ai
      publishedAt: Sun, 30 Nov 2025 08:20:26 GMT
      summary: Google launches Gemini 3 & Nano Banana Pro, Anthropic releases Opus 4.5, and more!
      relevanceScore: 55
      topics:
        - capabilities
        - language-models
      entities:
        - language-models
    - title: "LWiAI Podcast #225 - GPT 5.1, Kimi K2 Thinking, Remote Labor Index"
      url: https://lastweekin.ai/p/lwiai-podcast-225-gpt-51-kimi-k2
      sourceId: last-week-in-ai
      publishedAt: Sat, 22 Nov 2025 08:27:26 GMT
      summary: OpenAI says the brand-new GPT-5.1 is &#8216;warmer&#8217;, Baidu Unveils ERNIE 5.0, and more!
      relevanceScore: 55
      topics:
        - capabilities
        - language-models
      entities:
        - language-models
    - title: "Last Week in AI #326 - Qualcomm AI Chips, MiniMax M2, Kimi K2 Thinking"
      url: https://lastweekin.ai/p/last-week-in-ai-326-qualcomm-ai-chips
      sourceId: last-week-in-ai
      publishedAt: Sun, 09 Nov 2025 18:57:47 GMT
      summary: Qualcomm announces AI chips to compete with AMD and Nvidia, MiniMax Releases MiniMax M2, Universal partners
        with Udio, and more!
      relevanceScore: 55
      topics:
        - compute-hardware
        - capabilities
      entities:
        - compute-hardware
    - title: "Revolutionizing Long-Term Memory in AI: New Horizons with High-Capacity and High-Speed Storage"
      url: https://arxiv.org/abs/2602.16192
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: 'arXiv:2602.16192v1 Announce Type: new Abstract: Driven by our mission of "uplifting the world with memory,"
        this paper explores the design concept of "memory" that is essential for achieving artificial superintelligence
        (ASI). Rather than proposing novel methods, we focus on several alternative approaches whose potential benefits
        are widely imaginable, yet have remained largely unexplored. The currently dominant paradigm, which can be
        termed "extract then store," involves extracting information '
      relevanceScore: 55
      topics:
        - agentic-ai
        - capabilities
        - long-horizon
      entities:
        - agentic-ai
        - long-horizon
    - title: Do Personality Traits Interfere? Geometric Limitations of Steering in Large Language Models
      url: https://arxiv.org/abs/2602.15847
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15847v1 Announce Type: cross Abstract: Personality steering in large language models (LLMs)
        commonly relies on injecting trait-specific steering vectors, implicitly assuming that personality traits can be
        controlled independently. In this work, we examine whether this assumption holds by analysing the geometric
        relationships between Big Five personality steering directions. We study steering vectors extracted from two
        model families (LLaMA-3-8B and Mistral-8B) and apply a range of geo"
      relevanceScore: 55
      topics:
        - language-models
        - interpretability
        - steering
        - alignment
      entities:
        - language-models
        - interpretability-sufficient
        - alignment-progress
    - title: AI as Teammate or Tool? A Review of Human-AI Interaction in Decision Support
      url: https://arxiv.org/abs/2602.15865
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15865v1 Announce Type: cross Abstract: The integration of Artificial Intelligence (AI) necessitates
        determining whether systems function as tools or collaborative teammates. In this study, by synthesizing
        Human-AI Interaction (HAI) literature, we analyze this distinction across four dimensions: interaction design,
        trust calibration, collaborative frameworks and healthcare applications. Our analysis reveals that static
        interfaces and miscalibrated trust limit AI efficacy. Performance h"
      relevanceScore: 55
      topics:
        - human-ai-interaction
        - decision-support
        - alignment
      entities:
        - alignment-progress
        - solutions
    - title: Evidence for Daily and Weekly Periodic Variability in GPT-4o Performance
      url: https://arxiv.org/abs/2602.15889
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15889v1 Announce Type: cross Abstract: Large language models (LLMs) are increasingly used in
        research both as tools and as objects of investigation. Much of this work implicitly assumes that LLM
        performance under fixed conditions (identical model snapshot, hyperparameters, and prompt) is time-invariant. If
        average output quality changes systematically over time, this assumption is violated, threatening the
        reliability, validity, and reproducibility of findings. To empirically examine "
      relevanceScore: 55
      topics:
        - language-models
        - model-behavior
        - reliability
        - epistemic-risks
      entities:
        - language-models
        - epistemic-risks
    - title: "From Tool Orchestration to Code Execution: A Study of MCP Design Choices"
      url: https://arxiv.org/abs/2602.15945
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15945v1 Announce Type: cross Abstract: Model Context Protocols (MCPs) provide a unified platform
        for agent systems to discover, select, and orchestrate tools across heterogeneous execution environments. As
        MCP-based systems scale to incorporate larger tool catalogs and multiple concurrently connected MCP servers,
        traditional tool-by-tool invocation increases coordination overhead, fragments state management, and limits
        support for wide-context operations. To address these scalability "
      relevanceScore: 55
      topics:
        - agentic-ai
        - tool-use
        - agent-systems
        - safety-research
      entities:
        - agentic-ai
        - tool-use
        - safety-research
    - title: Can Generative Artificial Intelligence Survive Data Contamination? Theoretical Guarantees under Contaminated
        Recursive Training
      url: https://arxiv.org/abs/2602.16065
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16065v1 Announce Type: cross Abstract: Generative Artificial Intelligence (AI), such as large
        language models (LLMs), has become a transformative force across science, industry, and society. As these
        systems grow in popularity, web data becomes increasingly interwoven with this AI-generated material and it is
        increasingly difficult to separate them from naturally generated content. As generative models are updated
        regularly, later models will inevitably be trained on mixtures of human"
      relevanceScore: 55
      topics:
        - language-models
        - data-contamination
        - safety-research
        - robustness
      entities:
        - language-models
        - safety-research
    - title: "HiPER: Hierarchical Reinforcement Learning with Explicit Credit Assignment for Large Language Model Agents"
      url: https://arxiv.org/abs/2602.16165
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16165v1 Announce Type: cross Abstract: Training LLMs as interactive agents for multi-turn
        decision-making remains challenging, particularly in long-horizon tasks with sparse and delayed rewards, where
        agents must execute extended sequences of actions before receiving meaningful feedback. Most existing
        reinforcement learning (RL) approaches model LLM agents as flat policies operating at a single time scale,
        selecting one action at each turn. In sparse-reward settings, such flat policie"
      relevanceScore: 55
      topics:
        - agentic-ai
        - long-horizon
        - reasoning
      entities:
        - agentic-ai
        - long-horizon
        - reasoning
    - title: "The Diversity Paradox revisited: Systemic Effects of Feedback Loops in Recommender Systems"
      url: https://arxiv.org/abs/2602.16315
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16315v1 Announce Type: cross Abstract: Recommender systems shape individual choices through
        feedback loops in which user behavior and algorithmic recommendations coevolve over time. The systemic effects
        of these loops remain poorly understood, in part due to unrealistic assumptions in existing simulation studies.
        We propose a feedback-loop model that captures implicit feedback, periodic retraining, probabilistic adoption of
        recommendations, and heterogeneous recommender systems. We ap"
      relevanceScore: 55
      topics:
        - feedback-loops
        - structural-risks
      entities:
        - feedback-loops
        - structural-risks
    - title: "Team of Thoughts: Efficient Test-time Scaling of Agentic Systems through Orchestrated Tool Calling"
      url: https://arxiv.org/abs/2602.16485
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16485v1 Announce Type: cross Abstract: Existing Multi-Agent Systems (MAS) typically rely on static,
        homogeneous model configurations, limiting their ability to exploit the distinct strengths of differently
        post-trained models. To address this, we introduce Team-of-Thoughts, a novel MAS architecture that leverages the
        complementary capabilities of heterogeneous agents via an orchestrator-tool paradigm. Our framework introduces
        two key mechanisms to optimize performance: (1) an orchestr"
      relevanceScore: 55
      topics:
        - agentic-ai
        - tool-use
        - reasoning
      entities:
        - agentic-ai
        - tool-use
        - reasoning
    - title: Causal and Compositional Abstraction
      url: https://arxiv.org/abs/2602.16612
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16612v1 Announce Type: cross Abstract: Abstracting from a low level to a more explanatory high
        level of description, and ideally while preserving causal structure, is fundamental to scientific practice, to
        causal inference problems, and to robust, efficient and interpretable AI. We present a general account of
        abstractions between low and high level models as natural transformations, focusing on the case of causal
        models. This provides a new formalisation of causal abstraction, unifyi"
      relevanceScore: 55
      topics:
        - interpretability-sufficient
        - reasoning
      entities:
        - interpretability-sufficient
        - reasoning
    - title: A Review of Fairness and A Practical Guide to Selecting Context-Appropriate Fairness Metrics in Machine Learning
      url: https://arxiv.org/abs/2411.06624
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2411.06624v4 Announce Type: replace Abstract: Recent regulatory proposals for artificial intelligence
        emphasize fairness requirements for machine learning models. However, precisely defining the appropriate measure
        of fairness is challenging due to philosophical, cultural and political contexts. Biases can infiltrate machine
        learning models in complex ways depending on the model's context, rendering a single common metric of fairness
        insufficient. This ambiguity highlights the need for cri"
      relevanceScore: 55
      topics:
        - regulation-debate
        - safety-research
        - structural-risks
      entities:
        - regulation-debate
        - safety-research
    - title: "DIAGPaper: Diagnosing Valid and Specific Weaknesses in Scientific Papers via Multi-Agent Reasoning"
      url: https://arxiv.org/abs/2601.07611
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2601.07611v2 Announce Type: replace Abstract: Paper weakness identification using single-agent or
        multi-agent LLMs has attracted increasing attention, yet existing approaches exhibit key limitations. Many
        multi-agent systems simulate human roles at a surface level, missing the underlying criteria that lead experts
        to assess complementary intellectual aspects of a paper. Moreover, prior methods implicitly assume identified
        weaknesses are valid, ignoring reviewer bias, misunderstanding, and "
      relevanceScore: 55
      topics:
        - agentic-ai
        - reasoning
      entities:
        - agentic-ai
        - reasoning
    - title: "From Pixels to Policies: Reinforcing Spatial Reasoning in Language Models for Content-Aware Layout Design"
      url: https://arxiv.org/abs/2602.13912
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.13912v2 Announce Type: replace Abstract: We introduce LaySPA, a reinforcement learning framework
        that equips large language models (LLMs) with explicit and interpretable spatial reasoning for content-aware
        graphic layout design. LaySPA addresses two key challenges: LLMs' limited spatial reasoning and the lack of
        opacity in design decision making. Instead of operating at the pixel level, we reformulate layout design as a
        policy learning problem over a structured textual spatial environ"
      relevanceScore: 55
      topics:
        - agentic-ai
        - reasoning
        - tool-use
      entities:
        - agentic-ai
        - reasoning
        - tool-use
    - title: "PLAICraft: Large-Scale Time-Aligned Vision-Speech-Action Dataset for Embodied AI"
      url: https://arxiv.org/abs/2505.12707
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2505.12707v2 Announce Type: replace-cross Abstract: Advances in deep generative modeling have made it
        increasingly plausible to train human-level embodied agents. Yet progress has been limited by the absence of
        large-scale, real-time, multi-modal, and socially interactive datasets that reflect the sensory-motor complexity
        of natural environments. To address this, we present PLAICraft, a novel data collection platform and dataset
        capturing multiplayer Minecraft interactions across five time"
      relevanceScore: 55
      topics:
        - embodied-ai
        - multimodal
        - dataset
        - long-horizon
      entities:
        - agentic-ai
        - long-horizon
    - title: "Software Dependencies 2.0: An Empirical Study of Reuse and Integration of Pre-Trained Models in Open-Source
        Projects"
      url: https://arxiv.org/abs/2509.06085
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2509.06085v2 Announce Type: replace-cross Abstract: Pre-trained models (PTMs) are machine learning
        models that have been trained in advance, often on large-scale data, and can be reused for new tasks, thereby
        reducing the need for costly training from scratch. Their widespread adoption introduces a new class of software
        dependency, which we term Software Dependencies 2.0, extending beyond conventional libraries to learned
        behaviors embodied in trained models and their associated artifacts."
      relevanceScore: 55
      topics:
        - pre-trained-models
        - model-reuse
        - software-engineering
      entities:
        - language-models
    - title: Multilingual Routing in Mixture-of-Experts
      url: https://arxiv.org/abs/2510.04694
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2510.04694v2 Announce Type: replace-cross Abstract: Mixture-of-Experts (MoE) architectures have become
        the key to scaling modern LLMs, yet little is understood about how their sparse routing dynamics respond to
        multilingual data. In this work, we analyze expert routing patterns using parallel multilingual datasets and
        present highly interpretable layer-wise phenomena. We find that MoE models route tokens in language-specific
        ways in the early and late decoder layers but exhibit significant"
      relevanceScore: 55
      topics:
        - mixture-of-experts
        - sparse-models
        - language-models
        - scaling
      entities:
        - language-models
        - sparse-moe
    - title: Reasoning Up the Instruction Ladder for Controllable Language Models
      url: https://arxiv.org/abs/2511.04694
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2511.04694v4 Announce Type: replace-cross Abstract: As large language model (LLM) based systems take on
        high-stakes roles in real-world decision-making, they must reconcile competing instructions from multiple
        sources (e.g., model developers, users, and tools) within a single prompt context. Thus, enforcing an
        instruction hierarchy (IH) in LLMs, where higher-level directives override lower-priority requests, is critical
        for the reliability and controllability of LLMs. In this work, we refr"
      relevanceScore: 55
      topics:
        - language-models
        - alignment
        - instruction-following
        - control
      entities:
        - language-models
        - alignment-progress
    - title: Scaling Verification Can Be More Effective than Scaling Policy Learning for Vision-Language-Action Alignment
      url: https://arxiv.org/abs/2602.12281
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: 'arXiv:2602.12281v2 Announce Type: replace-cross Abstract: The long-standing vision of general-purpose robots
        hinges on their ability to understand and act upon natural language instructions. Vision-Language-Action (VLA)
        models have made remarkable progress toward this goal, yet their generated actions can still misalign with the
        given instructions. In this paper, we investigate test-time verification as a means to shrink the
        "intention-action gap." We first characterize the test-time scaling law'
      relevanceScore: 55
      topics:
        - vision-language-models
        - robotics
        - alignment
        - verification
      entities:
        - alignment-progress
        - tool-use
    - title: A Geometric Analysis of Small-sized Language Model Hallucinations
      url: https://arxiv.org/abs/2602.14778
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.14778v2 Announce Type: replace-cross Abstract: Hallucinations -- fluent but factually incorrect
        responses -- pose a major challenge to the reliability of language models, especially in multi-step or agentic
        settings. This work investigates hallucinations in small-sized LLMs through a geometric perspective, starting
        from the hypothesis that when models generate multiple responses to the same prompt, genuine ones exhibit
        tighter clustering in the embedding space, we prove this hypothesi"
      relevanceScore: 55
      topics:
        - language-models
        - hallucinations
        - reliability
        - safety
      entities:
        - safety-research
        - accident-risks
    - title: "STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens"
      url: https://arxiv.org/abs/2602.15620
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15620v2 Announce Type: replace-cross Abstract: Reinforcement Learning (RL) has significantly
        improved large language model reasoning, but existing RL fine-tuning methods rely heavily on heuristic
        techniques such as entropy regularization and reweighting to maintain stability. In practice, they often suffer
        from late-stage performance collapse, leading to degraded reasoning quality and unstable training. Our analysis
        shows that the magnitude of token-wise policy gradients in RL is nega"
      relevanceScore: 55
      topics:
        - reinforcement learning
        - LLM training
        - reasoning
      entities:
        - language-models
        - reasoning
    - title: Quality-constrained Entropy Maximization Policy Optimization for LLM Diversity
      url: https://arxiv.org/abs/2602.15894
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15894v1 Announce Type: new Abstract: Recent research indicates that while alignment methods
        significantly improve the quality of large language model(LLM) outputs, they simultaneously reduce the diversity
        of the models' output. Although some methods have been proposed to enhance LLM output diversity, they often come
        at the cost of reduced performance. In this work, we first theoretically demonstrate that the alignment task can
        be decomposed into two distributions: quality and diversit"
      relevanceScore: 55
      topics:
        - alignment
        - LLM diversity
        - quality-safety tradeoff
      entities:
        - language-models
        - alignment-progress
        - safety-capability-tradeoff
    - title: "MultiCW: A Large-Scale Balanced Benchmark Dataset for Training Robust Check-Worthiness Detection Models"
      url: https://arxiv.org/abs/2602.16298
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16298v1 Announce Type: new Abstract: Large Language Models (LLMs) are beginning to reshape how
        media professionals verify information, yet automated support for detecting check-worthy claims a key step in
        the fact-checking process remains limited. We introduce the Multi-Check-Worthy (MultiCW) dataset, a balanced
        multilingual benchmark for check-worthy claim detection spanning 16 languages, 7 topical domains, and 2 writing
        styles. It consists of 123,722 samples, evenly distributed betw"
      relevanceScore: 55
      topics:
        - misinformation detection
        - fact-checking
        - LLM applications
      entities:
        - language-models
        - epistemic-risks
    - title: "AREG: Adversarial Resource Extraction Game for Evaluating Persuasion and Resistance in Large Language Models"
      url: https://arxiv.org/abs/2602.16639
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16639v1 Announce Type: new Abstract: Evaluating the social intelligence of Large Language Models
        (LLMs) increasingly requires moving beyond static text generation toward dynamic, adversarial interaction. We
        introduce the Adversarial Resource Extraction Game (AREG), a benchmark that operationalizes persuasion and
        resistance as a multi-turn, zero-sum negotiation over financial resources. Using a round-robin tournament across
        frontier models, AREG enables joint evaluation of offensive (p"
      relevanceScore: 55
      topics:
        - language-models
        - persuasion
        - adversarial
        - safety
        - alignment
      entities:
        - language-models
        - persuasion
    - title: "MoE-Spec: Expert Budgeting for Efficient Speculative Decoding"
      url: https://arxiv.org/abs/2602.16052
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16052v1 Announce Type: new Abstract: Speculative decoding accelerates Large Language Model (LLM)
        inference by verifying multiple drafted tokens in parallel. However, for Mixture-of-Experts (MoE) models, this
        parallelism introduces a severe bottleneck: large draft trees activate many unique experts, significantly
        increasing memory pressure and diminishing speedups from speculative decoding relative to autoregressive
        decoding. Prior methods reduce speculation depth when MoE verification"
      relevanceScore: 55
      topics:
        - speculative-decoding
        - inference-efficiency
        - mixture-of-experts
        - language-models
      entities:
        - language-models
        - sparse-moe
    - title: Causality is Key for Interpretability Claims to Generalise
      url: https://arxiv.org/abs/2602.16698
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16698v1 Announce Type: new Abstract: Interpretability research on large language models (LLMs) has
        yielded important insights into model behaviour, yet recurring pitfalls persist: findings that do not
        generalise, and causal interpretations that outrun the evidence. Our position is that causal inference specifies
        what constitutes a valid mapping from model activations to invariant high-level structures, the data or
        assumptions needed to achieve it, and the inferences it can support. Sp"
      relevanceScore: 55
      topics:
        - interpretability
        - llm-behavior
        - causality
        - alignment
      entities:
        - interpretability-sufficient
        - language-models
    - title: "How to Label Resynthesized Audio: The Dual Role of Neural Audio Codecs in Audio Deepfake Detection"
      url: https://arxiv.org/abs/2602.16343
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16343v1 Announce Type: cross Abstract: Since Text-to-Speech systems typically don't produce
        waveforms directly, recent spoof detection studies use resynthesized waveforms from vocoders and neural audio
        codecs to simulate an attacker. Unlike vocoders, which are specifically designed for speech synthesis, neural
        audio codecs were originally developed for compressing audio for storage and transmission. However, their
        ability to discretize speech also sparked interest in language-modeling"
      relevanceScore: 55
      topics:
        - deepfakes-authentication-crisis
        - misuse-risks
      entities:
        - deepfakes-authentication-crisis
        - misuse-risks
    - title: Are Object-Centric Representations Better At Compositional Generalization?
      url: https://arxiv.org/abs/2602.16689
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16689v1 Announce Type: cross Abstract: Compositional generalization, the ability to reason about
        novel combinations of familiar concepts, is fundamental to human cognition and a critical challenge for machine
        learning. Object-centric (OC) representations, which encode a scene as a set of objects, are often argued to
        support such generalization, but systematic evidence in visually rich settings is limited. We introduce a Visual
        Question Answering benchmark across three controlled visua"
      relevanceScore: 55
      topics:
        - capabilities
        - reasoning
        - compositional-generalization
      entities:
        - capabilities
        - reasoning
    - title: Out-of-Distribution Detection in Molecular Complexes via Diffusion Models for Irregular Graphs
      url: https://arxiv.org/abs/2512.18454
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2512.18454v2 Announce Type: replace Abstract: Predictive machine learning models generally excel on
        in-distribution data, but their performance degrades on out-of-distribution (OOD) inputs. Reliable deployment
        therefore requires robust OOD detection, yet this is particularly challenging for irregular 3D graphs that
        combine continuous geometry with categorical identities and are unordered by construction. Here, we present a
        probabilistic OOD detection framework for complex 3D graph data bui"
      relevanceScore: 55
      topics:
        - out-of-distribution-detection
        - robustness
        - diffusion-models
      entities:
        - safety-research
        - accident-risks
    - title: "Features as Rewards: Scalable Supervision for Open-Ended Tasks via Interpretability"
      url: https://arxiv.org/abs/2602.10067
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.10067v3 Announce Type: replace Abstract: Language models trained on large-scale datasets have been
        shown to learn features that encode abstract concepts such as factuality or intent. Such features are
        traditionally used for test-time monitoring or steering. We present an alternative affordance: features as
        scalable supervision for open-ended tasks. We consider the case of hallucination-reduction as a desirable, yet
        open-ended behavior and design a reinforcement learning (RL) pipeline,"
      relevanceScore: 55
      topics:
        - interpretability
        - language-models
        - reward-learning
        - supervision
      entities:
        - interpretability-sufficient
        - language-models
    - title: "Harness engineering: leveraging Codex in an agent-first world"
      url: https://openai.com/index/harness-engineering
      sourceId: openai-blog
      publishedAt: Wed, 11 Feb 2026 09:00:00 GMT
      summary: By Ryan Lopopolo, Member of the Technical Staff
      relevanceScore: 50
      topics:
        - agentic-ai
        - tool-use
        - coding
      entities:
        - agentic-ai
        - tool-use
        - coding
    - title: "Making AI work for everyone, everywhere: our approach to localization"
      url: https://openai.com/index/our-approach-to-localization
      sourceId: openai-blog
      publishedAt: Fri, 06 Feb 2026 10:00:00 GMT
      summary: OpenAI shares its approach to AI localization, showing how globally shared frontier models can be adapted to
        local languages, laws, and cultures without compromising safety.
      relevanceScore: 50
      topics:
        - deployment
        - safety-research
        - regulation-debate
      entities:
        - regulation-debate
    - title: Introducing the Codex app
      url: https://openai.com/index/introducing-the-codex-app
      sourceId: openai-blog
      publishedAt: Mon, 02 Feb 2026 00:00:00 GMT
      summary: Introducing the Codex app for macOS—a command center for AI coding and software development with multiple
        agents, parallel workflows, and long-running tasks.
      relevanceScore: 50
      topics:
        - agentic-ai
        - coding
        - tool-use
      entities:
        - agentic-ai
        - coding
        - tool-use
    - title: EMEA Youth & Wellbeing Grant
      url: https://openai.com/index/emea-youth-and-wellbeing-grant
      sourceId: openai-blog
      publishedAt: Wed, 28 Jan 2026 01:00:00 GMT
      summary: Apply for the EMEA Youth & Wellbeing Grant, a €500,000 program funding NGOs and researchers advancing youth
        safety and wellbeing in the age of AI.
      relevanceScore: 50
      topics:
        - safety-research
        - public-opinion
      entities:
        - safety-research
        - public-opinion
    - title: Stargate Community
      url: https://openai.com/index/stargate-community
      sourceId: openai-blog
      publishedAt: Tue, 20 Jan 2026 19:00:00 GMT
      summary: Stargate Community plans detail a community-first approach to AI infrastructure, using locally tailored plans
        shaped by community input, energy needs, and workforce priorities.
      relevanceScore: 50
      topics:
        - compute-hardware
        - ai-megaproject-infrastructure
        - geopolitics
      entities:
        - compute-hardware
        - ai-megaproject-infrastructure
    - title: Datadog uses Codex for system-level code review
      url: https://openai.com/index/datadog
      sourceId: openai-blog
      publishedAt: Fri, 09 Jan 2026 00:00:00 GMT
      summary: OpenAI and Datadog brand graphic with the OpenAI wordmark on the left, the Datadog logo on the right, and a
        central abstract brown fur-like texture panel on a white background.
      relevanceScore: 50
      topics:
        - agentic-ai
        - tool-use
        - safety-research
      entities:
        - agentic-ai
        - tool-use
    - title: How We Used Codex to Ship Sora for Android in 28 Days
      url: https://openai.com/index/shipping-sora-for-android-with-codex
      sourceId: openai-blog
      publishedAt: Fri, 12 Dec 2025 00:00:00 GMT
      summary: OpenAI shipped Sora for Android in 28 days using Codex. AI-assisted planning, translation, and parallel coding
        workflows helped a nimble team deliver rapid, reliable development.
      relevanceScore: 50
      topics:
        - coding
        - capabilities
      entities:
        - coding
        - capabilities
    - title: Introducing OpenAI for Australia
      url: https://openai.com/global-affairs/openai-for-australia
      sourceId: openai-blog
      publishedAt: Thu, 04 Dec 2025 19:00:00 GMT
      summary: OpenAI is launching OpenAI for Australia to build sovereign AI infrastructure, upskill more than 1.5 million
        workers, and accelerate innovation across the country’s growing AI ecosystem.
      relevanceScore: 50
      topics:
        - geopolitics
        - ai-megaproject-infrastructure
        - economic-labor
      entities:
        - __index__/knowledge-base/metrics
    - title: Expanding data residency access to business customers worldwide
      url: https://openai.com/index/expanding-data-residency-access-to-business-customers-worldwide
      sourceId: openai-blog
      publishedAt: Tue, 25 Nov 2025 22:00:00 GMT
      summary: OpenAI expands data residency for ChatGPT Enterprise, ChatGPT Edu, and the API Platform, enabling eligible
        customers to store data at rest in-region.
      relevanceScore: 50
      topics:
        - structural-risks
        - regulation-debate
      entities: []
    - title: Inside JetBrains—the company reshaping how the world writes code
      url: https://openai.com/index/jetbrains-2025
      sourceId: openai-blog
      publishedAt: Tue, 25 Nov 2025 00:00:00 GMT
      summary: JetBrains is integrating GPT-5 across its coding tools, helping millions of developers design, reason, and
        build software faster.
      relevanceScore: 50
      topics:
        - coding
        - tool-use
        - capabilities
      entities:
        - __index__/knowledge-base/capabilities
    - title: Introducing IndQA
      url: https://openai.com/index/introducing-indqa
      sourceId: openai-blog
      publishedAt: Mon, 03 Nov 2025 22:30:00 GMT
      summary: OpenAI introduces IndQA, a new benchmark for evaluating AI systems in Indian languages. Built with domain
        experts, IndQA tests cultural understanding and reasoning across 12 languages and 10 knowledge areas.
      relevanceScore: 50
      topics:
        - safety-research
        - evaluation
        - benchmarking
        - language-models
      entities:
        - language-models
    - title: The next chapter of the Microsoft–OpenAI partnership
      url: https://openai.com/index/next-chapter-of-microsoft-openai-partnership
      sourceId: openai-blog
      publishedAt: Tue, 28 Oct 2025 06:00:00 GMT
      summary: Microsoft and OpenAI sign a new agreement that strengthens its long-term partnership, expands innovation, and
        ensures responsible AI progress.
      relevanceScore: 50
      topics:
        - governance
        - partnership
        - responsible-ai
      entities:
        - solutions
    - title: Argentina’s AI opportunity
      url: https://openai.com/global-affairs/argentinas-ai-opportunity
      sourceId: openai-blog
      publishedAt: Tue, 14 Oct 2025 06:00:00 GMT
      summary: OpenAI and Sur Energy are exploring Argentina’s first Stargate project—an AI and clean energy collaboration
        that could make Argentina a Latin American leader in artificial intelligence, sustainable infrastructure, and
        digital innovation.
      relevanceScore: 50
      topics:
        - geopolitics
        - agi-development
        - compute-hardware
      entities:
        - geopolitics
        - compute-hardware
    - title: Sora 2 is here
      url: https://openai.com/index/sora-2
      sourceId: openai-blog
      publishedAt: Tue, 30 Sep 2025 00:00:00 GMT
      summary: Our latest video generation model is more physically accurate, realistic, and controllable than prior systems.
        It also features synchronized dialogue and sound effects. Create with it in the new Sora app.
      relevanceScore: 50
      topics:
        - capabilities
        - tool-use
      entities:
        - capabilities
        - tool-use
    - title: Outbound coordinated vulnerability disclosure policy
      url: https://openai.com/policies/outbound-coordinated-disclosure-policy
      sourceId: openai-blog
      publishedAt: Mon, 22 Sep 2025 00:00:00 GMT
      summary: Outbound coordinated vulnerability disclosure policy
      relevanceScore: 50
      topics:
        - safety-research
        - misuse-risks
      entities:
        - safety-research
    - title: OpenAI and Greek Government launch ‘OpenAI for Greece’
      url: https://openai.com/global-affairs/openai-for-greece
      sourceId: openai-blog
      publishedAt: Fri, 05 Sep 2025 08:00:00 GMT
      summary: OpenAI and the Greek Government have launched “OpenAI for Greece” to bring ChatGPT Edu into secondary schools
        and support responsible AI learning. This partnership aims to boost AI literacy, fuel local start-ups, and drive
        national economic growth.
      relevanceScore: 50
      topics:
        - education
        - AI-literacy
        - responsible-AI
      entities:
        - safety-research
    - title: Scaling accounting capacity with OpenAI
      url: https://openai.com/index/basis
      sourceId: openai-blog
      publishedAt: Tue, 12 Aug 2025 00:00:00 GMT
      summary: Built with OpenAI o3, o3-Pro, GPT-4.1, and GPT-5, Basis’ AI agents help accounting firms save up to 30% of
        their time and expand capacity for advisory and growth.
      relevanceScore: 50
      topics:
        - capabilities
        - agents
        - automation
        - enterprise
      entities:
        - agentic-ai
        - capabilities
    - title: Open Weights and AI for All
      url: https://openai.com/global-affairs/open-weights-and-ai-for-all
      sourceId: openai-blog
      publishedAt: Tue, 05 Aug 2025 00:00:00 GMT
      summary: AI’s next frontier isn’t just about capability—it’s about who gets to use it. Our mission to put AI in the
        hands of as many people as possible is what drives us. Today’s release of our most capable open-weights models
        is a major step forward that makes advanced AI more open, flexible, and accessible worldwide.
      relevanceScore: 50
      topics:
        - open-vs-closed
        - capabilities
        - safety-research
      entities:
        - open-vs-closed
    - title: Pioneering an AI clinical copilot with Penda Health
      url: https://openai.com/index/ai-clinical-copilot-penda-health
      sourceId: openai-blog
      publishedAt: Tue, 22 Jul 2025 10:00:00 GMT
      summary: OpenAI and Penda Health debut an AI clinical copilot that cuts diagnostic errors by 16% in real-world
        use—offering a new path for safe, effective AI in healthcare.
      relevanceScore: 50
      topics:
        - safety-research
        - deployment-architectures-table
        - accident-risks
      entities:
        - safety-research
        - deployment-architectures-table
    - title: The EU Code of Practice and future of AI in Europe
      url: https://openai.com/global-affairs/eu-code-of-practice
      sourceId: openai-blog
      publishedAt: Fri, 11 Jul 2025 09:30:00 GMT
      summary: OpenAI joins the EU Code of Practice, advancing responsible AI while partnering with European governments to
        drive innovation, infrastructure, and economic growth.
      relevanceScore: 50
      topics:
        - regulation-debate
        - geopolitics
        - safety-research
      entities:
        - regulation-debate
        - geopolitics
    - title: Introducing OpenAI for Government
      url: https://openai.com/global-affairs/introducing-openai-for-government
      sourceId: openai-blog
      publishedAt: Mon, 16 Jun 2025 00:00:00 GMT
      summary: We’re launching OpenAI for Government, a new initiative focused on bringing our most advanced AI tools to
        public servants across the United States. We're supporting the U.S. government's efforts in adopting
        best-in-class technology and deploying these tools in service of the public good.
      relevanceScore: 50
      topics:
        - governance
        - deployment-architectures
        - lab-behavior
      entities:
        - deployment-architectures-table
        - lab-behavior
    - title: "Addendum to OpenAI o3 and o4-mini system card: OpenAI o3 Operator"
      url: https://openai.com/index/o3-o4-mini-system-card-addendum-operator-o3
      sourceId: openai-blog
      publishedAt: Fri, 23 May 2025 00:00:00 GMT
      summary: We are replacing the existing GPT-4o-based model for Operator with a version based on OpenAI o3. The API
        version will remain based on 4o.
      relevanceScore: 50
      topics:
        - agentic-ai
        - capabilities
        - safety-research
      entities:
        - agentic-ai
        - capabilities
        - safety-research
    - title: "Addendum to o3 and o4-mini system card: Codex"
      url: https://openai.com/index/o3-o4-mini-codex-system-card-addendum
      sourceId: openai-blog
      publishedAt: Fri, 16 May 2025 08:00:00 GMT
      summary: Codex is a cloud-based coding agent. Codex is powered by codex-1, a version of OpenAI o3 optimized for software
        engineering. codex-1 was trained using reinforcement learning on real-world coding tasks in a variety of
        environments to generate code that closely mirrors human style and PR preferences, adheres precisely to
        instructions, and iteratively runs tests until passing results are achieved.
      relevanceScore: 50
      topics:
        - agentic-ai
        - coding
        - capabilities
      entities:
        - agentic-ai
        - coding
    - title: OpenAI announces nonprofit commission advisors
      url: https://openai.com/index/nonprofit-commission-advisors
      sourceId: openai-blog
      publishedAt: Tue, 15 Apr 2025 13:00:00 GMT
      summary: OpenAI is appointing four new advisors to help inform OpenAI’s philanthropic efforts.
      relevanceScore: 50
      topics:
        - governance
        - nonprofit-structure
        - organizational-alignment
      entities: []
    - title: Early methods for studying affective use and emotional well-being on ChatGPT
      url: https://openai.com/index/affective-use-study
      sourceId: openai-blog
      publishedAt: Fri, 21 Mar 2025 10:00:00 GMT
      summary: An OpenAI and MIT Media Lab Research collaboration.
      relevanceScore: 50
      topics:
        - safety-research
        - human-wellbeing
        - evaluation
      entities:
        - eval-types-table
    - title: Introducing the SWE-Lancer benchmark
      url: https://openai.com/index/swe-lancer
      sourceId: openai-blog
      publishedAt: Tue, 18 Feb 2025 10:00:00 GMT
      summary: Can frontier LLMs earn $1 million from real-world freelance software engineering?
      relevanceScore: 50
      topics:
        - capabilities
        - agentic-ai
        - reasoning
      entities:
        - capabilities
        - agentic-ai
        - reasoning
    - title: OpenAI and the CSU system bring AI to 500,000 students & faculty
      url: https://openai.com/index/openai-and-the-csu-system
      sourceId: openai-blog
      publishedAt: Tue, 04 Feb 2025 11:30:00 GMT
      summary: The largest deployment of ChatGPT to date will expand the use of AI in education and help the United States
        build an AI-ready workforce.
      relevanceScore: 50
      topics:
        - economic-labor
        - capabilities
        - public-opinion
      entities:
        - economic-labor
    - title: OpenAI’s Economic Blueprint
      url: https://openai.com/global-affairs/openais-economic-blueprint
      sourceId: openai-blog
      publishedAt: Mon, 13 Jan 2025 03:00:00 GMT
      summary: OpenAI’s Economic Blueprint
      relevanceScore: 50
      topics:
        - geopolitics
        - economic-labor
        - agi-development
      entities:
        - economic-labor
        - agi-development
    - title: Sora is here
      url: https://openai.com/index/sora-is-here
      sourceId: openai-blog
      publishedAt: Mon, 09 Dec 2024 10:00:00 GMT
      summary: Our video generation model, Sora, is now available to use at sora.com. Users can generate videos up to 1080p
        resolution, up to 20 sec long, and in widescreen, vertical or square aspect ratios. You can bring your own
        assets to extend, remix, and blend, or generate entirely new content from text.
      relevanceScore: 50
      topics:
        - capabilities
        - deployment-architectures-table
      entities:
        - capabilities
        - deployment-architectures-table
    - title: OpenAI appoints Scott Schools as Chief Compliance Officer
      url: https://openai.com/global-affairs/openai-chief-compliance-officer-announcement
      sourceId: openai-blog
      publishedAt: Tue, 22 Oct 2024 10:30:00 GMT
      summary: OpenAI appoints Scott Schools as Chief Compliance Officer
      relevanceScore: 50
      topics:
        - lab-behavior
        - governance
        - compliance
      entities:
        - lab-behavior
    - title: OpenAI o1-mini
      url: https://openai.com/index/openai-o1-mini-advancing-cost-efficient-reasoning
      sourceId: openai-blog
      publishedAt: Thu, 12 Sep 2024 10:01:00 GMT
      summary: Advancing cost-efficient reasoning
      relevanceScore: 50
      topics:
        - reasoning
        - capabilities
      entities:
        - reasoning
        - capabilities
    - title: OpenAI o1 Contributions
      url: https://openai.com/openai-o1-contributions
      sourceId: openai-blog
      publishedAt: Thu, 12 Sep 2024 10:00:00 GMT
      summary: OpenAI o1 Contributions
      relevanceScore: 50
      topics:
        - safety-research
        - capabilities
      entities:
        - safety-research
        - capabilities
    - title: Introducing SWE-bench Verified
      url: https://openai.com/index/introducing-swe-bench-verified
      sourceId: openai-blog
      publishedAt: Tue, 13 Aug 2024 10:00:00 GMT
      summary: We’re releasing a human-validated subset of SWE-bench that more reliably evaluates AI models’ ability to solve
        real-world software issues.
      relevanceScore: 50
      topics:
        - evaluation
        - benchmarking
        - capabilities
        - safety-research
      entities:
        - safety-research
        - __index__/knowledge-base/metrics
    - title: New compliance and administrative tools for ChatGPT Enterprise
      url: https://openai.com/index/new-tools-for-chatgpt-enterprise
      sourceId: openai-blog
      publishedAt: Thu, 18 Jul 2024 00:00:00 GMT
      summary: Compliance API integrations, SCIM, and GPT controls to support compliance programs, data security, and user
        access at scale
      relevanceScore: 50
      topics:
        - governance
        - compliance
        - safety
        - deployment
      entities:
        - lab-behavior
    - title: Empowering defenders through our Cybersecurity Grant Program
      url: https://openai.com/index/empowering-defenders-through-our-cybersecurity-grant-program
      sourceId: openai-blog
      publishedAt: Thu, 20 Jun 2024 10:00:00 GMT
      summary: Highlighting innovative research and AI integration in cybersecurity
      relevanceScore: 50
      topics:
        - safety-research
        - cybersecurity
        - defense
      entities:
        - safety-research
    - title: Ilya Sutskever to leave OpenAI, Jakub Pachocki announced as Chief Scientist
      url: https://openai.com/index/jakub-pachocki-announced-as-chief-scientist
      sourceId: openai-blog
      publishedAt: Tue, 14 May 2024 18:00:00 GMT
      summary: ""
      relevanceScore: 50
      topics:
        - lab-behavior
      entities:
        - lab-behavior
    - title: Spring Update
      url: https://openai.com/index/spring-update
      sourceId: openai-blog
      publishedAt: Mon, 13 May 2024 10:00:00 GMT
      summary: Introducing GPT-4o and making more capabilities available for free in ChatGPT.
      relevanceScore: 50
      topics:
        - capabilities
        - language-models
      entities:
        - capabilities
        - language-models
    - title: Our approach to data and AI
      url: https://openai.com/index/approach-to-data-and-ai
      sourceId: openai-blog
      publishedAt: Tue, 07 May 2024 00:00:00 GMT
      summary: Just over a year after launching ChatGPT, AI is changing how we live, work and learn. It’s also raised
        important conversations about data in the age of AI. More on our approach, a new Media Manager for creators and
        content owners, and where we’re headed.
      relevanceScore: 50
      topics:
        - safety-research
        - misuse-risks
      entities:
        - safety-research
        - misuse-risks
    - title: Klarna's AI assistant does the work of 700 full-time agents
      url: https://openai.com/index/klarna
      sourceId: openai-blog
      publishedAt: Fri, 05 Apr 2024 00:00:00 GMT
      summary: Klarna is using AI to revolutionize personal shopping, customer service, and employee productivity.
      relevanceScore: 50
      topics:
        - deployment
        - capabilities
        - economic-labor
        - automation-bias-cascade
      entities:
        - economic-labor
        - automation-bias-cascade
    - title: Navigating the challenges and opportunities of synthetic voices
      url: https://openai.com/index/navigating-the-challenges-and-opportunities-of-synthetic-voices
      sourceId: openai-blog
      publishedAt: Fri, 29 Mar 2024 00:00:00 GMT
      summary: We’re sharing lessons from a small scale preview of Voice Engine, a model for creating custom voices.
      relevanceScore: 50
      topics:
        - deployment
        - misuse-risks
        - deepfakes-authentication-crisis
      entities:
        - misuse-risks
        - deepfakes-authentication-crisis
    - title: GPT-4V(ision) system card
      url: https://openai.com/index/gpt-4v-system-card
      sourceId: openai-blog
      publishedAt: Mon, 25 Sep 2023 07:00:00 GMT
      summary: ""
      relevanceScore: 50
      topics:
        - capabilities
        - safety-research
      entities:
        - language-models
    - title: Insights from global conversations
      url: https://openai.com/index/insights-from-global-conversations
      sourceId: openai-blog
      publishedAt: Thu, 29 Jun 2023 07:00:00 GMT
      summary: We are sharing what we learned from our conversations across 22 countries, and how we will be incorporating
        those insights moving forward.
      relevanceScore: 50
      topics:
        - public-opinion
        - expert-opinion
      entities:
        - __index__/knowledge-base/metrics
    - title: Introducing ChatGPT
      url: https://openai.com/index/chatgpt
      sourceId: openai-blog
      publishedAt: Wed, 30 Nov 2022 08:00:00 GMT
      summary: We’ve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it
        possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect premises, and reject
        inappropriate requests.
      relevanceScore: 50
      topics:
        - capabilities
        - language-models
        - deployment
      entities:
        - language-models
        - capabilities
    - title: Learning to play Minecraft with Video PreTraining
      url: https://openai.com/index/vpt
      sourceId: openai-blog
      publishedAt: Thu, 23 Jun 2022 07:00:00 GMT
      summary: We trained a neural network to play Minecraft by Video PreTraining (VPT) on a massive unlabeled video dataset
        of human Minecraft play, while using only a small amount of labeled contractor data. With fine-tuning, our model
        can learn to craft diamond tools, a task that usually takes proficient humans over 20 minutes (24,000 actions).
        Our model uses the native human interface of keypresses and mouse movements, making it quite general, and
        represents a step towards general computer-using agents.
      relevanceScore: 50
      topics:
        - capabilities
        - reasoning
        - tool-use
      entities:
        - reasoning
        - tool-use
    - title: Solving (some) formal math olympiad problems
      url: https://openai.com/index/formal-math
      sourceId: openai-blog
      publishedAt: Wed, 02 Feb 2022 08:00:00 GMT
      summary: We built a neural theorem prover for Lean that learned to solve a variety of challenging high-school olympiad
        problems, including problems from the AMC12 and AIME competitions, as well as two problems adapted from the IMO.
      relevanceScore: 50
      topics:
        - capabilities
        - reasoning
        - scientific-research
      entities:
        - reasoning
        - scientific-research
    - title: OpenAI Residency
      url: https://openai.com/index/openai-residency
      sourceId: openai-blog
      publishedAt: Tue, 30 Nov 2021 08:00:00 GMT
      summary: As part of our effort to support and develop AI talent, we’re excited to announce the OpenAI Residency.
      relevanceScore: 50
      topics:
        - ai-talent-market-dynamics
        - lab-behavior
      entities:
        - ai-talent-market-dynamics
        - lab-behavior
    - title: Evaluating large language models trained on code
      url: https://openai.com/index/evaluating-large-language-models-trained-on-code
      sourceId: openai-blog
      publishedAt: Wed, 07 Jul 2021 07:00:00 GMT
      summary: ""
      relevanceScore: 50
      topics:
        - coding
        - capabilities
        - language-models
      entities:
        - coding
        - language-models
    - title: Will Hurd joins OpenAI’s board of directors
      url: https://openai.com/index/will-hurd-joins
      sourceId: openai-blog
      publishedAt: Mon, 03 May 2021 07:00:00 GMT
      summary: OpenAI is committed to developing general-purpose artificial intelligence that benefits all humanity, and we
        believe that achieving our goal requires expertise in public policy as well as technology. So, we’re delighted
        to announce that Congressman Will Hurd has joined our board of directors.
      relevanceScore: 50
      topics:
        - lab-behavior
        - expert-opinion
        - governance
      entities:
        - lab-behavior
    - title: Scaling Kubernetes to 7,500 nodes
      url: https://openai.com/index/scaling-kubernetes-to-7500-nodes
      sourceId: openai-blog
      publishedAt: Mon, 25 Jan 2021 08:00:00 GMT
      summary: We’ve scaled Kubernetes clusters to 7,500 nodes, producing a scalable infrastructure for large models like
        GPT-3, CLIP, and DALL·E, but also for rapid small-scale iterative research such as Scaling Laws for Neural
        Language Models.
      relevanceScore: 50
      topics:
        - compute-hardware
        - ai-megaproject-infrastructure
      entities:
        - compute-hardware
        - ai-megaproject-infrastructure
    - title: "CLIP: Connecting text and images"
      url: https://openai.com/index/clip
      sourceId: openai-blog
      publishedAt: Tue, 05 Jan 2021 08:00:00 GMT
      summary: We’re introducing a neural network called CLIP which efficiently learns visual concepts from natural language
        supervision. CLIP can be applied to any visual classification benchmark by simply providing the names of the
        visual categories to be recognized, similar to the “zero-shot” capabilities of GPT-2 and GPT-3.
      relevanceScore: 50
      topics:
        - capabilities
        - world-models
        - interpretability-sufficient
      entities:
        - world-models
    - title: OpenAI Five defeats Dota 2 world champions
      url: https://openai.com/index/openai-five-defeats-dota-2-world-champions
      sourceId: openai-blog
      publishedAt: Mon, 15 Apr 2019 07:00:00 GMT
      summary: OpenAI Five is the first AI to beat the world champions in an esports game, having won two back-to-back games
        versus the world champion Dota 2 team, OG, at Finals this weekend. Both OpenAI Five and DeepMind’s AlphaStar had
        previously beaten good pros privately but lost their live pro matches, making this also the first time an AI has
        beaten esports pros on livestream.
      relevanceScore: 50
      topics:
        - reinforcement-learning
        - capabilities
        - multi-agent
      entities:
        - capabilities
    - title: Spinning Up in Deep RL
      url: https://openai.com/index/spinning-up-in-deep-rl
      sourceId: openai-blog
      publishedAt: Thu, 08 Nov 2018 08:00:00 GMT
      summary: We’re releasing Spinning Up in Deep RL, an educational resource designed to let anyone learn to become a
        skilled practitioner in deep reinforcement learning. Spinning Up consists of crystal-clear examples of RL code,
        educational exercises, documentation, and tutorials.
      relevanceScore: 50
      topics:
        - education
        - reinforcement-learning
        - resources
      entities:
        - safety-research
    - title: "FFJORD: Free-form continuous dynamics for scalable reversible generative models"
      url: https://openai.com/index/ffjord
      sourceId: openai-blog
      publishedAt: Tue, 02 Oct 2018 07:00:00 GMT
      summary: ""
      relevanceScore: 50
      topics:
        - generative-models
        - normalizing-flows
        - architecture
      entities:
        - architecture-scenarios-table
    - title: Learning dexterity
      url: https://openai.com/index/learning-dexterity
      sourceId: openai-blog
      publishedAt: Mon, 30 Jul 2018 07:00:00 GMT
      summary: We’ve trained a human-like robot hand to manipulate physical objects with unprecedented dexterity.
      relevanceScore: 50
      topics:
        - robotics
        - reinforcement-learning
        - dexterity
      entities:
        - tool-use
    - title: "Retro Contest: Results"
      url: https://openai.com/index/retro-contest-results
      sourceId: openai-blog
      publishedAt: Fri, 22 Jun 2018 07:00:00 GMT
      summary: The first run of our Retro Contest—exploring the development of algorithms that can generalize from previous
        experience—is now complete.
      relevanceScore: 50
      topics:
        - reinforcement-learning
        - generalization
        - benchmarks
      entities:
        - capabilities
    - title: Evolved Policy Gradients
      url: https://openai.com/index/evolved-policy-gradients
      sourceId: openai-blog
      publishedAt: Wed, 18 Apr 2018 07:00:00 GMT
      summary: We’re releasing an experimental metalearning approach called Evolved Policy Gradients, a method that evolves
        the loss function of learning agents, which can enable fast training on novel tasks. Agents trained with EPG can
        succeed at basic tasks at test time that were outside their training regime, like learning to navigate to an
        object on a different side of the room from where it was placed during training.
      relevanceScore: 50
      topics:
        - capabilities
        - reasoning
      entities:
        - capabilities
    - title: Requests for Research 2.0
      url: https://openai.com/index/requests-for-research-2
      sourceId: openai-blog
      publishedAt: Wed, 31 Jan 2018 08:00:00 GMT
      summary: We’re releasing a new batch of seven unsolved problems which have come up in the course of our research at
        OpenAI.
      relevanceScore: 50
      topics:
        - safety-research
        - alignment-progress
      entities:
        - safety-research
        - alignment-progress
    - title: Block-sparse GPU kernels
      url: https://openai.com/index/block-sparse-gpu-kernels
      sourceId: openai-blog
      publishedAt: Wed, 06 Dec 2017 08:00:00 GMT
      summary: "We’re releasing highly-optimized GPU kernels for an underexplored class of neural network architectures:
        networks with block-sparse weights. Depending on the chosen sparsity, these kernels can run orders of magnitude
        faster than cuBLAS or cuSPARSE. We’ve used them to attain state-of-the-art results in text sentiment analysis
        and generative modeling of text and images."
      relevanceScore: 50
      topics:
        - compute-hardware
        - capabilities
      entities:
        - compute-hardware
        - capabilities
    - title: Generalizing from simulation
      url: https://openai.com/index/generalizing-from-simulation
      sourceId: openai-blog
      publishedAt: Thu, 19 Oct 2017 07:00:00 GMT
      summary: Our latest robotics techniques allow robot controllers, trained entirely in simulation and deployed on physical
        robots, to react to unplanned changes in the environment as they solve simple tasks. That is, we’ve used these
        techniques to build closed-loop systems rather than open-loop ones as before.
      relevanceScore: 50
      topics:
        - capabilities
        - tool-use
      entities:
        - capabilities
    - title: Meta-learning for wrestling
      url: https://openai.com/index/meta-learning-for-wrestling
      sourceId: openai-blog
      publishedAt: Wed, 11 Oct 2017 07:00:00 GMT
      summary: We show that for the task of simulated robot wrestling, a meta-learning agent can learn to quickly defeat a
        stronger non-meta-learning agent, and also show that the meta-learning agent can adapt to physical malfunction.
      relevanceScore: 50
      topics:
        - meta-learning
        - reinforcement-learning
        - multi-agent
        - competitive-dynamics
      entities:
        - agentic-ai
        - reasoning
    - title: Robots that learn
      url: https://openai.com/index/robots-that-learn
      sourceId: openai-blog
      publishedAt: Tue, 16 May 2017 07:00:00 GMT
      summary: We’ve created a robotics system, trained entirely in simulation and deployed on a physical robot, which can
        learn a new task after seeing it done once.
      relevanceScore: 50
      topics:
        - robotics
        - learning
        - sim-to-real
        - one-shot-learning
      entities:
        - tool-use
    - title: Evolution strategies as a scalable alternative to reinforcement learning
      url: https://openai.com/index/evolution-strategies
      sourceId: openai-blog
      publishedAt: Fri, 24 Mar 2017 07:00:00 GMT
      summary: We’ve discovered that evolution strategies (ES), an optimization technique that’s been known for decades,
        rivals the performance of standard reinforcement learning (RL) techniques on modern RL benchmarks (e.g.
        Atari/MuJoCo), while overcoming many of RL’s inconveniences.
      relevanceScore: 50
      topics:
        - evolution-strategies
        - reinforcement-learning
        - optimization
        - scaling
      entities:
        - compute-hardware
    - title: Team update
      url: https://openai.com/index/team-update-january
      sourceId: openai-blog
      publishedAt: Mon, 30 Jan 2017 08:00:00 GMT
      summary: The OpenAI team is now 45 people. Together, we’re pushing the frontier of AI capabilities—whether by validating
        novel ideas, creating new software systems, or deploying machine learning on robots.
      relevanceScore: 50
      topics:
        - lab-behavior
        - capabilities
      entities:
        - lab-behavior
        - capabilities
    - title: Special projects
      url: https://openai.com/index/special-projects
      sourceId: openai-blog
      publishedAt: Thu, 28 Jul 2016 07:00:00 GMT
      summary: Impactful scientific work requires working on the right problems—problems which are not just interesting, but
        whose solutions matter.
      relevanceScore: 50
      topics:
        - research-direction
        - impact
      entities: []
    - title: OpenAI Gym Beta
      url: https://openai.com/index/openai-gym-beta
      sourceId: openai-blog
      publishedAt: Wed, 27 Apr 2016 07:00:00 GMT
      summary: We’re releasing the public beta of OpenAI Gym, a toolkit for developing and comparing reinforcement learning
        (RL) algorithms. It consists of a growing suite of environments (from simulated robots to Atari games), and a
        site for comparing and reproducing results.
      relevanceScore: 50
      topics:
        - reinforcement-learning
        - benchmarking
        - tool-use
      entities:
        - tool-use
    - title: "Google DeepMind supports U.S. Department of Energy on Genesis: a national mission to accelerate innovation and
        scientific discovery"
      url: https://deepmind.google/blog/google-deepmind-supports-us-department-of-energy-on-genesis/
      sourceId: deepmind-blog
      publishedAt: Mon, 24 Nov 2025 14:12:03 +0000
      summary: Google DeepMind and the DOE partner on Genesis, a new effort to accelerate science with AI.
      relevanceScore: 50
      topics:
        - scientific-research
        - agi-development
        - geopolitics
      entities:
        - scientific-research
        - agi-development
        - geopolitics
    - title: Accelerating discovery with the AI for Math Initiative
      url: https://deepmind.google/blog/accelerating-discovery-with-the-ai-for-math-initiative/
      sourceId: deepmind-blog
      publishedAt: Wed, 29 Oct 2025 14:31:13 +0000
      summary: The initiative brings together some of the world's most prestigious research institutions to pioneer the use of
        AI in mathematical research.
      relevanceScore: 50
      topics:
        - capabilities
        - scientific-research
      entities:
        - capabilities
        - scientific-research
    - title: "Introducing Gemma 3n: The developer guide"
      url: https://deepmind.google/blog/introducing-gemma-3n-the-developer-guide/
      sourceId: deepmind-blog
      publishedAt: Sat, 25 Oct 2025 17:54:47 +0000
      summary: Gemma 3n is designed for the developer community that helped shape Gemma.
      relevanceScore: 50
      topics:
        - language-models
        - capabilities
      entities:
        - language-models
        - capabilities
    - title: Advanced audio dialog and generation with Gemini 2.5
      url: https://deepmind.google/blog/advanced-audio-dialog-and-generation-with-gemini-25/
      sourceId: deepmind-blog
      publishedAt: Tue, 03 Jun 2025 17:15:47 +0000
      summary: Gemini 2.5 has new capabilities in AI-powered audio dialog and generation.
      relevanceScore: 50
      topics:
        - language-models
        - capabilities
      entities:
        - language-models
        - capabilities
    - title: Build rich, interactive web apps with an updated Gemini 2.5 Pro
      url: https://deepmind.google/blog/build-rich-interactive-web-apps-with-an-updated-gemini-25-pro/
      sourceId: deepmind-blog
      publishedAt: Tue, 06 May 2025 15:00:00 +0000
      summary: Our updated version of Gemini 2.5 Pro Preview has improved capabilities for coding.
      relevanceScore: 50
      topics:
        - language-models
        - coding
        - capabilities
      entities:
        - language-models
        - coding
        - capabilities
    - title: Start building with Gemini 2.0 Flash and Flash-Lite
      url: https://deepmind.google/blog/start-building-with-gemini-20-flash-and-flash-lite/
      sourceId: deepmind-blog
      publishedAt: Tue, 25 Feb 2025 18:02:12 +0000
      summary: Gemini 2.0 Flash-Lite is now generally available in the Gemini API for production use in Google AI Studio and
        for enterprise customers on Vertex AI
      relevanceScore: 50
      topics:
        - language-models
        - capabilities
      entities:
        - language-models
        - capabilities
    - title: "Introducing Gemini 2.0: our new AI model for the agentic era"
      url: https://deepmind.google/blog/introducing-gemini-20-our-new-ai-model-for-the-agentic-era/
      sourceId: deepmind-blog
      publishedAt: Wed, 11 Dec 2024 15:30:40 +0000
      summary: Today, we’re announcing Gemini 2.0, our most capable multimodal AI model yet.
      relevanceScore: 50
      topics:
        - capabilities
        - agentic-ai
        - language-models
      entities:
        - agentic-ai
        - language-models
    - title: How AlphaChip transformed computer chip design
      url: https://deepmind.google/blog/how-alphachip-transformed-computer-chip-design/
      sourceId: deepmind-blog
      publishedAt: Thu, 26 Sep 2024 14:08:00 +0000
      summary: Our AI method has accelerated and optimized chip design, and its superhuman chip layouts are used in hardware
        around the world.
      relevanceScore: 50
      topics:
        - capabilities
        - compute-hardware
      entities:
        - compute-hardware
    - title: I want to actually get good at forecasting this year (Group Invite)
      url: https://www.lesswrong.com/posts/jronsvchwjB74BDEb/i-want-to-actually-get-good-at-forecasting-this-year-group
      sourceId: lesswrong
      publishedAt: Thu, 19 Feb 2026 04:48:55 GMT
      summary: Published on February 19, 2026 1:41 AM GMTI’ve read Superforecasting, but I find that actually applying the "10
        commandments" is difficult in isolation. The feedback loops in the real world are too slow, and it’s too easy to
        skip post-mortems when no one is watching.My goal for this year is to put in substantial work to become a
        superforecaster (or at least get much closer).To do this, I am starting a dedicated online community for peer
        accountability and high-frequency practice. I’m looking for
      relevanceScore: 50
      topics:
        - agi-timeline
        - forecasting
      entities:
        - __index__/knowledge-base/forecasting
        - agi-timeline
    - title: "Last Week in AI #334 - Kimi K2.5 & Code, Genie 3, OpenClaw & Moltbook"
      url: https://lastweekin.ai/p/last-week-in-ai-334-kimi-k25-and
      sourceId: last-week-in-ai
      publishedAt: Wed, 04 Feb 2026 05:25:56 GMT
      summary: China&#8217;s Moonshot releases a new open source model Kimi K2.5 and a coding agent, Google Brings Genie
        3&#8217;s Interactive World-Building Prototype to AI Ultra Subscribers, and more!
      relevanceScore: 50
      topics:
        - capabilities
        - language-models
        - open-source
      entities:
        - language-models
        - agentic-ai
    - title: "LWiAI Podcast #229 - Gemini 3 Flash, ChatGPT Apps, Nemotron 3"
      url: https://lastweekin.ai/p/lwiai-podcast-229-gemini-3-flash
      sourceId: last-week-in-ai
      publishedAt: Thu, 25 Dec 2025 21:29:26 GMT
      summary: Google launches Gemini 3 Flash, ChatGPT launches an app store, Introducing GPT-5.2-Codex
      relevanceScore: 50
      topics:
        - capabilities
        - language-models
        - tool-use
      entities:
        - language-models
    - title: "Last Week in AI #327 - Gemini 3, Opus 4.5, Nano Banana Pro, GPT-5.1-Codex-Max"
      url: https://lastweekin.ai/p/last-week-in-ai-327-gemini-3-opus
      sourceId: last-week-in-ai
      publishedAt: Tue, 25 Nov 2025 19:21:47 GMT
      summary: It's a big week! Lots of exciting releases, plus nvidia earnings and a whole bunch of cool research.
      relevanceScore: 50
      topics:
        - capabilities
        - language-models
      entities:
        - language-models
    - title: Improving Interactive In-Context Learning from Natural Language Feedback
      url: https://arxiv.org/abs/2602.16066
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16066v1 Announce Type: new Abstract: Adapting one's thought process based on corrective feedback is
        an essential ability in human learning, particularly in collaborative settings. In contrast, the current large
        language model training paradigm relies heavily on modeling vast, static corpora. While effective for knowledge
        acquisition, it overlooks the interactive feedback loops essential for models to adapt dynamically to their
        context. In this work, we propose a framework that treats "
      relevanceScore: 50
      topics:
        - agentic-ai
        - alignment-progress
      entities:
        - agentic-ai
    - title: "Agent Skill Framework: Perspectives on the Potential of Small Language Models in Industrial Environments"
      url: https://arxiv.org/abs/2602.16653
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16653v1 Announce Type: new Abstract: Agent Skill framework, now widely and officially supported by
        major players such as GitHub Copilot, LangChain, and OpenAI, performs especially well with proprietary models by
        improving context engineering, reducing hallucinations, and boosting task accuracy. Based on these observations,
        an investigation is conducted to determine whether the Agent Skill paradigm provides similar benefits to small
        language models (SLMs). This question matters in indu"
      relevanceScore: 50
      topics:
        - agentic-ai
        - language-models
        - tool-use
      entities:
        - agentic-ai
        - tool-use
        - language-models
    - title: "State Design Matters: How Representations Shape Dynamic Reasoning in Large Language Models"
      url: https://arxiv.org/abs/2602.15858
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15858v1 Announce Type: cross Abstract: As large language models (LLMs) move from static reasoning
        tasks toward dynamic environments, their success depends on the ability to navigate and respond to an
        environment that changes as they interact at inference time. An underexplored factor in these settings is the
        representation of the state. Holding model parameters fixed, we systematically vary three key aspects: (1) state
        granularity (long form versus summary), (2) structure (natural lan"
      relevanceScore: 50
      topics:
        - language-models
        - reasoning
        - dynamic-environments
      entities:
        - language-models
        - reasoning
        - agentic-ai
    - title: Egocentric Bias in Vision-Language Models
      url: https://arxiv.org/abs/2602.15892
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15892v1 Announce Type: cross Abstract: Visual perspective taking--inferring how the world appears
        from another's viewpoint--is foundational to social cognition. We introduce FlipSet, a diagnostic benchmark for
        Level-2 visual perspective taking (L2 VPT) in vision-language models. The task requires simulating 180-degree
        rotations of 2D character strings from another agent's perspective, isolating spatial transformation from 3D
        scene complexity. Evaluating 103 VLMs reveals systematic ego"
      relevanceScore: 50
      topics:
        - vision-language-models
        - bias
        - interpretability
        - epistemic-risks
      entities:
        - epistemic-risks
    - title: "Doc-to-LoRA: Learning to Instantly Internalize Contexts"
      url: https://arxiv.org/abs/2602.15902
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15902v1 Announce Type: cross Abstract: Long input sequences are central to in-context learning,
        document understanding, and multi-step reasoning of Large Language Models (LLMs). However, the quadratic
        attention cost of Transformers makes inference memory-intensive and slow. While context distillation (CD) can
        transfer information into model parameters, per-prompt distillation is impractical due to training costs and
        latency. To address these limitations, we propose Doc-to-LoRA (D2L), "
      relevanceScore: 50
      topics:
        - language-models
        - long-horizon
        - in-context-learning
        - reasoning
      entities:
        - language-models
        - long-horizon
        - reasoning
    - title: "From Reflection to Repair: A Scoping Review of Dataset Documentation Tools"
      url: https://arxiv.org/abs/2602.15968
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15968v1 Announce Type: cross Abstract: Dataset documentation is widely recognized as essential for
        the responsible development of automated systems. Despite growing efforts to support documentation through
        different kinds of artifacts, little is known about the motivations shaping documentation tool design or the
        factors hindering their adoption. We present a systematic review supported by mixed-methods analysis of 59
        dataset documentation publications to examine the motivations behin"
      relevanceScore: 50
      topics:
        - safety-research
        - dataset-documentation
        - responsible-ai
        - epistemic-risks
      entities:
        - safety-research
        - epistemic-risks
    - title: "ScenicRules: An Autonomous Driving Benchmark with Multi-Objective Specifications and Abstract Scenarios"
      url: https://arxiv.org/abs/2602.16073
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16073v1 Announce Type: cross Abstract: Developing autonomous driving systems for complex traffic
        environments requires balancing multiple objectives, such as avoiding collisions, obeying traffic rules, and
        making efficient progress. In many situations, these objectives cannot be satisfied simultaneously, and explicit
        priority relations naturally arise. Also, driving rules require context, so it is important to formally model
        the environment scenarios within which such rules apply. Exi"
      relevanceScore: 50
      topics:
        - autonomous-systems
        - safety-research
        - multi-objective
        - accident-risks
      entities:
        - safety-research
        - accident-risks
    - title: Balancing Faithfulness and Performance in Reasoning via Multi-Listener Soft Execution
      url: https://arxiv.org/abs/2602.16154
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16154v1 Announce Type: cross Abstract: Chain-of-thought (CoT) reasoning sometimes fails to
        faithfully reflect the true computation of a large language model (LLM), hampering its utility in explaining how
        LLMs arrive at their answers. Moreover, optimizing for faithfulness and interpretability in reasoning often
        degrades task performance. To address this tradeoff and improve CoT faithfulness, we propose Reasoning Execution
        by Multiple Listeners (REMUL), a multi-party reinforcement learn"
      relevanceScore: 50
      topics:
        - language-models
        - reasoning
        - interpretability-sufficient
      entities:
        - language-models
        - reasoning
    - title: "Long-Tail Knowledge in Large Language Models: Taxonomy, Mechanisms, Interventions and Implications"
      url: https://arxiv.org/abs/2602.16201
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16201v1 Announce Type: cross Abstract: Large language models (LLMs) are trained on web-scale
        corpora that exhibit steep power-law distributions, in which the distribution of knowledge is highly
        long-tailed, with most appearing infrequently. While scaling has improved average-case performance, persistent
        failures on low-frequency, domain-specific, cultural, and temporal knowledge remain poorly characterized. This
        paper develops a structured taxonomy and analysis of long-Tail Knowledge "
      relevanceScore: 50
      topics:
        - language-models
        - capabilities
      entities:
        - language-models
        - capabilities
    - title: Learning to Learn from Language Feedback with Social Meta-Learning
      url: https://arxiv.org/abs/2602.16488
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16488v1 Announce Type: cross Abstract: Large language models (LLMs) often struggle to learn from
        corrective feedback within a conversational context. They are rarely proactive in soliciting this feedback, even
        when faced with ambiguity, which can make their dialogues feel static, one-sided, and lacking the adaptive
        qualities of human conversation. To address these limitations, we draw inspiration from social meta-learning
        (SML) in humans - the process of learning how to learn from oth"
      relevanceScore: 50
      topics:
        - alignment-progress
        - language-models
      entities:
        - alignment-progress
        - language-models
    - title: "DataJoint 2.0: A Computational Substrate for Agentic Scientific Workflows"
      url: https://arxiv.org/abs/2602.16585
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16585v1 Announce Type: cross Abstract: Operational rigor determines whether human-agent
        collaboration succeeds or fails. Scientific data pipelines need the equivalent of DevOps -- SciOps -- yet common
        approaches fragment provenance across disconnected systems without transactional guarantees. DataJoint 2.0
        addresses this gap through the relational workflow model: tables represent workflow steps, rows represent
        artifacts, foreign keys prescribe execution order. The schema specifies not"
      relevanceScore: 50
      topics:
        - agentic-ai
        - scientific-research
      entities:
        - agentic-ai
        - scientific-research
    - title: Who can we trust? LLM-as-a-jury for Comparative Assessment
      url: https://arxiv.org/abs/2602.16610
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16610v1 Announce Type: cross Abstract: Large language models (LLMs) are increasingly applied as
        automatic evaluators for natural language generation assessment often using pairwise comparative judgements.
        Existing approaches typically rely on single judges or aggregate multiple judges assuming equal reliability. In
        practice, LLM judges vary substantially in performance across tasks and aspects, and their judgment
        probabilities may be biased and inconsistent. Furthermore, human-labelle"
      relevanceScore: 50
      topics:
        - language-models
        - safety-research
      entities:
        - language-models
        - safety-research
    - title: Large Language Models for Water Distribution Systems Modeling and Decision-Making
      url: https://arxiv.org/abs/2503.16191
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2503.16191v2 Announce Type: replace Abstract: The integration of Large Language Models (LLMs) into
        engineering workflows presents new opportunities for making computational tools more accessible. Especially
        where such tools remain underutilized due to technical or expertise barriers, such as water distribution system
        (WDS) management. This study introduces LLM-EPANET, an agent-based framework that enables natural language
        interaction with EPANET, the benchmark WDS simulator. The framework "
      relevanceScore: 50
      topics:
        - agentic-ai
        - tool-use
      entities:
        - agentic-ai
        - tool-use
    - title: "RoboSpatial: Teaching Spatial Understanding to 2D and 3D Vision-Language Models for Robotics"
      url: https://arxiv.org/abs/2411.16537
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2411.16537v5 Announce Type: replace-cross Abstract: Spatial understanding is a crucial capability that
        enables robots to perceive their surroundings, reason about their environment, and interact with it
        meaningfully. In modern robotics, these capabilities are increasingly provided by vision-language models.
        However, these models face significant challenges in spatial reasoning tasks, as their training data are based
        on general-purpose image datasets that often lack sophisticated spatial un"
      relevanceScore: 50
      topics:
        - agentic-ai
        - tool-use
        - reasoning
      entities:
        - agentic-ai
        - tool-use
        - reasoning
    - title: "m1: Unleash the Potential of Test-Time Scaling for Medical Reasoning with Large Language Models"
      url: https://arxiv.org/abs/2504.00869
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2504.00869v2 Announce Type: replace-cross Abstract: Test-time scaling has emerged as a powerful
        technique for enhancing the reasoning capabilities of large language models. However, its effectiveness in
        medical reasoning remains uncertain, as the medical domain fundamentally differs from mathematical tasks in
        terms of knowledge representation and decision-making processes. In this paper, we provide the first
        comprehensive investigation of test-time scaling for medical reasoning and present"
      relevanceScore: 50
      topics:
        - test-time-scaling
        - reasoning
        - language-models
      entities:
        - language-models
        - reasoning
    - title: Experience-based Knowledge Correction for Robust Planning in Minecraft
      url: https://arxiv.org/abs/2505.24157
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2505.24157v3 Announce Type: replace-cross Abstract: Large Language Model (LLM)-based planning has
        advanced embodied agents in long-horizon environments such as Minecraft, where acquiring latent knowledge of
        goal (or item) dependencies and feasible actions is critical. However, LLMs often begin with flawed priors and
        fail to correct them through prompting, even with feedback. We present XENON (eXpErience-based kNOwledge
        correctioN), an agent that algorithmically revises knowledge from exper"
      relevanceScore: 50
      topics:
        - language-models
        - planning
        - long-horizon
        - embodied-ai
      entities:
        - language-models
        - long-horizon
        - agentic-ai
    - title: Expressive Power of Graph Transformers via Logic
      url: https://arxiv.org/abs/2508.01067
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2508.01067v2 Announce Type: replace-cross Abstract: Transformers are the basis of modern large language
        models, but relatively little is known about their precise expressive power on graphs. We study the expressive
        power of graph transformers (GTs) by Dwivedi and Bresson (2020) and GPS-networks by Ramp\\'asek et al. (2022),
        both under soft-attention and average hard-attention. Our study covers two scenarios: the theoretical setting
        with real numbers and the more practical case with floats. "
      relevanceScore: 50
      topics:
        - transformers
        - expressiveness
        - interpretability
      entities:
        - language-models
        - interpretability-sufficient
    - title: "COGITAO: A Visual Reasoning Framework To Study Compositionality & Generalization"
      url: https://arxiv.org/abs/2509.05249
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2509.05249v2 Announce Type: replace-cross Abstract: The ability to compose learned concepts and apply
        them in novel settings is key to human intelligence, but remains a persistent limitation in state-of-the-art
        machine learning models. To address this issue, we introduce COGITAO, a modular and extensible data generation
        framework and benchmark designed to systematically study compositionality and generalization in visual domains.
        Drawing inspiration from ARC-AGI's problem-setting, COGITAO "
      relevanceScore: 50
      topics:
        - compositionality
        - generalization
        - reasoning
      entities:
        - reasoning
    - title: Predicting Training Re-evaluation Curves Enables Effective Data Curriculums for LLMs
      url: https://arxiv.org/abs/2509.25380
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2509.25380v2 Announce Type: replace-cross Abstract: Data curriculums have become central to successful
        LLM training, yet principles governing optimal data placement remain unclear. We introduce the *training
        re-evaluation curve (TREC)*, a diagnostic that retrospectively evaluates training batches *using the final model
        weights*. The TREC characterizes how well a trained model retains training data as a function of *when* the data
        was encountered during training. Analyzing TRECs for models "
      relevanceScore: 50
      topics:
        - training-data
        - curriculum-learning
        - language-models
      entities:
        - language-models
    - title: Mastering Olympiad-Level Physics with Artificial Intelligence
      url: https://arxiv.org/abs/2511.10515
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2511.10515v2 Announce Type: replace-cross Abstract: Olympiad-level physics problem-solving significantly
        challenges both humans and artificial intelligence (AI), as it requires integrating appropriate modeling,
        application of physical principles, and precise calculation within long reasoning processes. In this paper, we
        introduce LOCA (LOgical Chain Augmentation), an AI agent framework designed for complex physics reasoning. LOCA
        decomposes long reasoning into serialized atomic and verifia"
      relevanceScore: 50
      topics:
        - reasoning
        - capabilities
        - language-models
        - scientific-research
      entities:
        - reasoning
        - capabilities
        - scientific-research
    - title: "Vision and Language: Novel Representations and Artificial intelligence for Driving Scene Safety Assessment and
        Autonomous Vehicle Planning"
      url: https://arxiv.org/abs/2602.07680
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.07680v2 Announce Type: replace-cross Abstract: Vision-language models (VLMs) have recently emerged
        as powerful representation learning systems that align visual observations with natural language concepts,
        offering new opportunities for semantic reasoning in safety-critical autonomous driving. This paper investigates
        how vision-language representations support driving scene safety assessment and decision-making when integrated
        into perception, prediction, and planning pipelines. We st"
      relevanceScore: 50
      topics:
        - vision-language-models
        - autonomous-vehicles
        - safety
      entities:
        - autonomous-weapons-escalation
        - safety-research
    - title: Knowledge-Based Design Requirements for Generative Social Robots in Higher Education
      url: https://arxiv.org/abs/2602.12873
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.12873v2 Announce Type: replace-cross Abstract: Generative social robots (GSRs) powered by large
        language models enable adaptive, conversational tutoring but also introduce risks such as hallucinations,
        overreliance, and privacy violations. Existing frameworks for educational technologies and responsible AI
        primarily define desired behaviors, yet they rarely specify the knowledge prerequisites that enable generative
        systems to express these behaviors reliably. To address this gap, we a"
      relevanceScore: 50
      topics:
        - language-models
        - social-robots
        - safety
        - hallucinations
        - misuse-risks
      entities:
        - misuse-risks
        - safety-research
    - title: "From Transcripts to AI Agents: Knowledge Extraction, RAG Integration, and Robust Evaluation of Conversational AI
        Assistants"
      url: https://arxiv.org/abs/2602.15859
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15859v1 Announce Type: new Abstract: Building reliable conversational AI assistants for
        customer-facing industries remains challenging due to noisy conversational data, fragmented knowledge, and the
        requirement for accurate human hand-off - particularly in domains that depend heavily on real-time information.
        This paper presents an end-to-end framework for constructing and evaluating a conversational AI assistant
        directly from historical call transcripts. Incoming transcripts are firs"
      relevanceScore: 50
      topics:
        - conversational AI
        - agents
        - reliability
      entities:
        - language-models
        - agentic-ai
    - title: "Towards Fair and Efficient De-identification: Quantifying the Efficiency and Generalizability of
        De-identification Approaches"
      url: https://arxiv.org/abs/2602.15869
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15869v1 Announce Type: new Abstract: Large language models (LLMs) have shown strong performance on
        clinical de-identification, the task of identifying sensitive identifiers to protect privacy. However, previous
        work has not examined their generalizability between formats, cultures, and genders. In this work, we
        systematically evaluate fine-tuned transformer models (BERT, ClinicalBERT, ModernBERT), small LLMs (Llama 1-8B,
        Qwen 1.5-7B), and large LLMs (Llama-70B, Qwen-72B) at de-identif"
      relevanceScore: 50
      topics:
        - privacy
        - de-identification
        - LLM safety
      entities:
        - language-models
        - misuse-risks
    - title: "CLAA: Cross-Layer Attention Aggregation for Accelerating LLM Prefill"
      url: https://arxiv.org/abs/2602.16054
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16054v1 Announce Type: new Abstract: The prefill stage in long-context LLM inference remains a
        computational bottleneck. Recent token-ranking heuristics accelerate inference by selectively processing a
        subset of semantically relevant tokens. However, existing methods suffer from unstable token importance
        estimation, often varying between layers. Evaluating token-ranking quality independently from heuristic-specific
        architectures is challenging. To address this, we introduce an Answer-"
      relevanceScore: 50
      topics:
        - LLM inference
        - optimization
        - compute efficiency
      entities:
        - language-models
        - compute-hardware
    - title: "TabAgent: A Framework for Replacing Agentic Generative Components with Tabular-Textual Classifiers"
      url: https://arxiv.org/abs/2602.16429
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16429v1 Announce Type: new Abstract: Agentic systems, AI architectures that autonomously execute
        multi-step workflows to achieve complex goals, are often built using repeated large language model (LLM) calls
        for closed-set decision tasks such as routing, shortlisting, gating, and verification. While convenient, this
        design makes deployments slow and expensive due to cumulative latency and token usage. We propose TabAgent, a
        framework for replacing generative decision components in clo"
      relevanceScore: 50
      topics:
        - agentic systems
        - LLM replacement
        - efficiency
      entities:
        - agentic-ai
        - language-models
    - title: "Randomized Masked Finetuning: An Efficient Way to Mitigate Memorization of PIIs in LLMs"
      url: https://arxiv.org/abs/2512.03310
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2512.03310v3 Announce Type: replace Abstract: The current literature on memorization in Natural Language
        Models, especially Large Language Models (LLMs), poses severe security and privacy risks, as models tend to
        memorize personally identifying information (PIIs) from training data. We introduce Randomized Masked
        Fine-Tuning (RMFT), a novel privacy-preserving fine-tuning technique that reduces PII memorization while
        minimizing performance impact. Using the Enron Email Dataset, we demonstra"
      relevanceScore: 50
      topics:
        - language-models
        - privacy
        - safety
        - memorization
      entities:
        - language-models
    - title: Multi-Channel Replay Speech Detection using Acoustic Maps
      url: https://arxiv.org/abs/2602.16399
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16399v1 Announce Type: cross Abstract: Replay attacks remain a critical vulnerability for automatic
        speaker verification systems, particularly in real-time voice assistant applications. In this work, we propose
        acoustic maps as a novel spatial feature representation for replay speech detection from multi-channel
        recordings. Derived from classical beamforming over discrete azimuth and elevation grids, acoustic maps encode
        directional energy distributions that reflect physical differenc"
      relevanceScore: 50
      topics:
        - misuse-risks
        - security
      entities:
        - misuse-risks
    - title: "GEPC: Group-Equivariant Posterior Consistency for Out-of-Distribution Detection in Diffusion Models"
      url: https://arxiv.org/abs/2602.00191
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.00191v2 Announce Type: replace Abstract: Diffusion models learn a time-indexed score field
        $\\mathbf{s}_\\theta(\\mathbf{x}_t,t)$ that often inherits approximate equivariances (flips, rotations, circular
        shifts) from in-distribution (ID) data and convolutional backbones. Most diffusion-based out-of-distribution
        (OOD) detectors exploit score magnitude or local geometry (energies, curvature, covariance spectra) and largely
        ignore equivariances. We introduce Group-Equivariant Posterior Cons"
      relevanceScore: 50
      topics:
        - out-of-distribution-detection
        - diffusion-models
        - robustness
      entities:
        - safety-research
        - accident-risks
    - title: "Quant VideoGen: Auto-Regressive Long Video Generation via 2-Bit KV-Cache Quantization"
      url: https://arxiv.org/abs/2602.02958
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.02958v2 Announce Type: replace Abstract: Despite rapid progress in autoregressive video diffusion,
        an emerging system algorithm bottleneck limits both deployability and generation capability: KV cache memory. In
        autoregressive video generation models, the KV cache grows with generation history and quickly dominates GPU
        memory, often exceeding 30 GB, preventing deployment on widely available hardware. More critically, constrained
        KV cache budgets restrict the effective working memory, "
      relevanceScore: 50
      topics:
        - video-generation
        - quantization
        - efficiency
        - scaling
      entities:
        - compute-hardware
        - capabilities
    - title: Strategic Hiring under Algorithmic Monoculture
      url: https://arxiv.org/abs/2502.20063
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: 'arXiv:2502.20063v2 Announce Type: replace-cross Abstract: We study the impact of strategic behavior in labor
        markets characterized by algorithmic monoculture, where firms compete for a shared pool of applicants using a
        common algorithmic evaluation. In this setting, "naive" hiring strategies lead to severe congestion, as firms
        collectively target the same high-scoring candidates. We model this competition as a game with
        capacity-constrained firms and fully characterize the set of Nash equilibria'
      relevanceScore: 50
      topics:
        - algorithmic-bias
        - labor-markets
        - ai-systems-impact
      entities:
        - automation-bias-cascade
    - title: "TimeOmni-1: Incentivizing Complex Reasoning with Time Series in Large Language Models"
      url: https://arxiv.org/abs/2509.24803
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2509.24803v2 Announce Type: replace Abstract: Recent advances in multimodal time series learning
        underscore a paradigm shift from analytics centered on basic patterns toward advanced time series understanding
        and reasoning. However, existing multimodal time series datasets mostly remain at the level of surface alignment
        and question answering, without reaching the depth of genuine reasoning. The absence of well-defined tasks that
        genuinely require time series reasoning, along with the scar"
      relevanceScore: 48
      topics:
        - reasoning
        - language-models
      entities:
        - reasoning
        - language-models
    - title: Vulnerability Analysis of Safe Reinforcement Learning via Inverse Constrained Reinforcement Learning
      url: https://arxiv.org/abs/2602.16543
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16543v1 Announce Type: new Abstract: Safe reinforcement learning (Safe RL) aims to ensure policy
        performance while satisfying safety constraints. However, most existing Safe RL methods assume benign
        environments, making them vulnerable to adversarial perturbations commonly encountered in real-world settings.
        In addition, existing gradient-based adversarial attacks typically require access to the policy's gradient
        information, which is often impractical in real-world scenarios. To addr"
      relevanceScore: 48
      topics:
        - safe-reinforcement-learning
        - safety
        - constraints
        - robustness
      entities:
        - safety-research
        - alignment-robustness-trajectory
    - title: Scaling social science research
      url: https://openai.com/index/scaling-social-science-research
      sourceId: openai-blog
      publishedAt: Fri, 13 Feb 2026 09:00:00 GMT
      summary: GABRIEL is a new open-source toolkit from OpenAI that uses GPT to turn qualitative text and images into
        quantitative data, helping social scientists analyze research at scale.
      relevanceScore: 45
      topics:
        - capabilities
        - scientific-research
        - tool-use
      entities:
        - scientific-research
        - tool-use
    - title: Snowflake and OpenAI partner to bring frontier intelligence to enterprise data
      url: https://openai.com/index/snowflake-partnership
      sourceId: openai-blog
      publishedAt: Mon, 02 Feb 2026 06:00:00 GMT
      summary: OpenAI and Snowflake partner in a $200M agreement to bring frontier intelligence into enterprise data, enabling
        AI agents and insights directly in Snowflake.
      relevanceScore: 45
      topics:
        - deployment
        - agentic-ai
        - economic-labor
      entities:
        - agentic-ai
        - economic-labor
    - title: The next chapter for AI in the EU
      url: https://openai.com/index/the-next-chapter-for-ai-in-the-eu
      sourceId: openai-blog
      publishedAt: Wed, 28 Jan 2026 01:00:00 GMT
      summary: OpenAI launches the EU Economic Blueprint 2.0 with new data, partnerships, and initiatives to accelerate AI
        adoption, skills, and growth across Europe.
      relevanceScore: 45
      topics:
        - geopolitics
        - regulation-debate
        - economic-labor
      entities:
        - geopolitics
        - regulation-debate
    - title: "Horizon 1000: Advancing AI for primary healthcare"
      url: https://openai.com/index/horizon-1000
      sourceId: openai-blog
      publishedAt: Tue, 20 Jan 2026 21:00:00 GMT
      summary: OpenAI and the Gates Foundation launch Horizon 1000, a $50M pilot advancing AI capabilities for healthcare in
        Africa. The initiative aims to reach 1,000 clinics by 2028.
      relevanceScore: 45
      topics:
        - capabilities
        - safety-research
        - geopolitics
      entities:
        - capabilities
        - geopolitics
    - title: OpenAI for Healthcare
      url: https://openai.com/index/openai-for-healthcare
      sourceId: openai-blog
      publishedAt: Thu, 08 Jan 2026 12:00:00 GMT
      summary: OpenAI for Healthcare enables secure, enterprise-grade AI that supports HIPAA compliance—reducing
        administrative burden and supporting clinical workflows.
      relevanceScore: 45
      topics:
        - safety-research
        - misuse-risks
      entities:
        - safety-research
    - title: AI literacy resources for teens and parents
      url: https://openai.com/index/ai-literacy-resources-for-teens-and-parents
      sourceId: openai-blog
      publishedAt: Thu, 18 Dec 2025 11:00:00 GMT
      summary: OpenAI shares new AI literacy resources to help teens and parents use ChatGPT thoughtfully, safely, and with
        confidence. The guides include expert-vetted tips for responsible use, critical thinking, healthy boundaries,
        and supporting teens through emotional or sensitive topics.
      relevanceScore: 45
      topics:
        - public-opinion
        - safety-research
      entities:
        - public-opinion
    - title: The state of enterprise AI
      url: https://openai.com/index/the-state-of-enterprise-ai-2025-report
      sourceId: openai-blog
      publishedAt: Mon, 08 Dec 2025 04:00:00 GMT
      summary: Key findings from OpenAI’s enterprise data show accelerating AI adoption, deeper integration, and measurable
        productivity gains across industries in 2025.
      relevanceScore: 45
      topics:
        - ai-acceleration-tradeoff
        - economic-labor
        - capabilities
      entities:
        - __index__/knowledge-base/metrics
    - title: Accenture and OpenAI accelerate enterprise AI success
      url: https://openai.com/index/accenture-partnership
      sourceId: openai-blog
      publishedAt: Mon, 01 Dec 2025 05:00:00 GMT
      summary: Accenture and OpenAI are collaborating to help enterprises bring agentic AI capabilities into the core of their
        business and unlock new levels of growth.
      relevanceScore: 45
      topics:
        - agentic-ai
        - economic-labor
        - ai-acceleration-tradeoff
      entities: []
    - title: Introducing OpenAI for Ireland
      url: https://openai.com/index/openai-for-ireland
      sourceId: openai-blog
      publishedAt: Fri, 14 Nov 2025 04:00:00 GMT
      summary: OpenAI launches OpenAI for Ireland, partnering with the Irish Government, Dogpatch Labs and Patch to help SMEs,
        founders and young builders use AI to innovate, boost productivity and build the next generation of Irish tech
        startups.
      relevanceScore: 45
      topics:
        - geopolitics
        - economic-labor
        - ai-acceleration-tradeoff
      entities: []
    - title: Fighting the New York Times’ invasion of user privacy
      url: https://openai.com/index/fighting-nyt-user-privacy-invasion
      sourceId: openai-blog
      publishedAt: Wed, 12 Nov 2025 06:00:00 GMT
      summary: OpenAI is fighting the New York Times’ demand for 20 million private ChatGPT conversations and accelerating new
        security and privacy protections to protect your data.
      relevanceScore: 45
      topics:
        - privacy
        - security
        - data-protection
      entities: []
    - title: Codex is now generally available
      url: https://openai.com/index/codex-now-generally-available
      sourceId: openai-blog
      publishedAt: Mon, 06 Oct 2025 10:50:00 GMT
      summary: "OpenAI Codex is now generally available with powerful new features for developers: a Slack integration, Codex
        SDK, and admin tools like usage dashboards and workspace management—making Codex easier to use and manage at
        scale."
      relevanceScore: 45
      topics:
        - capabilities
        - coding
        - tool-use
      entities:
        - coding
        - tool-use
    - title: Combating online child sexual exploitation & abuse
      url: https://openai.com/index/combating-online-child-sexual-exploitation-abuse
      sourceId: openai-blog
      publishedAt: Mon, 29 Sep 2025 03:00:00 GMT
      summary: Discover how OpenAI combats online child sexual exploitation and abuse with strict usage policies, advanced
        detection tools, and industry collaboration to block, report, and prevent AI misuse.
      relevanceScore: 45
      topics:
        - misuse-risks
        - safety-research
      entities: []
    - title: "Addendum to GPT-5 system card: GPT-5-Codex"
      url: https://openai.com/index/gpt-5-system-card-addendum-gpt-5-codex
      sourceId: openai-blog
      publishedAt: Mon, 15 Sep 2025 00:00:00 GMT
      summary: "This addendum to the GPT-5 system card shares a new model: GPT-5-Codex, a version of GPT-5 further optimized
        for agentic coding in Codex. GPT-5-Codex adjusts its thinking effort more dynamically based on task complexity,
        responding quickly to simple conversational queries or small tasks, while independently working for longer on
        more complex tasks."
      relevanceScore: 45
      topics:
        - agentic-ai
        - coding
        - capabilities
      entities:
        - agentic-ai
        - coding
        - capabilities
    - title: "A People-First AI Fund: $50M to support nonprofits"
      url: https://openai.com/index/people-first-ai-fund
      sourceId: openai-blog
      publishedAt: Mon, 08 Sep 2025 14:00:00 GMT
      summary: Applications are now open for OpenAI’s People-First AI Fund, a $50M initiative supporting U.S. nonprofits
        advancing education, community innovation, and economic opportunity. Apply by October 8, 2025, for unrestricted
        grants that help communities shape AI for the public good.
      relevanceScore: 45
      topics:
        - funding
        - nonprofit
        - education
      entities:
        - safety-research
    - title: Supporting nonprofit and community innovation
      url: https://openai.com/index/supporting-nonprofit-and-community-innovation
      sourceId: openai-blog
      publishedAt: Thu, 28 Aug 2025 05:00:00 GMT
      summary: OpenAI launches a $50M People-First AI Fund to help U.S. nonprofits scale impact with AI. Applications open
        Sept 8–Oct 8, 2025 for grants in education, healthcare, research, and more.
      relevanceScore: 45
      topics:
        - funding
        - nonprofit
        - impact
      entities:
        - safety-research
    - title: Announcing the OpenAI Learning Accelerator
      url: https://openai.com/global-affairs/learning-accelerator
      sourceId: openai-blog
      publishedAt: Mon, 25 Aug 2025 06:00:00 GMT
      summary: OpenAI announces the launch of OpenAI Learning Accelerator, an initiative that aims to bring advanced AI to
        India’s educators and millions of learners nationwide through accelerated AI research, training, and deployment.
      relevanceScore: 45
      topics:
        - education
        - AI-research
        - training
      entities:
        - safety-research
    - title: How Amgen uses GPT-5
      url: https://openai.com/index/gpt-5-amgen
      sourceId: openai-blog
      publishedAt: Thu, 07 Aug 2025 00:00:00 GMT
      summary: Learn how Amgen uses GPT-5.
      relevanceScore: 45
      topics:
        - capabilities
        - enterprise-use
      entities:
        - capabilities
    - title: How Cursor uses GPT-5
      url: https://openai.com/index/gpt-5-cursor
      sourceId: openai-blog
      publishedAt: Thu, 07 Aug 2025 00:00:00 GMT
      summary: Learn how Cursor uses GPT-5.
      relevanceScore: 45
      topics:
        - language-models
        - tool-use
        - capabilities
      entities:
        - language-models
    - title: OpenAI’s new economic analysis
      url: https://openai.com/global-affairs/new-economic-analysis
      sourceId: openai-blog
      publishedAt: Tue, 22 Jul 2025 00:00:00 GMT
      summary: Analysis provides insights into ChatGPT’s impact on the economy. OpenAI also launches new research
        collaboration to study AI’s broader effects on the labor market and productivity.
      relevanceScore: 45
      topics:
        - economic-labor
        - capabilities
        - metrics
      entities:
        - economic-labor
        - metrics
    - title: No-code personal agents, powered by GPT-4.1 and Realtime API
      url: https://openai.com/index/genspark
      sourceId: openai-blog
      publishedAt: Tue, 01 Jul 2025 10:00:00 GMT
      summary: Learn how Genspark built a $36M ARR AI product in 45 days—with no-code agents powered by GPT-4.1 and OpenAI
        Realtime API.
      relevanceScore: 45
      topics:
        - agentic-ai
        - tool-use
        - capabilities
      entities:
        - agentic-ai
        - tool-use
        - capabilities
    - title: New tools and features in the Responses API
      url: https://openai.com/index/new-tools-and-features-in-the-responses-api
      sourceId: openai-blog
      publishedAt: Wed, 21 May 2025 08:00:00 GMT
      summary: "New features in the Responses API: Remote MCP, image gen, Code Interpreter, and more. Powering faster, smarter
        agents with GPT-4o & o-series models, plus new features for reliability and efficiency."
      relevanceScore: 45
      topics:
        - agentic-ai
        - tool-use
        - capabilities
      entities:
        - agentic-ai
        - tool-use
    - title: Introducing OpenAI for Countries
      url: https://openai.com/global-affairs/openai-for-countries
      sourceId: openai-blog
      publishedAt: Wed, 07 May 2025 03:00:00 GMT
      summary: A new initiative to support countries around the world that want to build on democratic AI rails.
      relevanceScore: 45
      topics:
        - governance
        - geopolitics
        - regulation-debate
      entities:
        - governance
        - geopolitics
        - regulation-debate
    - title: Leadership updates
      url: https://openai.com/index/leadership-updates-march-2025
      sourceId: openai-blog
      publishedAt: Mon, 24 Mar 2025 10:00:00 GMT
      summary: OpenAI has grown a lot. We remain focused on the same core—pursuing frontier AI research that accelerates human
        progress–but we now also deliver products used by hundreds of millions of people.
      relevanceScore: 45
      topics:
        - lab-behavior
        - organizational-structure
      entities:
        - lab-behavior
    - title: New tools for building agents
      url: https://openai.com/index/new-tools-for-building-agents
      sourceId: openai-blog
      publishedAt: Tue, 11 Mar 2025 10:00:00 GMT
      summary: We’re evolving our platform to help developers and enterprises build useful and reliable agents.
      relevanceScore: 45
      topics:
        - agentic-ai
        - tool-use
        - capabilities
      entities:
        - agentic-ai
        - tool-use
    - title: OpenAI at the Paris AI Action Summit
      url: https://openai.com/global-affairs/openai-at-the-paris-ai-action-summit
      sourceId: openai-blog
      publishedAt: Fri, 07 Feb 2025 17:00:00 GMT
      summary: OpenAI looks forward to engaging with global leaders on AI’s role in shaping innovation and economic prosperity.
      relevanceScore: 45
      topics:
        - geopolitics
        - regulation-debate
        - public-opinion
      entities:
        - international-coordination-game
    - title: Dr. Ronnie Chatterji named OpenAI’s first Chief Economist
      url: https://openai.com/global-affairs/openai-chief-economist-announcement
      sourceId: openai-blog
      publishedAt: Tue, 22 Oct 2024 10:05:00 GMT
      summary: Dr. Ronnie Chatterji named OpenAI’s first Chief Economist
      relevanceScore: 45
      topics:
        - lab-behavior
        - governance
      entities:
        - lab-behavior
    - title: Creating agent and human collaboration with GPT 4o
      url: https://openai.com/index/altera
      sourceId: openai-blog
      publishedAt: Tue, 01 Oct 2024 09:59:00 GMT
      summary: Altera uses GPT-4o to build a new area of human collaboration
      relevanceScore: 45
      topics:
        - agentic-ai
        - tool-use
        - human-ai-collaboration
      entities:
        - agentic-ai
        - tool-use
    - title: Coding with OpenAI o1
      url: https://openai.com/index/o1-coding
      sourceId: openai-blog
      publishedAt: Thu, 12 Sep 2024 00:00:00 GMT
      summary: Scott Wu, CEO and Co-Founder of Cognition, explains how OpenAI o1 makes coding decisions in a more human-like
        way.
      relevanceScore: 45
      topics:
        - coding
        - reasoning
        - capabilities
      entities:
        - coding
        - reasoning
        - capabilities
    - title: Achieving 10x growth with agentic sales prospecting
      url: https://openai.com/index/clay
      sourceId: openai-blog
      publishedAt: Tue, 18 Jun 2024 07:00:00 GMT
      summary: ""
      relevanceScore: 45
      topics:
        - agentic-ai
        - tool-use
        - capabilities
      entities:
        - agentic-ai
        - tool-use
    - title: Introducing more enterprise-grade features for API customers
      url: https://openai.com/index/more-enterprise-grade-features-for-api-customers
      sourceId: openai-blog
      publishedAt: Tue, 23 Apr 2024 00:00:00 GMT
      summary: Increasing enterprise support with more security features and controls, updates to our Assistants API, and
        tools to better manage costs.
      relevanceScore: 45
      topics:
        - deployment
        - safety-research
        - structural
      entities:
        - structural
    - title: OpenAI Data Partnerships
      url: https://openai.com/index/data-partnerships
      sourceId: openai-blog
      publishedAt: Thu, 09 Nov 2023 08:00:00 GMT
      summary: Working together to create open-source and private datasets for AI training.
      relevanceScore: 45
      topics:
        - capabilities
        - lab-behavior
      entities:
        - capabilities
        - lab-behavior
    - title: DALL·E 3 system card
      url: https://openai.com/index/dall-e-3-system-card
      sourceId: openai-blog
      publishedAt: Tue, 03 Oct 2023 07:00:00 GMT
      summary: ""
      relevanceScore: 45
      topics:
        - capabilities
        - safety-research
      entities:
        - language-models
    - title: Efficient training of language models to fill in the middle
      url: https://openai.com/index/efficient-training-of-language-models-to-fill-in-the-middle
      sourceId: openai-blog
      publishedAt: Thu, 28 Jul 2022 07:00:00 GMT
      summary: ""
      relevanceScore: 45
      topics:
        - capabilities
        - language-models
        - compute-hardware
      entities:
        - language-models
    - title: "New GPT-3 capabilities: Edit & insert"
      url: https://openai.com/index/gpt-3-edit-insert
      sourceId: openai-blog
      publishedAt: Tue, 15 Mar 2022 07:00:00 GMT
      summary: We’ve released new versions of GPT-3 and Codex which can edit or insert content into existing text, rather than
        just completing existing text.
      relevanceScore: 45
      topics:
        - capabilities
        - language-models
        - coding
      entities:
        - language-models
        - coding
    - title: Customizing GPT-3 for your application
      url: https://openai.com/index/customizing-gpt-3
      sourceId: openai-blog
      publishedAt: Tue, 14 Dec 2021 08:00:00 GMT
      summary: Fine-tune with a single command.
      relevanceScore: 45
      topics:
        - language-models
        - capabilities
        - deployment
      entities:
        - language-models
    - title: "OpenAI Scholars 2021: Final projects"
      url: https://openai.com/index/openai-scholars-2021-final-projects
      sourceId: openai-blog
      publishedAt: Mon, 10 May 2021 07:00:00 GMT
      summary: We’re proud to announce that the 2021 class of OpenAI Scholars has completed our six-month mentorship program
        and have produced an open-source research project with stipends and support from OpenAI.
      relevanceScore: 45
      topics:
        - ai-talent-market-dynamics
        - lab-behavior
      entities:
        - ai-talent-market-dynamics
    - title: "DALL·E: Creating images from text"
      url: https://openai.com/index/dall-e
      sourceId: openai-blog
      publishedAt: Tue, 05 Jan 2021 08:00:00 GMT
      summary: We’ve trained a neural network called DALL·E that creates images from text captions for a wide range of
        concepts expressible in natural language.
      relevanceScore: 45
      topics:
        - capabilities
        - language-models
      entities:
        - language-models
    - title: OpenAI licenses GPT-3 technology to Microsoft
      url: https://openai.com/index/openai-licenses-gpt-3-technology-to-microsoft
      sourceId: openai-blog
      publishedAt: Tue, 22 Sep 2020 07:00:00 GMT
      summary: OpenAI has agreed to license GPT-3 to Microsoft for their own products and services.
      relevanceScore: 45
      topics:
        - deployment
        - lab-behavior
      entities:
        - lab-behavior
    - title: Image GPT
      url: https://openai.com/index/image-gpt
      sourceId: openai-blog
      publishedAt: Wed, 17 Jun 2020 07:00:00 GMT
      summary: We find that, just as a large transformer model trained on language can generate coherent text, the same exact
        model trained on pixel sequences can generate coherent image completions and samples. By establishing a
        correlation between sample quality and image classification accuracy, we show that our best generative model
        also contains features competitive with top convolutional nets in the unsupervised setting.
      relevanceScore: 45
      topics:
        - capabilities
        - world-models
      entities:
        - world-models
    - title: Solving Rubik’s Cube with a robot hand
      url: https://openai.com/index/solving-rubiks-cube
      sourceId: openai-blog
      publishedAt: Tue, 15 Oct 2019 07:00:00 GMT
      summary: We’ve trained a pair of neural networks to solve the Rubik’s Cube with a human-like robot hand. The neural
        networks are trained entirely in simulation, using the same reinforcement learning code as OpenAI Five paired
        with a new technique called Automatic Domain Randomization (ADR). The system can handle situations it never saw
        during training, such as being prodded by a stuffed giraffe. This shows that reinforcement learning isn’t just a
        tool for virtual tasks, but can solve physical-world probl
      relevanceScore: 45
      topics:
        - reinforcement-learning
        - robotics
        - capabilities
      entities:
        - capabilities
    - title: Implicit generation and generalization methods for energy-based models
      url: https://openai.com/index/energy-based-models
      sourceId: openai-blog
      publishedAt: Thu, 21 Mar 2019 07:00:00 GMT
      summary: We’ve made progress towards stable and scalable training of energy-based models (EBMs) resulting in better
        sample quality and generalization ability than existing models. Generation in EBMs spends more compute to
        continually refine its answers and doing so can generate samples competitive with GANs at low temperatures,
        while also having mode coverage guarantees of likelihood-based models. We hope these findings stimulate further
        research into this promising class of models.
      relevanceScore: 45
      topics:
        - generative-models
        - capabilities
      entities:
        - capabilities
    - title: "Spinning Up in Deep RL: Workshop review"
      url: https://openai.com/index/spinning-up-in-deep-rl-workshop-review
      sourceId: openai-blog
      publishedAt: Tue, 26 Feb 2019 08:00:00 GMT
      summary: On February 2, we held our first Spinning Up Workshop as part of our new education initiative at OpenAI.
      relevanceScore: 45
      topics:
        - education
        - reinforcement-learning
        - training
      entities: []
    - title: Gym Retro
      url: https://openai.com/index/gym-retro
      sourceId: openai-blog
      publishedAt: Fri, 25 May 2018 07:00:00 GMT
      summary: We’re releasing the full version of Gym Retro, a platform for reinforcement learning research on games. This
        brings our publicly-released game count from around 70 Atari games and 30 Sega games to over 1,000 games across
        a variety of backing emulators. We’re also releasing the tool we use to add new games to the platform.
      relevanceScore: 45
      topics:
        - capabilities
        - tool-use
      entities:
        - capabilities
    - title: "Gotta Learn Fast: A new benchmark for generalization in RL"
      url: https://openai.com/index/gotta-learn-fast
      sourceId: openai-blog
      publishedAt: Tue, 10 Apr 2018 07:00:00 GMT
      summary: ""
      relevanceScore: 45
      topics:
        - capabilities
        - reasoning
      entities:
        - capabilities
    - title: "Multi-Goal Reinforcement Learning: Challenging robotics environments and request for research"
      url: https://openai.com/index/multi-goal-reinforcement-learning
      sourceId: openai-blog
      publishedAt: Mon, 26 Feb 2018 08:00:00 GMT
      summary: ""
      relevanceScore: 45
      topics:
        - capabilities
        - tool-use
      entities:
        - capabilities
    - title: Ingredients for robotics research
      url: https://openai.com/index/ingredients-for-robotics-research
      sourceId: openai-blog
      publishedAt: Mon, 26 Feb 2018 08:00:00 GMT
      summary: We’re releasing eight simulated robotics environments and a Baselines implementation of Hindsight Experience
        Replay, all developed for our research over the past year. We’ve used these environments to train models which
        work on physical robots. We’re also releasing a set of requests for robotics research.
      relevanceScore: 45
      topics:
        - capabilities
        - tool-use
      entities:
        - capabilities
    - title: Learning sparse neural networks through L₀ regularization
      url: https://openai.com/index/learning-sparse-neural-networks-through-l0-regularization
      sourceId: openai-blog
      publishedAt: Mon, 04 Dec 2017 08:00:00 GMT
      summary: ""
      relevanceScore: 45
      topics:
        - capabilities
      entities:
        - capabilities
    - title: Learning a hierarchy
      url: https://openai.com/index/learning-a-hierarchy
      sourceId: openai-blog
      publishedAt: Thu, 26 Oct 2017 07:00:00 GMT
      summary: We’ve developed a hierarchical reinforcement learning algorithm that learns high-level actions useful for
        solving a range of tasks, allowing fast solving of tasks requiring thousands of timesteps. Our algorithm, when
        applied to a set of navigation problems, discovers a set of high-level actions for walking and crawling in
        different directions, which enables the agent to master new navigation tasks quickly.
      relevanceScore: 45
      topics:
        - capabilities
        - reasoning
      entities:
        - capabilities
    - title: Sim-to-real transfer of robotic control with dynamics randomization
      url: https://openai.com/index/sim-to-real-transfer-of-robotic-control-with-dynamics-randomization
      sourceId: openai-blog
      publishedAt: Wed, 18 Oct 2017 07:00:00 GMT
      summary: ""
      relevanceScore: 45
      topics:
        - reinforcement-learning
        - robotics
        - sim-to-real
        - capabilities
      entities:
        - tool-use
    - title: Proximal Policy Optimization
      url: https://openai.com/index/openai-baselines-ppo
      sourceId: openai-blog
      publishedAt: Thu, 20 Jul 2017 07:00:00 GMT
      summary: We’re releasing a new class of reinforcement learning algorithms, Proximal Policy Optimization (PPO), which
        perform comparably or better than state-of-the-art approaches while being much simpler to implement and tune.
        PPO has become the default reinforcement learning algorithm at OpenAI because of its ease of use and good
        performance.
      relevanceScore: 45
      topics:
        - reinforcement-learning
        - policy-optimization
        - algorithms
      entities: []
    - title: Unsupervised sentiment neuron
      url: https://openai.com/index/unsupervised-sentiment-neuron
      sourceId: openai-blog
      publishedAt: Thu, 06 Apr 2017 07:00:00 GMT
      summary: We’ve developed an unsupervised system which learns an excellent representation of sentiment, despite being
        trained only to predict the next character in the text of Amazon reviews.
      relevanceScore: 45
      topics:
        - unsupervised-learning
        - representation-learning
        - language-models
      entities:
        - language-models
    - title: One-shot imitation learning
      url: https://openai.com/index/one-shot-imitation-learning
      sourceId: openai-blog
      publishedAt: Tue, 21 Mar 2017 07:00:00 GMT
      summary: ""
      relevanceScore: 45
      topics:
        - imitation-learning
        - one-shot-learning
        - robotics
      entities:
        - tool-use
    - title: Learning to communicate
      url: https://openai.com/index/learning-to-communicate
      sourceId: openai-blog
      publishedAt: Thu, 16 Mar 2017 07:00:00 GMT
      summary: In this post we’ll outline new OpenAI research in which agents develop their own language.
      relevanceScore: 45
      topics:
        - agentic-ai
        - communication
        - multi-agent
      entities:
        - agentic-ai
    - title: Emergence of grounded compositional language in multi-agent populations
      url: https://openai.com/index/emergence-of-grounded-compositional-language-in-multi-agent-populations
      sourceId: openai-blog
      publishedAt: Wed, 15 Mar 2017 07:00:00 GMT
      summary: ""
      relevanceScore: 45
      topics:
        - agentic-ai
        - language
        - multi-agent
      entities:
        - agentic-ai
    - title: Universe
      url: https://openai.com/index/universe
      sourceId: openai-blog
      publishedAt: Mon, 05 Dec 2016 08:00:00 GMT
      summary: We’re releasing Universe, a software platform for measuring and training an AI’s general intelligence across
        the world’s supply of games, websites and other applications.
      relevanceScore: 45
      topics:
        - capabilities
        - benchmarking
      entities:
        - capabilities
    - title: "Gemini 3 Deep Think: Advancing science, research and engineering"
      url: https://deepmind.google/blog/gemini-3-deep-think-advancing-science-research-and-engineering/
      sourceId: deepmind-blog
      publishedAt: Thu, 12 Feb 2026 16:15:09 +0000
      summary: Our most specialized reasoning mode is now updated to solve modern science, research and engineering challenges.
      relevanceScore: 45
      topics:
        - reasoning
        - scientific-research
        - capabilities
      entities:
        - reasoning
        - scientific-research
    - title: Mapping, modeling, and understanding nature with AI
      url: https://deepmind.google/blog/mapping-modeling-and-understanding-nature-with-ai/
      sourceId: deepmind-blog
      publishedAt: Wed, 05 Nov 2025 16:59:46 +0000
      summary: AI models can help map species, protect forests and listen to birds around the world
      relevanceScore: 45
      topics:
        - capabilities
        - scientific-research
      entities:
        - capabilities
        - scientific-research
    - title: Exploring the context of online images with Backstory
      url: https://deepmind.google/blog/exploring-the-context-of-online-images-with-backstory/
      sourceId: deepmind-blog
      publishedAt: Fri, 24 Oct 2025 03:17:11 +0000
      summary: New experimental AI tool helps people explore the context and origin of images seen online.
      relevanceScore: 45
      topics:
        - capabilities
        - misuse-risks
      entities:
        - capabilities
        - misuse-risks
    - title: Bringing AI to the next generation of fusion energy
      url: https://deepmind.google/blog/bringing-ai-to-the-next-generation-of-fusion-energy/
      sourceId: deepmind-blog
      publishedAt: Thu, 23 Oct 2025 22:04:14 +0000
      summary: We’re partnering with Commonwealth Fusion Systems (CFS) to bring clean, safe, limitless fusion energy closer to
        reality.
      relevanceScore: 45
      topics:
        - capabilities
        - scientific-research
      entities:
        - capabilities
        - scientific-research
    - title: Experiment with Gemini 2.0 Flash native image generation
      url: https://deepmind.google/blog/experiment-with-gemini-20-flash-native-image-generation/
      sourceId: deepmind-blog
      publishedAt: Wed, 12 Mar 2025 14:58:00 +0000
      summary: Native image output is available in Gemini 2.0 Flash for developers to experiment with in Google AI Studio and
        the Gemini API.
      relevanceScore: 45
      topics:
        - generative-models
        - capabilities
      entities:
        - capabilities
    - title: Gemini 2.0 is now available to everyone
      url: https://deepmind.google/blog/gemini-2-0-is-now-available-to-everyone/
      sourceId: deepmind-blog
      publishedAt: Wed, 05 Feb 2025 16:00:00 +0000
      summary: We’re announcing new updates to Gemini 2.0 Flash, plus introducing Gemini 2.0 Flash-Lite and Gemini 2.0 Pro
        Experimental.
      relevanceScore: 45
      topics:
        - capabilities
        - language-models
        - large-language-models
      entities:
        - large-language-models
    - title: Our latest advances in robot dexterity
      url: https://deepmind.google/blog/advances-in-robot-dexterity/
      sourceId: deepmind-blog
      publishedAt: Thu, 12 Sep 2024 14:00:00 +0000
      summary: Two new AI systems, ALOHA Unleashed and DemoStart, help robots learn to perform complex tasks that require
        dexterous movement
      relevanceScore: 45
      topics:
        - agentic-ai
        - capabilities
        - tool-use
      entities:
        - agentic-ai
        - tool-use
    - title: With 10x Growth Since 2023, Llama Is the Leading Engine of AI Innovation
      url: https://ai.meta.com/blog/llama-usage-doubled-may-through-july-2024/
      sourceId: meta-ai-blog
      publishedAt: 2026-02-19
      summary: "  Highlights Llama's explosive growth, with models approaching 350 million downloads to date and over 20
        million downloads in a single month, cementing Llama as the leading open-source model family."
      relevanceScore: 45
      topics:
        - capabilities
        - language-models
        - lab-behavior
      entities:
        - language-models
        - lab-behavior
    - title: The Boundary of Self in Cooperative Reasoning
      url: https://forum.effectivealtruism.org/posts/GhiqCCBySWNFEmF7a/the-boundary-of-self-in-cooperative-reasoning
      sourceId: ea-forum
      publishedAt: Thu, 19 Feb 2026 00:34:32 GMT
      summary: "Published on February 19, 2026 12:34 AM GMTWhat these Thought Experiments DoCooperative dilemmas ordinarily
        leave these two reasoning patterns entangled, because they usually recommend the same action. The clone setup,
        and specifically Experiment B, is a controlled condition that separates them. It exposes a distinction that is
        real and consequential, but ordinarily concealed by surface agreement.Experiment AA rational agent is playing a
        one-shot prisoner's dilemma with their perfect clone: an e"
      relevanceScore: 45
      topics:
        - reasoning
        - alignment
        - cooperative-behavior
      entities:
        - reasoning
        - alignment-progress
    - title: "LWiAI Podcast #233 - Moltbot, Genie 3, Qwen3-Max-Thinking"
      url: https://lastweekin.ai/p/lwiai-podcast-233-moltbot-genie-3
      sourceId: last-week-in-ai
      publishedAt: Fri, 06 Feb 2026 05:06:04 GMT
      summary: Google adds Gemini AI-powered &#8216;auto browse&#8217; to Chrome, Users flock to open source Moltbot for
        always-on AI, Qwen3-Max-Thinking debuts, and more!
      relevanceScore: 45
      topics:
        - capabilities
        - language-models
        - tool-use
      entities:
        - language-models
        - agentic-ai
    - title: "Framework of Thoughts: A Foundation Framework for Dynamic and Optimized Reasoning based on Chains, Trees, and
        Graphs"
      url: https://arxiv.org/abs/2602.16512
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16512v1 Announce Type: new Abstract: Prompting schemes such as Chain of Thought, Tree of Thoughts,
        and Graph of Thoughts can significantly enhance the reasoning capabilities of large language models. However,
        most existing schemes require users to define static, problem-specific reasoning structures that lack
        adaptability to dynamic or unseen problem types. Additionally, these schemes are often under-optimized in terms
        of hyperparameters, prompts, runtime, and prompting cost. To addre"
      relevanceScore: 45
      topics:
        - reasoning
        - chain-of-thought
        - language-models
      entities:
        - reasoning
        - language-models
    - title: Kalman-Inspired Runtime Stability and Recovery in Hybrid Reasoning Systems
      url: https://arxiv.org/abs/2602.15855
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15855v1 Announce Type: cross Abstract: Hybrid reasoning systems that combine learned components
        with model-based inference are increasingly deployed in tool-augmented decision loops, yet their runtime
        behavior under partial observability and sustained evidence mismatch remains poorly understood. In practice,
        failures often arise as gradual divergence of internal reasoning dynamics rather than as isolated prediction
        errors. This work studies runtime stability in hybrid reasoning system"
      relevanceScore: 45
      topics:
        - reasoning
        - hybrid-systems
        - stability
        - reliability
      entities:
        - reasoning
        - agentic-ai
    - title: "FUTURE-VLA: Forecasting Unified Trajectories Under Real-time Execution"
      url: https://arxiv.org/abs/2602.15882
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15882v1 Announce Type: cross Abstract: General vision-language models increasingly support unified
        spatiotemporal reasoning over long video streams, yet deploying such capabilities on robots remains constrained
        by the prohibitive latency of processing long-horizon histories and generating high-dimensional future
        predictions. To bridge this gap, we present FUTURE-VLA, a unified architecture that reformulates long-horizon
        control and future forecasting as a monolithic sequence-generatio"
      relevanceScore: 45
      topics:
        - robotics
        - vision-language-models
        - long-horizon
        - tool-use
      entities:
        - long-horizon
        - tool-use
    - title: "AI-CARE: Carbon-Aware Reporting Evaluation Metric for AI Models"
      url: https://arxiv.org/abs/2602.16042
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16042v1 Announce Type: cross Abstract: As machine learning (ML) continues its rapid expansion, the
        environmental cost of model training and inference has become a critical societal concern. Existing benchmarks
        overwhelmingly focus on standard performance metrics such as accuracy, BLEU, or mAP, while largely ignoring
        energy consumption and carbon emissions. This single-objective evaluation paradigm is increasingly misaligned
        with the practical requirements of large-scale deployment, pa"
      relevanceScore: 45
      topics:
        - safety-research
        - environmental-impact
        - compute-hardware
        - structural
      entities:
        - safety-research
        - compute-hardware
        - structural
    - title: Updating Parametric Knowledge with Context Distillation Retains Post-Training Capabilities
      url: https://arxiv.org/abs/2602.16093
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16093v1 Announce Type: cross Abstract: Post-training endows pretrained LLMs with a variety of
        desirable skills, including instruction-following, reasoning, and others. However, these post-trained LLMs only
        encode knowledge up to a cut-off date, necessitating continual adaptation. Unfortunately, existing solutions
        cannot simultaneously learn new knowledge from an adaptation document corpora and mitigate the forgetting of
        earlier learned capabilities. To address this, we introduce Disti"
      relevanceScore: 45
      topics:
        - language-models
        - post-training
        - capabilities
      entities:
        - language-models
        - capabilities
    - title: "The Weight of a Bit: EMFI Sensitivity Analysis of Embedded Deep Learning Models"
      url: https://arxiv.org/abs/2602.16309
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16309v1 Announce Type: cross Abstract: Fault injection attacks on embedded neural network models
        have been shown as a potent threat. Numerous works studied resilience of models from various points of view. As
        of now, there is no comprehensive study that would evaluate the influence of number representations used for
        model parameters against electromagnetic fault injection (EMFI) attacks. In this paper, we investigate how four
        different number representations influence the success of a"
      relevanceScore: 45
      topics:
        - safety-research
        - misuse-risks
      entities:
        - safety-research
        - misuse-risks
    - title: "RoboGene: Boosting VLA Pre-training via Diversity-Driven Agentic Framework for Real-World Task Generation"
      url: https://arxiv.org/abs/2602.16444
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16444v1 Announce Type: cross Abstract: The pursuit of general-purpose robotic manipulation is
        hindered by the scarcity of diverse, real-world interaction data. Unlike data collection from web in vision or
        language, robotic data collection is an active process incurring prohibitive physical costs. Consequently,
        automated task curation to maximize data value remains a critical yet under-explored challenge. Existing manual
        methods are unscalable and biased toward common tasks, while off-"
      relevanceScore: 45
      topics:
        - agentic-ai
        - capabilities
        - tool-use
      entities:
        - agentic-ai
        - capabilities
        - tool-use
    - title: "MerLean: An Agentic Framework for Autoformalization in Quantum Computation"
      url: https://arxiv.org/abs/2602.16554
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16554v1 Announce Type: cross Abstract: We introduce MerLean, a fully automated agentic framework
        for autoformalization in quantum computation. MerLean extracts mathematical statements from \\LaTeX{} source
        files, formalizes them into verified Lean~4 code built on Mathlib, and translates the result back into
        human-readable \\LaTeX{} for semantic review. We evaluate MerLean on three theoretical quantum computing papers
        producing 2,050 Lean declarations from 114 statements in total. MerLea"
      relevanceScore: 45
      topics:
        - agentic-ai
        - scientific-research
      entities:
        - agentic-ai
        - scientific-research
    - title: "SurgRAW: Multi-Agent Workflow with Chain of Thought Reasoning for Robotic Surgical Video Analysis"
      url: https://arxiv.org/abs/2503.10265
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2503.10265v2 Announce Type: replace Abstract: Robotic-assisted surgery (RAS) is central to modern
        surgery, driving the need for intelligent systems with accurate scene understanding. Most existing surgical AI
        methods rely on isolated, task-specific models, leading to fragmented pipelines with limited interpretability
        and no unified understanding of RAS scene. Vision-Language Models (VLMs) offer strong zero-shot reasoning, but
        struggle with hallucinations, domain gaps and weak task-interdep"
      relevanceScore: 45
      topics:
        - agentic-ai
        - tool-use
      entities:
        - agentic-ai
        - tool-use
    - title: Understanding Transformer Optimization via Gradient Heterogeneity
      url: https://arxiv.org/abs/2502.00213
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2502.00213v4 Announce Type: replace-cross Abstract: Transformers are difficult to optimize with
        stochastic gradient descent (SGD) and largely rely on adaptive optimizers such as Adam. Despite their empirical
        success, the reasons behind Adam's superior performance over SGD remain poorly understood. In this study, we
        analyze the optimization of Transformer models through the lens of \\emph{gradient heterogeneity}, defined as
        the variation in gradient norms across parameter blocks. We provide "
      relevanceScore: 45
      topics:
        - optimization
        - transformers
        - training
      entities:
        - language-models
    - title: "Chain of Thought in Order: Discovering Learning-Friendly Orders for Arithmetic"
      url: https://arxiv.org/abs/2506.23875
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2506.23875v3 Announce Type: replace-cross Abstract: The chain of thought, i.e., step-by-step reasoning,
        is one of the fundamental mechanisms of Transformers. While the design of intermediate reasoning steps has been
        extensively studied and shown to critically influence performance on mathematical, multi-step reasoning tasks,
        the ordering of these steps has received little attention, despite its significant effect on the difficulty of
        reasoning. This study addresses a novel task of unraveli"
      relevanceScore: 45
      topics:
        - reasoning
        - chain-of-thought
        - transformers
      entities:
        - reasoning
    - title: "MedReasoner: Reinforcement Learning Drives Reasoning Grounding from Clinical Thought to Pixel-Level Precision"
      url: https://arxiv.org/abs/2508.08177
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2508.08177v3 Announce Type: replace-cross Abstract: Accurately grounding regions of interest (ROIs) is
        critical for diagnosis and treatment planning in medical imaging. While multimodal large language models (MLLMs)
        combine visual perception with natural language, current medical-grounding pipelines still rely on supervised
        fine-tuning with explicit spatial hints, making them ill-equipped to handle the implicit queries common in
        clinical practice. This work makes three core contributions. "
      relevanceScore: 45
      topics:
        - reinforcement-learning
        - medical-reasoning
        - language-models
      entities:
        - language-models
    - title: "FeatBench: Towards More Realistic Evaluation of Feature-level Code Generation"
      url: https://arxiv.org/abs/2509.22237
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2509.22237v2 Announce Type: replace-cross Abstract: Evaluating Large Language Models (LLMs) on
        repository-level feature implementation is a critical frontier in software engineering. However, establishing a
        benchmark that faithfully mirrors realistic development scenarios remains a significant challenge. Existing
        feature-level benchmarks generally suffer from two primary limitations: unrealistic task inputs enriched with
        code hints and significant data leakage risks due to their static nat"
      relevanceScore: 45
      topics:
        - code-generation
        - language-models
        - evaluation
      entities:
        - language-models
        - coding
    - title: "Mixture-of-Experts as Soft Clustering: A Dual Jacobian-PCA Spectral Geometry Perspective"
      url: https://arxiv.org/abs/2601.11616
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2601.11616v2 Announce Type: replace-cross Abstract: Mixture-of-Experts (MoE) architectures are widely
        used for efficiency and conditional computation, but their effect on the geometry of learned functions and
        representations remains poorly understood. We study MoEs through a geometric lens, interpreting routing as soft
        partitioning into overlapping expert-local charts. We introduce a Dual Jacobian-PCA spectral probe that analyzes
        local function geometry via Jacobian singular value spectra "
      relevanceScore: 45
      topics:
        - mixture-of-experts
        - model-architecture
        - efficiency
      entities:
        - sparse-moe
        - architecture-scenarios-table
    - title: "VIRENA: Virtual Arena for Research, Education, and Democratic Innovation"
      url: https://arxiv.org/abs/2602.12207
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.12207v2 Announce Type: replace-cross Abstract: Digital platforms shape how people communicate,
        deliberate, and form opinions. Studying these dynamics has become increasingly difficult due to restricted data
        access, ethical constraints on real-world experiments, and limitations of existing research tools. VIRENA
        (Virtual Arena) is a platform that enables controlled experimentation in realistic social media environments.
        Multiple participants interact simultaneously in realistic replica"
      relevanceScore: 45
      topics:
        - ai-systems
        - social-impact
        - disinformation
        - epistemic-risks
      entities:
        - epistemic-risks
        - disinformation-detection-race
    - title: "Multi-source Heterogeneous Public Opinion Analysis via Collaborative Reasoning and Adaptive Fusion: A
        Systematically Integrated Approach"
      url: https://arxiv.org/abs/2602.15857
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15857v1 Announce Type: new Abstract: The analysis of public opinion from multiple heterogeneous
        sources presents significant challenges due to structural differences, semantic variations, and
        platform-specific biases. This paper introduces a novel Collaborative Reasoning and Adaptive Fusion (CRAF)
        framework that systematically integrates traditional feature-based methods with large language models (LLMs)
        through a structured multi-stage reasoning mechanism. Our approach features four "
      relevanceScore: 45
      topics:
        - public opinion
        - LLM analysis
        - misinformation
      entities:
        - language-models
        - public-opinion
    - title: "VDLM: Variable Diffusion LMs via Robust Latent-to-Text Rendering"
      url: https://arxiv.org/abs/2602.15870
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15870v1 Announce Type: new Abstract: Autoregressive language models decode left-to-right with
        irreversible commitments, limiting revision during multi-step reasoning. We propose \\textbf{VDLM}, a modular
        variable diffusion language model that separates semantic planning from text rendering. VDLM applies LLaDA-style
        masked diffusion over semantic variable embeddings to enable iterative refinement in latent space, then
        post-trains the planner with trajectory-aware optimization using embe"
      relevanceScore: 45
      topics:
        - language models
        - reasoning
        - decoding
      entities:
        - language-models
        - reasoning
    - title: LLMs Exhibit Significantly Lower Uncertainty in Creative Writing Than Professional Writers
      url: https://arxiv.org/abs/2602.16162
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16162v1 Announce Type: new Abstract: We argue that uncertainty is a key and understudied limitation
        of LLMs' performance in creative writing, which is often characterized as trite and clich\\'e-ridden. Literary
        theory identifies uncertainty as a necessary condition for creative expression, while current alignment
        strategies steer models away from uncertain outputs to ensure factuality and reduce hallucination. We formalize
        this tension by quantifying the \"uncertainty gap\" between human"
      relevanceScore: 45
      topics:
        - LLM limitations
        - uncertainty
        - creative tasks
      entities:
        - language-models
        - capabilities
    - title: "When Stereotypes GTG: The Impact of Predictive Text Suggestions on Gender Bias in Human-AI Co-Writing"
      url: https://arxiv.org/abs/2409.20390
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2409.20390v2 Announce Type: replace Abstract: AI-based systems such as language models have been shown
        to replicate and even amplify social biases reflected in their training data. Among other questionable
        behaviors, this can lead to AI-generated text--and text suggestions--that contain normatively inappropriate
        stereotypical associations. Little is known, however, about how this behavior impacts the writing produced by
        people using these systems. We address this gap by measuring how much "
      relevanceScore: 45
      topics:
        - language-models
        - bias
        - safety
        - alignment
      entities:
        - language-models
    - title: Differentially Private Non-convex Distributionally Robust Optimization
      url: https://arxiv.org/abs/2602.16155
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16155v1 Announce Type: new Abstract: Real-world deployments routinely face distribution shifts,
        group imbalances, and adversarial perturbations, under which the traditional Empirical Risk Minimization (ERM)
        framework can degrade severely. Distributionally Robust Optimization (DRO) addresses this issue by optimizing
        the worst-case expected loss over an uncertainty set of distributions, offering a principled approach to
        robustness. Meanwhile, as training data in DRO always involves sens"
      relevanceScore: 45
      topics:
        - differential-privacy
        - robustness
        - adversarial-perturbations
      entities:
        - misuse-risks
    - title: Easy Data Unlearning Bench
      url: https://arxiv.org/abs/2602.16400
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16400v1 Announce Type: new Abstract: Evaluating machine unlearning methods remains technically
        challenging, with recent benchmarks requiring complex setups and significant engineering overhead. We introduce
        a unified and extensible benchmarking suite that simplifies the evaluation of unlearning algorithms using the
        KLoM (KL divergence of Margins) metric. Our framework provides precomputed model ensembles, oracle outputs, and
        streamlined infrastructure for running evaluations out of th"
      relevanceScore: 45
      topics:
        - machine-unlearning
        - privacy
        - safety
        - benchmarking
      entities:
        - safety-research
    - title: Visual Memory Injection Attacks for Multi-Turn Conversations
      url: https://arxiv.org/abs/2602.15927
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15927v1 Announce Type: cross Abstract: Generative large vision-language models (LVLMs) have
        recently achieved impressive performance gains, and their user base is growing rapidly. However, the security of
        LVLMs, in particular in a long-context multi-turn setting, is largely underexplored. In this paper, we consider
        the realistic scenario in which an attacker uploads a manipulated image to the web/social media. A benign user
        downloads this image and uses it as input to the LVLM. Our no"
      relevanceScore: 45
      topics:
        - vision-language-models
        - adversarial-attacks
        - security
        - robustness
      entities:
        - misuse-risks
        - language-models
    - title: Benchmarking Stochastic Approximation Algorithms for Fairness-Constrained Training of Deep Neural Networks
      url: https://arxiv.org/abs/2507.04033
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2507.04033v2 Announce Type: replace Abstract: The ability to train Deep Neural Networks (DNNs) with
        constraints is instrumental in improving the fairness of modern machine-learning models. Many algorithms have
        been analysed in recent years, and yet there is no standard, widely accepted method for the constrained training
        of DNNs. In this paper, we provide a challenging benchmark of real-world large-scale fairness-constrained
        learning tasks, built on top of the US Census (Folktables). We po"
      relevanceScore: 45
      topics:
        - fairness
        - deep-learning
        - constraints
      entities:
        - safety-research
    - title: Feature salience -- not task-informativeness -- drives machine learning model explanations
      url: https://arxiv.org/abs/2602.09238
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.09238v3 Announce Type: replace Abstract: Explainable AI (XAI) promises to provide insight into
        machine learning models' decision processes, where one goal is to identify failures such as shortcut learning.
        This promise relies on the field's assumption that input features marked as important by an XAI must contain
        information about the target variable. However, it is unclear whether informativeness is indeed the main driver
        of importance attribution in practice, or if other data proper"
      relevanceScore: 45
      topics:
        - interpretability
        - explainable-ai
        - model-failures
      entities:
        - interpretability-sufficient
    - title: "From Collapse to Improvement: Statistical Perspectives on the Evolutionary Dynamics of Iterative Training on
        Contaminated Sources"
      url: https://arxiv.org/abs/2602.10531
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.10531v2 Announce Type: replace-cross Abstract: The problem of model collapse has presented new
        challenges in iterative training of generative models, where such training with synthetic data leads to an
        overall degradation of performance. This paper looks at the problem from a statistical viewpoint, illustrating
        that one can actually hope for improvement when models are trained on data contaminated with synthetic samples,
        as long as there is some amount of fresh information from the tr"
      relevanceScore: 45
      topics:
        - generative-models
        - model-collapse
        - synthetic-data
        - training-dynamics
      entities: []
    - title: "BPP: Long-Context Robot Imitation Learning by Focusing on Key History Frames"
      url: https://arxiv.org/abs/2602.15010
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15010v2 Announce Type: replace-cross Abstract: Many robot tasks require attending to the history of
        past observations. For example, finding an item in a room requires remembering which places have already been
        searched. However, the best-performing robot policies typically condition only on the current observation,
        limiting their applicability to such tasks. Naively conditioning on past observations often fails due to
        spurious correlations: policies latch onto incidental features of t"
      relevanceScore: 45
      topics:
        - robot-learning
        - imitation-learning
        - long-context
        - tool-use
      entities:
        - __index__/knowledge-base/capabilities
        - agentic-ai
    - title: Sequential Membership Inference Attacks
      url: https://arxiv.org/abs/2602.16596
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16596v1 Announce Type: new Abstract: Modern AI models are not static. They go through multiple
        updates in their lifecycles. Thus, exploiting the model dynamics to create stronger Membership Inference (MI)
        attacks and tighter privacy audits are timely questions. Though the literature empirically shows that using a
        sequence of model updates can increase the power of MI attacks, rigorous analysis of the `optimal' MI attacks is
        limited to static models with infinite samples. Hence, we dev"
      relevanceScore: 42
      topics:
        - privacy
        - membership-inference
        - model-security
        - adversarial
      entities:
        - safety-research
    - title: "Beyond rate limits: scaling access to Codex and Sora"
      url: https://openai.com/index/beyond-rate-limits
      sourceId: openai-blog
      publishedAt: Fri, 13 Feb 2026 09:00:00 GMT
      summary: How OpenAI built a real-time access system combining rate limits, usage tracking, and credits to power
        continuous access to Sora and Codex.
      relevanceScore: 40
      topics:
        - deployment-architectures-table
        - capabilities
      entities:
        - deployment-architectures-table
    - title: Introducing Prism
      url: https://openai.com/index/introducing-prism
      sourceId: openai-blog
      publishedAt: Tue, 27 Jan 2026 00:00:00 GMT
      summary: Prism is a free LaTeX-native workspace with GPT-5.2 built in, helping researchers write, collaborate, and
        reason in one place.
      relevanceScore: 40
      topics:
        - capabilities
        - scientific-research
        - tool-use
      entities:
        - scientific-research
        - tool-use
    - title: Introducing Edu for Countries
      url: https://openai.com/index/edu-for-countries
      sourceId: openai-blog
      publishedAt: Wed, 21 Jan 2026 01:00:00 GMT
      summary: Edu for Countries is a new OpenAI initiative helping governments use AI to modernize education systems and
        build future-ready workforces.
      relevanceScore: 40
      topics:
        - geopolitics
        - agi-development
      entities:
        - geopolitics
        - agi-development
    - title: ServiceNow powers actionable enterprise AI with OpenAI
      url: https://openai.com/index/servicenow-powers-actionable-enterprise-ai-with-openai
      sourceId: openai-blog
      publishedAt: Tue, 20 Jan 2026 05:45:00 GMT
      summary: ServiceNow expands access to OpenAI frontier models to power AI-driven enterprise workflows, summarization,
        search, and voice across the ServiceNow Platform.
      relevanceScore: 40
      topics:
        - agentic-ai
        - capabilities
      entities:
        - agentic-ai
    - title: OpenAI’s Raising Concerns Policy
      url: https://openai.com/index/openai-raising-concerns-policy
      sourceId: openai-blog
      publishedAt: Mon, 12 Jan 2026 00:00:00 GMT
      summary: We’re publishing our Raising Concerns Policy, which protects employees’ rights to make protected disclosures.
      relevanceScore: 40
      topics:
        - lab-behavior
        - safety-research
      entities:
        - lab-behavior
    - title: Introducing ChatGPT Health
      url: https://openai.com/index/introducing-chatgpt-health
      sourceId: openai-blog
      publishedAt: Wed, 07 Jan 2026 00:00:00 GMT
      summary: ChatGPT Health is a dedicated experience that securely connects your health data and apps, with privacy
        protections and a physician-informed design.
      relevanceScore: 40
      topics:
        - safety-research
        - misuse-risks
      entities:
        - safety-research
    - title: BNY builds “AI for everyone, everywhere” with OpenAI
      url: https://openai.com/index/bny
      sourceId: openai-blog
      publishedAt: Fri, 12 Dec 2025 00:00:00 GMT
      summary: BNY is using OpenAI technology to expand AI adoption enterprise-wide. Through its Eliza platform, 20,000+
        employees are building AI agents that enhance efficiency and improve client outcomes.
      relevanceScore: 40
      topics:
        - agentic-ai
        - deployment
      entities:
        - agentic-ai
    - title: Ten years
      url: https://openai.com/index/ten-years
      sourceId: openai-blog
      publishedAt: Thu, 11 Dec 2025 00:00:00 GMT
      summary: OpenAI reflects on ten years of progress, from early research breakthroughs to widely used AI systems that
        reshaped what’s possible. We share lessons from the past decade and why we remain optimistic about building AGI
        that benefits all of humanity.
      relevanceScore: 40
      topics:
        - lab-behavior
        - expert-opinion
      entities:
        - lab-behavior
        - expert-opinion
    - title: Launching our first OpenAI Certifications courses
      url: https://openai.com/index/openai-certificate-courses
      sourceId: openai-blog
      publishedAt: Tue, 09 Dec 2025 06:00:00 GMT
      summary: Learn how OpenAI’s new certifications and AI Foundations courses help people build real-world AI skills, boost
        career opportunities, and prepare for the future of work.
      relevanceScore: 40
      topics:
        - public-opinion
        - safety-research
      entities:
        - public-opinion
        - safety-research
    - title: OpenAI takes an ownership stake in Thrive Holdings to accelerate enterprise AI adoption
      url: https://openai.com/index/thrive-holdings
      sourceId: openai-blog
      publishedAt: Mon, 01 Dec 2025 05:00:00 GMT
      summary: OpenAI takes an ownership stake in Thrive Holdings to accelerate enterprise AI adoption, embedding frontier
        research and engineering directly into accounting and IT services to boost speed, accuracy, and efficiency while
        creating a scalable model for industry-wide transformation.
      relevanceScore: 40
      topics:
        - agentic-ai
        - economic-labor
        - ai-acceleration-tradeoff
      entities: []
    - title: Our approach to mental health-related litigation
      url: https://openai.com/index/mental-health-litigation-approach
      sourceId: openai-blog
      publishedAt: Tue, 25 Nov 2025 12:00:00 GMT
      summary: We’re sharing our approach to mental health-related litigation. O handle sensitive cases with care,
        transparency, and respect while continuing to strengthen safety and support in ChatGPT.
      relevanceScore: 40
      topics:
        - epistemic-risks
        - structural-risks
      entities: []
    - title: A free version of ChatGPT built for teachers
      url: https://openai.com/index/chatgpt-for-teachers
      sourceId: openai-blog
      publishedAt: Wed, 19 Nov 2025 00:00:00 GMT
      summary: ChatGPT for Teachers is a secure workspace with education‑grade privacy and admin controls. Free for verified
        U.S. K–12 educators through June 2027.
      relevanceScore: 40
      topics:
        - safety-research
        - structural-risks
      entities: []
    - title: Intuit and OpenAI join forces on new AI-powered experiences
      url: https://openai.com/index/intuit-partnership
      sourceId: openai-blog
      publishedAt: Tue, 18 Nov 2025 05:00:00 GMT
      summary: OpenAI and Intuit have entered a $100M+ multi-year partnership to launch Intuit app experiences in ChatGPT and
        expand Intuit’s use of OpenAI’s frontier models to power personalized financial tools.
      relevanceScore: 40
      topics:
        - agentic-ai
        - tool-use
        - economic-labor
      entities: []
    - title: Introducing GPT-5.1 for developers
      url: https://openai.com/index/gpt-5-1-for-developers
      sourceId: openai-blog
      publishedAt: Thu, 13 Nov 2025 00:00:00 GMT
      summary: GPT-5.1 is now available in the API, bringing faster adaptive reasoning, extended prompt caching, improved
        coding performance, and new apply_patch and shell tools.
      relevanceScore: 40
      topics:
        - capabilities
        - language-models
        - coding
      entities:
        - language-models
        - coding
    - title: Consensus accelerates research with GPT-5 and Responses API
      url: https://openai.com/index/consensus
      sourceId: openai-blog
      publishedAt: Thu, 23 Oct 2025 09:00:00 GMT
      summary: Consensus uses GPT-5 and OpenAI’s Responses API to power a multi-agent research assistant that reads, analyzes,
        and synthesizes evidence in minutes—helping over 8 million researchers accelerate scientific discovery.
      relevanceScore: 40
      topics:
        - capabilities
        - scientific-research
        - agentic-ai
      entities:
        - agentic-ai
        - scientific-research
    - title: Introducing apps in ChatGPT and the new Apps SDK
      url: https://openai.com/index/introducing-apps-in-chatgpt
      sourceId: openai-blog
      publishedAt: Mon, 06 Oct 2025 10:00:00 GMT
      summary: We’re introducing a new generation of apps you can chat with, right inside ChatGPT. Developers can start
        building them today with the new Apps SDK, available in preview.
      relevanceScore: 40
      topics:
        - agentic-ai
        - tool-use
        - capabilities
      entities:
        - agentic-ai
        - tool-use
    - title: SAP and OpenAI partner to launch sovereign ‘OpenAI for Germany’
      url: https://openai.com/global-affairs/openai-for-germany
      sourceId: openai-blog
      publishedAt: Wed, 24 Sep 2025 04:00:00 GMT
      summary: SAP and OpenAI launch OpenAI for Germany, a 2026 partnership to bring secure, sovereign AI to Germany’s public
        sector, enabling safe, efficient public services.
      relevanceScore: 40
      topics:
        - geopolitics
        - regulation-debate
      entities:
        - regulation-debate
        - geopolitics
    - title: Creating a safe, observable AI infrastructure for 1 million classrooms
      url: https://openai.com/index/schoolai
      sourceId: openai-blog
      publishedAt: Mon, 22 Sep 2025 10:00:00 GMT
      summary: Discover how SchoolAI, built on OpenAI’s GPT-4.1, image generation, and TTS, powers safe, teacher-guided AI
        tools for 1 million classrooms worldwide—boosting engagement, oversight, and personalized learning.
      relevanceScore: 40
      topics:
        - safety-research
        - misuse-risks
      entities:
        - safety-research
    - title: Building towards age prediction
      url: https://openai.com/index/building-towards-age-prediction
      sourceId: openai-blog
      publishedAt: Tue, 16 Sep 2025 06:00:00 GMT
      summary: Learn how OpenAI is building age prediction and parental controls in ChatGPT to create safer, age-appropriate
        experiences for teens while supporting families with new tools.
      relevanceScore: 40
      topics:
        - safety-research
        - misuse-risks
      entities:
        - safety-research
    - title: Teen safety, freedom, and privacy
      url: https://openai.com/index/teen-safety-freedom-and-privacy
      sourceId: openai-blog
      publishedAt: Tue, 16 Sep 2025 06:00:00 GMT
      summary: Explore OpenAI’s approach to balancing teen safety, freedom, and privacy in AI use.
      relevanceScore: 40
      topics:
        - safety-research
        - misuse-risks
      entities:
        - safety-research
    - title: Expanding economic opportunity with AI
      url: https://openai.com/index/expanding-economic-opportunity-with-ai
      sourceId: openai-blog
      publishedAt: Thu, 04 Sep 2025 11:30:00 GMT
      summary: OpenAI is launching a Jobs Platform and new Certifications to connect workers with jobs, training, and
        certifications. Learn how we’re expanding economic opportunity and making AI skills more accessible.
      relevanceScore: 40
      topics:
        - economic-opportunity
        - jobs
        - training
      entities:
        - economic-labor
    - title: Creative writing with GPT-5
      url: https://openai.com/index/gpt-5-creative-writing
      sourceId: openai-blog
      publishedAt: Thu, 07 Aug 2025 00:02:00 GMT
      summary: Learn how GPT-5 assists with creative writing.
      relevanceScore: 40
      topics:
        - capabilities
        - creative-writing
      entities:
        - capabilities
    - title: First look at GPT-5
      url: https://openai.com/index/gpt-5-first-look
      sourceId: openai-blog
      publishedAt: Thu, 07 Aug 2025 00:00:00 GMT
      summary: See how a group of leading developers use GPT-5 for the first time.
      relevanceScore: 40
      topics:
        - capabilities
        - developer-experience
      entities:
        - capabilities
    - title: Resolving digital threats 100x faster with OpenAI
      url: https://openai.com/index/outtake
      sourceId: openai-blog
      publishedAt: Thu, 24 Jul 2025 00:00:00 GMT
      summary: Discover how Outtake uses GPT-4.1 and OpenAI o3 to power AI agents that detect and resolve digital threats 100x
        faster than before.
      relevanceScore: 40
      topics:
        - agentic-ai
        - tool-use
        - capabilities
      entities:
        - agentic-ai
        - tool-use
    - title: OpenAI and UK Government announce strategic partnership to deliver AI-driven growth
      url: https://openai.com/global-affairs/openai-and-uk-government-partnership
      sourceId: openai-blog
      publishedAt: Mon, 21 Jul 2025 10:00:00 GMT
      summary: OpenAI partners with the UK Government to boost AI adoption, drive economic growth, and enhance public services
        for a thriving AI ecosystem in the UK.
      relevanceScore: 40
      topics:
        - geopolitics
        - regulation-debate
      entities:
        - geopolitics
    - title: Customizable, no-code voice agent automation with GPT-4o
      url: https://openai.com/index/retell-ai
      sourceId: openai-blog
      publishedAt: Thu, 26 Jun 2025 10:00:00 GMT
      summary: Retell AI is transforming the call center with AI voice automation powered by GPT-4o and GPT-4.1. Its no-code
        platform enables businesses to launch natural, real-time voice agents that cut call costs, boost CSAT, and
        automate customer conversations—without scripts or hold times.
      relevanceScore: 40
      topics:
        - agentic-ai
        - tool-use
        - capabilities
      entities:
        - agentic-ai
        - tool-use
    - title: Driving scalable growth with OpenAI o3, GPT-4.1, and CUA
      url: https://openai.com/index/unify
      sourceId: openai-blog
      publishedAt: Tue, 24 Jun 2025 00:00:00 GMT
      summary: Unify, an AI-powered GTM platform, uses OpenAI’s o3, GPT-4.1, and CUA to automate prospecting, research, and
        outreach. With hyper-personalized messaging and an always-on workflow, Unify helps teams generate pipeline at
        scale while focusing on high-impact customer interactions.
      relevanceScore: 40
      topics:
        - agentic-ai
        - reasoning
        - capabilities
      entities:
        - agentic-ai
        - reasoning
    - title: How we’re responding to The New York Times’ data demands in order to protect user privacy
      url: https://openai.com/index/response-to-nyt-data-demands
      sourceId: openai-blog
      publishedAt: Thu, 05 Jun 2025 16:30:00 GMT
      summary: OpenAI is fighting a court order at the demands of The New York Times and plaintiffs, which involves retention
        of consumer ChatGPT and API user data indefinitely. Learn how we’re working to uphold user privacy, address
        legal requirements, and stay true to our data protection commitments.
      relevanceScore: 40
      topics:
        - governance
        - regulation-debate
        - structural
      entities:
        - regulation-debate
        - structural
    - title: Shipping code faster with o3, o4-mini, and GPT-4.1
      url: https://openai.com/index/coderabbit
      sourceId: openai-blog
      publishedAt: Thu, 22 May 2025 10:25:00 GMT
      summary: CodeRabbit uses OpenAI models to revolutionize code reviews—boosting accuracy, accelerating PR merges, and
        helping developers ship faster with fewer bugs and higher ROI.
      relevanceScore: 40
      topics:
        - coding
        - tool-use
        - capabilities
      entities:
        - coding
        - tool-use
    - title: Automating 90% of finance and legal work with agents
      url: https://openai.com/index/hebbia
      sourceId: openai-blog
      publishedAt: Tue, 25 Mar 2025 10:00:00 GMT
      summary: Hebbia’s deep research automates 90% of finance and legal work, powered by OpenAI
      relevanceScore: 40
      topics:
        - agentic-ai
        - automation
        - economic-impact
      entities:
        - agentic-ai
        - economic-labor
    - title: Introducing NextGenAI
      url: https://openai.com/index/introducing-nextgenai
      sourceId: openai-blog
      publishedAt: Tue, 04 Mar 2025 06:00:00 GMT
      summary: OpenAI commits $50M in funding and tools to leading institutions.
      relevanceScore: 40
      topics:
        - safety-research
        - agi-development
      entities:
        - safety-research
        - agi-development
    - title: Introducing data residency in Europe
      url: https://openai.com/index/introducing-data-residency-in-europe
      sourceId: openai-blog
      publishedAt: Wed, 05 Feb 2025 22:00:00 GMT
      summary: Data residency builds on OpenAI’s enterprise-grade data privacy, security, and compliance programs supporting
        customers worldwide.
      relevanceScore: 40
      topics:
        - regulation-debate
        - structural
      entities: []
    - title: Partnering with Axios expands OpenAI’s work with the news industry
      url: https://openai.com/index/partnering-with-axios-expands-openai-work-with-the-news-industry
      sourceId: openai-blog
      publishedAt: Wed, 15 Jan 2025 03:00:00 GMT
      summary: Publishers representing hundreds of newsrooms and content brands are using OpenAI partnerships and grant
        programs to adopt AI tools and strengthen the news ecosystem, while ChatGPT users gain access to information
        from leading, reliable publications.
      relevanceScore: 40
      topics:
        - public-opinion
        - economic-labor
      entities:
        - public-opinion
        - economic-labor
    - title: Building smarter maps with GPT-4o vision fine-tuning
      url: https://openai.com/index/grab
      sourceId: openai-blog
      publishedAt: Wed, 20 Nov 2024 17:00:00 GMT
      summary: Building smarter maps with GPT-4o vision fine-tuning
      relevanceScore: 40
      topics:
        - capabilities
        - vision-models
        - fine-tuning
      entities:
        - capabilities
    - title: New funding to scale the benefits of AI
      url: https://openai.com/index/scale-the-benefits-of-ai
      sourceId: openai-blog
      publishedAt: Wed, 02 Oct 2024 10:00:00 GMT
      summary: We are making progress on our mission to ensure that artificial general intelligence benefits all of humanity.
      relevanceScore: 40
      topics:
        - agi-development
        - capabilities
        - ai-megaproject-infrastructure
      entities:
        - agi-development
        - ai-megaproject-infrastructure
    - title: Model Distillation in the API
      url: https://openai.com/index/api-model-distillation
      sourceId: openai-blog
      publishedAt: Tue, 01 Oct 2024 10:02:00 GMT
      summary: Fine-tune a cost-efficient model with the outputs of a large frontier model–all on the OpenAI platform
      relevanceScore: 40
      topics:
        - capabilities
        - compute-hardware
      entities:
        - capabilities
        - compute-hardware
    - title: Answering quantum physics questions with OpenAI o1
      url: https://openai.com/index/o1-quantum-physics
      sourceId: openai-blog
      publishedAt: Thu, 12 Sep 2024 00:00:00 GMT
      summary: Quantum physicist Mario Krenn uses OpenAI o1 to help answer life's biggest questions.
      relevanceScore: 40
      topics:
        - reasoning
        - scientific-research
        - capabilities
      entities:
        - reasoning
        - scientific-research
        - capabilities
    - title: Decoding genetics with OpenAI o1
      url: https://openai.com/index/o1-genetics
      sourceId: openai-blog
      publishedAt: Thu, 12 Sep 2024 00:00:00 GMT
      summary: Geneticist Catherine Brownstein demonstrates how OpenAI o1 can speed up the process of diagnosing rare medical
        challenges.
      relevanceScore: 40
      topics:
        - reasoning
        - scientific-research
        - capabilities
      entities:
        - reasoning
        - scientific-research
        - capabilities
    - title: Economics and reasoning with OpenAI o1
      url: https://openai.com/index/o1-economics
      sourceId: openai-blog
      publishedAt: Thu, 12 Sep 2024 00:00:00 GMT
      summary: Economist Tyler Cowen explains how OpenAI o1 tackles complex economic questions.
      relevanceScore: 40
      topics:
        - reasoning
        - capabilities
      entities:
        - reasoning
        - capabilities
    - title: Fine-tuning now available for GPT-4o
      url: https://openai.com/index/gpt-4o-fine-tuning
      sourceId: openai-blog
      publishedAt: Tue, 20 Aug 2024 10:00:00 GMT
      summary: Fine-tune custom versions of GPT-4o to increase performance and accuracy for your applications
      relevanceScore: 40
      topics:
        - fine-tuning
        - capabilities
        - model-development
      entities:
        - language-models
    - title: "GPT-4o mini: advancing cost-efficient intelligence"
      url: https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence
      sourceId: openai-blog
      publishedAt: Thu, 18 Jul 2024 10:00:00 GMT
      summary: Introducing the most cost-efficient small model in the market
      relevanceScore: 40
      topics:
        - capabilities
        - compute-efficiency
        - scaling
      entities:
        - language-models
        - compute-hardware
    - title: Improved Techniques for Training Consistency Models
      url: https://openai.com/index/improved-techniques-for-training-consistency-models
      sourceId: openai-blog
      publishedAt: Thu, 20 Jun 2024 00:00:00 GMT
      summary: Consistency models are a nascent family of generative models that can sample high quality data in one step
        without the need for adversarial training.
      relevanceScore: 40
      topics:
        - model-development
        - generative-models
        - capabilities
      entities:
        - language-models
    - title: Automating customer support agents
      url: https://openai.com/index/mavenagi
      sourceId: openai-blog
      publishedAt: Wed, 29 May 2024 09:00:00 GMT
      summary: MavenAGI is a new software company for the AI era. They recently launched an AI customer service agent, built
        on the flexibility of GPT-4, which a number of companies like Tripadvisor, Clickup and Rho are already using to
        save time and better serve their customers.
      relevanceScore: 40
      topics:
        - agentic-ai
        - tool-use
        - capabilities
      entities:
        - agentic-ai
        - tool-use
    - title: Introducing ChatGPT and Whisper APIs
      url: https://openai.com/index/introducing-chatgpt-and-whisper-apis
      sourceId: openai-blog
      publishedAt: Wed, 24 Apr 2024 00:00:00 GMT
      summary: Developers can now integrate ChatGPT and Whisper models into their apps and products through our API.
      relevanceScore: 40
      topics:
        - deployment
        - capabilities
        - tool-use
      entities:
        - tool-use
    - title: Building a data-driven, efficient culture with AI
      url: https://openai.com/index/holiday-extras
      sourceId: openai-blog
      publishedAt: Mon, 18 Mar 2024 07:00:00 GMT
      summary: Holiday Extras rolls out ChatGPT Enterprise across every team, boosting productivity by 500 hours weekly.
      relevanceScore: 40
      topics:
        - deployment
        - economic-labor
      entities:
        - economic-labor
    - title: Sam Altman returns as CEO, OpenAI has a new initial board
      url: https://openai.com/index/sam-altman-returns-as-ceo-openai-has-a-new-initial-board
      sourceId: openai-blog
      publishedAt: Wed, 29 Nov 2023 08:00:00 GMT
      summary: Mira Murati as CTO, Greg Brockman returns as President. Read messages from CEO Sam Altman and board chair Bret
        Taylor.
      relevanceScore: 40
      topics:
        - lab-behavior
      entities:
        - lab-behavior
    - title: ChatGPT can now see, hear, and speak
      url: https://openai.com/index/chatgpt-can-now-see-hear-and-speak
      sourceId: openai-blog
      publishedAt: Mon, 25 Sep 2023 07:00:00 GMT
      summary: We are beginning to roll out new voice and image capabilities in ChatGPT. They offer a new, more intuitive type
        of interface by allowing you to have a voice conversation or show ChatGPT what you’re talking about.
      relevanceScore: 40
      topics:
        - capabilities
        - language-models
      entities:
        - language-models
    - title: Teaching with AI
      url: https://openai.com/index/teaching-with-ai
      sourceId: openai-blog
      publishedAt: Thu, 31 Aug 2023 07:00:00 GMT
      summary: We’re releasing a guide for teachers using ChatGPT in their classroom—including suggested prompts, an
        explanation of how ChatGPT works and its limitations, the efficacy of AI detectors, and bias.
      relevanceScore: 40
      topics:
        - capabilities
        - misuse-risks
        - epistemic-risks
      entities:
        - language-models
    - title: "March 20 ChatGPT outage: Here’s what happened"
      url: https://openai.com/index/march-20-chatgpt-outage
      sourceId: openai-blog
      publishedAt: Fri, 24 Mar 2023 07:00:00 GMT
      summary: An update on our findings, the actions we’ve taken, and technical details of the bug.
      relevanceScore: 40
      topics:
        - incident-response
        - reliability
        - deployment
      entities: []
    - title: DALL·E now available without waitlist
      url: https://openai.com/index/dall-e-now-available-without-waitlist
      sourceId: openai-blog
      publishedAt: Wed, 28 Sep 2022 07:00:00 GMT
      summary: New users can start creating straight away. Lessons learned from deployment and improvements to our safety
        systems make wider availability possible.
      relevanceScore: 40
      topics:
        - deployment
        - safety-systems
        - misuse-risks
      entities:
        - misuse-risks
    - title: Evolution through large models
      url: https://openai.com/index/evolution-through-large-models
      sourceId: openai-blog
      publishedAt: Fri, 17 Jun 2022 07:00:00 GMT
      summary: ""
      relevanceScore: 40
      topics:
        - capabilities
      entities: []
    - title: Powering next generation applications with OpenAI Codex
      url: https://openai.com/index/codex-apps
      sourceId: openai-blog
      publishedAt: Tue, 24 May 2022 07:00:00 GMT
      summary: Codex is now powering 70 different applications across a variety of use cases through the OpenAI API.
      relevanceScore: 40
      topics:
        - capabilities
        - coding
        - tool-use
      entities:
        - coding
        - tool-use
    - title: Introducing text and code embeddings
      url: https://openai.com/index/introducing-text-and-code-embeddings
      sourceId: openai-blog
      publishedAt: Tue, 25 Jan 2022 08:00:00 GMT
      summary: We are introducing embeddings, a new endpoint in the OpenAI API that makes it easy to perform natural language
        and code tasks like semantic search, clustering, topic modeling, and classification.
      relevanceScore: 40
      topics:
        - capabilities
        - language-models
      entities:
        - language-models
    - title: Helen Toner joins OpenAI’s board of directors
      url: https://openai.com/index/helen-toner-joins
      sourceId: openai-blog
      publishedAt: Wed, 08 Sep 2021 07:00:00 GMT
      summary: Today, we’re excited to announce the appointment of Helen Toner to our board of directors.
      relevanceScore: 40
      topics:
        - lab-behavior
        - expert-opinion
      entities:
        - lab-behavior
    - title: GPT-3 powers the next generation of apps
      url: https://openai.com/index/gpt-3-apps
      sourceId: openai-blog
      publishedAt: Thu, 25 Mar 2021 07:00:00 GMT
      summary: Over 300 applications are delivering GPT-3–powered search, conversation, text completion, and other advanced AI
        features through our API.
      relevanceScore: 40
      topics:
        - capabilities
        - deployment
      entities:
        - language-models
    - title: "OpenAI Scholars 2020: Final projects"
      url: https://openai.com/index/openai-scholars-2020-final-projects
      sourceId: openai-blog
      publishedAt: Thu, 09 Jul 2020 07:00:00 GMT
      summary: Our third class of OpenAI Scholars presented their final projects at virtual Demo Day, showcasing their
        research results from over the past five months.
      relevanceScore: 40
      topics:
        - ai-talent-market-dynamics
        - lab-behavior
      entities:
        - ai-talent-market-dynamics
    - title: Procgen and MineRL Competitions
      url: https://openai.com/index/procgen-minerl-competitions
      sourceId: openai-blog
      publishedAt: Sat, 20 Jun 2020 07:00:00 GMT
      summary: We’re excited to announce that OpenAI is co-organizing two NeurIPS 2020 competitions with AIcrowd, Carnegie
        Mellon University, and DeepMind, using Procgen Benchmark and MineRL.
      relevanceScore: 40
      topics:
        - capabilities
        - scientific-research
      entities:
        - scientific-research
    - title: OpenAI API
      url: https://openai.com/index/openai-api
      sourceId: openai-blog
      publishedAt: Thu, 11 Jun 2020 07:00:00 GMT
      summary: We’re releasing an API for accessing new AI models developed by OpenAI.
      relevanceScore: 40
      topics:
        - deployment
        - capabilities
      entities:
        - language-models
    - title: Jukebox
      url: https://openai.com/index/jukebox
      sourceId: openai-blog
      publishedAt: Thu, 30 Apr 2020 07:00:00 GMT
      summary: We’re introducing Jukebox, a neural net that generates music, including rudimentary singing, as raw audio in a
        variety of genres and artist styles. We’re releasing the model weights and code, along with a tool to explore
        the generated samples.
      relevanceScore: 40
      topics:
        - capabilities
        - world-models
      entities:
        - world-models
    - title: Procgen Benchmark
      url: https://openai.com/index/procgen-benchmark
      sourceId: openai-blog
      publishedAt: Tue, 03 Dec 2019 08:00:00 GMT
      summary: We’re releasing Procgen Benchmark, 16 simple-to-use procedurally-generated environments which provide a direct
        measure of how quickly a reinforcement learning agent learns generalizable skills.
      relevanceScore: 40
      topics:
        - reinforcement-learning
        - benchmarking
      entities:
        - capabilities
    - title: "OpenAI Fellows Summer 2018: Final projects"
      url: https://openai.com/index/openai-summer-fellows-2018
      sourceId: openai-blog
      publishedAt: Wed, 19 Dec 2018 08:00:00 GMT
      summary: Our first cohort of OpenAI Fellows has concluded, with each Fellow going from a machine learning beginner to
        core OpenAI contributor in the course of a 6-month apprenticeship.
      relevanceScore: 40
      topics:
        - education
        - training-programs
        - talent
      entities:
        - ai-talent-market-dynamics
    - title: "OpenAI Scholars 2019: Applications open"
      url: https://openai.com/index/openai-scholars-2019
      sourceId: openai-blog
      publishedAt: Thu, 11 Oct 2018 07:00:00 GMT
      summary: We are now accepting applications for our second cohort of OpenAI Scholars, a program where we provide 6–10
        stipends and mentorship to individuals from underrepresented groups to study deep learning full-time for 3
        months and open-source a project.
      relevanceScore: 40
      topics:
        - education
        - diversity
        - training-programs
      entities:
        - ai-talent-market-dynamics
    - title: OpenAI Fellows Winter 2019 & Interns Summer 2019
      url: https://openai.com/index/openai-fellows-interns-2019
      sourceId: openai-blog
      publishedAt: Tue, 09 Oct 2018 07:00:00 GMT
      summary: We are now accepting applications for OpenAI Fellows and Interns for 2019.
      relevanceScore: 40
      topics:
        - education
        - talent
        - internships
      entities:
        - ai-talent-market-dynamics
    - title: "OpenAI Scholars 2018: Final projects"
      url: https://openai.com/index/openai-scholars-2018-final-projects
      sourceId: openai-blog
      publishedAt: Mon, 10 Sep 2018 07:00:00 GMT
      summary: Our first cohort of OpenAI Scholars has now completed the program.
      relevanceScore: 40
      topics:
        - education
        - training-programs
      entities: []
    - title: "OpenAI Five Benchmark: Results"
      url: https://openai.com/index/openai-five-benchmark-results
      sourceId: openai-blog
      publishedAt: Mon, 06 Aug 2018 07:00:00 GMT
      summary: "Yesterday, OpenAI Five won a best-of-three against a team of 99.95th percentile Dota players: Blitz, Cap,
        Fogged, Merlini, and MoonMeander—four of whom have played Dota professionally—in front of a live audience and
        100,000 concurrent livestream viewers."
      relevanceScore: 40
      topics:
        - game-playing
        - dota
        - benchmarks
      entities: []
    - title: "OpenAI Scholars 2018: Meet our Scholars"
      url: https://openai.com/index/openai-scholars-2018-meet-our-scholars
      sourceId: openai-blog
      publishedAt: Wed, 25 Jul 2018 07:00:00 GMT
      summary: Our first class of OpenAI Scholars is underway, and you can now follow along as this group of experienced
        software developers becomes machine learning practitioners.
      relevanceScore: 40
      topics:
        - education
        - training-programs
      entities: []
    - title: OpenAI Five
      url: https://openai.com/index/openai-five
      sourceId: openai-blog
      publishedAt: Mon, 25 Jun 2018 07:00:00 GMT
      summary: Our team of five neural networks, OpenAI Five, has started to defeat amateur human teams at Dota 2.
      relevanceScore: 40
      topics:
        - game-playing
        - dota
        - benchmarks
      entities: []
    - title: Retro Contest
      url: https://openai.com/index/retro-contest
      sourceId: openai-blog
      publishedAt: Thu, 05 Apr 2018 07:00:00 GMT
      summary: We’re launching a transfer learning contest that measures a reinforcement learning algorithm’s ability to
        generalize from previous experience.
      relevanceScore: 40
      topics:
        - capabilities
      entities:
        - capabilities
    - title: Improving GANs using optimal transport
      url: https://openai.com/index/improving-gans-using-optimal-transport
      sourceId: openai-blog
      publishedAt: Thu, 15 Mar 2018 07:00:00 GMT
      summary: ""
      relevanceScore: 40
      topics:
        - capabilities
      entities:
        - capabilities
    - title: "Reptile: A scalable meta-learning algorithm"
      url: https://openai.com/index/reptile
      sourceId: openai-blog
      publishedAt: Wed, 07 Mar 2018 08:00:00 GMT
      summary: We’ve developed a simple meta-learning algorithm called Reptile which works by repeatedly sampling a task,
        performing stochastic gradient descent on it, and updating the initial parameters towards the final parameters
        learned on that task. Reptile is the application of the Shortest Descent algorithm to the meta-learning setting,
        and is mathematically similar to first-order MAML (which is a version of the well-known MAML algorithm) that
        only needs black-box access to an optimizer such as SGD or A
      relevanceScore: 40
      topics:
        - capabilities
      entities:
        - capabilities
    - title: Some considerations on learning to explore via meta-reinforcement learning
      url: https://openai.com/index/some-considerations-on-learning-to-explore-via-meta-reinforcement-learning
      sourceId: openai-blog
      publishedAt: Sat, 03 Mar 2018 08:00:00 GMT
      summary: ""
      relevanceScore: 40
      topics:
        - capabilities
      entities:
        - capabilities
    - title: Discovering types for entity disambiguation
      url: https://openai.com/index/discovering-types-for-entity-disambiguation
      sourceId: openai-blog
      publishedAt: Wed, 07 Feb 2018 08:00:00 GMT
      summary: We’ve built a system for automatically figuring out which object is meant by a word by having a neural network
        decide if the word belongs to each of about 100 automatically-discovered “types” (non-exclusive categories).
      relevanceScore: 40
      topics:
        - capabilities
        - language-models
      entities:
        - language-models
        - capabilities
    - title: Asymmetric actor critic for image-based robot learning
      url: https://openai.com/index/asymmetric-actor-critic-for-image-based-robot-learning
      sourceId: openai-blog
      publishedAt: Wed, 18 Oct 2017 07:00:00 GMT
      summary: ""
      relevanceScore: 40
      topics:
        - reinforcement-learning
        - robotics
        - vision
        - capabilities
      entities:
        - tool-use
    - title: Domain randomization and generative models for robotic grasping
      url: https://openai.com/index/domain-randomization-and-generative-models-for-robotic-grasping
      sourceId: openai-blog
      publishedAt: Tue, 17 Oct 2017 07:00:00 GMT
      summary: ""
      relevanceScore: 40
      topics:
        - reinforcement-learning
        - robotics
        - generative-models
        - capabilities
      entities:
        - tool-use
    - title: Better exploration with parameter noise
      url: https://openai.com/index/better-exploration-with-parameter-noise
      sourceId: openai-blog
      publishedAt: Thu, 27 Jul 2017 07:00:00 GMT
      summary: We’ve found that adding adaptive noise to the parameters of reinforcement learning algorithms frequently boosts
        performance. This exploration method is simple to implement and very rarely decreases performance, so it’s worth
        trying on any problem.
      relevanceScore: 40
      topics:
        - reinforcement-learning
        - exploration
        - algorithms
      entities: []
    - title: Hindsight Experience Replay
      url: https://openai.com/index/hindsight-experience-replay
      sourceId: openai-blog
      publishedAt: Wed, 05 Jul 2017 07:00:00 GMT
      summary: ""
      relevanceScore: 40
      topics:
        - reinforcement-learning
        - experience-replay
        - algorithms
      entities: []
    - title: Teacher–student curriculum learning
      url: https://openai.com/index/teacher-student-curriculum-learning
      sourceId: openai-blog
      publishedAt: Sat, 01 Jul 2017 07:00:00 GMT
      summary: ""
      relevanceScore: 40
      topics:
        - curriculum-learning
        - reinforcement-learning
      entities: []
    - title: Stochastic Neural Networks for hierarchical reinforcement learning
      url: https://openai.com/index/stochastic-neural-networks-for-hierarchical-reinforcement-learning
      sourceId: openai-blog
      publishedAt: Mon, 10 Apr 2017 07:00:00 GMT
      summary: ""
      relevanceScore: 40
      topics:
        - reinforcement-learning
        - hierarchical-learning
        - neural-networks
      entities: []
    - title: Prediction and control with temporal segment models
      url: https://openai.com/index/prediction-and-control-with-temporal-segment-models
      sourceId: openai-blog
      publishedAt: Sun, 12 Mar 2017 08:00:00 GMT
      summary: ""
      relevanceScore: 40
      topics:
        - reasoning
        - temporal-models
      entities: []
    - title: "#Exploration: A study of count-based exploration for deep reinforcement learning"
      url: https://openai.com/index/exploration
      sourceId: openai-blog
      publishedAt: Tue, 15 Nov 2016 08:00:00 GMT
      summary: ""
      relevanceScore: 40
      topics:
        - reinforcement-learning
        - exploration
      entities: []
    - title: "RL²: Fast reinforcement learning via slow reinforcement learning"
      url: https://openai.com/index/rl2
      sourceId: openai-blog
      publishedAt: Wed, 09 Nov 2016 08:00:00 GMT
      summary: ""
      relevanceScore: 40
      topics:
        - reinforcement-learning
        - meta-learning
      entities: []
    - title: Report from the self-organizing conference
      url: https://openai.com/index/report-from-the-self-organizing-conference
      sourceId: openai-blog
      publishedAt: Thu, 13 Oct 2016 07:00:00 GMT
      summary: Last week we hosted over a hundred and fifty AI practitioners in our offices for our first self-organizing
        conference on machine learning.
      relevanceScore: 40
      topics:
        - scientific-research
        - community
      entities: []
    - title: Transfer from simulation to real world through learning deep inverse dynamics model
      url: https://openai.com/index/transfer-from-simulation-to-real-world-through-learning-deep-inverse-dynamics-model
      sourceId: openai-blog
      publishedAt: Tue, 11 Oct 2016 07:00:00 GMT
      summary: ""
      relevanceScore: 40
      topics:
        - simulation
        - robotics
        - transfer-learning
      entities: []
    - title: Adversarial training methods for semi-supervised text classification
      url: https://openai.com/index/adversarial-training-methods-for-semi-supervised-text-classification
      sourceId: openai-blog
      publishedAt: Wed, 25 May 2016 07:00:00 GMT
      summary: ""
      relevanceScore: 40
      topics:
        - adversarial-training
        - robustness
      entities: []
    - title: Welcome, Pieter and Shivon!
      url: https://openai.com/index/welcome-pieter-and-shivon
      sourceId: openai-blog
      publishedAt: Tue, 26 Apr 2016 07:00:00 GMT
      summary: We have two more team updates.
      relevanceScore: 40
      topics:
        - lab-behavior
        - team
      entities:
        - lab-behavior
    - title: Accelerating Mathematical and Scientific Discovery with Gemini Deep Think
      url: https://deepmind.google/blog/accelerating-mathematical-and-scientific-discovery-with-gemini-deep-think/
      sourceId: deepmind-blog
      publishedAt: Mon, 09 Feb 2026 16:12:06 +0000
      summary: Research papers point to the growing impact of Deep Think across fields
      relevanceScore: 40
      topics:
        - scientific-research
        - capabilities
      entities:
        - scientific-research
    - title: "Gemini 3 Flash: frontier intelligence built for speed"
      url: https://deepmind.google/blog/gemini-3-flash-frontier-intelligence-built-for-speed/
      sourceId: deepmind-blog
      publishedAt: Wed, 17 Dec 2025 11:58:17 +0000
      summary: Gemini 3 Flash offers frontier intelligence built for speed at a fraction of the cost.
      relevanceScore: 40
      topics:
        - capabilities
        - language-models
      entities:
        - language-models
    - title: How AI is giving Northern Ireland teachers time back
      url: https://deepmind.google/blog/how-ai-is-giving-northern-ireland-teachers-time-back/
      sourceId: deepmind-blog
      publishedAt: Mon, 10 Nov 2025 16:50:39 +0000
      summary: A six-month long pilot program with the Northern Ireland Education Authority’s C2k initiative found that
        integrating Gemini and other generative AI tools saved participating teachers an average of 10 hours per week.
      relevanceScore: 40
      topics:
        - economic-labor
        - capabilities
      entities:
        - economic-labor
        - capabilities
    - title: AlphaEarth Foundations helps map our planet in unprecedented detail
      url: https://deepmind.google/blog/alphaearth-foundations-helps-map-our-planet-in-unprecedented-detail/
      sourceId: deepmind-blog
      publishedAt: Fri, 24 Oct 2025 19:06:32 +0000
      summary: New AI model integrates petabytes of Earth observation data to generate a unified data representation that
        revolutionizes global mapping and monitoring
      relevanceScore: 40
      topics:
        - capabilities
        - scientific-research
      entities:
        - capabilities
        - scientific-research
    - title: Aeneas transforms how historians connect the past
      url: https://deepmind.google/blog/aeneas-transforms-how-historians-connect-the-past/
      sourceId: deepmind-blog
      publishedAt: Fri, 24 Oct 2025 02:58:37 +0000
      summary: Introducing the first model for contextualizing ancient inscriptions, designed to help historians better
        interpret, attribute and restore fragmentary texts.
      relevanceScore: 40
      topics:
        - capabilities
        - scientific-research
      entities:
        - capabilities
        - scientific-research
    - title: How AI is helping advance the science of bioacoustics to save endangered species
      url: https://deepmind.google/blog/how-ai-is-helping-advance-the-science-of-bioacoustics-to-save-endangered-species/
      sourceId: deepmind-blog
      publishedAt: Fri, 24 Oct 2025 02:30:54 +0000
      summary: Our new Perch model helps conservationists analyze audio faster to protect endangered species, from Hawaiian
        honeycreepers to coral reefs.
      relevanceScore: 40
      topics:
        - capabilities
        - scientific-research
      entities:
        - capabilities
        - scientific-research
    - title: How a Gemma model helped discover a new potential cancer therapy pathway
      url: https://deepmind.google/blog/how-a-gemma-model-helped-discover-a-new-potential-cancer-therapy-pathway/
      sourceId: deepmind-blog
      publishedAt: Thu, 23 Oct 2025 18:22:55 +0000
      summary: We’re launching a new 27 billion parameter foundation model for single-cell analysis built on the Gemma family
        of open models.
      relevanceScore: 40
      topics:
        - scientific-research
        - capabilities
        - language-models
      entities:
        - scientific-research
        - language-models
        - capabilities
    - title: "AlphaGenome: AI for better understanding the genome"
      url: https://deepmind.google/blog/alphagenome-ai-for-better-understanding-the-genome/
      sourceId: deepmind-blog
      publishedAt: Wed, 25 Jun 2025 13:59:00 +0000
      summary: Introducing a new, unifying DNA sequence model that advances regulatory variant-effect prediction and promises
        to shed new light on genome function — now available via API.
      relevanceScore: 40
      topics:
        - scientific-research
        - capabilities
        - language-models
      entities:
        - scientific-research
        - language-models
        - capabilities
    - title: Fuel your creativity with new generative media models and tools
      url: https://deepmind.google/blog/fuel-your-creativity-with-new-generative-media-models-and-tools/
      sourceId: deepmind-blog
      publishedAt: Tue, 20 May 2025 09:45:00 +0000
      summary: Introducing Veo 3 and Imagen 4, and a new tool for filmmaking called Flow.
      relevanceScore: 40
      topics:
        - generative-models
        - capabilities
      entities:
        - capabilities
    - title: "DolphinGemma: How Google AI is helping decode dolphin communication"
      url: https://deepmind.google/blog/dolphingemma-how-google-ai-is-helping-decode-dolphin-communication/
      sourceId: deepmind-blog
      publishedAt: Mon, 14 Apr 2025 17:00:00 +0000
      summary: DolphinGemma, a large language model developed by Google, is helping scientists study how dolphins communicate
        — and hopefully find out what they're saying, too.
      relevanceScore: 40
      topics:
        - language-models
        - scientific-research
        - capabilities
      entities:
        - language-models
        - scientific-research
        - capabilities
    - title: Demis Hassabis & John Jumper awarded Nobel Prize in Chemistry
      url: https://deepmind.google/blog/demis-hassabis-john-jumper-awarded-nobel-prize-in-chemistry/
      sourceId: deepmind-blog
      publishedAt: Wed, 09 Oct 2024 11:45:00 +0000
      summary: The award recognizes their work developing AlphaFold, a groundbreaking AI system that predicts the 3D structure
        of proteins from their amino acid sequences.
      relevanceScore: 40
      topics:
        - scientific-research
        - capabilities
      entities:
        - scientific-research
    - title: Updated production-ready Gemini models, reduced 1.5 Pro pricing, increased rate limits, and more
      url: https://deepmind.google/blog/updated-production-ready-gemini-models-reduced-15-pro-pricing-increased-rate-limits-and-more/
      sourceId: deepmind-blog
      publishedAt: Tue, 24 Sep 2024 16:03:03 +0000
      summary: We’re releasing two updated production-ready Gemini models
      relevanceScore: 40
      topics:
        - capabilities
        - language-models
      entities:
        - language-models
    - title: "The Future of AI: Built with Llama"
      url: https://ai.meta.com/blog/future-of-ai-built-with-llama/
      sourceId: meta-ai-blog
      publishedAt: 2026-02-19
      summary: "  Reflects on how, as of the close of 2024, Meta is leading the industry forward in AI product and technology
        experiences and setting a new standard for how the industry builds and advances AI."
      relevanceScore: 40
      topics:
        - capabilities
        - lab-behavior
      entities:
        - lab-behavior
    - title: How Uncertain Is the Grade? A Benchmark of Uncertainty Metrics for LLM-Based Automatic Assessment
      url: https://arxiv.org/abs/2602.16039
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16039v1 Announce Type: new Abstract: The rapid rise of large language models (LLMs) is reshaping
        the landscape of automatic assessment in education. While these systems demonstrate substantial advantages in
        adaptability to diverse question types and flexibility in output formats, they also introduce new challenges
        related to output uncertainty, stemming from the inherently probabilistic nature of LLMs. Output uncertainty is
        an inescapable challenge in automatic assessment, as assessme"
      relevanceScore: 40
      topics:
        - language-models
        - interpretability-sufficient
      entities:
        - language-models
    - title: "GPSBench: Do Large Language Models Understand GPS Coordinates?"
      url: https://arxiv.org/abs/2602.16105
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16105v1 Announce Type: new Abstract: Large Language Models (LLMs) are increasingly deployed in
        applications that interact with the physical world, such as navigation, robotics, or mapping, making robust
        geospatial reasoning a critical capability. Despite that, LLMs' ability to reason about GPS coordinates and
        real-world geography remains underexplored. We introduce GPSBench, a dataset of 57,800 samples across 17 tasks
        for evaluating geospatial reasoning in LLMs, spanning geometric coo"
      relevanceScore: 40
      topics:
        - language-models
        - capabilities
      entities:
        - language-models
    - title: "Leveraging Large Language Models for Causal Discovery: a Constraint-based, Argumentation-driven Approach"
      url: https://arxiv.org/abs/2602.16481
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16481v1 Announce Type: new Abstract: Causal discovery seeks to uncover causal relations from data,
        typically represented as causal graphs, and is essential for predicting the effects of interventions. While
        expert knowledge is required to construct principled causal graphs, many statistical methods have been proposed
        to leverage observational data with varying formal guarantees. Causal Assumption-based Argumentation (ABA) is a
        framework that uses symbolic reasoning to ensure correspon"
      relevanceScore: 40
      topics:
        - causal-reasoning
        - language-models
        - interpretability
      entities:
        - language-models
        - interpretability-sufficient
    - title: Decoupling Strategy and Execution in Task-Focused Dialogue via Goal-Oriented Preference Optimization
      url: https://arxiv.org/abs/2602.15854
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15854v1 Announce Type: cross Abstract: Large language models show potential in task-oriented
        dialogue systems, yet existing training methods often rely on token-level likelihood or preference optimization,
        which poorly align with long-horizon task success. To address this, we propose Goal-Oriented Preference
        Optimization (GOPO), a hierarchical reinforcement learning framework that decouples strategy planning from
        response generation via an Expert Agent and a Customer Service Agent. Th"
      relevanceScore: 40
      topics:
        - language-models
        - dialogue-systems
        - preference-optimization
      entities:
        - language-models
    - title: "Not the Example, but the Process: How Self-Generated Examples Enhance LLM Reasoning"
      url: https://arxiv.org/abs/2602.15863
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15863v1 Announce Type: cross Abstract: Recent studies have shown that Large Language Models (LLMs)
        can improve their reasoning performance through self-generated few-shot examples, achieving results comparable
        to manually curated in-context examples. However, the underlying mechanism behind these gains remains unclear,
        making it hard to decide when and how to apply the technique effectively. In this work, we argue that the key
        benefit arises not from the generated examples themselves "
      relevanceScore: 40
      topics:
        - language-models
        - reasoning
        - few-shot-learning
      entities:
        - language-models
        - reasoning
    - title: "Understand Then Memory: A Cognitive Gist-Driven RAG Framework with Global Semantic Diffusion"
      url: https://arxiv.org/abs/2602.15895
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15895v1 Announce Type: cross Abstract: Retrieval-Augmented Generation (RAG) effectively mitigates
        hallucinations in LLMs by incorporating external knowledge. However, the inherent discrete representation of
        text in existing frameworks often results in a loss of semantic integrity, leading to retrieval deviations.
        Inspired by the human episodic memory mechanism, we propose CogitoRAG, a RAG framework that simulates human
        cognitive memory processes. The core of this framework lies in the"
      relevanceScore: 40
      topics:
        - language-models
        - hallucinations
        - reasoning
      entities:
        - language-models
        - reasoning
    - title: "EarthSpatialBench: Benchmarking Spatial Reasoning Capabilities of Multimodal LLMs on Earth Imagery"
      url: https://arxiv.org/abs/2602.15918
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15918v1 Announce Type: cross Abstract: Benchmarking spatial reasoning in multimodal large language
        models (MLLMs) has attracted growing interest in computer vision due to its importance for embodied AI and other
        agentic systems that require precise interaction with the physical world. However, spatial reasoning on Earth
        imagery has lagged behind, as it uniquely involves grounding objects in georeferenced images and quantitatively
        reasoning about distances, directions, and topological "
      relevanceScore: 40
      topics:
        - multimodal-llms
        - reasoning
        - spatial-reasoning
        - benchmarking
      entities:
        - reasoning
    - title: "Transforming GenAI Policy to Prompting Instruction: An RCT of Scalable Prompting Interventions in a CS1 Course"
      url: https://arxiv.org/abs/2602.16033
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16033v1 Announce Type: cross Abstract: Despite universal GenAI adoption, students cannot
        distinguish task performance from actual learning and lack skills to leverage AI for learning, leading to worse
        exam performance when AI use remains unreflective. Yet few interventions teaching students to prompt AI as a
        tutor rather than solution provider have been validated at scale through randomized controlled trials (RCTs). To
        bridge this gap, we conducted a semester-long RCT (N=979) with fou"
      relevanceScore: 40
      topics:
        - language-models
        - education
        - ai-governance
        - responsible-ai
      entities: []
    - title: "Conjugate Learning Theory: Uncovering the Mechanisms of Trainability and Generalization in Deep Neural Networks"
      url: https://arxiv.org/abs/2602.16177
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16177v1 Announce Type: cross Abstract: In this work, we propose a notion of practical learnability
        grounded in finite sample settings, and develop a conjugate learning theoretical framework based on convex
        conjugate duality to characterize this learnability property. Building on this foundation, we demonstrate that
        training deep neural networks (DNNs) with mini-batch stochastic gradient descent (SGD) achieves global optima of
        empirical risk by jointly controlling the extreme eigenvalu"
      relevanceScore: 40
      topics:
        - language-models
        - capabilities
      entities:
        - language-models
        - capabilities
    - title: Are LLMs Ready to Replace Bangla Annotators?
      url: https://arxiv.org/abs/2602.16241
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16241v1 Announce Type: cross Abstract: Large Language Models (LLMs) are increasingly used as
        automated annotators to scale dataset creation, yet their reliability as unbiased annotators--especially for
        low-resource and identity-sensitive settings--remains poorly understood. In this work, we study the behavior of
        LLMs as zero-shot annotators for Bangla hate speech, a task where even human agreement is challenging, and
        annotator bias can have serious downstream consequences. We conduct "
      relevanceScore: 40
      topics:
        - language-models
        - capabilities
      entities:
        - language-models
        - capabilities
    - title: "Guide-Guard: Off-Target Predicting in CRISPR Applications"
      url: https://arxiv.org/abs/2602.16327
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16327v1 Announce Type: cross Abstract: With the introduction of cyber-physical genome sequencing
        and editing technologies, such as CRISPR, researchers can more easily access tools to investigate and create
        remedies for a variety of topics in genetics and health science (e.g. agriculture and medicine). As the field
        advances and grows, new concerns present themselves in the ability to predict the off-target behavior. In this
        work, we explore the underlying biological and chemical model "
      relevanceScore: 40
      topics:
        - misuse-risks
        - bioweapons-ai-uplift
      entities:
        - misuse-risks
    - title: "IndicEval: A Bilingual Indian Educational Evaluation Framework for Large Language Models"
      url: https://arxiv.org/abs/2602.16467
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16467v1 Announce Type: cross Abstract: The rapid advancement of large language models (LLMs)
        necessitates evaluation frameworks that reflect real-world academic rigor and multilingual complexity. This
        paper introduces IndicEval, a scalable benchmarking platform designed to assess LLM performance using authentic
        high-stakes examination questions from UPSC, JEE, and NEET across STEM and humanities domains in both English
        and Hindi. Unlike synthetic benchmarks, IndicEval grounds evaluati"
      relevanceScore: 40
      topics:
        - language-models
        - safety-research
      entities:
        - language-models
        - safety-research
    - title: "FlowPrefill: Decoupling Preemption from Prefill Scheduling Granularity to Mitigate Head-of-Line Blocking in LLM
        Serving"
      url: https://arxiv.org/abs/2602.16603
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16603v1 Announce Type: cross Abstract: The growing demand for large language models (LLMs) requires
        serving systems to handle many concurrent requests with diverse service level objectives (SLOs). This
        exacerbates head-of-line (HoL) blocking during the compute-intensive prefill phase, where long-running requests
        monopolize resources and delay higher-priority ones, leading to widespread time-to-first-token (TTFT) SLO
        violations. While chunked prefill enables interruptibility, it introd"
      relevanceScore: 40
      topics:
        - language-models
        - compute-hardware
      entities:
        - language-models
        - compute-hardware
    - title: "Earth AI: Unlocking Geospatial Insights with Foundation Models and Cross-Modal Reasoning"
      url: https://arxiv.org/abs/2510.18318
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2510.18318v4 Announce Type: replace Abstract: Geospatial data offers immense potential for understanding
        our planet. However, the sheer volume and diversity of this data along with its varied resolutions, timescales,
        and sparsity pose significant challenges for thorough analysis and interpretation. This paper introduces Earth
        AI, a family of geospatial AI models and agentic reasoning that enables significant advances in our ability to
        unlock novel and profound insights into our planet. Thi"
      relevanceScore: 40
      topics:
        - language-models
        - tool-use
      entities:
        - language-models
        - tool-use
    - title: Integrating Chain-of-Thought and Retrieval Augmented Generation Enhances Rare Disease Diagnosis from Clinical
        Notes
      url: https://arxiv.org/abs/2503.12286
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2503.12286v2 Announce Type: replace-cross Abstract: Background: Several studies show that large language
        models (LLMs) struggle with phenotype-driven gene prioritization for rare diseases. These studies typically use
        Human Phenotype Ontology (HPO) terms to prompt foundation models like GPT and LLaMA to predict candidate genes.
        However, in real-world settings, foundation models are not optimized for domain-specific tasks like clinical
        diagnosis, yet inputs are unstructured clinical notes ra"
      relevanceScore: 40
      topics:
        - language-models
        - reasoning
        - medical-applications
      entities:
        - language-models
        - reasoning
    - title: "WINA: Weight Informed Neuron Activation for Accelerating Large Language Model Inference"
      url: https://arxiv.org/abs/2505.19427
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2505.19427v2 Announce Type: replace-cross Abstract: The growing computational demands of large language
        models (LLMs) make efficient inference and activation strategies increasingly critical. While recent approaches,
        such as Mixture-of-Experts (MoE), leverage selective activation but require specialized training, training-free
        sparse activation methods offer broader applicability and superior resource efficiency through their
        plug-and-play design. However, many existing methods rely solely"
      relevanceScore: 40
      topics:
        - inference-efficiency
        - language-models
        - optimization
      entities:
        - language-models
    - title: "DiffusionBlocks: Block-wise Neural Network Training via Diffusion Interpretation"
      url: https://arxiv.org/abs/2506.14202
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2506.14202v3 Announce Type: replace-cross Abstract: End-to-end backpropagation requires storing
        activations throughout all layers, creating memory bottlenecks that limit model scalability. Existing block-wise
        training methods offer means to alleviate this problem, but they rely on ad-hoc local objectives and remain
        largely unexplored beyond classification tasks. We propose $\\textit{DiffusionBlocks}$, a principled framework
        for transforming transformer-based networks into genuinely independ"
      relevanceScore: 40
      topics:
        - neural-network-training
        - memory-efficiency
        - scalability
      entities: []
    - title: Lossless Vocabulary Reduction for Auto-Regressive Language Models
      url: https://arxiv.org/abs/2510.08102
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2510.08102v2 Announce Type: replace-cross Abstract: Tokenization -- the process of decomposing a given
        text into a sequence of subwords called tokens -- is one of the key components in the development of language
        models. Particularly, auto-regressive language models generate texts token by token, i.e., by predicting the
        next-token distribution given the previous ones, and thus tokenization directly affects their efficiency in text
        generation. Since each language model has their own vocabul"
      relevanceScore: 40
      topics:
        - tokenization
        - language-models
        - efficiency
      entities:
        - language-models
    - title: Language-Guided Invariance Probing of Vision-Language Models
      url: https://arxiv.org/abs/2511.13494
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2511.13494v2 Announce Type: replace-cross Abstract: Recent vision-language models (VLMs) such as CLIP,
        OpenCLIP, EVA02-CLIP and SigLIP achieve strong zero-shot performance, but it is unclear how reliably they
        respond to controlled linguistic perturbations. We introduce Language-Guided Invariance Probing (LGIP), a
        benchmark that measures (i) invariance to meaning-preserving paraphrases and (ii) sensitivity to
        meaning-changing semantic flips in image-text matching. Using 40k MS COCO images w"
      relevanceScore: 40
      topics:
        - vision-language-models
        - interpretability
        - robustness
      entities:
        - interpretability-sufficient
    - title: "Indic-TunedLens: Interpreting Multilingual Models in Indian Languages"
      url: https://arxiv.org/abs/2602.15038
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15038v2 Announce Type: replace-cross Abstract: Multilingual large language models (LLMs) are
        increasingly deployed in linguistically diverse regions like India, yet most interpretability tools remain
        tailored to English. Prior work reveals that LLMs often operate in English centric representation spaces, making
        cross lingual interpretability a pressing concern. We introduce Indic-TunedLens, a novel interpretability
        framework specifically for Indian languages that learns shared affine "
      relevanceScore: 40
      topics:
        - multilingual-models
        - interpretability
        - language-models
      entities:
        - interpretability-sufficient
        - language-models
    - title: Reranker Optimization via Geodesic Distances on k-NN Manifolds
      url: https://arxiv.org/abs/2602.15860
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15860v1 Announce Type: new Abstract: Current neural reranking approaches for retrieval-augmented
        generation (RAG) rely on cross-encoders or large language models (LLMs), requiring substantial computational
        resources and exhibiting latencies of 3-5 seconds per query. We propose Maniscope, a geometric reranking method
        that computes geodesic distances on k-nearest neighbor (k-NN) manifolds constructed over retrieved document
        candidates. This approach combines global cosine similarity wit"
      relevanceScore: 40
      topics:
        - RAG
        - retrieval
        - LLM optimization
      entities:
        - language-models
    - title: "P-RAG: Prompt-Enhanced Parametric RAG with LoRA and Selective CoT for Biomedical and Multi-Hop QA"
      url: https://arxiv.org/abs/2602.15874
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15874v1 Announce Type: new Abstract: Large Language Models (LLMs) demonstrate remarkable
        capabilities but remain limited by their reliance on static training data. Retrieval-Augmented Generation (RAG)
        addresses this constraint by retrieving external knowledge during inference, though it still depends heavily on
        knowledge base quality. To explore potential improvements, we evaluated three RAG variants-Standard RAG, DA-RAG,
        and our proposed Prompt-Enhanced Parametric RAG (P-RAG), a hybr"
      relevanceScore: 40
      topics:
        - RAG
        - LLM capabilities
        - question answering
      entities:
        - language-models
    - title: MultiCube-RAG for Multi-hop Question Answering
      url: https://arxiv.org/abs/2602.15898
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15898v1 Announce Type: new Abstract: Multi-hop question answering (QA) necessitates multi-step
        reasoning and retrieval across interconnected subjects, attributes, and relations. Existing retrieval-augmented
        generation (RAG) methods struggle to capture these structural semantics accurately, resulting in suboptimal
        performance. Graph-based RAGs structure such information in graphs, but the resulting graphs are often noisy and
        computationally expensive. Moreover, most methods rely on sin"
      relevanceScore: 40
      topics:
        - multi-hop reasoning
        - RAG
        - question answering
      entities:
        - language-models
        - reasoning
    - title: Label-Consistent Data Generation for Aspect-Based Sentiment Analysis Using LLM Agents
      url: https://arxiv.org/abs/2602.16379
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16379v1 Announce Type: new Abstract: We propose an agentic data augmentation method for
        Aspect-Based Sentiment Analysis (ABSA) that uses iterative generation and verification to produce high quality
        synthetic training examples. To isolate the effect of agentic structure, we also develop a closely matched
        prompting-based baseline using the same model and instructions. Both methods are evaluated across three ABSA
        subtasks (Aspect Term Extraction (ATE), Aspect Sentiment Classification (A"
      relevanceScore: 40
      topics:
        - agentic systems
        - data generation
        - sentiment analysis
      entities:
        - agentic-ai
        - language-models
    - title: "SPELL: Self-Play Reinforcement Learning for Evolving Long-Context Language Models"
      url: https://arxiv.org/abs/2509.23863
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2509.23863v3 Announce Type: replace Abstract: Progress in long-context reasoning for large language
        models (LLMs) has lagged behind other recent advances. This gap arises not only from the intrinsic difficulty of
        processing long texts, but also from the scarcity of reliable human annotations and programmatically verifiable
        reward signals. In this paper, we propose SPELL, a multi-role self-play reinforcement learning framework that
        enables scalable, label-free optimization for long-context "
      relevanceScore: 40
      topics:
        - language-models
        - long-horizon
        - reasoning
        - capabilities
      entities:
        - language-models
        - long-horizon
        - reasoning
        - capabilities
    - title: "SNAP-UQ: Self-supervised Next-Activation Prediction for Single-Pass Uncertainty in TinyML"
      url: https://arxiv.org/abs/2508.12907
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2508.12907v4 Announce Type: replace-cross Abstract: Reliable uncertainty estimation is a key missing
        piece for on-device monitoring in TinyML: microcontrollers must detect failures, distribution shift, or accuracy
        drops under strict flash/latency budgets, yet common uncertainty approaches (deep ensembles, MC dropout, early
        exits, temporal buffering) typically require multiple passes, extra branches, or state that is impractical on
        milliwatt hardware. This paper proposes a novel and practic"
      relevanceScore: 40
      topics:
        - uncertainty-estimation
        - reliability
        - edge-deployment
      entities: []
    - title: Can Vision-Language Models See Squares? Text-Recognition Mediates Spatial Reasoning Across Three Model Families
      url: https://arxiv.org/abs/2602.15950
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15950v1 Announce Type: cross Abstract: We present a simple experiment that exposes a fundamental
        limitation in vision-language models (VLMs): the inability to accurately localize filled cells in binary grids
        when those cells lack textual identity. We generate fifteen 15x15 grids with varying density (10.7%-41.8% filled
        cells) and render each as two image types -- text symbols (. and #) and filled squares without gridlines -- then
        ask three frontier VLMs (Claude Opus, ChatGPT 5.2, and "
      relevanceScore: 40
      topics:
        - vision-language-models
        - interpretability
        - spatial-reasoning
        - limitations
      entities:
        - interpretability-sufficient
        - language-models
    - title: Stage-wise Dynamics of Classifier-Free Guidance in Diffusion Models
      url: https://arxiv.org/abs/2509.22007
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2509.22007v2 Announce Type: replace Abstract: Classifier-Free Guidance (CFG) is widely used to improve
        conditional fidelity in diffusion models, but its impact on sampling dynamics remains poorly understood. Prior
        studies, often restricted to unimodal conditional distributions or simplified cases, provide only a partial
        picture. We analyze CFG under multimodal conditionals and show that the sampling process unfolds in three
        successive stages. In the Direction Shift stage, guidance accelera"
      relevanceScore: 40
      topics:
        - diffusion-models
        - conditional-generation
      entities: []
    - title: Imitation Learning for Combinatorial Optimisation under Uncertainty
      url: https://arxiv.org/abs/2601.05383
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2601.05383v3 Announce Type: replace Abstract: Imitation learning (IL) provides a data-driven framework
        for approximating policies for large-scale combinatorial optimisation problems formulated as sequential decision
        problems (SDPs), where exact solution methods are computationally intractable. A central but underexplored
        aspect of IL in this context is the role of the \\emph{expert} that generates training demonstrations. Existing
        studies employ a wide range of expert constructions, yet lac"
      relevanceScore: 40
      topics:
        - imitation-learning
        - combinatorial-optimization
      entities: []
    - title: Statistical Inference Leveraging Synthetic Data with Distribution-Free Guarantees
      url: https://arxiv.org/abs/2509.20345
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2509.20345v2 Announce Type: replace-cross Abstract: The rapid proliferation of high-quality synthetic
        data -- generated by advanced AI models or collected as auxiliary data from related tasks -- presents both
        opportunities and challenges for statistical inference. This paper introduces a GEneral Synthetic-Powered
        Inference (GESPI) framework that wraps around any statistical inference procedure to safely enhance sample
        efficiency by combining synthetic and real data. Our framework leverages"
      relevanceScore: 40
      topics:
        - synthetic-data
        - statistical-inference
        - ai-generated-content
      entities: []
    - title: "Steering diffusion models with quadratic rewards: a fine-grained analysis"
      url: https://arxiv.org/abs/2602.16570
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16570v1 Announce Type: new Abstract: Inference-time algorithms are an emerging paradigm in which
        pre-trained models are used as subroutines to solve downstream tasks. Such algorithms have been proposed for
        tasks ranging from inverse problems and guided image generation to reasoning. However, the methods currently
        deployed in practice are heuristics with a variety of failure modes -- and we have very little understanding of
        when these heuristics can be efficiently improved. In this pap"
      relevanceScore: 38
      topics:
        - diffusion-models
        - reward-optimization
        - inference-time
        - alignment
      entities:
        - alignment-progress
    - title: Introducing OpenAI for India
      url: https://openai.com/index/openai-for-india
      sourceId: openai-blog
      publishedAt: Wed, 18 Feb 2026 21:00:00 GMT
      summary: OpenAI for India expands AI access across the country—building local infrastructure, powering enterprises, and
        advancing workforce skills.
      relevanceScore: 35
      topics:
        - deployment
        - geopolitics
        - economic-labor
      entities:
        - agi-development
    - title: The Sora feed philosophy
      url: https://openai.com/index/sora-feed-philosophy
      sourceId: openai-blog
      publishedAt: Tue, 03 Feb 2026 00:00:00 GMT
      summary: Discover the Sora feed philosophy—built to spark creativity, foster connections, and keep experiences safe with
        personalized recommendations, parental controls, and strong guardrails.
      relevanceScore: 35
      topics:
        - safety-research
        - misuse-risks
      entities:
        - misuse-risks
    - title: Scaling PostgreSQL to power 800 million ChatGPT users
      url: https://openai.com/index/scaling-postgresql
      sourceId: openai-blog
      publishedAt: Thu, 22 Jan 2026 12:00:00 GMT
      summary: An inside look at how OpenAI scaled PostgreSQL to millions of queries per second using replicas, caching, rate
        limiting, and workload isolation.
      relevanceScore: 35
      topics:
        - compute-hardware
        - capabilities
      entities:
        - compute-hardware
    - title: "Inside GPT-5 for Work: How Businesses Use GPT-5"
      url: https://openai.com/business/guides-and-resources/chatgpt-usage-and-adoption-patterns-at-work
      sourceId: openai-blog
      publishedAt: Thu, 22 Jan 2026 00:00:00 GMT
      summary: A data-driven report on how workers across industries use ChatGPT—covering adoption trends, top tasks,
        departmental patterns, and the future of AI at work.
      relevanceScore: 35
      topics:
        - economic-labor
        - capabilities
      entities:
        - economic-labor
    - title: Our approach to age prediction
      url: https://openai.com/index/our-approach-to-age-prediction
      sourceId: openai-blog
      publishedAt: Tue, 20 Jan 2026 00:00:00 GMT
      summary: ChatGPT is rolling out age prediction to estimate if accounts are under or over 18, applying safeguards for
        teens and refining accuracy over time.
      relevanceScore: 35
      topics:
        - safety-research
        - misuse-risks
      entities:
        - safety-research
        - misuse-risks
    - title: How Tolan builds voice-first AI with GPT-5.1
      url: https://openai.com/index/tolan
      sourceId: openai-blog
      publishedAt: Wed, 07 Jan 2026 10:00:00 GMT
      summary: Tolan built a voice-first AI companion with GPT-5.1, combining low-latency responses, real-time context
        reconstruction, and memory-driven personalities for natural conversations.
      relevanceScore: 35
      topics:
        - language-models
        - capabilities
      entities:
        - language-models
    - title: Deepening our collaboration with the U.S. Department of Energy
      url: https://openai.com/index/us-department-of-energy-collaboration
      sourceId: openai-blog
      publishedAt: Thu, 18 Dec 2025 11:00:00 GMT
      summary: OpenAI and the U.S. Department of Energy have signed a memorandum of understanding to deepen collaboration on
        AI and advanced computing in support of scientific discovery. The agreement builds on ongoing work with national
        laboratories and helps establish a framework for applying AI to high-impact research across the DOE ecosystem.
      relevanceScore: 35
      topics:
        - geopolitics
        - agi-development
      entities:
        - geopolitics
        - agi-development
    - title: Developers can now submit apps to ChatGPT
      url: https://openai.com/index/developers-can-now-submit-apps-to-chatgpt
      sourceId: openai-blog
      publishedAt: Wed, 17 Dec 2025 00:00:00 GMT
      summary: Developers can now submit apps for review and publication in ChatGPT, with approved apps appearing in a new
        in-product directory for easy discovery. Updated tools, guidelines, and the Apps SDK help developers build
        powerful chat-native experiences that bring real-world actions into ChatGPT.
      relevanceScore: 35
      topics:
        - deployment
        - tool-use
      entities:
        - tool-use
    - title: BBVA and OpenAI collaborate to transform global banking
      url: https://openai.com/index/bbva-collaboration-expansion
      sourceId: openai-blog
      publishedAt: Fri, 12 Dec 2025 00:00:00 GMT
      summary: BBVA is expanding its work with OpenAI through a multi-year AI transformation program, rolling out ChatGPT
        Enterprise to all 120,000 employees. Together, the companies will develop AI solutions that enhance customer
        interactions, streamline operations, and help build an AI-native banking experience.
      relevanceScore: 35
      topics:
        - deployment
        - lab-behavior
      entities:
        - lab-behavior
    - title: The Walt Disney Company and OpenAI reach landmark agreement to bring beloved characters to Sora
      url: https://openai.com/index/disney-sora-agreement
      sourceId: openai-blog
      publishedAt: Thu, 11 Dec 2025 00:00:00 GMT
      summary: Disney and OpenAI have reached an agreement to bring more than 200 Disney, Marvel, Pixar and Star Wars
        characters to Sora for fan-inspired short videos. The agreement emphasizes responsible AI in entertainment and
        includes Disney’s company-wide use of ChatGPT Enterprise and the OpenAI API.
      relevanceScore: 35
      topics:
        - deployment
        - misuse-risks
      entities:
        - misuse-risks
    - title: How Scout24 is building the next generation of real-estate search with AI
      url: https://openai.com/index/scout24
      sourceId: openai-blog
      publishedAt: Tue, 09 Dec 2025 16:00:00 GMT
      summary: Scout24 has created a GPT-5 powered conversational assistant that reimagines real-estate search, guiding users
        with clarifying questions, summaries, and tailored listing recommendations.
      relevanceScore: 35
      topics:
        - deployment
        - tool-use
      entities:
        - tool-use
    - title: Building AI fluency at scale with ChatGPT Enterprise
      url: https://openai.com/index/commonwealth-bank-of-australia
      sourceId: openai-blog
      publishedAt: Tue, 09 Dec 2025 00:00:00 GMT
      summary: Commonwealth Bank of Australia partners with OpenAI to roll out ChatGPT Enterprise to 50,000 employees,
        building AI fluency at scale to improve customer service and fraud response.
      relevanceScore: 35
      topics:
        - deployment
        - economic-labor
      entities:
        - economic-labor
    - title: Announcing the initial People-First AI Fund grantees
      url: https://openai.com/index/people-first-ai-fund-grantees
      sourceId: openai-blog
      publishedAt: Wed, 03 Dec 2025 08:00:00 GMT
      summary: The OpenAI Foundation announces the initial recipients of the People-First AI Fund, awarding $40.5M in
        unrestricted grants to 208 nonprofits supporting community innovation and opportunity.
      relevanceScore: 35
      topics:
        - safety-research
        - alignment-progress
      entities: []
    - title: Helping 1,000 small businesses build with AI
      url: https://openai.com/index/small-business-ai-jam
      sourceId: openai-blog
      publishedAt: Thu, 20 Nov 2025 06:00:00 GMT
      summary: OpenAI is partnering with DoorDash, SCORE, and local organizations to help 1,000 small businesses build with
        AI. The Small Business AI Jam gives Main Street business owners hands-on tools and training to compete and grow.
      relevanceScore: 35
      topics:
        - economic-labor
        - ai-acceleration-tradeoff
      entities: []
    - title: How Scania is accelerating work with AI across its global workforce
      url: https://openai.com/index/scania
      sourceId: openai-blog
      publishedAt: Wed, 19 Nov 2025 00:00:00 GMT
      summary: "Description: Global manufacturer Scania is scaling AI with ChatGPT Enterprise. With team-based onboarding and
        strong guardrails, AI is boosting productivity, quality, and innovation."
      relevanceScore: 35
      topics:
        - economic-labor
        - ai-acceleration-tradeoff
      entities: []
    - title: How Philips is scaling AI literacy across 70,000 employees
      url: https://openai.com/index/philips
      sourceId: openai-blog
      publishedAt: Thu, 13 Nov 2025 00:00:00 GMT
      summary: Philips is scaling AI literacy with ChatGPT Enterprise, training 70,000 employees to use AI responsibly and
        improve healthcare outcomes worldwide.
      relevanceScore: 35
      topics:
        - ai-literacy
        - responsible-ai
        - deployment
      entities:
        - deployment-architectures-table
    - title: "GPT-5.1: A smarter, more conversational ChatGPT"
      url: https://openai.com/index/gpt-5-1
      sourceId: openai-blog
      publishedAt: Wed, 12 Nov 2025 00:00:00 GMT
      summary: We’re upgrading the GPT-5 series with warmer, more capable models and new ways to customize ChatGPT’s tone and
        style. GPT-5.1 starts rolling out today to paid users.
      relevanceScore: 35
      topics:
        - capabilities
        - language-models
      entities:
        - language-models
    - title: OpenAI acquires Software Applications Incorporated, maker of Sky
      url: https://openai.com/index/openai-acquires-software-applications-incorporated
      sourceId: openai-blog
      publishedAt: Thu, 23 Oct 2025 10:00:00 GMT
      summary: OpenAI has acquired Software Applications Incorporated, maker of Sky—a natural language interface for Mac that
        brings AI directly into your desktop experience. Together, we’re integrating Sky’s deep macOS capabilities into
        ChatGPT to make AI more intuitive, contextual, and action-oriented.
      relevanceScore: 35
      topics:
        - capabilities
        - tool-use
      entities:
        - capabilities
    - title: With GPT-5, Wrtn builds lifestyle AI for millions in Korea
      url: https://openai.com/index/wrtn
      sourceId: openai-blog
      publishedAt: Thu, 02 Oct 2025 10:00:00 GMT
      summary: Wrtn scaled AI apps to 6.5M users in Korea with GPT-5, creating ‘Lifestyle AI’ that blends productivity,
        creativity, and learning—now expanding across East Asia.
      relevanceScore: 35
      topics:
        - deployment-architectures-table
        - economic-labor
        - capabilities
      entities:
        - deployment-architectures-table
    - title: Introducing parental controls
      url: https://openai.com/index/introducing-parental-controls
      sourceId: openai-blog
      publishedAt: Mon, 29 Sep 2025 03:00:00 GMT
      summary: We’re rolling out parental controls and a new parent resource page to help families guide how ChatGPT works in
        their homes.
      relevanceScore: 35
      topics:
        - safety-research
        - misuse-risks
      entities: []
    - title: Partnering with AARP to help keep older adults safe online
      url: https://openai.com/index/aarp-partnership-older-adults-online-safety
      sourceId: openai-blog
      publishedAt: Fri, 26 Sep 2025 06:00:00 GMT
      summary: OpenAI and AARP are partnering to help older adults stay safe online with new AI training, scam-spotting tools,
        and nationwide programs through OpenAI Academy and OATS’s Senior Planet initiative.
      relevanceScore: 35
      topics:
        - misuse-risks
        - safety-research
      entities: []
    - title: Introducing upgrades to Codex
      url: https://openai.com/index/introducing-upgrades-to-codex
      sourceId: openai-blog
      publishedAt: Mon, 15 Sep 2025 10:00:00 GMT
      summary: Codex just got faster, more reliable, and better at real-time collaboration and tackling tasks independently
        anywhere you develop—whether via the terminal, IDE, web, or even your phone.
      relevanceScore: 35
      topics:
        - coding
        - capabilities
      entities:
        - coding
        - capabilities
    - title: Mixi reimagines communication with ChatGPT
      url: https://openai.com/index/mixi
      sourceId: openai-blog
      publishedAt: Wed, 20 Aug 2025 17:00:00 GMT
      summary: Discover how MIXI, a leader in digital entertainment and lifestyle services in Japan, uses ChatGPT Enterprise
        to transform productivity, boost AI adoption across teams, and create a secure environment for innovation.
      relevanceScore: 35
      topics:
        - enterprise-adoption
        - productivity
      entities: []
    - title: Q&A with DoorDash’s CPO, Mariana Garavaglia
      url: https://openai.com/index/doordash-mariana-garavaglia
      sourceId: openai-blog
      publishedAt: Mon, 18 Aug 2025 00:00:00 GMT
      summary: Learn how DoorDash is scaling AI adoption to empower employees to build, learn, and innovate faster in a
        conversation with Chief People Officer Mariana Garavaglia.
      relevanceScore: 35
      topics:
        - enterprise-adoption
        - workforce
      entities:
        - economic-labor
    - title: Providing ChatGPT to the Entire U.S. Federal Workforce
      url: https://openai.com/index/providing-chatgpt-to-the-entire-us-federal-workforce
      sourceId: openai-blog
      publishedAt: Wed, 06 Aug 2025 00:00:00 GMT
      summary: Today, OpenAI for Government is announcing a new partnership with the U.S. General Services Administration
        (GSA) to launch a transformative initiative. For the next year, ChatGPT Enterprise will be available to the
        entire federal executive branch workforce at essentially no cost.
      relevanceScore: 35
      topics:
        - deployment-architectures-table
        - geopolitics
      entities:
        - deployment-architectures-table
    - title: Model ML is helping financial firms rebuild with AI from the ground up
      url: https://openai.com/index/model-ml-chaz-englander
      sourceId: openai-blog
      publishedAt: Wed, 23 Jul 2025 00:00:00 GMT
      summary: As part of our Executive Function series, Model ML CEO Chaz Englander discusses how AI-native infrastructure
        and autonomous agents are transforming financial services workflows.
      relevanceScore: 35
      topics:
        - agentic-ai
        - capabilities
      entities:
        - agentic-ai
    - title: Statement from the OpenAI Board of Directors on the Nonprofit Commission Report
      url: https://openai.com/index/nonprofit-commission-report
      sourceId: openai-blog
      publishedAt: Thu, 17 Jul 2025 00:00:00 GMT
      summary: The Board of Directors thanks the members of the independent OpenAI Nonprofit Commission for their extensive
        work and engagement.
      relevanceScore: 35
      topics:
        - alignment-progress
        - lab-behavior
      entities:
        - lab-behavior
    - title: Working with 400,000 teachers to shape the future of AI in schools
      url: https://openai.com/global-affairs/aft
      sourceId: openai-blog
      publishedAt: Tue, 08 Jul 2025 07:00:00 GMT
      summary: OpenAI partners with the American Federation of Teachers to launch a 5-year initiative equipping 400,000 K-12
        educators to lead AI innovation in classrooms.
      relevanceScore: 35
      topics:
        - education
        - ai-deployment
        - public-opinion
      entities:
        - public-opinion
    - title: Introducing data residency in Asia
      url: https://openai.com/index/introducing-data-residency-in-asia
      sourceId: openai-blog
      publishedAt: Wed, 07 May 2025 18:00:00 GMT
      summary: Data residency builds on OpenAI’s enterprise-grade data privacy, security, and compliance programs supporting
        customers worldwide.
      relevanceScore: 35
      topics:
        - governance
        - structural
      entities:
        - structural
    - title: The Washington Post partners with OpenAI on search content
      url: https://openai.com/global-affairs/the-washington-post-partners-with-openai
      sourceId: openai-blog
      publishedAt: Tue, 22 Apr 2025 06:00:00 GMT
      summary: The Washington Post is partnering with with OpenAI to integrate news into ChatGPT, providing users with
        summaries, quotes, and direct links to original reporting.
      relevanceScore: 35
      topics:
        - deployment
        - ai-applications
        - misinformation-risks
      entities:
        - disinformation-detection-race
    - title: Introducing 4o Image Generation
      url: https://openai.com/index/introducing-4o-image-generation
      sourceId: openai-blog
      publishedAt: Tue, 25 Mar 2025 11:05:00 GMT
      summary: At OpenAI, we have long believed image generation should be a primary capability of our language models. That’s
        why we’ve built our most advanced image generator yet into GPT‑4o. The result—image generation that is not only
        beautiful, but useful.
      relevanceScore: 35
      topics:
        - capabilities
        - image-generation
      entities:
        - capabilities
    - title: The court rejects Elon’s latest attempt to slow OpenAI down
      url: https://openai.com/index/court-rejects-elon
      sourceId: openai-blog
      publishedAt: Fri, 14 Mar 2025 09:00:00 GMT
      summary: We welcome the court’s March 4, 2025, decision rejecting Elon Musk’s latest attempt to slow down OpenAI for his
        personal benefit.
      relevanceScore: 35
      topics:
        - geopolitics
        - lab-behavior
      entities:
        - geopolitics
        - lab-behavior
    - title: 1,000 Scientist AI Jam Session
      url: https://openai.com/global-affairs/1000-scientist-ai-jam-session
      sourceId: openai-blog
      publishedAt: Fri, 28 Feb 2025 08:00:00 GMT
      summary: OpenAI and nine national labs bring together leading scientists for first-of-its kind event.
      relevanceScore: 35
      topics:
        - safety-research
        - scientific-research
      entities:
        - safety-research
        - scientific-research
    - title: Building an autonomous financial analyst with o1 and o3-mini
      url: https://openai.com/index/endex
      sourceId: openai-blog
      publishedAt: Thu, 27 Feb 2025 09:30:00 GMT
      summary: Endex builds the future of financial analysis, powered by OpenAI’s reasoning models.
      relevanceScore: 35
      topics:
        - reasoning
        - agentic-ai
        - deployment
      entities:
        - reasoning
        - agentic-ai
    - title: Introducing the Intelligence Age
      url: https://openai.com/global-affairs/introducing-the-intelligence-age
      sourceId: openai-blog
      publishedAt: Sun, 09 Feb 2025 22:00:00 GMT
      summary: We aired our first-ever television ad during the Super Bowl to pique people’s curiosity and help us all realize
        how AI can open up new possibilities for us, create more fulfillment in our lives, and make us more productive,
        just as all the tools that came before AI did for those who came before us.
      relevanceScore: 35
      topics:
        - public-opinion
        - ai-acceleration-tradeoff
      entities:
        - anthropic-impact
    - title: Bertelsmann powers creativity and productivity with OpenAI
      url: https://openai.com/index/bertelsmann-powers-creativity-and-productivity-with-openai
      sourceId: openai-blog
      publishedAt: Wed, 22 Jan 2025 17:00:00 GMT
      summary: Bertelsmann, the global media, services, and education company headquartered in Germany, will integrate
        OpenAI’s technology across multiple brands around the world.
      relevanceScore: 35
      topics:
        - capabilities
        - economic-labor
      entities:
        - economic-labor
    - title: Elon Musk wanted an OpenAI for-profit
      url: https://openai.com/index/elon-musk-wanted-an-openai-for-profit
      sourceId: openai-blog
      publishedAt: Fri, 13 Dec 2024 00:00:00 GMT
      summary: Elon Musk’s latest legal filing against OpenAI marks his fourth attempt in less than a year to reframe his
        claims. However, his own words and actions speak for themselves—in 2017, Elon not only wanted, but actually
        created, a for-profit as OpenAI’s proposed new structure.
      relevanceScore: 35
      topics:
        - lab-behavior
        - structural
      entities:
        - lab-behavior
        - structural
    - title: Shaping the future of financial services
      url: https://openai.com/index/morgan-stanley
      sourceId: openai-blog
      publishedAt: Wed, 04 Dec 2024 10:00:00 GMT
      summary: Morgan Stanley uses AI evals to shape the future of financial services
      relevanceScore: 35
      topics:
        - deployment
        - ai-evals
        - applications
      entities:
        - eval-types-table
    - title: New Credit Facility Enhances Financial Flexibility
      url: https://openai.com/index/new-credit-facility-enhances-financial-flexibility
      sourceId: openai-blog
      publishedAt: Thu, 03 Oct 2024 07:00:00 GMT
      summary: In addition to securing $6.6 billion in new funding from leading investors, we have established a new $4
        billion credit facility with leading banks, including JPMorgan Chase, Citi, Goldman Sachs, Morgan Stanley,
        Santander, Wells Fargo, SMBC, UBS, and HSBC.
      relevanceScore: 35
      topics:
        - compute-hardware
        - ai-megaproject-infrastructure
        - frontier-lab-cost-structure
      entities:
        - compute-hardware
        - ai-megaproject-infrastructure
        - frontier-lab-cost-structure
    - title: Introducing vision to the fine-tuning API
      url: https://openai.com/index/introducing-vision-to-the-fine-tuning-api
      sourceId: openai-blog
      publishedAt: Tue, 01 Oct 2024 10:04:00 GMT
      summary: Developers can now fine-tune GPT-4o with images and text to improve vision capabilities
      relevanceScore: 35
      topics:
        - capabilities
        - language-models
      entities:
        - language-models
        - capabilities
    - title: Fine-tuning GPT-4o webinar
      url: https://openai.com/business/fine-tuning-gpt-4o-webinar
      sourceId: openai-blog
      publishedAt: Mon, 26 Aug 2024 00:00:00 GMT
      summary: Fine-Tuning GPT-4o Webinar
      relevanceScore: 35
      topics:
        - fine-tuning
        - capabilities
        - model-development
      entities:
        - language-models
    - title: Introducing Structured Outputs in the API
      url: https://openai.com/index/introducing-structured-outputs-in-the-api
      sourceId: openai-blog
      publishedAt: Tue, 06 Aug 2024 10:00:00 GMT
      summary: We are introducing Structured Outputs in the API—model outputs now reliably adhere to developer-supplied JSON
        Schemas.
      relevanceScore: 35
      topics:
        - capabilities
        - model-development
        - tool-use
      entities:
        - tool-use
        - language-models
    - title: Consistency Models
      url: https://openai.com/index/consistency-models
      sourceId: openai-blog
      publishedAt: Thu, 20 Jun 2024 00:00:00 GMT
      summary: Diffusion models have significantly advanced the fields of image, audio, and video generation, but they depend
        on an iterative sampling process that causes slow generation.
      relevanceScore: 35
      topics:
        - model-development
        - generative-models
        - capabilities
      entities:
        - language-models
    - title: Using GPT-4o reasoning to transform cancer care
      url: https://openai.com/index/color-health
      sourceId: openai-blog
      publishedAt: Mon, 17 Jun 2024 04:15:00 GMT
      summary: Color Health is working with OpenAI to pioneer a new way of accelerating cancer patients’ access to treatment.
        Their new Cancer Copilot application uses GPT-4o to identify missing diagnostics and create tailored workup
        plans, enabling healthcare providers to make evidence-based decisions about cancer screening and treatment.
      relevanceScore: 35
      topics:
        - capabilities
        - scientific-research
      entities:
        - capabilities
        - scientific-research
    - title: "The Newsroom AI Catalyst: a global program with WAN-IFRA"
      url: https://openai.com/index/newsroom-ai-catalyst-global-program-with-wan-ifra
      sourceId: openai-blog
      publishedAt: Wed, 29 May 2024 08:00:00 GMT
      summary: We’re collaborating with WAN-IFRA, the World Association of News Publishers, to launch a global accelerator
        program that will assist over 100 news publishers to explore and integrate AI in their newsroom.
      relevanceScore: 35
      topics:
        - capabilities
        - misuse-risks
      entities:
        - capabilities
        - misuse-risks
    - title: API Partnership with Stack Overflow
      url: https://openai.com/index/api-partnership-with-stack-overflow
      sourceId: openai-blog
      publishedAt: Mon, 06 May 2024 00:00:00 GMT
      summary: API Partnership with Stack Overflow Stack Overflow and OpenAI today announced a new API partnership that will
        empower developers with the collective strengths of the world’s leading knowledge platform for highly technical
        content with the world’s most popular LLM models for AI development.
      relevanceScore: 35
      topics:
        - deployment
        - capabilities
        - tool-use
      entities:
        - tool-use
    - title: GPT-4 API general availability and deprecation of older models in the Completions API
      url: https://openai.com/index/gpt-4-api-general-availability
      sourceId: openai-blog
      publishedAt: Wed, 24 Apr 2024 00:00:00 GMT
      summary: GPT-3.5 Turbo, DALL·E and Whisper APIs are also generally available, and we are releasing a deprecation plan
        for older models of the Completions API, which will retire at the beginning of 2024.
      relevanceScore: 35
      topics:
        - deployment
        - capabilities
      entities:
        - language-models
    - title: Introducing improvements to the fine-tuning API and expanding our custom models program
      url: https://openai.com/index/introducing-improvements-to-the-fine-tuning-api-and-expanding-our-custom-models-program
      sourceId: openai-blog
      publishedAt: Thu, 04 Apr 2024 00:00:00 GMT
      summary: We’re adding new features to help developers have more control over fine-tuning and announcing new ways to
        build custom models with OpenAI.
      relevanceScore: 35
      topics:
        - deployment
        - capabilities
      entities: []
    - title: Reducing health insurance costs and improving care
      url: https://openai.com/index/oscar
      sourceId: openai-blog
      publishedAt: Mon, 01 Apr 2024 00:00:00 GMT
      summary: Oscar brings AI to health insurance, reducing costs and improving patient care.
      relevanceScore: 35
      topics:
        - deployment
        - capabilities
      entities: []
    - title: Embedding AI into developer software
      url: https://openai.com/index/jetbrains
      sourceId: openai-blog
      publishedAt: Thu, 21 Mar 2024 07:00:00 GMT
      summary: JetBrains uses OpenAI’s API to build its fastest-growing product ever.
      relevanceScore: 35
      topics:
        - deployment
        - capabilities
        - tool-use
      entities:
        - tool-use
    - title: Enterprise-ready trust and safety
      url: https://openai.com/index/salesforce
      sourceId: openai-blog
      publishedAt: Mon, 18 Mar 2024 07:00:00 GMT
      summary: Salesforce integrates OpenAI’s enterprise-ready LLMs to transform customer applications.
      relevanceScore: 35
      topics:
        - deployment
        - capabilities
      entities: []
    - title: Memory and new controls for ChatGPT
      url: https://openai.com/index/memory-and-new-controls-for-chatgpt
      sourceId: openai-blog
      publishedAt: Tue, 13 Feb 2024 00:00:00 GMT
      summary: We’re testing the ability for ChatGPT to remember things you discuss to make future chats more helpful. You’re
        in control of ChatGPT’s memory.
      relevanceScore: 35
      topics:
        - capabilities
      entities:
        - capabilities
    - title: OpenAI announces leadership transition
      url: https://openai.com/index/openai-announces-leadership-transition
      sourceId: openai-blog
      publishedAt: Fri, 17 Nov 2023 08:00:00 GMT
      summary: ""
      relevanceScore: 35
      topics:
        - lab-behavior
      entities:
        - lab-behavior
    - title: Simplifying contract reviews with AI
      url: https://openai.com/index/ironclad
      sourceId: openai-blog
      publishedAt: Wed, 11 Oct 2023 07:00:00 GMT
      summary: Ironclad uses GPT-4 to simplify the contract review process.
      relevanceScore: 35
      topics:
        - language-models
        - tool-use
        - capabilities
      entities:
        - language-models
    - title: OpenAI partners with Scale to provide support for enterprises fine-tuning models
      url: https://openai.com/index/openai-partners-with-scale-to-provide-support-for-enterprises-fine-tuning-models
      sourceId: openai-blog
      publishedAt: Thu, 24 Aug 2023 07:00:00 GMT
      summary: OpenAI’s customers can leverage Scale’s AI expertise to customize our most advanced models.
      relevanceScore: 35
      topics:
        - capabilities
        - tool-use
      entities:
        - language-models
    - title: GPT-3.5 Turbo fine-tuning and API updates
      url: https://openai.com/index/gpt-3-5-turbo-fine-tuning-and-api-updates
      sourceId: openai-blog
      publishedAt: Tue, 22 Aug 2023 07:00:00 GMT
      summary: Developers can now bring their own data to customize GPT-3.5 Turbo for their use cases.
      relevanceScore: 35
      topics:
        - capabilities
        - language-models
      entities:
        - language-models
    - title: Partnership with American Journalism Project to support local news
      url: https://openai.com/index/partnership-with-american-journalism-project-to-support-local-news
      sourceId: openai-blog
      publishedAt: Tue, 18 Jul 2023 07:00:00 GMT
      summary: A new $5+ million partnership aims to explore ways the development of artificial intelligence (AI) can support
        a thriving, innovative local news field, and ensure local news organizations shape the future of this emerging
        technology.
      relevanceScore: 35
      topics:
        - capabilities
        - misuse-risks
      entities:
        - language-models
    - title: Function calling and other API updates
      url: https://openai.com/index/function-calling-and-other-api-updates
      sourceId: openai-blog
      publishedAt: Tue, 13 Jun 2023 07:00:00 GMT
      summary: We’re announcing updates including more steerable API models, function calling capabilities, longer context,
        and lower prices.
      relevanceScore: 35
      topics:
        - capabilities
        - language-models
      entities:
        - language-models
    - title: New ways to manage your data in ChatGPT
      url: https://openai.com/index/new-ways-to-manage-your-data-in-chatgpt
      sourceId: openai-blog
      publishedAt: Tue, 25 Apr 2023 07:00:00 GMT
      summary: ChatGPT users can now turn off chat history, allowing you to choose which conversations can be used to train
        our models.
      relevanceScore: 35
      topics:
        - data-governance
        - privacy
        - training-data
      entities: []
    - title: Introducing Whisper
      url: https://openai.com/index/whisper
      sourceId: openai-blog
      publishedAt: Wed, 21 Sep 2022 07:00:00 GMT
      summary: We’ve trained and are open-sourcing a neural net called Whisper that approaches human level robustness and
        accuracy on English speech recognition.
      relevanceScore: 35
      topics:
        - capabilities
        - language-models
      entities:
        - language-models
    - title: Text and code embeddings by contrastive pre-training
      url: https://openai.com/index/text-and-code-embeddings-by-contrastive-pre-training
      sourceId: openai-blog
      publishedAt: Mon, 24 Jan 2022 08:00:00 GMT
      summary: ""
      relevanceScore: 35
      topics:
        - capabilities
        - language-models
      entities:
        - language-models
    - title: "Introducing Triton: Open-source GPU programming for neural networks"
      url: https://openai.com/index/triton
      sourceId: openai-blog
      publishedAt: Wed, 28 Jul 2021 07:00:00 GMT
      summary: We’re releasing Triton 1.0, an open-source Python-like programming language which enables researchers with no
        CUDA experience to write highly efficient GPU code—most of the time on par with what an expert would be able to
        produce.
      relevanceScore: 35
      topics:
        - compute-hardware
        - capabilities
      entities:
        - compute-hardware
    - title: Organizational update from OpenAI
      url: https://openai.com/index/organizational-update
      sourceId: openai-blog
      publishedAt: Tue, 29 Dec 2020 08:00:00 GMT
      summary: It’s been a year of dramatic change and growth at OpenAI.
      relevanceScore: 35
      topics:
        - lab-behavior
      entities:
        - lab-behavior
    - title: Dota 2 with large scale deep reinforcement learning
      url: https://openai.com/index/dota-2-with-large-scale-deep-reinforcement-learning
      sourceId: openai-blog
      publishedAt: Fri, 13 Dec 2019 08:00:00 GMT
      summary: ""
      relevanceScore: 35
      topics:
        - reinforcement-learning
        - capabilities
      entities:
        - capabilities
    - title: "The International 2018: Results"
      url: https://openai.com/index/the-international-2018-results
      sourceId: openai-blog
      publishedAt: Thu, 23 Aug 2018 07:00:00 GMT
      summary: OpenAI Five lost two games against top Dota 2 players at The International in Vancouver this week, maintaining
        a good chance of winning for the first 20–35 minutes of both games.
      relevanceScore: 35
      topics:
        - game-playing
        - dota
        - benchmarks
      entities: []
    - title: OpenAI Five Benchmark
      url: https://openai.com/index/openai-five-benchmark
      sourceId: openai-blog
      publishedAt: Wed, 18 Jul 2018 07:00:00 GMT
      summary: The OpenAI Five Benchmark match is now over!
      relevanceScore: 35
      topics:
        - game-playing
        - dota
        - benchmarks
      entities: []
    - title: OpenAI Fellows Fall 2018
      url: https://openai.com/index/openai-fellows
      sourceId: openai-blog
      publishedAt: Wed, 30 May 2018 07:00:00 GMT
      summary: We’re now accepting applications for the next cohort of OpenAI Fellows, a program which offers a compensated
        6-month apprenticeship in AI research at OpenAI.
      relevanceScore: 35
      topics:
        - lab-behavior
        - ai-talent-market-dynamics
      entities:
        - lab-behavior
    - title: Variance reduction for policy gradient with action-dependent factorized baselines
      url: https://openai.com/index/variance-reduction-for-policy-gradient-with-action-dependent-factorized-baselines
      sourceId: openai-blog
      publishedAt: Tue, 20 Mar 2018 07:00:00 GMT
      summary: ""
      relevanceScore: 35
      topics:
        - capabilities
      entities:
        - capabilities
    - title: On first-order meta-learning algorithms
      url: https://openai.com/index/on-first-order-meta-learning-algorithms
      sourceId: openai-blog
      publishedAt: Thu, 08 Mar 2018 08:00:00 GMT
      summary: ""
      relevanceScore: 35
      topics:
        - capabilities
      entities:
        - capabilities
    - title: OpenAI Scholars
      url: https://openai.com/index/openai-scholars
      sourceId: openai-blog
      publishedAt: Tue, 06 Mar 2018 08:00:00 GMT
      summary: We’re providing 6–10 stipends and mentorship to individuals from underrepresented groups to study deep learning
        full-time for 3 months and open-source a project.
      relevanceScore: 35
      topics:
        - lab-behavior
        - ai-talent-market-dynamics
      entities:
        - lab-behavior
    - title: Nonlinear computation in deep linear networks
      url: https://openai.com/index/nonlinear-computation-in-deep-linear-networks
      sourceId: openai-blog
      publishedAt: Fri, 29 Sep 2017 07:00:00 GMT
      summary: ""
      relevanceScore: 35
      topics:
        - deep-learning
        - neural-networks
        - architecture
      entities:
        - architecture-scenarios-table
    - title: "OpenAI Baselines: ACKTR & A2C"
      url: https://openai.com/index/openai-baselines-acktr-a2c
      sourceId: openai-blog
      publishedAt: Fri, 18 Aug 2017 07:00:00 GMT
      summary: "We’re releasing two new OpenAI Baselines implementations: ACKTR and A2C. A2C is a synchronous, deterministic
        variant of Asynchronous Advantage Actor Critic (A3C) which we’ve found gives equal performance. ACKTR is a more
        sample-efficient reinforcement learning algorithm than TRPO and A2C, and requires only slightly more computation
        than A2C per update."
      relevanceScore: 35
      topics:
        - reinforcement-learning
        - algorithms
        - baselines
      entities: []
    - title: UCB exploration via Q-ensembles
      url: https://openai.com/index/ucb-exploration-via-q-ensembles
      sourceId: openai-blog
      publishedAt: Mon, 05 Jun 2017 07:00:00 GMT
      summary: ""
      relevanceScore: 35
      topics:
        - reinforcement-learning
        - exploration
        - algorithms
      entities: []
    - title: "OpenAI Baselines: DQN"
      url: https://openai.com/index/openai-baselines-dqn
      sourceId: openai-blog
      publishedAt: Wed, 24 May 2017 07:00:00 GMT
      summary: We’re open-sourcing OpenAI Baselines, our internal effort to reproduce reinforcement learning algorithms with
        performance on par with published results. We’ll release the algorithms over upcoming months; today’s release
        includes DQN and three of its variants.
      relevanceScore: 35
      topics:
        - reinforcement-learning
        - deep-q-learning
        - baselines
      entities: []
    - title: Equivalence between policy gradients and soft Q-learning
      url: https://openai.com/index/equivalence-between-policy-gradients-and-soft-q-learning
      sourceId: openai-blog
      publishedAt: Fri, 21 Apr 2017 07:00:00 GMT
      summary: ""
      relevanceScore: 35
      topics:
        - reinforcement-learning
        - policy-gradients
        - q-learning
      entities: []
    - title: Distill
      url: https://openai.com/index/distill
      sourceId: openai-blog
      publishedAt: Mon, 20 Mar 2017 07:00:00 GMT
      summary: We’re excited to support today’s launch of Distill, a new kind of journal aimed at excellent communication of
        machine learning results (novel or existing).
      relevanceScore: 35
      topics:
        - scientific-research
        - machine-learning
      entities: []
    - title: Third-person imitation learning
      url: https://openai.com/index/third-person-imitation-learning
      sourceId: openai-blog
      publishedAt: Mon, 06 Mar 2017 08:00:00 GMT
      summary: ""
      relevanceScore: 35
      topics:
        - learning
        - imitation
      entities: []
    - title: A connection between generative adversarial networks, inverse reinforcement learning, and energy-based models
      url: https://openai.com/index/a-connection-between-generative-adversarial-networks-inverse-reinforcement-learning-and-energy-based-models
      sourceId: openai-blog
      publishedAt: Fri, 11 Nov 2016 08:00:00 GMT
      summary: ""
      relevanceScore: 35
      topics:
        - generative-models
        - inverse-reinforcement-learning
      entities: []
    - title: Semi-supervised knowledge transfer for deep learning from private training data
      url: https://openai.com/index/semi-supervised-knowledge-transfer-for-deep-learning-from-private-training-data
      sourceId: openai-blog
      publishedAt: Tue, 18 Oct 2016 07:00:00 GMT
      summary: ""
      relevanceScore: 35
      topics:
        - privacy
        - learning
      entities: []
    - title: Machine Learning Unconference
      url: https://openai.com/index/machine-learning-unconference
      sourceId: openai-blog
      publishedAt: Thu, 18 Aug 2016 07:00:00 GMT
      summary: The latest information about the Unconference is now available at the Unconference wiki, which will be
        periodically updated with more information for attendees.
      relevanceScore: 35
      topics:
        - community
        - scientific-research
      entities: []
    - title: Generative models
      url: https://openai.com/index/generative-models
      sourceId: openai-blog
      publishedAt: Thu, 16 Jun 2016 07:00:00 GMT
      summary: "This post describes four projects that share a common theme of enhancing or using generative models, a branch
        of unsupervised learning techniques in machine learning. In addition to describing our work, this post will tell
        you a bit more about generative models: what they are, why they are important, and where they might be going."
      relevanceScore: 35
      topics:
        - generative-models
        - unsupervised-learning
      entities: []
    - title: "Weight normalization: A simple reparameterization to accelerate training of deep neural networks"
      url: https://openai.com/index/weight-normalization
      sourceId: openai-blog
      publishedAt: Thu, 25 Feb 2016 08:00:00 GMT
      summary: ""
      relevanceScore: 35
      topics:
        - deep-learning-era
        - capabilities
      entities:
        - deep-learning-era
    - title: "Project Genie: Experimenting with infinite, interactive worlds"
      url: https://deepmind.google/blog/project-genie-experimenting-with-infinite-interactive-worlds/
      sourceId: deepmind-blog
      publishedAt: Thu, 29 Jan 2026 17:01:05 +0000
      summary: Google AI Ultra subscribers in the U.S. can try out Project Genie, an experimental research prototype that lets
        you create and explore worlds.
      relevanceScore: 35
      topics:
        - world-models
        - capabilities
      entities:
        - world-models
    - title: "Google's year in review: 8 areas with research breakthroughs in 2025"
      url: https://deepmind.google/blog/googles-year-in-review-8-areas-with-research-breakthroughs-in-2025/
      sourceId: deepmind-blog
      publishedAt: Tue, 23 Dec 2025 17:01:02 +0000
      summary: "Google 2025 recap: Research breakthroughs of the year"
      relevanceScore: 35
      topics:
        - capabilities
        - scientific-research
      entities:
        - scientific-research
    - title: "WeatherNext 2: Our most advanced weather forecasting model"
      url: https://deepmind.google/blog/weathernext-2-our-most-advanced-weather-forecasting-model/
      sourceId: deepmind-blog
      publishedAt: Mon, 17 Nov 2025 15:09:23 +0000
      summary: The new AI model delivers more efficient, more accurate and higher-resolution global weather predictions.
      relevanceScore: 35
      topics:
        - capabilities
        - scientific-research
      entities:
        - capabilities
        - scientific-research
    - title: Using AI to perceive the universe in greater depth
      url: https://deepmind.google/blog/using-ai-to-perceive-the-universe-in-greater-depth/
      sourceId: deepmind-blog
      publishedAt: Fri, 24 Oct 2025 02:21:07 +0000
      summary: Using AI to perceive the universe in greater depth
      relevanceScore: 35
      topics:
        - capabilities
      entities:
        - capabilities
    - title: Introducing Veo 3.1 and advanced creative capabilities
      url: https://deepmind.google/blog/introducing-veo-31-and-advanced-creative-capabilities/
      sourceId: deepmind-blog
      publishedAt: Thu, 23 Oct 2025 18:38:55 +0000
      summary: We’re rolling out significant updates to Veo that give people even more creative control.
      relevanceScore: 35
      topics:
        - generative-models
        - capabilities
      entities:
        - capabilities
    - title: Generate videos in Gemini and Whisk with Veo 2
      url: https://deepmind.google/blog/generate-videos-in-gemini-and-whisk-with-veo-2/
      sourceId: deepmind-blog
      publishedAt: Tue, 15 Apr 2025 17:00:00 +0000
      summary: Transform text-based prompts into high-resolution eight-second videos in Gemini Advanced and use Whisk Animate
        to turn images into eight-second animated clips.
      relevanceScore: 35
      topics:
        - generative-models
        - capabilities
      entities:
        - capabilities
    - title: State-of-the-art video and image generation with Veo 2 and Imagen 3
      url: https://deepmind.google/blog/state-of-the-art-video-and-image-generation-with-veo-2-and-imagen-3/
      sourceId: deepmind-blog
      publishedAt: Mon, 16 Dec 2024 17:01:16 +0000
      summary: We’re rolling out a new, state-of-the-art video model, Veo 2, and updates to Imagen 3. Plus, check out our new
        experiment, Whisk.
      relevanceScore: 35
      topics:
        - capabilities
        - tool-use
      entities:
        - tool-use
    - title: Everything We Announced at Our First-Ever LlamaCon
      url: https://ai.meta.com/blog/llamacon-llama-news/
      sourceId: meta-ai-blog
      publishedAt: 2026-02-19
      summary: "  A comprehensive roundup of everything announced at LlamaCon, including how to get started with Meta's newest
        releases."
      relevanceScore: 35
      topics:
        - capabilities
        - language-models
      entities:
        - language-models
    - title: "Todd, Ord, Galef, Yudkowsky: German Podcast Sums Up EA/LW Books"
      url: https://www.lesswrong.com/posts/pWqby3gmfxgL95M5u/todd-ord-galef-yudkowsky-german-podcast-sums-up-ea-lw-books
      sourceId: lesswrong
      publishedAt: Wed, 18 Feb 2026 23:58:29 GMT
      summary: "Published on February 18, 2026 9:44 PM GMTIf you understand German and these books are still on your reading
        list, here’s a convenient way to get familiar with their contents. On Buchdialoge.de, I publish 15-minute
        podcasts on non-fiction books. Instead of a dry monologue, we use a casual dialogue format to summarize the
        contents, accompanied by a short article presenting the key points. Our episodes with an EA / LessWrong
        background include: Benjamin Todd – 80,000 Hours Eliezer Yudkowsky & Nate"
      relevanceScore: 35
      topics:
        - expert-opinion
        - ai-safety-community
      entities:
        - expert-opinion
    - title: Towards Efficient Constraint Handling in Neural Solvers for Routing Problems
      url: https://arxiv.org/abs/2602.16012
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16012v1 Announce Type: new Abstract: Neural solvers have achieved impressive progress in addressing
        simple routing problems, particularly excelling in computational efficiency. However, their advantages under
        complex constraints remain nascent, for which current constraint-handling schemes via feasibility masking or
        implicit feasibility awareness can be inefficient or inapplicable for hard constraints. In this paper, we
        present Construct-and-Refine (CaR), the first general and efficie"
      relevanceScore: 35
      topics:
        - agentic-ai
        - tool-use
      entities:
        - agentic-ai
    - title: "Evidence-Grounded Subspecialty Reasoning: Evaluating a Curated Clinical Intelligence Layer on the 2025
        Endocrinology Board-Style Examination"
      url: https://arxiv.org/abs/2602.16050
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16050v1 Announce Type: new Abstract: Background: Large language models have demonstrated strong
        performance on general medical examinations, but subspecialty clinical reasoning remains challenging due to
        rapidly evolving guidelines and nuanced evidence hierarchies. Methods: We evaluated January Mirror, an
        evidence-grounded clinical reasoning system, against frontier LLMs (GPT-5, GPT-5.2, Gemini-3-Pro) on a
        120-question endocrinology board-style examination. Mirror integrates a curated"
      relevanceScore: 35
      topics:
        - language-models
        - capabilities
      entities:
        - language-models
    - title: Causally-Guided Automated Feature Engineering with Multi-Agent Reinforcement Learning
      url: https://arxiv.org/abs/2602.16435
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16435v1 Announce Type: new Abstract: Automated feature engineering (AFE) enables AI systems to
        autonomously construct high-utility representations from raw tabular data. However, existing AFE methods rely on
        statistical heuristics, yielding brittle features that fail under distribution shift. We introduce CAFE, a
        framework that reformulates AFE as a causally-guided sequential decision process, bridging causal discovery with
        reinforcement learning-driven feature construction. Phase I l"
      relevanceScore: 35
      topics:
        - automated-reasoning
        - multi-agent-systems
        - feature-engineering
      entities:
        - agentic-ai
        - reasoning
    - title: "The Perplexity Paradox: Why Code Compresses Better Than Math in LLM Prompts"
      url: https://arxiv.org/abs/2602.15843
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: 'arXiv:2602.15843v1 Announce Type: cross Abstract: In "Compress or Route?" (Johnson, 2026), we found that code
        generation tolerates aggressive prompt compression (r >= 0.6) while chain-of-thought reasoning degrades
        gradually. That study was limited to HumanEval (164 problems), left the "perplexity paradox" mechanism
        unvalidated, and provided no adaptive algorithm. This paper addresses all three gaps. First, we validate across
        six code benchmarks (HumanEval, MBPP, HumanEval+, MultiPL-E) and four r'
      relevanceScore: 35
      topics:
        - language-models
        - reasoning
        - prompt-engineering
      entities:
        - language-models
        - reasoning
    - title: Preference Optimization for Review Question Generation Improves Writing Quality
      url: https://arxiv.org/abs/2602.15849
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15849v1 Announce Type: cross Abstract: Peer review relies on substantive, evidence-based questions,
        yet existing LLM-based approaches often generate surface-level queries, drawing over 50\\% of their question
        tokens from a paper's first page. To bridge this gap, we develop IntelliReward, a novel reward model built from
        a frozen autoregressive LLM with trainable multi-head transformers over the final 50 token states, which
        outperforms API-based SFT baselines in predicting expert-level h"
      relevanceScore: 35
      topics:
        - language-models
        - preference-optimization
        - quality-control
      entities:
        - language-models
    - title: "Rethinking Soft Compression in Retrieval-Augmented Generation: A Query-Conditioned Selector Perspective"
      url: https://arxiv.org/abs/2602.15856
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15856v1 Announce Type: cross Abstract: Retrieval-Augmented Generation (RAG) effectively grounds
        Large Language Models (LLMs) with external knowledge and is widely applied to Web-related tasks. However, its
        scalability is hindered by excessive context length and redundant retrievals. Recent research on soft context
        compression aims to address this by encoding long documents into compact embeddings, yet they often underperform
        non-compressed RAG due to their reliance on auto-encoder-lik"
      relevanceScore: 35
      topics:
        - language-models
        - retrieval-augmented-generation
      entities:
        - language-models
    - title: "Playing With AI: How Do State-Of-The-Art Large Language Models Perform in the 1977 Text-Based Adventure Game
        Zork?"
      url: https://arxiv.org/abs/2602.15867
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15867v1 Announce Type: cross Abstract: In this positioning paper, we evaluate the problem-solving
        and reasoning capabilities of contemporary Large Language Models (LLMs) through their performance in Zork, the
        seminal text-based adventure game first released in 1977. The game's dialogue-based structure provides a
        controlled environment for assessing how LLM-based chatbots interpret natural language descriptions and generate
        appropriate action sequences to succeed in the game. We test t"
      relevanceScore: 35
      topics:
        - language-models
        - reasoning
        - problem-solving
      entities:
        - language-models
        - reasoning
    - title: "Fly0: Decoupling Semantic Grounding from Geometric Planning for Zero-Shot Aerial Navigation"
      url: https://arxiv.org/abs/2602.15875
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15875v1 Announce Type: cross Abstract: Current Visual-Language Navigation (VLN) methodologies face
        a trade-off between semantic understanding and control precision. While Multimodal Large Language Models (MLLMs)
        offer superior reasoning, deploying them as low-level controllers leads to high latency, trajectory
        oscillations, and poor generalization due to weak geometric grounding. To address these limitations, we propose
        Fly0, a framework that decouples semantic reasoning from geometri"
      relevanceScore: 35
      topics:
        - language-models
        - autonomous-navigation
        - robotics
      entities:
        - language-models
        - agentic-ai
    - title: "Foundation Models for Medical Imaging: Status, Challenges, and Directions"
      url: https://arxiv.org/abs/2602.15913
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15913v1 Announce Type: cross Abstract: Foundation models (FMs) are rapidly reshaping medical
        imaging, shifting the field from narrowly trained, task-specific networks toward large, general-purpose models
        that can be adapted across modalities, anatomies, and clinical tasks. In this review, we synthesize the emerging
        landscape of medical imaging FMs along three major axes: principles of FM design, applications of FMs, and
        forward-looking challenges and opportunities. Taken together, thi"
      relevanceScore: 35
      topics:
        - foundation-models
        - capabilities
        - medical-ai
      entities:
        - capabilities
    - title: "MaS-VQA: A Mask-and-Select Framework for Knowledge-Based Visual Question Answering"
      url: https://arxiv.org/abs/2602.15915
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15915v1 Announce Type: cross Abstract: Knowledge-based Visual Question Answering (KB-VQA) requires
        models to answer questions by integrating visual information with external knowledge. However, retrieved
        knowledge is often noisy, partially irrelevant, or misaligned with the visual content, while internal model
        knowledge is difficult to control and interpret. Naive aggregation of these sources limits reasoning
        effectiveness and reduces answer accuracy. To address this, we propose MaS-V"
      relevanceScore: 35
      topics:
        - vision-language-models
        - reasoning
        - knowledge-integration
      entities:
        - reasoning
    - title: "MedProbCLIP: Probabilistic Adaptation of Vision-Language Foundation Model for Reliable Radiograph-Report
        Retrieval"
      url: https://arxiv.org/abs/2602.16019
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16019v1 Announce Type: cross Abstract: Vision-language foundation models have emerged as powerful
        general-purpose representation learners with strong potential for multimodal understanding, but their
        deterministic embeddings often fail to provide the reliability required for high-stakes biomedical applications.
        This work introduces MedProbCLIP, a probabilistic vision-language learning framework for chest X-ray and
        radiology report representation learning and bidirectional retrieval. M"
      relevanceScore: 35
      topics:
        - vision-language-models
        - medical-ai
        - reliability
      entities: []
    - title: Federated Graph AGI for Cross-Border Insider Threat Intelligence in Government Financial Schemes
      url: https://arxiv.org/abs/2602.16109
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16109v1 Announce Type: cross Abstract: Cross-border insider threats pose a critical challenge to
        government financial schemes, particularly when dealing with distributed, privacy-sensitive data across multiple
        jurisdictions. Existing approaches face fundamental limitations: they cannot effectively share intelligence
        across borders due to privacy constraints, lack reasoning capabilities to understand complex multi-step attack
        patterns, and fail to capture intricate graph-structured rel"
      relevanceScore: 35
      topics:
        - agentic-ai
        - misuse-risks
      entities:
        - agentic-ai
        - misuse-risks
    - title: "SIT-LMPC: Safe Information-Theoretic Learning Model Predictive Control for Iterative Tasks"
      url: https://arxiv.org/abs/2602.16187
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16187v1 Announce Type: cross Abstract: Robots executing iterative tasks in complex, uncertain
        environments require control strategies that balance robustness, safety, and high performance. This paper
        introduces a safe information-theoretic learning model predictive control (SIT-LMPC) algorithm for iterative
        tasks. Specifically, we design an iterative control framework based on an information-theoretic model predictive
        control algorithm to address a constrained infinite-horizon optimal"
      relevanceScore: 35
      topics:
        - safety-research
      entities:
        - safety-research
    - title: Graphon Mean-Field Subsampling for Cooperative Heterogeneous Multi-Agent Reinforcement Learning
      url: https://arxiv.org/abs/2602.16196
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16196v1 Announce Type: cross Abstract: Coordinating large populations of interacting agents is a
        central challenge in multi-agent reinforcement learning (MARL), where the size of the joint state-action space
        scales exponentially with the number of agents. Mean-field methods alleviate this burden by aggregating agent
        interactions, but these approaches assume homogeneous interactions. Recent graphon-based frameworks capture
        heterogeneity, but are computationally expensive as the number "
      relevanceScore: 35
      topics:
        - agentic-ai
        - multi-actor-landscape
      entities:
        - agentic-ai
    - title: "Generative AI Usage of University Students: Navigating Between Education and Business"
      url: https://arxiv.org/abs/2602.16307
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16307v1 Announce Type: cross Abstract: This study investigates generative artificial intelligence
        (GenAI) usage of university students who study alongside their professional career. Previous literature has paid
        little attention to part-time students and the intersectional use of GenAI between education and business. This
        study examines with a grounded theory approach the characteristics of GenAI usage of part-time students. Eleven
        students from a distance learning university were inte"
      relevanceScore: 35
      topics:
        - language-models
        - public-opinion
      entities:
        - language-models
        - public-opinion
    - title: "HAWX: A Hardware-Aware FrameWork for Fast and Scalable ApproXimation of DNNs"
      url: https://arxiv.org/abs/2602.16336
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16336v1 Announce Type: cross Abstract: This work presents HAWX, a hardware-aware scalable
        exploration framework that employs multi-level sensitivity scoring at different DNN abstraction levels
        (operator, filter, layer, and model) to guide selective integration of heterogeneous AxC blocks. Supported by
        predictive models for accuracy, power, and area, HAWX accelerates the evaluation of candidate configurations,
        achieving over 23* speedup in a layer-level search with two candidate approx"
      relevanceScore: 35
      topics:
        - compute-hardware
        - capabilities
      entities:
        - compute-hardware
    - title: "From Growing to Looping: A Unified View of Iterative Computation in LLMs"
      url: https://arxiv.org/abs/2602.16490
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16490v1 Announce Type: cross Abstract: Looping, reusing a block of layers across depth, and depth
        growing, training shallow-to-deep models by duplicating middle layers, have both been linked to stronger
        reasoning, but their relationship remains unclear. We provide a mechanistic unification: looped and depth-grown
        models exhibit convergent depth-wise signatures, including increased reliance on late layers and recurring
        patterns aligned with the looped or grown block. These shared signa"
      relevanceScore: 35
      topics:
        - language-models
        - architecture-scenarios-table
      entities:
        - language-models
        - architecture-scenarios-table
    - title: Almost Sure Convergence of Differential Temporal Difference Learning for Average Reward Markov Decision Processes
      url: https://arxiv.org/abs/2602.16629
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16629v1 Announce Type: cross Abstract: The average reward is a fundamental performance metric in
        reinforcement learning (RL) focusing on the long-run performance of an agent. Differential temporal difference
        (TD) learning algorithms are a major advance for average reward RL as they provide an efficient online method to
        learn the value functions associated with the average reward in both on-policy and off-policy settings. However,
        existing convergence guarantees require a local clock i"
      relevanceScore: 35
      topics:
        - reasoning
        - long-horizon
      entities:
        - reasoning
        - long-horizon
    - title: Scalable Precise Computation of Shannon Entropy
      url: https://arxiv.org/abs/2502.01160
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2502.01160v3 Announce Type: replace Abstract: Quantitative information flow analyses (QIF) are a class
        of techniques for measuring the amount of confidential information leaked by a program to its public outputs.
        Shannon entropy is an important method to quantify the amount of leakage in QIF. This paper focuses on the
        programs modeled in Boolean constraints and optimizes the two stages of the Shannon entropy computation to
        implement a scalable precise tool PSE. In the first stage, we desig"
      relevanceScore: 35
      topics:
        - interpretability-sufficient
      entities: []
    - title: "MC-LLaVA: Multi-Concept Personalized Vision-Language Model"
      url: https://arxiv.org/abs/2411.11706
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2411.11706v4 Announce Type: replace-cross Abstract: Current vision-language models (VLMs) show
        exceptional abilities across diverse tasks, such as visual question answering. To enhance user experience,
        recent studies have investigated VLM personalization to understand user-provided concepts. However, they mainly
        focus on single concepts, neglecting the existence and interplay of multiple concepts, which limits real-world
        applicability. This paper proposes MC-LLaVA, a multi-concept personal"
      relevanceScore: 35
      topics:
        - language-models
      entities:
        - language-models
    - title: Adaptive Rank Allocation for Federated Parameter-Efficient Fine-Tuning of Language Models
      url: https://arxiv.org/abs/2501.14406
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2501.14406v4 Announce Type: replace-cross Abstract: Pre-trained Language Models (PLMs) have demonstrated
        their superiority and versatility in modern Natural Language Processing (NLP), effectively adapting to various
        downstream tasks through further fine-tuning. Federated Parameter-Efficient Fine-Tuning (FedPEFT) has emerged as
        a promising solution to address privacy and efficiency challenges in distributed training for PLMs on
        resource-constrained local devices. However, our measurements r"
      relevanceScore: 35
      topics:
        - language-models
      entities:
        - language-models
    - title: "Forget Forgetting: Continual Learning in a World of Abundant Memory"
      url: https://arxiv.org/abs/2502.07274
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: 'arXiv:2502.07274v5 Announce Type: replace-cross Abstract: Continual learning (CL) has traditionally focused on
        minimizing exemplar memory, a constraint often misaligned with modern systems where GPU time, not storage, is
        the primary bottleneck. This paper challenges this paradigm by investigating a more realistic regime: one where
        memory is abundant enough to mitigate forgetting, but full retraining from scratch remains prohibitively
        expensive. In this practical "middle ground", we find that the'
      relevanceScore: 35
      topics:
        - continual-learning
        - memory-efficiency
      entities: []
    - title: "FindAnything: Open-Vocabulary and Object-Centric Mapping for Robot Exploration in Any Environment"
      url: https://arxiv.org/abs/2504.08603
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2504.08603v3 Announce Type: replace-cross Abstract: Geometrically accurate and semantically expressive
        map representations have proven invaluable for robot deployment and task planning in unknown environments.
        Nevertheless, real-time, open-vocabulary semantic understanding of large-scale unknown environments still
        presents open challenges, mainly due to computational requirements. In this paper we present FindAnything, an
        open-world mapping framework that incorporates vision-language infor"
      relevanceScore: 35
      topics:
        - robotics
        - embodied-ai
        - vision
      entities:
        - agentic-ai
    - title: "FreqPolicy: Efficient Flow-based Visuomotor Policy via Frequency Consistency"
      url: https://arxiv.org/abs/2506.08822
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2506.08822v2 Announce Type: replace-cross Abstract: Generative modeling-based visuomotor policies have
        been widely adopted in robotic manipulation, attributed to their ability to model multimodal action
        distributions. However, the high inference cost of multi-step sampling limits its applicability in real-time
        robotic systems. Existing approaches accelerate sampling in generative modeling-based visuomotor policies by
        adapting techniques originally developed to speed up image generation. Ho"
      relevanceScore: 35
      topics:
        - robotics
        - visuomotor-control
        - generative-models
      entities:
        - agentic-ai
    - title: "CreativityPrism: A Holistic Evaluation Framework for Large Language Model Creativity"
      url: https://arxiv.org/abs/2510.20091
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2510.20091v2 Announce Type: replace-cross Abstract: Creativity is often seen as a hallmark of human
        intelligence. While large language models (LLMs) are increasingly perceived as generating creative text, there
        is still no holistic and scalable framework to evaluate their creativity across diverse scenarios. Existing
        methods of LLM creativity evaluation either heavily rely on humans, limiting speed and scalability, or are
        fragmented across different domains and different definitions of cre"
      relevanceScore: 35
      topics:
        - language-models
        - evaluation
        - capabilities
      entities:
        - language-models
        - capabilities
    - title: "StableQAT: Stable Quantization-Aware Training at Ultra-Low Bitwidths"
      url: https://arxiv.org/abs/2601.19320
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2601.19320v2 Announce Type: replace-cross Abstract: Quantization-aware training (QAT) is essential for
        deploying large models under strict memory and latency constraints, yet achieving stable and robust optimization
        at ultra-low bitwidths remains challenging. Common approaches based on the straight-through estimator (STE) or
        soft quantizers often suffer from gradient mismatch, instability, or high computational overhead. As such, we
        propose StableQAT, a unified and efficient QAT framework "
      relevanceScore: 35
      topics:
        - quantization
        - model-compression
        - efficiency
      entities:
        - compute-hardware
    - title: Arming Data Agents with Tribal Knowledge
      url: https://arxiv.org/abs/2602.13521
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.13521v2 Announce Type: replace-cross Abstract: Natural language to SQL (NL2SQL) translation enables
        non-expert users to query relational databases through natural language. Recently, NL2SQL agents, powered by the
        reasoning capabilities of Large Language Models (LLMs), have significantly advanced NL2SQL translation.
        Nonetheless, NL2SQL agents still make mistakes when faced with large-scale real-world databases because they
        lack knowledge of how to correctly leverage the underlying data"
      relevanceScore: 35
      topics:
        - language-models
        - tool-use
        - databases
      entities:
        - tool-use
    - title: "Far Out: Evaluating Language Models on Slang in Australian and Indian English"
      url: https://arxiv.org/abs/2602.15373
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15373v2 Announce Type: replace-cross Abstract: Language models exhibit systematic performance gaps
        when processing text in non-standard language varieties, yet their ability to comprehend variety-specific slang
        remains underexplored for several languages. We present a comprehensive evaluation of slang awareness in Indian
        English (en-IN) and Australian English (en-AU) across seven state-of-the-art language models. We construct two
        complementary datasets: WEB, containing 377 web-sourced"
      relevanceScore: 35
      topics:
        - language-models
        - evaluation
        - robustness
        - capabilities
      entities:
        - language-models
        - capabilities
    - title: Gated Tree Cross-attention for Checkpoint-Compatible Syntax Injection in Decoder-Only LLMs
      url: https://arxiv.org/abs/2602.15846
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15846v1 Announce Type: new Abstract: Decoder-only large language models achieve strong broad
        performance but are brittle to minor grammatical perturbations, undermining reliability for downstream
        reasoning. However, directly injecting explicit syntactic structure into an existing checkpoint can interfere
        with its pretrained competence. We introduce a checkpoint-compatible gated tree cross-attention (GTCA) branch
        that reads precomputed constituency chunk memory while leaving backbone a"
      relevanceScore: 35
      topics:
        - LLM robustness
        - grammar
        - reliability
      entities:
        - language-models
    - title: The Validity of Coreference-based Evaluations of Natural Language Understanding
      url: https://arxiv.org/abs/2602.16200
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16200v1 Announce Type: new Abstract: In this thesis, I refine our understanding as to what
        conclusions we can reach from coreference-based evaluations by expanding existing evaluation practices and
        considering the extent to which evaluation results are either converging or conflicting. First, I analyze
        standard coreference evaluations and show that their design often leads to non-generalizable conclusions due to
        issues of measurement validity - including contestedness (multiple, compe"
      relevanceScore: 35
      topics:
        - NLU evaluation
        - coreference
      entities:
        - language-models
    - title: "Utility-Preserving De-Identification for Math Tutoring: Investigating Numeric Ambiguity in the MathEd-PII
        Benchmark Dataset"
      url: https://arxiv.org/abs/2602.16571
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16571v1 Announce Type: new Abstract: Large-scale sharing of dialogue-based data is instrumental for
        advancing the science of teaching and learning, yet rigorous de-identification remains a major barrier. In
        mathematics tutoring transcripts, numeric expressions frequently resemble structured identifiers (e.g., dates or
        IDs), leading generic Personally Identifiable Information (PII) detection systems to over-redact core
        instructional content and reduce dataset utility. This work asks ho"
      relevanceScore: 35
      topics:
        - language-models
        - privacy
        - safety
      entities:
        - language-models
    - title: "ModalImmune: Immunity Driven Unlearning via Self Destructive Training"
      url: https://arxiv.org/abs/2602.16197
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16197v1 Announce Type: cross Abstract: Multimodal systems are vulnerable to partial or complete
        loss of input channels at deployment, which undermines reliability in real-world settings. This paper presents
        ModalImmune, a training framework that enforces modality immunity by intentionally and controllably collapsing
        selected modality information during training so the model learns joint representations that are robust to
        destructive modality influence. The framework combines a spectru"
      relevanceScore: 35
      topics:
        - language-models
        - robustness
        - safety
      entities:
        - language-models
    - title: "When Algorithms Meet Artists: Semantic Compression of Artists' Concerns in the Public AI-Art Debate"
      url: https://arxiv.org/abs/2508.03037
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2508.03037v4 Announce Type: replace Abstract: Artists occupy a paradoxical position in generative AI:
        their work trains the models reshaping creative labor. We tested whether their concerns achieve proportional
        representation in public discourse shaping AI governance. Analyzing public AI-art discourse (news, podcasts,
        legal filings, research; 2013--2025) and projecting 1,259 survey-derived artist statements into this semantic
        space, we find stark compression: 95% of artist concerns cluster"
      relevanceScore: 35
      topics:
        - language-models
        - misuse-risks
        - societal-impact
      entities:
        - language-models
        - misuse-risks
    - title: Embedding Inversion via Conditional Masked Diffusion Language Models
      url: https://arxiv.org/abs/2602.11047
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.11047v3 Announce Type: replace Abstract: We frame embedding inversion as conditional masked
        diffusion, recovering all tokens in parallel through iterative denoising rather than sequential autoregressive
        generation. A masked diffusion language model is conditioned on the target embedding via adaptive layer
        normalization, requiring only 8 forward passes with no access to the target encoder at inference time. On
        32-token sequences across three embedding models, the method achieves token "
      relevanceScore: 35
      topics:
        - language-models
        - embeddings
        - technical-methods
      entities:
        - language-models
    - title: Verifier-Constrained Flow Expansion for Discovery Beyond the Data
      url: https://arxiv.org/abs/2602.15984
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15984v1 Announce Type: new Abstract: Flow and diffusion models are typically pre-trained on limited
        available data (e.g., molecular samples), covering only a fraction of the valid design space (e.g., the full
        molecular space). As a consequence, they tend to generate samples from only a narrow portion of the feasible
        domain. This is a fundamental limitation for scientific discovery applications, where one typically aims to
        sample valid designs beyond the available data distribution. To"
      relevanceScore: 35
      topics:
        - generative-models
        - diffusion-models
        - discovery
      entities: []
    - title: Investigating GNN Convergence on Large Randomly Generated Graphs with Realistic Node Feature Correlations
      url: https://arxiv.org/abs/2602.16145
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16145v1 Announce Type: new Abstract: There are a number of existing studies analysing the
        convergence behaviour of graph neural networks on large random graphs. Unfortunately, the majority of these
        studies do not model correlations between node features, which would naturally exist in a variety of real-life
        networks. Consequently, the derived limitations of GNNs, resulting from such convergence behaviour, is not truly
        reflective of the expressive power of GNNs when applied to realisti"
      relevanceScore: 35
      topics:
        - graph-neural-networks
        - convergence-analysis
      entities: []
    - title: "Towards Secure and Scalable Energy Theft Detection: A Federated Learning Approach for Resource-Constrained Smart
        Meters"
      url: https://arxiv.org/abs/2602.16181
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16181v1 Announce Type: new Abstract: Energy theft poses a significant threat to the stability and
        efficiency of smart grids, leading to substantial economic losses and operational challenges. Traditional
        centralized machine learning approaches for theft detection require aggregating user data, raising serious
        concerns about privacy and data security. These issues are further exacerbated in smart meter environments,
        where devices are often resource-constrained and lack the capacity to "
      relevanceScore: 35
      topics:
        - federated-learning
        - privacy
        - security
      entities: []
    - title: Fast KV Compaction via Attention Matching
      url: https://arxiv.org/abs/2602.16284
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16284v1 Announce Type: new Abstract: Scaling language models to long contexts is often bottlenecked
        by the size of the key-value (KV) cache. In deployed settings, long contexts are typically managed through
        compaction in token space via summarization. However, summarization can be highly lossy, substantially harming
        downstream performance. Recent work on Cartridges has shown that it is possible to train highly compact KV
        caches in latent space that closely match full-context performan"
      relevanceScore: 35
      topics:
        - language-models
        - efficiency
        - attention-mechanisms
        - long-context
      entities:
        - language-models
        - long-horizon
    - title: Learning with Locally Private Examples by Inverse Weierstrass Private Stochastic Gradient Descent
      url: https://arxiv.org/abs/2602.16436
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16436v1 Announce Type: new Abstract: Releasing data once and for all under noninteractive Local
        Differential Privacy (LDP) enables complete data reusability, but the resulting noise may create bias in
        subsequent analyses. In this work, we leverage the Weierstrass transform to characterize this bias in binary
        classification. We prove that inverting this transform leads to a bias-correction method to compute unbiased
        estimates of nonlinear functions on examples released under LDP. We th"
      relevanceScore: 35
      topics:
        - privacy
        - differential-privacy
        - machine-learning
      entities: []
    - title: Protecting the Undeleted in Machine Unlearning
      url: https://arxiv.org/abs/2602.16697
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: 'arXiv:2602.16697v1 Announce Type: new Abstract: Machine unlearning aims to remove specific data points from a
        trained model, often striving to emulate "perfect retraining", i.e., producing the model that would have been
        obtained had the deleted data never been included. We demonstrate that this approach, and security definitions
        that enable it, carry significant privacy risks for the remaining (undeleted) data points. We present a
        reconstruction attack showing that for certain tasks, which can b'
      relevanceScore: 35
      topics:
        - machine-unlearning
        - data-privacy
        - alignment
        - safety
      entities:
        - safety-research
    - title: World Action Models are Zero-shot Policies
      url: https://arxiv.org/abs/2602.15922
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15922v1 Announce Type: cross Abstract: State-of-the-art Vision-Language-Action (VLA) models excel
        at semantic generalization but struggle to generalize to unseen physical motions in novel environments. We
        introduce DreamZero, a World Action Model (WAM) built upon a pretrained video diffusion backbone. Unlike VLAs,
        WAMs learn physical dynamics by predicting future world states and actions, using video as a dense
        representation of how the world evolves. By jointly modeling video and act"
      relevanceScore: 35
      topics:
        - vision-language-models
        - world-models
        - generalization
        - robotics
      entities:
        - world-models
        - agentic-ai
    - title: The Limits of Long-Context Reasoning in Automated Bug Fixing
      url: https://arxiv.org/abs/2602.16069
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16069v1 Announce Type: cross Abstract: Rapidly increasing context lengths have led to the
        assumption that large language models (LLMs) can directly reason over entire codebases. Concurrently, recent
        advances in LLMs have enabled strong performance on software engineering benchmarks, particularly when paired
        with agentic workflows. In this work, we systematically evaluate whether current LLMs can reliably perform
        long-context code debugging and patch generation. Using SWE-bench Verifie"
      relevanceScore: 35
      topics:
        - llm
        - long-context
        - reasoning
        - code-generation
        - limitations
      entities:
        - long-horizon
        - reasoning
        - language-models
    - title: Functional Decomposition and Shapley Interactions for Interpreting Survival Models
      url: https://arxiv.org/abs/2602.16505
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16505v1 Announce Type: cross Abstract: Hazard and survival functions are natural, interpretable
        targets in time-to-event prediction, but their inherent non-additivity fundamentally limits standard additive
        explanation methods. We introduce Survival Functional Decomposition (SurvFD), a principled approach for
        analyzing feature interactions in machine learning survival models. By decomposing higher-order effects into
        time-dependent and time-independent components, SurvFD offers a previo"
      relevanceScore: 35
      topics:
        - interpretability-sufficient
      entities:
        - interpretability-sufficient
    - title: "Learning Distributed Equilibria in Linear-Quadratic Stochastic Differential Games: An $\\alpha$-Potential
        Approach"
      url: https://arxiv.org/abs/2602.16555
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16555v1 Announce Type: cross Abstract: We analyze independent policy-gradient (PG) learning in
        $N$-player linear-quadratic (LQ) stochastic differential games. Each player employs a distributed policy that
        depends only on its own state and updates the policy independently using the gradient of its own objective. We
        establish global linear convergence of these methods to an equilibrium by showing that the LQ game admits an
        $\\alpha$-potential structure, with $\\alpha$ determined by the de"
      relevanceScore: 35
      topics:
        - agentic-ai
        - multipolar-competition
      entities:
        - agentic-ai
        - multipolar-competition
    - title: "SoK: Data Minimization in Machine Learning"
      url: https://arxiv.org/abs/2508.10836
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2508.10836v2 Announce Type: replace Abstract: Data minimization (DM) describes the principle of
        collecting only the data strictly necessary for a given task. It is a foundational principle across major data
        protection regulations like GDPR and CPRA. Violations of this principle have substantial real-world
        consequences, with regulatory actions resulting in fines reaching hundreds of millions of dollars. Notably, the
        relevance of data minimization is particularly pronounced in machine learni"
      relevanceScore: 35
      topics:
        - data-minimization
        - privacy
        - machine-learning
      entities:
        - safety-research
    - title: Synthesizing High-Quality Visual Question Answering from Medical Documents with Generator-Verifier LMMs
      url: https://arxiv.org/abs/2510.25867
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2510.25867v2 Announce Type: replace Abstract: Large Multimodal Models (LMMs) are increasingly capable of
        answering medical questions that require joint reasoning over images and text, yet training general medical VQA
        systems is impeded by the lack of large, openly usable, high-quality corpora. We present MedVLSynther, a
        rubric-guided generator-verifier framework that synthesizes high-quality multiple-choice VQA items directly from
        open biomedical literature by conditioning on figures, capt"
      relevanceScore: 35
      topics:
        - multimodal-models
        - medical-ai
        - question-answering
      entities: []
    - title: High entropy leads to symmetry equivariant policies in Dec-POMDPs
      url: https://arxiv.org/abs/2511.22581
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2511.22581v2 Announce Type: replace Abstract: We prove that in any Dec-POMDP, sufficiently high entropy
        regularization ensures that policy gradient ascent with tabular softmax parametrization always converges, for
        any initialization, to the same joint policy, and that this joint policy is equivariant w.r.t. all symmetries of
        the Dec-POMDP. In particular, policies coming from different random seeds will be fully compatible, in that
        their cross-play returns are equal to their self-play retur"
      relevanceScore: 35
      topics:
        - multi-agent-reinforcement-learning
        - policy-gradient
      entities: []
    - title: "VerifiableFL: Verifiable Claims for Federated Learning using Exclaves"
      url: https://arxiv.org/abs/2412.10537
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2412.10537v4 Announce Type: replace-cross Abstract: In federated learning (FL), data providers jointly
        train a machine learning model without sharing their training data. This makes it challenging to provide
        verifiable claims about the trained FL model, e.g., related to the employed training data, any data
        sanitization, or the correct training algorithm-a malicious data provider can simply deviate from the correct
        training protocol without detection. While prior FL training systems have ex"
      relevanceScore: 35
      topics:
        - federated-learning
        - privacy
        - verification
      entities: []
    - title: Logarithmic-time Schedules for Scaling Language Models with Momentum
      url: https://arxiv.org/abs/2602.05298
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.05298v2 Announce Type: replace-cross Abstract: In practice, the hyperparameters $(\\beta_1,
        \\beta_2)$ and weight-decay $\\lambda$ in AdamW are typically kept at fixed values. Is there any reason to do
        otherwise? We show that for large-scale language model training, the answer is yes: by exploiting the power-law
        structure of language data, one can design time-varying schedules for $(\\beta_1, \\beta_2, \\lambda)$ that
        deliver substantial performance gains. We study logarithmic-time scheduli"
      relevanceScore: 35
      topics:
        - language-models
        - training
        - optimization
        - scaling
      entities:
        - language-models
        - scaling-debate
    - title: "Learning Gradient Flow: Using Equation Discovery to Accelerate Engineering Optimization"
      url: https://arxiv.org/abs/2602.13513
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.13513v2 Announce Type: replace-cross Abstract: In this work, we investigate the use of data-driven
        equation discovery for dynamical systems to model and forecast continuous-time dynamics of unconstrained
        optimization problems. To avoid expensive evaluations of the objective function and its gradient, we leverage
        trajectory data on the optimization variables to learn the continuous-time dynamics associated with gradient
        descent, Newton's method, and ADAM optimization. The discovered gr"
      relevanceScore: 35
      topics:
        - machine-learning
        - optimization
        - equation-discovery
      entities:
        - __index__/knowledge-base/capabilities
    - title: Synthesis and Verification of Transformer Programs
      url: https://arxiv.org/abs/2602.16473
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16473v1 Announce Type: new Abstract: C-RASP is a simple programming language that was recently
        shown to capture concepts expressible by transformers. In this paper, we develop new algorithmic techniques for
        automatically verifying C-RASPs. To this end, we establish a connection to the verification of synchronous
        dataflow programs in Lustre, which enables us to exploit state-of-the-art model checkers utilizing highly
        optimized SMT-solvers. Our second contribution addresses learning a C"
      relevanceScore: 32
      topics:
        - transformers
        - program-synthesis
        - interpretability
        - verification
      entities:
        - interpretability-sufficient
    - title: Testing ads in ChatGPT
      url: https://openai.com/index/testing-ads-in-chatgpt
      sourceId: openai-blog
      publishedAt: Mon, 09 Feb 2026 11:00:00 GMT
      summary: OpenAI begins testing ads in ChatGPT to support free access, with clear labeling, answer independence, strong
        privacy protections, and user control.
      relevanceScore: 30
      topics:
        - deployment
        - economic-labor
      entities: []
    - title: VfL Wolfsburg turns ChatGPT into a club-wide capability
      url: https://openai.com/index/vfl-wolfsburg
      sourceId: openai-blog
      publishedAt: Wed, 04 Feb 2026 00:00:00 GMT
      summary: By focusing on people, not pilots, the Bundesliga club is scaling efficiency, creativity, and knowledge—without
        losing its football identity.
      relevanceScore: 30
      topics:
        - deployment
        - economic-labor
      entities:
        - economic-labor
    - title: Taisei Corporation shapes the next generation of talent with ChatGPT
      url: https://openai.com/index/taisei
      sourceId: openai-blog
      publishedAt: Thu, 29 Jan 2026 00:00:00 GMT
      summary: Taisei Corporation uses ChatGPT Enterprise to support HR-led talent development and scale generative AI across
        its global construction business.
      relevanceScore: 30
      topics:
        - deployment
        - economic-labor
      entities:
        - economic-labor
    - title: PVH reimagines the future of fashion with OpenAI
      url: https://openai.com/index/pvh-future-of-fashion
      sourceId: openai-blog
      publishedAt: Tue, 27 Jan 2026 06:00:00 GMT
      summary: PVH Corp., parent company of Calvin Klein and Tommy Hilfiger, is adopting ChatGPT Enterprise to bring AI into
        fashion design, supply chain, and consumer engagement.
      relevanceScore: 30
      topics:
        - deployment
        - economic-labor
      entities:
        - economic-labor
    - title: Inside Praktika's conversational approach to language learning
      url: https://openai.com/index/praktika
      sourceId: openai-blog
      publishedAt: Thu, 22 Jan 2026 05:00:00 GMT
      summary: How Praktika uses GPT-4.1 and GPT-5.2 to build adaptive AI tutors that personalize lessons, track progress, and
        help learners achieve real-world language fluency
      relevanceScore: 30
      topics:
        - language-models
        - capabilities
      entities:
        - language-models
    - title: AI for self empowerment
      url: https://openai.com/index/ai-for-self-empowerment
      sourceId: openai-blog
      publishedAt: Sun, 18 Jan 2026 12:00:00 GMT
      summary: How AI can expand human agency by closing the capability overhang—helping people, businesses, and countries
        unlock real productivity, growth, and opportunity.
      relevanceScore: 30
      topics:
        - capabilities
        - economic-labor
      entities:
        - capabilities
    - title: Introducing ChatGPT Go, now available worldwide
      url: https://openai.com/index/introducing-chatgpt-go
      sourceId: openai-blog
      publishedAt: Fri, 16 Jan 2026 00:00:00 GMT
      summary: ChatGPT Go is now available worldwide, offering expanded access to GPT-5.2 Instant, higher usage limits, and
        longer memory—making advanced AI more affordable globally.
      relevanceScore: 30
      topics:
        - capabilities
      entities:
        - capabilities
    - title: Announcing OpenAI Grove Cohort 2
      url: https://openai.com/index/openai-grove
      sourceId: openai-blog
      publishedAt: Fri, 02 Jan 2026 10:00:00 GMT
      summary: Applications are now open for OpenAI Grove Cohort 2, a 5-week founder program designed for individuals at any
        stage, from pre-idea to product. Participants receive $50K in API credits, early access to AI tools, and
        hands-on mentorship from the OpenAI team.
      relevanceScore: 30
      topics:
        - agi-development
        - capabilities
      entities:
        - agi-development
    - title: Introducing OpenAI Academy for News Organizations
      url: https://openai.com/index/openai-academy-for-news-organizations
      sourceId: openai-blog
      publishedAt: Wed, 17 Dec 2025 06:00:00 GMT
      summary: OpenAI is launching the OpenAI Academy for News Organizations, a new learning hub built with the American
        Journalism Project and The Lenfest Institute to help newsrooms use AI effectively. The Academy offers training,
        practical use cases, and responsible-use guidance to support journalists, editors, and publishers as they adopt
        AI in their reporting and operations.
      relevanceScore: 30
      topics:
        - public-opinion
        - deployment
      entities:
        - public-opinion
    - title: The new ChatGPT Images is here
      url: https://openai.com/index/new-chatgpt-images-is-here
      sourceId: openai-blog
      publishedAt: Tue, 16 Dec 2025 00:00:00 GMT
      summary: The new ChatGPT Images is powered by our flagship image generation model, delivering more precise edits,
        consistent details, and image generation up to 4× faster. The upgraded model is rolling out to all ChatGPT users
        today and is also available in the API as GPT-Image-1.5.
      relevanceScore: 30
      topics:
        - capabilities
      entities:
        - capabilities
    - title: Increasing revenue 300% by bringing AI to SMBs
      url: https://openai.com/index/podium
      sourceId: openai-blog
      publishedAt: Thu, 11 Dec 2025 00:00:00 GMT
      summary: Discover how Podium used OpenAI’s GPT-5 to build “Jerry,” an AI teammate driving 300% growth and transforming
        how Main Street businesses serve customers.
      relevanceScore: 30
      topics:
        - deployment
        - economic-labor
      entities:
        - economic-labor
    - title: Bringing powerful AI to millions across Europe with Deutsche Telekom
      url: https://openai.com/index/deutsche-telekom-collaboration
      sourceId: openai-blog
      publishedAt: Tue, 09 Dec 2025 00:00:00 GMT
      summary: OpenAI is collaborating with Deutsche Telekom to bring advanced, multilingual AI experiences to millions of
        people across Europe. ChatGPT Enterprise will also be deployed to help employees at Deutsche Telekom improve
        workflows and accelerate innovation.
      relevanceScore: 30
      topics:
        - deployment
        - geopolitics
      entities:
        - geopolitics
    - title: Instacart and OpenAI partner on AI shopping experiences
      url: https://openai.com/index/instacart-partnership
      sourceId: openai-blog
      publishedAt: Mon, 08 Dec 2025 06:00:00 GMT
      summary: OpenAI and Instacart are deepening their longstanding partnership by bringing the first fully integrated
        grocery shopping and Instant Checkout payment app to ChatGPT.
      relevanceScore: 30
      topics:
        - deployment
        - tool-use
      entities:
        - tool-use
    - title: OpenAI named Emerging Leader in Generative AI
      url: https://openai.com/index/gartner-2025-emerging-leader
      sourceId: openai-blog
      publishedAt: Mon, 17 Nov 2025 10:00:00 GMT
      summary: OpenAI has been named an Emerging Leader in Gartner’s 2025 Innovation Guide for Generative AI Model Providers.
        The recognition reflects our enterprise momentum, with over 1 million companies building with ChatGPT.
      relevanceScore: 30
      topics:
        - capabilities
        - expert-opinion
      entities: []
    - title: Work smarter with your company knowledge in ChatGPT
      url: https://openai.com/index/introducing-company-knowledge
      sourceId: openai-blog
      publishedAt: Thu, 23 Oct 2025 00:00:00 GMT
      summary: Company knowledge brings context from your apps into ChatGPT for answers specific to your business, with clear
        citations, security, privacy, and admin controls. Available now for Business, Enterprise, and Edu users.
      relevanceScore: 30
      topics:
        - deployment-architectures-table
        - economic-labor
      entities:
        - deployment-architectures-table
    - title: "Buy it in ChatGPT: Instant Checkout and the Agentic Commerce Protocol"
      url: https://openai.com/index/buy-it-in-chatgpt
      sourceId: openai-blog
      publishedAt: Mon, 29 Sep 2025 00:00:00 GMT
      summary: We’re taking first steps toward agentic commerce in ChatGPT with new ways for people, AI agents, and businesses
        to shop together.
      relevanceScore: 30
      topics:
        - agentic-ai
        - tool-use
      entities:
        - agentic-ai
    - title: Transforming the manufacturing industry with ChatGPT
      url: https://openai.com/index/eneos-materials
      sourceId: openai-blog
      publishedAt: Wed, 24 Sep 2025 17:00:00 GMT
      summary: By deploying ChatGPT Enterprise, ENEOS Materials transformed operations with faster research, safer plant
        design, and streamlined HR processes. Over 80% of employees report major workflow improvements, strengthening
        competitiveness in manufacturing.
      relevanceScore: 30
      topics:
        - capabilities
        - lab-behavior
      entities:
        - capabilities
    - title: How people are using ChatGPT
      url: https://openai.com/index/how-people-are-using-chatgpt
      sourceId: openai-blog
      publishedAt: Mon, 15 Sep 2025 03:00:00 GMT
      summary: New research from the largest study of ChatGPT use shows how the tool creates economic value through both
        personal and professional use. Adoption is broadening beyond early users, closing gaps and making AI a part of
        everyday life.
      relevanceScore: 30
      topics:
        - capabilities
        - economic-labor
      entities:
        - capabilities
        - economic-labor
    - title: Three lessons for creating a sustainable AI advantage
      url: https://openai.com/index/intercom
      sourceId: openai-blog
      publishedAt: Wed, 30 Jul 2025 00:00:00 GMT
      summary: Discover how Intercom built a scalable AI platform with 3 key lessons—from evaluations to architecture—to lead
        the future of customer support.
      relevanceScore: 30
      topics:
        - capabilities
        - safety-research
      entities: []
    - title: A $50 million fund to build with communities
      url: https://openai.com/index/50-million-fund-to-build-with-communities
      sourceId: openai-blog
      publishedAt: Fri, 18 Jul 2025 00:00:00 GMT
      summary: OpenAI is launching an initial $50 million fund that supports nonprofit and community organizations, informed
        by the independent OpenAI Nonprofit Commission report.
      relevanceScore: 30
      topics:
        - safety-research
        - alignment-progress
      entities:
        - safety-research
    - title: Intellectual freedom by design
      url: https://openai.com/global-affairs/intellectual-freedom-by-design
      sourceId: openai-blog
      publishedAt: Tue, 15 Jul 2025 00:00:00 GMT
      summary: ChatGPT is designed to be useful, trustworthy, and adaptable—so you can make it your own.
      relevanceScore: 30
      topics:
        - alignment-progress
        - safety-research
      entities:
        - safety-research
    - title: AI in Australia—OpenAI’s Economic Blueprint
      url: https://openai.com/global-affairs/openais-australia-economic-blueprint
      sourceId: openai-blog
      publishedAt: Mon, 30 Jun 2025 07:00:00 GMT
      summary: Today, OpenAI, in partnership with Mandala Partners, is sharing the OpenAI AI Economic Blueprint for Australia.
        At a time when boosting productivity has emerged as a national priority for Australia, the Blueprint provides a
        clear, actionable plan for how Australia can unlock the full economic and social potential of artificial
        intelligence.
      relevanceScore: 30
      topics:
        - economic-labor
        - geopolitics
      entities:
        - economic-labor
        - geopolitics
    - title: "Introducing AI stories: daily benefits shine a light on bigger opportunities"
      url: https://openai.com/global-affairs/ai-stories-daily-benefits-bigger-opportunities
      sourceId: openai-blog
      publishedAt: Tue, 06 May 2025 10:30:00 GMT
      summary: Sam Altman has written that we are entering the Intelligence Age, a time when AI will help people become
        dramatically more capable. The biggest problems of today—across science, medicine, education, national
        defense—will no longer seem intractable, but will in fact be solvable. New horizons of possibility and
        prosperity will open up.
      relevanceScore: 30
      topics:
        - capabilities
        - public-opinion
      entities:
        - capabilities
        - public-opinion
    - title: AI helps John Deere transform agriculture
      url: https://openai.com/index/john-deere-justin-rose
      sourceId: openai-blog
      publishedAt: Tue, 06 May 2025 00:00:00 GMT
      summary: John Deere’s Justin Rose talks about transforming agriculture with AI and shares how the company is scaling
        innovation to help farmers work smarter, more efficiently, and sustainably.
      relevanceScore: 30
      topics:
        - capabilities
        - economic-labor
      entities:
        - capabilities
        - economic-labor
    - title: Introducing our latest image generation model in the API
      url: https://openai.com/index/image-generation-api
      sourceId: openai-blog
      publishedAt: Wed, 23 Apr 2025 10:00:00 GMT
      summary: Our latest image generation model is now available in the API via ‘gpt-image-1’—enabling developers and
        businesses to build professional-grade, customizable visuals directly into their own tools and platforms.
      relevanceScore: 30
      topics:
        - capabilities
        - image-generation
      entities:
        - capabilities
    - title: Scaling the OpenAI Academy
      url: https://openai.com/global-affairs/scaling-the-openai-academy
      sourceId: openai-blog
      publishedAt: Tue, 25 Mar 2025 07:00:00 GMT
      summary: Online resource hub will support AI literacy and help people from all backgrounds access tools, best practices,
        and peer insights to use AI.
      relevanceScore: 30
      topics:
        - ai-literacy
        - education
      entities: []
    - title: Estonia and OpenAI to bring ChatGPT to schools nationwide
      url: https://openai.com/index/estonia-schools-and-chatgpt
      sourceId: openai-blog
      publishedAt: Tue, 25 Feb 2025 04:15:00 GMT
      summary: Estonia and OpenAI to bring ChatGPT to schools nationwide. OpenAI will work with the Estonian Government to
        provide students and teachers in the secondary school system with access to ChatGPT Edu.
      relevanceScore: 30
      topics:
        - deployment
        - public-opinion
      entities:
        - deployment
        - public-opinion
    - title: Introducing ChatGPT Pro
      url: https://openai.com/index/introducing-chatgpt-pro
      sourceId: openai-blog
      publishedAt: Thu, 05 Dec 2024 10:30:00 GMT
      summary: Broadening usage of frontier AI
      relevanceScore: 30
      topics:
        - deployment
        - commercialization
        - frontier-models
      entities:
        - capabilities
    - title: Introducing ChatGPT search
      url: https://openai.com/index/introducing-chatgpt-search
      sourceId: openai-blog
      publishedAt: Thu, 31 Oct 2024 10:00:00 GMT
      summary: Get fast, timely answers with links to relevant web sources
      relevanceScore: 30
      topics:
        - capabilities
        - deployment
      entities:
        - capabilities
    - title: Introducing the Realtime API
      url: https://openai.com/index/introducing-the-realtime-api
      sourceId: openai-blog
      publishedAt: Tue, 01 Oct 2024 10:05:00 GMT
      summary: Developers can now build fast speech-to-speech experiences into their applications
      relevanceScore: 30
      topics:
        - capabilities
        - tool-use
      entities:
        - tool-use
    - title: Genmab launches “AI Everywhere”
      url: https://openai.com/index/genmab
      sourceId: openai-blog
      publishedAt: Thu, 19 Sep 2024 04:00:00 GMT
      summary: Genmab embraces ChatGPT Enterprise, supported by OpenAI’s commitment to security and privacy
      relevanceScore: 30
      topics:
        - safety-research
        - lab-behavior
      entities:
        - lab-behavior
    - title: SearchGPT is a prototype of new AI search features
      url: https://openai.com/index/searchgpt-prototype
      sourceId: openai-blog
      publishedAt: Thu, 25 Jul 2024 00:00:00 GMT
      summary: We’re testing SearchGPT, a temporary prototype of new search features that give you fast and timely answers
        with clear and relevant sources.
      relevanceScore: 30
      topics:
        - capabilities
        - search
        - deployment
      entities:
        - language-models
    - title: OpenAI welcomes Sarah Friar (CFO) and Kevin Weil (CPO)
      url: https://openai.com/index/openai-welcomes-cfo-cpo
      sourceId: openai-blog
      publishedAt: Mon, 10 Jun 2024 10:30:00 GMT
      summary: OpenAI welcomes Sarah Friar (CFO) and Kevin Weil (CPO)
      relevanceScore: 30
      topics:
        - lab-behavior
      entities:
        - lab-behavior
    - title: Introducing OpenAI for Nonprofits
      url: https://openai.com/index/introducing-openai-for-nonprofits
      sourceId: openai-blog
      publishedAt: Thu, 30 May 2024 07:00:00 GMT
      summary: We’re launching a new initiative to enhance the accessibility of our tools for nonprofit organizations,
        including discounted rates for ChatGPT Team and Enterprise.
      relevanceScore: 30
      topics:
        - capabilities
      entities:
        - capabilities
    - title: OpenAI for Education
      url: https://openai.com/index/introducing-chatgpt-edu
      sourceId: openai-blog
      publishedAt: Thu, 30 May 2024 07:00:00 GMT
      summary: An affordable offering for universities to responsibly bring AI to campus.
      relevanceScore: 30
      topics:
        - capabilities
      entities:
        - capabilities
    - title: Enhancing news in ChatGPT with The Atlantic
      url: https://openai.com/index/enhancing-news-in-chatgpt-with-the-atlantic
      sourceId: openai-blog
      publishedAt: Wed, 29 May 2024 07:30:00 GMT
      summary: The Atlantic is announcing a strategic content and product partnership with OpenAI, which positions The
        Atlantic as a premium news source within OpenAI. The Atlantic’s articles will be discoverable within OpenAI’s
        products, including ChatGPT, and as a partner, The Atlantic will help to shape how news is surfaced and
        presented in future real-time discovery products.
      relevanceScore: 30
      topics:
        - capabilities
      entities:
        - capabilities
    - title: A Content and Product Partnership with Vox Media
      url: https://openai.com/index/a-content-and-product-partnership-with-vox-media
      sourceId: openai-blog
      publishedAt: Wed, 29 May 2024 07:00:00 GMT
      summary: In a multi-faceted agreement, Vox Media’s content will enhance the output of OpenAI’s ChatGPT, and the company
        will build on OpenAI’s technology to develop products to better serve its audiences and advertisers.
      relevanceScore: 30
      topics:
        - capabilities
      entities:
        - capabilities
    - title: A landmark multi-year global partnership with News Corp
      url: https://openai.com/index/news-corp-and-openai-sign-landmark-multi-year-global-partnership
      sourceId: openai-blog
      publishedAt: Wed, 22 May 2024 13:15:00 GMT
      summary: Companies Join Forces to Enrich OpenAI’s Generative AI Products and Platforms with Premium Journalism
      relevanceScore: 30
      topics:
        - capabilities
      entities:
        - capabilities
    - title: Accelerating the development of life-saving treatments
      url: https://openai.com/index/moderna
      sourceId: openai-blog
      publishedAt: Wed, 24 Apr 2024 00:00:00 GMT
      summary: Accelerating the development of life-saving treatments.
      relevanceScore: 30
      topics:
        - deployment
        - capabilities
        - scientific-research
      entities:
        - scientific-research
    - title: Customizing models for legal professionals
      url: https://openai.com/index/harvey
      sourceId: openai-blog
      publishedAt: Tue, 02 Apr 2024 00:00:00 GMT
      summary: Harvey partners with OpenAI to build a custom-trained model for legal professionals.
      relevanceScore: 30
      topics:
        - deployment
        - capabilities
      entities: []
    - title: Sora first impressions
      url: https://openai.com/index/sora-first-impressions
      sourceId: openai-blog
      publishedAt: Mon, 25 Mar 2024 00:00:00 GMT
      summary: Since we introduced Sora to the world last month, we’ve been working with artists to learn how Sora might aid
        in their creative process.
      relevanceScore: 30
      topics:
        - deployment
        - capabilities
      entities: []
    - title: Reimagining the email experience with AI
      url: https://openai.com/index/superhuman
      sourceId: openai-blog
      publishedAt: Mon, 18 Mar 2024 07:00:00 GMT
      summary: Superhuman introduces a new era of email with OpenAI.
      relevanceScore: 30
      topics:
        - deployment
        - capabilities
      entities: []
    - title: Saving lives with AI health coaching
      url: https://openai.com/index/healthify
      sourceId: openai-blog
      publishedAt: Wed, 13 Mar 2024 07:00:00 GMT
      summary: Healthify collaborates with OpenAI to improve millions of lives with sustainable weight loss.
      relevanceScore: 30
      topics:
        - deployment
        - capabilities
      entities: []
    - title: Using AI to improve patient access to clinical trials
      url: https://openai.com/index/paradigm
      sourceId: openai-blog
      publishedAt: Wed, 06 Mar 2024 08:00:00 GMT
      summary: Paradigm uses OpenAI’s API to improve patient access to clinical trials.
      relevanceScore: 30
      topics:
        - deployment
        - capabilities
      entities: []
    - title: Sparking a more productive company with ChatGPT Enterprise
      url: https://openai.com/index/match-group
      sourceId: openai-blog
      publishedAt: Wed, 06 Mar 2024 08:00:00 GMT
      summary: Match Group uses ChatGPT Enterprise to spark creativity and impact.
      relevanceScore: 30
      topics:
        - deployment
        - capabilities
      entities: []
    - title: Improving health literacy and patient well-being
      url: https://openai.com/index/lifespan
      sourceId: openai-blog
      publishedAt: Wed, 06 Mar 2024 08:00:00 GMT
      summary: Lifespan uses GPT-4 to radically improve health literacy and patient outcomes.
      relevanceScore: 30
      topics:
        - deployment
        - capabilities
      entities: []
    - title: OpenAI and journalism
      url: https://openai.com/index/openai-and-journalism
      sourceId: openai-blog
      publishedAt: Mon, 08 Jan 2024 08:00:00 GMT
      summary: We support journalism, partner with news organizations, and believe The New York Times lawsuit is without merit.
      relevanceScore: 30
      topics:
        - lab-behavior
      entities:
        - lab-behavior
    - title: Partnership with Axel Springer to deepen beneficial use of AI in journalism
      url: https://openai.com/index/axel-springer-partnership
      sourceId: openai-blog
      publishedAt: Wed, 13 Dec 2023 08:00:00 GMT
      summary: Axel Springer is the first publishing house globally to partner with us on a deeper integration of journalism
        in AI technologies.
      relevanceScore: 30
      topics:
        - lab-behavior
      entities:
        - lab-behavior
    - title: New models and developer products announced at DevDay
      url: https://openai.com/index/new-models-and-developer-products-announced-at-devday
      sourceId: openai-blog
      publishedAt: Mon, 06 Nov 2023 08:00:00 GMT
      summary: GPT-4 Turbo with 128K context and lower prices, the new Assistants API, GPT-4 Turbo with Vision, DALL·E 3 API,
        and more.
      relevanceScore: 30
      topics:
        - capabilities
      entities:
        - capabilities
    - title: Introducing ChatGPT Enterprise
      url: https://openai.com/index/introducing-chatgpt-enterprise
      sourceId: openai-blog
      publishedAt: Mon, 28 Aug 2023 07:00:00 GMT
      summary: Get enterprise-grade security & privacy and the most powerful version of ChatGPT yet.
      relevanceScore: 30
      topics:
        - capabilities
        - deployment-architectures-table
      entities:
        - language-models
    - title: Accurately analyzing large scale qualitative data
      url: https://openai.com/index/viable
      sourceId: openai-blog
      publishedAt: Fri, 07 Jul 2023 07:00:00 GMT
      summary: Viable uses GPT-4 to analyze qualitative data at a revolutionary scale with unparalleled accuracy.
      relevanceScore: 30
      topics:
        - capabilities
        - tool-use
      entities:
        - language-models
    - title: OpenAI and Microsoft extend partnership
      url: https://openai.com/index/openai-and-microsoft-extend-partnership
      sourceId: openai-blog
      publishedAt: Mon, 23 Jan 2023 08:00:00 GMT
      summary: We’re happy to announce that OpenAI and Microsoft are extending our partnership.
      relevanceScore: 30
      topics:
        - partnerships
        - industry
      entities: []
    - title: "Point-E: A system for generating 3D point clouds from complex prompts"
      url: https://openai.com/index/point-e
      sourceId: openai-blog
      publishedAt: Fri, 16 Dec 2022 08:00:00 GMT
      summary: ""
      relevanceScore: 30
      topics:
        - capabilities
        - 3d-generation
      entities:
        - capabilities
    - title: Hierarchical text-conditional image generation with CLIP latents
      url: https://openai.com/index/hierarchical-text-conditional-image-generation-with-clip-latents
      sourceId: openai-blog
      publishedAt: Wed, 13 Apr 2022 07:00:00 GMT
      summary: ""
      relevanceScore: 30
      topics:
        - capabilities
      entities: []
    - title: OpenAI Robotics Symposium 2019
      url: https://openai.com/index/symposium-2019
      sourceId: openai-blog
      publishedAt: Wed, 05 Jun 2019 07:00:00 GMT
      summary: We hosted the first OpenAI Robotics Symposium on April 27, 2019.
      relevanceScore: 30
      topics:
        - robotics
        - capabilities
      entities:
        - capabilities
    - title: OpenAI Five Finals
      url: https://openai.com/index/openai-five-finals
      sourceId: openai-blog
      publishedAt: Tue, 26 Mar 2019 07:00:00 GMT
      summary: We’ll be holding our final live event for OpenAI Five at 11:30am PT on April 13.
      relevanceScore: 30
      topics:
        - reinforcement-learning
        - capabilities
      entities:
        - capabilities
    - title: Report from the OpenAI hackathon
      url: https://openai.com/index/hackathon-follow-up
      sourceId: openai-blog
      publishedAt: Thu, 15 Mar 2018 07:00:00 GMT
      summary: On March 3rd, we hosted our first hackathon with 100 members of the artificial intelligence community.
      relevanceScore: 30
      topics:
        - lab-behavior
      entities:
        - lab-behavior
    - title: Faster physics in Python
      url: https://openai.com/index/faster-physics-in-python
      sourceId: openai-blog
      publishedAt: Wed, 28 Jun 2017 07:00:00 GMT
      summary: We’re open-sourcing a high-performance Python library for robotic simulation using the MuJoCo engine, developed
        over our past year of robotics research.
      relevanceScore: 30
      topics:
        - robotics
        - simulation
        - tools
      entities:
        - tool-use
    - title: Roboschool
      url: https://openai.com/index/roboschool
      sourceId: openai-blog
      publishedAt: Mon, 15 May 2017 07:00:00 GMT
      summary: "We are releasing Roboschool: open-source software for robot simulation, integrated with OpenAI Gym."
      relevanceScore: 30
      topics:
        - robotics
        - simulation
        - tools
      entities:
        - tool-use
    - title: "PixelCNN++: Improving the PixelCNN with discretized logistic mixture likelihood and other modifications"
      url: https://openai.com/index/pixelcnn-plus-plus
      sourceId: openai-blog
      publishedAt: Thu, 19 Jan 2017 08:00:00 GMT
      summary: ""
      relevanceScore: 30
      topics:
        - generative-models
        - architecture
      entities: []
    - title: On the quantitative analysis of decoder-based generative models
      url: https://openai.com/index/on-the-quantitative-analysis-of-decoder-based-generative-models
      sourceId: openai-blog
      publishedAt: Mon, 14 Nov 2016 08:00:00 GMT
      summary: ""
      relevanceScore: 30
      topics:
        - generative-models
      entities: []
    - title: Variational lossy autoencoder
      url: https://openai.com/index/variational-lossy-autoencoder
      sourceId: openai-blog
      publishedAt: Tue, 08 Nov 2016 08:00:00 GMT
      summary: ""
      relevanceScore: 30
      topics:
        - generative-models
        - autoencoders
      entities: []
    - title: Extensions and limitations of the neural GPU
      url: https://openai.com/index/extensions-and-limitations-of-the-neural-gpu
      sourceId: openai-blog
      publishedAt: Wed, 02 Nov 2016 07:00:00 GMT
      summary: ""
      relevanceScore: 30
      topics:
        - neural-networks
        - architecture
      entities: []
    - title: "D4RT: Teaching AI to see the world in four dimensions"
      url: https://deepmind.google/blog/d4rt-teaching-ai-to-see-the-world-in-four-dimensions/
      sourceId: deepmind-blog
      publishedAt: Fri, 16 Jan 2026 10:39:00 +0000
      summary: "D4RT: Unified, efficient 4D reconstruction and tracking up to 300x faster than prior methods."
      relevanceScore: 30
      topics:
        - capabilities
        - computer-vision
      entities: []
    - title: Build with Nano Banana Pro, our Gemini 3 Pro Image model
      url: https://deepmind.google/blog/build-with-nano-banana-pro-our-gemini-3-pro-image-model/
      sourceId: deepmind-blog
      publishedAt: Thu, 20 Nov 2025 15:11:14 +0000
      summary: ""
      relevanceScore: 30
      topics:
        - capabilities
      entities: []
    - title: Introducing Nano Banana Pro
      url: https://deepmind.google/blog/introducing-nano-banana-pro/
      sourceId: deepmind-blog
      publishedAt: Thu, 20 Nov 2025 15:05:02 +0000
      summary: ""
      relevanceScore: 30
      topics:
        - capabilities
      entities: []
    - title: Image editing in Gemini just got a major upgrade
      url: https://deepmind.google/blog/image-editing-in-gemini-just-got-a-major-upgrade/
      sourceId: deepmind-blog
      publishedAt: Thu, 23 Oct 2025 18:48:30 +0000
      summary: Transform images in amazing new ways with updated native image editing in the Gemini app.
      relevanceScore: 30
      topics:
        - capabilities
      entities:
        - capabilities
    - title: How we're supporting better tropical cyclone prediction with AI
      url: https://deepmind.google/blog/how-were-supporting-better-tropical-cyclone-prediction-with-ai/
      sourceId: deepmind-blog
      publishedAt: Thu, 12 Jun 2025 15:00:00 +0000
      summary: We’re launching Weather Lab, featuring our experimental cyclone predictions, and we’re partnering with the U.S.
        National Hurricane Center to support their forecasts and warnings this cyclone season.
      relevanceScore: 30
      topics:
        - scientific-research
        - capabilities
      entities:
        - scientific-research
        - capabilities
    - title: Music AI Sandbox, now with new features and broader access
      url: https://deepmind.google/blog/music-ai-sandbox-now-with-new-features-and-broader-access/
      sourceId: deepmind-blog
      publishedAt: Thu, 24 Apr 2025 15:01:00 +0000
      summary: Helping music professionals explore the potential of generative AI
      relevanceScore: 30
      topics:
        - generative-models
        - capabilities
      entities:
        - capabilities
    - title: AlphaQubit tackles one of quantum computing’s biggest challenges
      url: https://deepmind.google/blog/alphaqubit-tackles-one-of-quantum-computings-biggest-challenges/
      sourceId: deepmind-blog
      publishedAt: Wed, 20 Nov 2024 18:00:00 +0000
      summary: Our new AI system accurately identifies errors inside quantum computers, helping to make this new technology
        more reliable.
      relevanceScore: 30
      topics:
        - scientific-research
        - capabilities
      entities:
        - scientific-research
    - title: "EdgeNav-QE: QLoRA Quantization and Dynamic Early Exit for LAM-based Navigation on Edge Devices"
      url: https://arxiv.org/abs/2602.15836
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15836v1 Announce Type: cross Abstract: Large Action Models (LAMs) have shown immense potential in
        autonomous navigation by bridging high-level reasoning with low-level control. However, deploying these
        multi-billion parameter models on edge devices remains a significant challenge due to memory constraints and
        latency requirements. In this paper, we propose EdgeNav-QE, a novel framework that integrates Quantized Low-Rank
        Adaptation (QLoRA) with a dynamic early-exit (DEE) mechanism to o"
      relevanceScore: 30
      topics:
        - language-models
        - autonomous-systems
        - edge-deployment
      entities:
        - language-models
        - agentic-ai
    - title: Can LLMs Assess Personality? Validating Conversational AI for Trait Profiling
      url: https://arxiv.org/abs/2602.15848
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15848v1 Announce Type: cross Abstract: This study validates Large Language Models (LLMs) as a
        dynamic alternative to questionnaire-based personality assessment. Using a within-subjects experiment (N=33), we
        compared Big Five personality scores derived from guided LLM conversations against the gold-standard IPIP-50
        questionnaire, while also measuring user-perceived accuracy. Results indicate moderate convergent validity
        (r=0.38-0.58), with Conscientiousness, Openness, and Neuroticism s"
      relevanceScore: 30
      topics:
        - language-models
        - personality-assessment
      entities:
        - language-models
    - title: "CAST: Achieving Stable LLM-based Text Analysis for Data Analytics"
      url: https://arxiv.org/abs/2602.15861
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15861v1 Announce Type: cross Abstract: Text analysis of tabular data relies on two core operations:
        \\emph{summarization} for corpus-level theme extraction and \\emph{tagging} for row-level labeling. A critical
        limitation of employing large language models (LLMs) for these tasks is their inability to meet the high
        standards of output stability demanded by data analytics. To address this challenge, we introduce \\textbf{CAST}
        (\\textbf{C}onsistency via \\textbf{A}lgorithmic Prompting and \\t"
      relevanceScore: 30
      topics:
        - language-models
        - text-analysis
        - stability
      entities:
        - language-models
    - title: Test-Time Adaptation for Tactile-Vision-Language Models
      url: https://arxiv.org/abs/2602.15873
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15873v1 Announce Type: cross Abstract: Tactile-vision-language (TVL) models are increasingly
        deployed in real-world robotic and multimodal perception tasks, where test-time distribution shifts are
        unavoidable. Existing test-time adaptation (TTA) methods provide filtering in unimodal settings but lack
        explicit treatment of modality-wise reliability under asynchronous cross-modal shifts, leaving them brittle when
        some modalities become unreliable. We study TTA for TVL models under such "
      relevanceScore: 30
      topics:
        - multimodal-models
        - robotic-systems
      entities:
        - language-models
    - title: "DocSplit: A Comprehensive Benchmark Dataset and Evaluation Approach for Document Packet Recognition and
        Splitting"
      url: https://arxiv.org/abs/2602.15958
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15958v1 Announce Type: cross Abstract: Document understanding in real-world applications often
        requires processing heterogeneous, multi-page document packets containing multiple documents stitched together.
        Despite recent advances in visual document understanding, the fundamental task of document packet splitting,
        which involves separating a document packet into individual units, remains largely unaddressed. We present the
        first comprehensive benchmark dataset, DocSplit, along with no"
      relevanceScore: 30
      topics:
        - document-understanding
        - benchmarking
      entities: []
    - title: "Human-AI Collaboration in Large Language Model-Integrated Building Energy Management Systems: The Role of User
        Domain Knowledge and AI Literacy"
      url: https://arxiv.org/abs/2602.16140
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16140v1 Announce Type: cross Abstract: This study aimed to comprehend how user domain knowledge and
        artificial intelligence (AI) literacy impact the effective use of human-AI interactive building energy
        management system (BEMS). While prior studies have investigated the potential of integrating large language
        models (LLMs) into BEMS or building energy modeling, very few studies have examined how user interact with such
        systems. We conducted a systematic role-playing experiment, where "
      relevanceScore: 30
      topics:
        - language-models
        - tool-use
      entities:
        - language-models
        - tool-use
    - title: "Beyond Learning: A Training-Free Alternative to Model Adaptation"
      url: https://arxiv.org/abs/2602.16189
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16189v1 Announce Type: cross Abstract: Despite the continuous research and evolution of language
        models, they sometimes underperform previous versions. Existing approaches to overcome these challenges are
        resource-intensive, highlighting the need for alternatives that enable immediate action. We assume that each
        language model has a local module inside that is suitable for a specific function. First, this work identifies a
        set of modules showing consistent and local activation changes"
      relevanceScore: 30
      topics:
        - language-models
      entities:
        - language-models
    - title: "Hardware-accelerated graph neural networks: an alternative approach for neuromorphic event-based audio
        classification and keyword spotting on SoC FPGA"
      url: https://arxiv.org/abs/2602.16442
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16442v1 Announce Type: cross Abstract: As the volume of data recorded by embedded edge sensors
        increases, particularly from neuromorphic devices producing discrete event streams, there is a growing need for
        hardware-aware neural architectures that enable efficient, low-latency, and energy-conscious local processing.
        We present an FPGA implementation of event-graph neural networks for audio processing. We utilise an artificial
        cochlea that converts time-series signals into sparse event"
      relevanceScore: 30
      topics:
        - compute-hardware
        - neuromorphic
      entities:
        - compute-hardware
        - neuromorphic
    - title: A Systematic Evaluation of Sample-Level Tokenization Strategies for MEG Foundation Models
      url: https://arxiv.org/abs/2602.16626
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16626v1 Announce Type: cross Abstract: Recent success in natural language processing has motivated
        growing interest in large-scale foundation models for neuroimaging data. Such models often require
        discretization of continuous neural time series data, a process referred to as 'tokenization'. However, the
        impact of different tokenization strategies for neural data is currently poorly understood. In this work, we
        present a systematic evaluation of sample-level tokenization strategies fo"
      relevanceScore: 30
      topics:
        - capabilities
      entities:
        - capabilities
    - title: "SPARC: Scenario Planning and Reasoning for Automated C Unit Test Generation"
      url: https://arxiv.org/abs/2602.16671
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16671v1 Announce Type: cross Abstract: Automated unit test generation for C remains a formidable
        challenge due to the semantic gap between high-level program intent and the rigid syntactic constraints of
        pointer arithmetic and manual memory management. While Large Language Models (LLMs) exhibit strong generative
        capabilities, direct intent-to-code synthesis frequently suffers from the leap-to-code failure mode, where
        models prematurely emit code without grounding in program structure,"
      relevanceScore: 30
      topics:
        - agentic-ai
        - tool-use
      entities:
        - agentic-ai
        - tool-use
    - title: "GDGB: A Benchmark for Generative Dynamic Text-Attributed Graph Learning"
      url: https://arxiv.org/abs/2507.03267
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2507.03267v2 Announce Type: replace Abstract: Dynamic Text-Attributed Graphs (DyTAGs), which intricately
        integrate structural, temporal, and textual attributes, are crucial for modeling complex real-world systems.
        However, most existing DyTAG datasets exhibit poor textual quality, which severely limits their utility for
        generative DyTAG tasks requiring semantically rich inputs. Additionally, prior work mainly focuses on
        discriminative tasks on DyTAGs, resulting in a lack of standardized ta"
      relevanceScore: 30
      topics:
        - language-models
      entities:
        - language-models
    - title: "Ctrl-GenAug: Controllable Generative Augmentation for Medical Sequence Classification"
      url: https://arxiv.org/abs/2409.17091
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2409.17091v3 Announce Type: replace-cross Abstract: In the medical field, the limited availability of
        large-scale datasets and labor-intensive annotation processes hinder the performance of deep models.
        Diffusion-based generative augmentation approaches present a promising solution to this issue, having been
        proven effective in advancing downstream medical recognition tasks. Nevertheless, existing works lack sufficient
        semantic and sequential steerability for challenging video/3D sequence "
      relevanceScore: 30
      topics:
        - language-models
      entities:
        - language-models
    - title: "FedEFC: Federated Learning Using Enhanced Forward Correction Against Noisy Labels"
      url: https://arxiv.org/abs/2504.05615
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2504.05615v3 Announce Type: replace-cross Abstract: Federated Learning (FL) is a powerful framework for
        privacy-preserving distributed learning. It enables multiple clients to collaboratively train a global model
        without sharing raw data. However, handling noisy labels in FL remains a major challenge due to heterogeneous
        data distributions and communication constraints, which can severely degrade model performance. To address this
        issue, we propose FedEFC, a novel method designed to tackle"
      relevanceScore: 30
      topics:
        - federated-learning
        - privacy
        - distributed-learning
      entities: []
    - title: Modeling Human Behavior in a Strategic Network Game with Complex Group Dynamics
      url: https://arxiv.org/abs/2505.03795
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2505.03795v3 Announce Type: replace-cross Abstract: Human networks greatly impact important societal
        outcomes, including wealth and health inequality, poverty, and bullying. As such, understanding human networks
        is critical to learning how to promote favorable societal outcomes. As a step toward better understanding human
        networks, we compare and contrast several methods for learning models of human behavior in a strategic network
        game called the Junior High Game (JHG) [39]. These modeling"
      relevanceScore: 30
      topics:
        - game-theory
        - human-behavior
        - multi-agent
      entities: []
    - title: "Pinet: Optimizing hard-constrained neural networks with orthogonal projection layers"
      url: https://arxiv.org/abs/2508.10480
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2508.10480v2 Announce Type: replace-cross Abstract: We introduce an output layer for neural networks
        that ensures satisfaction of convex constraints. Our approach, $\\Pi$net, leverages operator splitting for rapid
        and reliable projections in the forward pass, and the implicit function theorem for backpropagation. We deploy
        $\\Pi$net as a feasible-by-design optimization proxy for parametric constrained optimization problems and obtain
        modest-accuracy solutions faster than traditional solvers "
      relevanceScore: 30
      topics:
        - neural-networks
        - constraint-satisfaction
        - optimization
      entities: []
    - title: Semantic Chunking and the Entropy of Natural Language
      url: https://arxiv.org/abs/2602.13194
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.13194v2 Announce Type: replace-cross Abstract: The entropy rate of printed English is famously
        estimated to be about one bit per character, a benchmark that modern large language models (LLMs) have only
        recently approached. This entropy rate implies that English contains nearly 80 percent redundancy relative to
        the five bits per character expected for random text. We introduce a statistical model that attempts to capture
        the intricate multi-scale structure of natural language, providi"
      relevanceScore: 30
      topics:
        - language-models
        - information-theory
        - capabilities
      entities:
        - language-models
        - capabilities
    - title: "High-Fidelity Network Management for Federated AI-as-a-Service: Cross-Domain Orchestration"
      url: https://arxiv.org/abs/2602.15281
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15281v2 Announce Type: replace-cross Abstract: To support the emergence of AI-as-a-Service (AIaaS),
        communication service providers (CSPs) are on the verge of a radical transformation-from pure connectivity
        providers to AIaaS a managed network service (control-and-orchestration plane that exposes AI models). In this
        model, the CSP is responsible not only for transport/communications, but also for intent-to-model resolution and
        joint network-compute orchestration, i.e., reliable and ti"
      relevanceScore: 30
      topics:
        - ai-infrastructure
        - distributed-systems
        - deployment
      entities:
        - deployment-architectures-table
    - title: "Every Little Helps: Building Knowledge Graph Foundation Model with Fine-grained Transferable Multi-modal Tokens"
      url: https://arxiv.org/abs/2602.15896
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15896v1 Announce Type: new Abstract: Multi-modal knowledge graph reasoning (MMKGR) aims to predict
        the missing links by exploiting both graph structure information and multi-modal entity contents. Most existing
        works are designed for a transductive setting, which learns dataset-specific embeddings and struggles to
        generalize to new KGs. Recent knowledge graph foundation models (KGFMs) improve cross-KG transfer, but they
        mainly exploit structural patterns and ignore rich multi-modal si"
      relevanceScore: 30
      topics:
        - knowledge graphs
        - multimodal
        - reasoning
      entities:
        - language-models
    - title: Optimizing Soft Prompt Tuning via Structural Evolution
      url: https://arxiv.org/abs/2602.16500
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16500v1 Announce Type: new Abstract: Soft prompt tuning leverages continuous embeddings to capture
        task-specific information in large pre-trained language models (LLMs), achieving competitive performance in
        few-shot settings. However, soft prompts rely on high-dimensional, implicit representations and lack explicit
        semantics and traceable training behaviors, which limits their interpretability. To address this limitation, we
        propose a soft prompt tuning optimization method based on to"
      relevanceScore: 30
      topics:
        - language-models
        - prompt-engineering
      entities:
        - language-models
    - title: Reinforced Fast Weights with Next-Sequence Prediction
      url: https://arxiv.org/abs/2602.16704
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16704v1 Announce Type: new Abstract: Fast weight architectures offer a promising alternative to
        attention-based transformers for long-context modeling by maintaining constant memory overhead regardless of
        context length. However, their potential is limited by the next-token prediction (NTP) training paradigm. NTP
        optimizes single-token predictions and ignores semantic coherence across multiple tokens following a prefix.
        Consequently, fast weight models, which dynamically update their "
      relevanceScore: 30
      topics:
        - language-models
        - architecture
        - long-context
      entities:
        - language-models
    - title: "Standardizing the Measurement of Text Diversity: A Tool and a Comparative Analysis of Scores"
      url: https://arxiv.org/abs/2403.00553
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2403.00553v3 Announce Type: replace Abstract: The diversity across outputs generated by LLMs shapes
        perception of their quality and utility. High lexical diversity is often desirable, but there is no standard
        method to measure this property. Templated answer structures and ``canned'' responses across different documents
        are readily noticeable, but difficult to visualize across large corpora. This work aims to standardize
        measurement of text diversity. Specifically, we empirically investiga"
      relevanceScore: 30
      topics:
        - language-models
        - evaluation
        - metrics
      entities:
        - language-models
        - __index__/knowledge-base/metrics
    - title: "DIAL: Direct Iterative Adversarial Learning for Realistic Multi-Turn Dialogue Simulation"
      url: https://arxiv.org/abs/2512.20773
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2512.20773v3 Announce Type: replace Abstract: Realistic user simulation is crucial for training and
        evaluating multi-turn dialogue systems, yet creating simulators that accurately replicate human behavior remains
        a significant challenge. An effective simulator must expose the failure modes of the systems under evaluation.
        This work introduces Direct Iterative Adversarial Learning (DIAL), a DPO-based adversarial training framework
        that iteratively enhances user simulator realism through a c"
      relevanceScore: 30
      topics:
        - language-models
        - adversarial
        - evaluation
      entities:
        - language-models
    - title: Geometry-Aware Uncertainty Quantification via Conformal Prediction on Manifolds
      url: https://arxiv.org/abs/2602.16015
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16015v1 Announce Type: new Abstract: Conformal prediction provides distribution-free coverage
        guaranties for regression; yet existing methods assume Euclidean output spaces and produce prediction regions
        that are poorly calibrated when responses lie on Riemannian manifolds. We propose \\emph{adaptive geodesic
        conformal prediction}, a framework that replaces Euclidean residuals with geodesic nonconformity scores and
        normalizes them by a cross-validated difficulty estimator to handle het"
      relevanceScore: 30
      topics:
        - uncertainty-quantification
        - conformal-prediction
      entities: []
    - title: On the Power of Source Screening for Learning Shared Feature Extractors
      url: https://arxiv.org/abs/2602.16125
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16125v1 Announce Type: new Abstract: Learning with shared representation is widely recognized as an
        effective way to separate commonalities from heterogeneity across various heterogeneous sources. Most existing
        work includes all related data sources via simultaneously training a common feature extractor and
        source-specific heads. It is well understood that data sources with low relevance or poor quality may hinder
        representation learning. In this paper, we further dive into the questi"
      relevanceScore: 30
      topics:
        - transfer-learning
        - feature-extraction
      entities: []
    - title: "Deep TPC: Temporal-Prior Conditioning for Time Series Forecasting"
      url: https://arxiv.org/abs/2602.16188
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16188v1 Announce Type: new Abstract: LLM-for-time series (TS) methods typically treat time
        shallowly, injecting positional or prompt-based cues once at the input of a largely frozen decoder, which limits
        temporal reasoning as this information degrades through the layers. We introduce Temporal-Prior Conditioning
        (TPC), which elevates time to a first-class modality that conditions the model at multiple depths. TPC attaches
        a small set of learnable time series tokens to the patch stream;"
      relevanceScore: 30
      topics:
        - time-series-forecasting
        - language-models
      entities:
        - language-models
    - title: Learning to Drive in New Cities Without Human Demonstrations
      url: https://arxiv.org/abs/2602.15891
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15891v1 Announce Type: cross Abstract: While autonomous vehicles have achieved reliable performance
        within specific operating regions, their deployment to new cities remains costly and slow. A key bottleneck is
        the need to collect many human demonstration trajectories when adapting driving policies to new cities that
        differ from those seen in training in terms of road geometry, traffic rules, and interaction patterns. In this
        paper, we show that self-play multi-agent reinforcement lea"
      relevanceScore: 30
      topics:
        - autonomous-vehicles
        - reinforcement-learning
        - deployment
        - safety
      entities:
        - safety-research
        - agentic-ai
    - title: Heuristic Search as Language-Guided Program Optimization
      url: https://arxiv.org/abs/2602.16038
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16038v1 Announce Type: cross Abstract: Large Language Models (LLMs) have advanced Automated
        Heuristic Design (AHD) in combinatorial optimization (CO) in the past few years. However, existing discovery
        pipelines often require extensive manual trial-and-error or reliance on domain expertise to adapt to new or
        complex problems. This stems from tightly coupled internal mechanisms that limit systematic improvement of the
        LLM-driven design process. To address this challenge, we propose a st"
      relevanceScore: 30
      topics:
        - llm
        - optimization
        - combinatorial-optimization
        - reasoning
      entities:
        - reasoning
        - language-models
    - title: Multi-Agent Combinatorial-Multi-Armed-Bandit framework for the Submodular Welfare Problem under Bandit Feedback
      url: https://arxiv.org/abs/2602.16183
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16183v1 Announce Type: cross Abstract: We study the \\emph{Submodular Welfare Problem} (SWP), where
        items are partitioned among agents with monotone submodular utilities to maximize the total welfare under
        \\emph{bandit feedback}. Classical SWP assumes full value-oracle access, achieving $(1-1/e)$ approximations via
        continuous-greedy algorithms. We extend this to a \\emph{multi-agent combinatorial bandit} framework
        (\\textsc{MA-CMAB}), where actions are partitions under full-bandit feedba"
      relevanceScore: 30
      topics:
        - agentic-ai
      entities:
        - agentic-ai
    - title: Zero-Shot Temporal Resolution Domain Adaptation for Spiking Neural Networks
      url: https://arxiv.org/abs/2411.04760
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2411.04760v3 Announce Type: replace Abstract: Spiking Neural Networks (SNNs) are biologically-inspired
        deep neural networks that efficiently extract temporal information while offering promising gains in terms of
        energy efficiency and latency when deployed on neuromorphic devices. SNN parameters are sensitive to temporal
        resolution, leading to significant performance drops when the temporal resolution of target data during
        deployment is not the same as that of the source data used for trai"
      relevanceScore: 30
      topics:
        - architecture-scenarios-table
      entities:
        - architecture-scenarios-table
    - title: "KnowIt: Deep Time Series Modeling and Interpretation"
      url: https://arxiv.org/abs/2507.06009
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2507.06009v2 Announce Type: replace Abstract: KnowIt (Knowledge discovery in time series data) is a
        flexible framework for building deep time series models and interpreting them. It is implemented as a Python
        toolkit, with source code and documentation available from https://must-deep-learning.github.io/KnowIt. It
        imposes minimal assumptions about task specifications and decouples the definition of dataset, deep neural
        network architecture, and interpretability technique through well defin"
      relevanceScore: 30
      topics:
        - time-series
        - interpretability
      entities:
        - interpretability-sufficient
    - title: Explainability for Fault Detection System in Chemical Processes
      url: https://arxiv.org/abs/2602.16341
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16341v1 Announce Type: new Abstract: In this work, we apply and compare two state-of-the-art
        eXplainability Artificial Intelligence (XAI) methods, the Integrated Gradients (IG) and the SHapley Additive
        exPlanations (SHAP), that explain the fault diagnosis decisions of a highly accurate Long Short-Time Memory
        (LSTM) classifier. The classifier is trained to detect faults in a benchmark non-linear chemical process, the
        Tennessee Eastman Process (TEP). It is highlighted how XAI methods ca"
      relevanceScore: 28
      topics:
        - interpretability
        - explainability
        - fault-detection
      entities: []
    - title: "Beyond SGD, Without SVD: Proximal Subspace Iteration LoRA with Diagonal Fractional K-FAC"
      url: https://arxiv.org/abs/2602.16456
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16456v1 Announce Type: new Abstract: Low-Rank Adaptation (LoRA) fine-tunes large models by learning
        low-rank updates on top of frozen weights, dramatically reducing trainable parameters and memory. In this work,
        we address the gap between training with full steps with low-rank projections (SVDLoRA) and LoRA fine-tuning. We
        propose LoRSum, a memory-efficient subroutine that closes this gap for gradient descent by casting LoRA
        optimization as a proximal sub-problem and solving it effici"
      relevanceScore: 28
      topics:
        - fine-tuning
        - efficiency
        - large-models
        - lora
      entities:
        - language-models
    - title: Navigating health questions with ChatGPT
      url: https://openai.com/index/navigating-health-questions
      sourceId: openai-blog
      publishedAt: Thu, 05 Feb 2026 00:00:00 GMT
      summary: A family shares how ChatGPT helped them prepare for critical cancer treatment decisions for their son alongside
        expert guidance from his doctors.
      relevanceScore: 25
      topics:
        - deployment
        - public-opinion
      entities:
        - public-opinion
    - title: Powering tax donations with AI powered personalized recommendations
      url: https://openai.com/index/trustbank
      sourceId: openai-blog
      publishedAt: Tue, 27 Jan 2026 00:00:00 GMT
      summary: TRUSTBANK partnered with Recursive to build Choice AI using OpenAI models, delivering personalized,
        conversational recommendations that simplify Furusato Nozei gift discovery. A multi-agent system helps donors
        navigate thousands of options and find gifts that match their preferences.
      relevanceScore: 25
      topics:
        - agentic-ai
        - tool-use
      entities:
        - agentic-ai
        - tool-use
    - title: How Indeed uses AI to help evolve the job search
      url: https://openai.com/index/indeed-maggie-hulce
      sourceId: openai-blog
      publishedAt: Mon, 26 Jan 2026 00:00:00 GMT
      summary: Indeed’s CRO Maggie Hulce shares how AI is transforming job search, recruiting, and talent acquisition for
        employers and job seekers.
      relevanceScore: 25
      topics:
        - economic-labor
        - capabilities
      entities:
        - economic-labor
    - title: A business that scales with the value of intelligence
      url: https://openai.com/index/a-business-that-scales-with-the-value-of-intelligence
      sourceId: openai-blog
      publishedAt: Sun, 18 Jan 2026 10:00:00 GMT
      summary: OpenAI’s business model scales with intelligence—spanning subscriptions, API, ads, commerce, and compute—driven
        by deepening ChatGPT adoption.
      relevanceScore: 25
      topics:
        - capabilities
      entities:
        - capabilities
    - title: Our approach to advertising and expanding access to ChatGPT
      url: https://openai.com/index/our-approach-to-advertising-and-expanding-access
      sourceId: openai-blog
      publishedAt: Fri, 16 Jan 2026 00:00:00 GMT
      summary: OpenAI plans to test advertising in the U.S. for ChatGPT’s free and Go tiers to expand affordable access to AI
        worldwide, while protecting privacy, trust, and answer quality.
      relevanceScore: 25
      topics:
        - capabilities
        - public-opinion
      entities:
        - public-opinion
    - title: Zenken boosts a lean sales team with ChatGPT Enterprise
      url: https://openai.com/index/zenken
      sourceId: openai-blog
      publishedAt: Tue, 13 Jan 2026 16:00:00 GMT
      summary: By rolling out ChatGPT Enterprise company-wide, Zenken has boosted sales performance, cut preparation time, and
        increased proposal success rates. AI-supported workflows are helping a lean team deliver more personalized,
        effective customer engagement.
      relevanceScore: 25
      topics:
        - economic-labor
        - capabilities
      entities:
        - economic-labor
    - title: "One in a million: celebrating the customers shaping AI’s future"
      url: https://openai.com/index/one-in-a-million-customers
      sourceId: openai-blog
      publishedAt: Mon, 22 Dec 2025 00:00:00 GMT
      summary: More than one million customers around the world now use OpenAI to empower their teams and unlock new
        opportunities. This post highlights how companies like PayPal, Virgin Atlantic, BBVA, Cisco, Moderna, and Canva
        are transforming the way work gets done with AI.
      relevanceScore: 25
      topics:
        - deployment
        - lab-behavior
      entities: []
    - title: How Virgin Atlantic uses AI to enhance every step of travel
      url: https://openai.com/index/virgin-atlantic-oliver-byers
      sourceId: openai-blog
      publishedAt: Mon, 08 Dec 2025 00:00:00 GMT
      summary: Virgin Atlantic CFO Oliver Byers shares how the airline is using AI to speed up development, improve
        decision-making, and elevate customer experience.
      relevanceScore: 25
      topics:
        - economic-labor
        - tool-use
      entities: []
    - title: A law and tax firm redefines efficiency with ChatGPT Business
      url: https://openai.com/index/steuerrecht
      sourceId: openai-blog
      publishedAt: Mon, 27 Oct 2025 00:00:00 GMT
      summary: Learn how Steuerrecht.com uses ChatGPT Business to streamline legal workflows, automate tax research, and scale
        client service—helping law firms boost productivity and stay competitive.
      relevanceScore: 25
      topics:
        - deployment-architectures-table
        - economic-labor
      entities:
        - deployment-architectures-table
    - title: HYGH powers next-gen digital ads with ChatGPT Business
      url: https://openai.com/index/hygh
      sourceId: openai-blog
      publishedAt: Fri, 10 Oct 2025 00:00:00 GMT
      summary: HYGH speeds up software development and campaign delivery with ChatGPT Business, cutting turnaround times,
        scaling output, and driving revenue growth.
      relevanceScore: 25
      topics:
        - deployment-architectures-table
        - economic-labor
      entities:
        - deployment-architectures-table
    - title: Growing impact and scale with ChatGPT
      url: https://openai.com/index/hibob
      sourceId: openai-blog
      publishedAt: Wed, 08 Oct 2025 08:00:00 GMT
      summary: Discover how HiBob uses ChatGPT Enterprise and custom GPTs to scale AI adoption, boost revenue, streamline HR
        workflows, and deliver AI-powered features in the Bob platform.
      relevanceScore: 25
      topics:
        - deployment-architectures-table
        - economic-labor
      entities:
        - deployment-architectures-table
    - title: Building OpenAI with OpenAI
      url: https://openai.com/index/building-openai-with-openai
      sourceId: openai-blog
      publishedAt: Mon, 29 Sep 2025 13:30:00 GMT
      summary: At OpenAI, we rely on our own technology to help streamline work, scale expertise, and drive outcomes. In our
        new series, OpenAI on OpenAI, we share lessons to help other organizations do the same.
      relevanceScore: 25
      topics:
        - lab-behavior
        - ai-acceleration-tradeoff
      entities: []
    - title: More ways to work with your team and tools in ChatGPT
      url: https://openai.com/index/more-ways-to-work-with-your-team
      sourceId: openai-blog
      publishedAt: Thu, 25 Sep 2025 11:00:00 GMT
      summary: ChatGPT business plans now support shared projects, smarter connectors, and enhanced compliance features to
        help teams work faster and more securely.
      relevanceScore: 25
      topics:
        - lab-behavior
      entities: []
    - title: Introducing ChatGPT Pulse
      url: https://openai.com/index/introducing-chatgpt-pulse
      sourceId: openai-blog
      publishedAt: Thu, 25 Sep 2025 00:00:00 GMT
      summary: Today we're releasing a preview of ChatGPT Pulse to Pro users on mobile. Pulse is a new experience where
        ChatGPT proactively does research to deliver personalized updates based on your chats, feedback, and connected
        apps like your calendar.
      relevanceScore: 25
      topics:
        - capabilities
      entities:
        - capabilities
    - title: CNA is transforming its newsroom with AI
      url: https://openai.com/index/cna-walter-fernandez
      sourceId: openai-blog
      publishedAt: Mon, 22 Sep 2025 17:17:00 GMT
      summary: In this Executive Function series from OpenAI, discover how CNA is transforming its newsroom with AI.
        Editor-in-Chief Walter Fernandez shares insights on AI adoption, culture, and the future of journalism.
      relevanceScore: 25
      topics:
        - lab-behavior
      entities: []
    - title: Vijaye Raji to become CTO of Applications with acquisition of Statsig
      url: https://openai.com/index/vijaye-raji-to-become-cto-of-applications-with-acquisition-of-statsig
      sourceId: openai-blog
      publishedAt: Tue, 02 Sep 2025 11:00:00 GMT
      summary: Vijaye Raji will step into a new role as CTO of Applications, reporting to CEO of Applications, Fidji Simo,
        following the acquisition of Statsig.
      relevanceScore: 25
      topics:
        - organizational-change
        - acquisition
      entities: []
    - title: What we’re optimizing ChatGPT for
      url: https://openai.com/index/optimizing-chatgpt
      sourceId: openai-blog
      publishedAt: Mon, 04 Aug 2025 00:00:00 GMT
      summary: We build ChatGPT to help you thrive in all the ways you want. Learn how we're improving support for tough
        moments, have rolled out reminders to take breaks, and are working on better life advice, all guided by expert
        input.
      relevanceScore: 25
      topics:
        - alignment-progress
      entities: []
    - title: AI as the greatest source of empowerment for all
      url: https://openai.com/index/ai-as-the-greatest-source-of-empowerment-for-all
      sourceId: openai-blog
      publishedAt: Mon, 21 Jul 2025 00:00:00 GMT
      summary: I’ve always considered myself a pragmatic technologist—someone who loves technology not for its own sake, but
        for the direct impact it can have on people’s lives. That’s what makes this job so exciting, since I believe AI
        will unlock more opportunities for more people than any other technology in history. If we get this right, AI
        can give everyone more power than ever.
      relevanceScore: 25
      topics:
        - alignment-progress
        - expert-opinion
      entities:
        - expert-opinion
    - title: Invideo AI uses OpenAI models to create videos 10x faster
      url: https://openai.com/index/invideo-ai
      sourceId: openai-blog
      publishedAt: Thu, 17 Jul 2025 00:00:00 GMT
      summary: Invideo AI uses OpenAI’s GPT-4.1, gpt-image-1, and text-to-speech models to transform creative ideas into
        professional videos in minutes.
      relevanceScore: 25
      topics:
        - tool-use
        - capabilities
      entities:
        - tool-use
    - title: Bringing the magic of AI to Mattel’s iconic brands
      url: https://openai.com/index/mattels-iconic-brands
      sourceId: openai-blog
      publishedAt: Thu, 12 Jun 2025 00:00:00 GMT
      summary: OpenAI and Mattel are partnering to integrate AI into iconic brands such as Barbie and Hot Wheels, aiming to
        enhance creative development, streamline workflows, and create new ways for fans to engage.
      relevanceScore: 25
      topics:
        - ai-deployment
        - capabilities
      entities:
        - capabilities
    - title: AI powers Expedia’s marketing evolution
      url: https://openai.com/index/expedia-jochen-koedijk
      sourceId: openai-blog
      publishedAt: Wed, 14 May 2025 10:00:00 GMT
      summary: A conversation with Jochen Koedijk, Chief Marketing Officer of Expedia Group.
      relevanceScore: 25
      topics:
        - capabilities
        - economic-labor
      entities:
        - capabilities
        - economic-labor
    - title: Lowe’s puts project expertise into every hand
      url: https://openai.com/index/lowes
      sourceId: openai-blog
      publishedAt: Wed, 07 May 2025 07:00:00 GMT
      summary: Lowe’s partnered with OpenAI to build Mylow and Mylow Companion, AI-powered tools that bring expert help to
        both customers and store associates—making complex home improvement projects easier to plan, navigate, and
        complete.
      relevanceScore: 25
      topics:
        - capabilities
        - tool-use
        - economic-labor
      entities:
        - tool-use
        - economic-labor
    - title: Lowe’s leverages AI to power home improvement retail
      url: https://openai.com/index/lowes-chandhu-nair
      sourceId: openai-blog
      publishedAt: Mon, 05 May 2025 05:00:00 GMT
      summary: A conversation with Chandhu Nair, Senior Vice President of Data, AI, and Innovation.
      relevanceScore: 25
      topics:
        - ai-applications
        - deployment
      entities: []
    - title: "New in ChatGPT for Business: March 2025"
      url: https://openai.com/business/new-in-chatgpt-for-work-march-updates-2025
      sourceId: openai-blog
      publishedAt: Tue, 18 Mar 2025 00:00:00 GMT
      summary: Join us as we share our latest releases and how ChatGPT is becoming more interactive, customized to the way
        your teams work, and agentic.
      relevanceScore: 25
      topics:
        - agentic-ai
        - capabilities
      entities:
        - agentic-ai
    - title: College students and ChatGPT adoption in the US
      url: https://openai.com/global-affairs/college-students-and-chatgpt
      sourceId: openai-blog
      publishedAt: Thu, 20 Feb 2025 06:00:00 GMT
      summary: A look into state-by-state adoption and how gaps might impact workforce readiness.
      relevanceScore: 25
      topics:
        - public-opinion
        - economic-labor
      entities:
        - public-opinion
        - economic-labor
    - title: Using OpenAI o1 for financial analysis
      url: https://openai.com/index/rogo
      sourceId: openai-blog
      publishedAt: Thu, 13 Feb 2025 07:00:00 GMT
      summary: Rogo scales AI-driven financial research with OpenAI o1
      relevanceScore: 25
      topics:
        - reasoning
        - deployment
      entities:
        - reasoning
    - title: Put AI to work for your product team
      url: https://openai.com/index/put-ai-to-work-for-your-product-team
      sourceId: openai-blog
      publishedAt: Mon, 09 Dec 2024 00:00:00 GMT
      summary: Put AI to work for your product team
      relevanceScore: 25
      topics:
        - deployment
        - product-integration
      entities: []
    - title: OpenAI en France
      url: https://openai.com/index/openai-en-france
      sourceId: openai-blog
      publishedAt: Fri, 15 Nov 2024 00:00:00 GMT
      summary: Our first office in continental Europe
      relevanceScore: 25
      topics:
        - lab-behavior
        - expansion
      entities:
        - lab-behavior
    - title: Delivering high-performance customer support
      url: https://openai.com/index/decagon
      sourceId: openai-blog
      publishedAt: Tue, 29 Oct 2024 10:00:00 GMT
      summary: Decagon and OpenAI deliver high-performance, fully automated customer support at scale
      relevanceScore: 25
      topics:
        - deployment
        - automation
      entities: []
    - title: Introducing canvas, a new way to write and code with ChatGPT.
      url: https://openai.com/index/introducing-canvas
      sourceId: openai-blog
      publishedAt: Thu, 03 Oct 2024 10:00:00 GMT
      summary: Introducing canvas
      relevanceScore: 25
      topics:
        - capabilities
        - tool-use
      entities:
        - tool-use
        - coding
    - title: Prompt Caching in the API
      url: https://openai.com/index/api-prompt-caching
      sourceId: openai-blog
      publishedAt: Tue, 01 Oct 2024 10:03:00 GMT
      summary: Offering automatic discounts on inputs that the model has recently seen
      relevanceScore: 25
      topics:
        - capabilities
      entities:
        - capabilities
    - title: Introducing the OpenAI Academy
      url: https://openai.com/global-affairs/openai-academy
      sourceId: openai-blog
      publishedAt: Mon, 23 Sep 2024 03:30:00 GMT
      summary: New initiative will fuel innovation by investing in developers and organizations leveraging AI, starting in
        low- and middle-income countries.
      relevanceScore: 25
      topics:
        - ai-talent-market-dynamics
        - capabilities
      entities:
        - ai-talent-market-dynamics
    - title: "Put AI to work: Lessons from hundreds of successful deployments"
      url: https://openai.com/business/put-ai-to-work-lessons-from-hundreds-of-successful-deployments
      sourceId: openai-blog
      publishedAt: Tue, 10 Sep 2024 00:00:00 GMT
      summary: "Put AI to Work: Lessons from Hundreds of Successful Deployments"
      relevanceScore: 25
      topics:
        - deployment-architectures-table
        - capabilities
      entities:
        - deployment-architectures-table
    - title: Personalizing education with ChatGPT
      url: https://openai.com/index/asu
      sourceId: openai-blog
      publishedAt: Mon, 26 Aug 2024 04:00:00 GMT
      summary: Arizona State University embraces ChatGPT campus-wide to personalize learning, advance research, and prepare
        students for the future
      relevanceScore: 25
      topics:
        - education
        - deployment
        - capabilities
      entities:
        - language-models
    - title: OpenAI acquires Rockset
      url: https://openai.com/index/openai-acquires-rockset
      sourceId: openai-blog
      publishedAt: Fri, 21 Jun 2024 08:00:00 GMT
      summary: OpenAI Acquires Rockset
      relevanceScore: 25
      topics:
        - acquisitions
        - infrastructure
      entities:
        - ai-megaproject-infrastructure
    - title: Surging developer productivity with custom GPTs
      url: https://openai.com/index/paf
      sourceId: openai-blog
      publishedAt: Tue, 18 Jun 2024 08:45:00 GMT
      summary: Paf adopted ChatGPT Enterprise across its entire company, with engineers using custom GPTs on a daily basis to
        speed up routine development tasks. Paf also integrated ChatGPT Enterprise into the grit:lab coding academy
        (gritlab.ax), training the next generation of software developers using an AI-augmented, systems-architecture
        mindset from day one. In addition to the wide range of use cases for developers and grit:lab students, 70% of
        Paf employees actively use ChatGPT Enterprise, spanning busin
      relevanceScore: 25
      topics:
        - deployment
        - productivity
        - tool-use
      entities:
        - tool-use
        - economic-labor
    - title: OpenAI and Apple announce partnership
      url: https://openai.com/index/openai-and-apple-announce-partnership
      sourceId: openai-blog
      publishedAt: Mon, 10 Jun 2024 11:55:00 GMT
      summary: OpenAI and Apple announce partnership to integrate ChatGPT into Apple experiences.
      relevanceScore: 25
      topics:
        - capabilities
      entities:
        - capabilities
    - title: Improvements to data analysis in ChatGPT
      url: https://openai.com/index/improvements-to-data-analysis-in-chatgpt
      sourceId: openai-blog
      publishedAt: Thu, 16 May 2024 15:00:00 GMT
      summary: Improvements to data analysis in ChatGPT Interact with tables and charts and add files directly from Google
        Drive and Microsoft OneDrive.
      relevanceScore: 25
      topics:
        - capabilities
      entities:
        - capabilities
    - title: OpenAI and Reddit Partnership
      url: https://openai.com/index/openai-and-reddit-partnership
      sourceId: openai-blog
      publishedAt: Thu, 16 May 2024 13:30:00 GMT
      summary: OpenAI and Reddit Partnership We’re bringing Reddit’s unique content to ChatGPT and our products.
      relevanceScore: 25
      topics:
        - capabilities
      entities:
        - capabilities
    - title: Creating an AI-powered Magic Studio
      url: https://openai.com/index/canva
      sourceId: openai-blog
      publishedAt: Thu, 16 May 2024 00:00:00 GMT
      summary: Canva is a visual communication platform, enjoyed by more than 175 million people monthly to make
        presentations, videos, documents, websites, social media graphics and more. A majority of the world’s knowledge
        workers lack design training, but Canva’s combination of an easy-to-use interface, vast libraries, and
        time-saving tools allows anyone to create visually compelling content.
      relevanceScore: 25
      topics:
        - capabilities
      entities:
        - capabilities
    - title: Collaborating with Carlyle to Chart the Future of Private Equity
      url: https://openai.com/index/collaborating-with-carlyle-to-chart-the-future-of-private-equity
      sourceId: openai-blog
      publishedAt: Tue, 14 May 2024 08:00:00 GMT
      summary: Collaborating with Carlyle to Chart the Future of Private Equity
      relevanceScore: 25
      topics:
        - capabilities
      entities:
        - capabilities
    - title: We’re bringing the Financial Times’ world-class journalism to ChatGPT
      url: https://openai.com/index/content-partnership-with-financial-times
      sourceId: openai-blog
      publishedAt: Mon, 29 Apr 2024 00:00:00 GMT
      summary: We will also collaborate on new AI experiences for FT readers.
      relevanceScore: 25
      topics:
        - deployment
        - capabilities
      entities: []
    - title: Start using ChatGPT instantly
      url: https://openai.com/index/start-using-chatgpt-instantly
      sourceId: openai-blog
      publishedAt: Mon, 01 Apr 2024 00:00:00 GMT
      summary: We’re making it easier for people to experience the benefits of AI without needing to sign up
      relevanceScore: 25
      topics:
        - deployment
      entities: []
    - title: Making education data accessible
      url: https://openai.com/index/zelma
      sourceId: openai-blog
      publishedAt: Thu, 28 Mar 2024 00:00:00 GMT
      summary: Zelma uses GPT-4 to make education data accessible.
      relevanceScore: 25
      topics:
        - deployment
        - capabilities
      entities: []
    - title: "Global news partnerships: Le Monde and Prisa Media"
      url: https://openai.com/index/global-news-partnerships-le-monde-and-prisa-media
      sourceId: openai-blog
      publishedAt: Wed, 13 Mar 2024 07:00:00 GMT
      summary: We have partnered with international news organizations Le Monde and Prisa Media to bring French and Spanish
        news content to ChatGPT.
      relevanceScore: 25
      topics:
        - deployment
      entities: []
    - title: New embedding models and API updates
      url: https://openai.com/index/new-embedding-models-and-api-updates
      sourceId: openai-blog
      publishedAt: Thu, 25 Jan 2024 08:00:00 GMT
      summary: We are launching a new generation of embedding models, new GPT-4 Turbo and moderation models, new API usage
        management tools, and soon, lower pricing on GPT-3.5 Turbo.
      relevanceScore: 25
      topics:
        - capabilities
      entities:
        - capabilities
    - title: Streamlining financial solutions for safety and growth
      url: https://openai.com/index/stripe
      sourceId: openai-blog
      publishedAt: Tue, 14 Mar 2023 07:00:00 GMT
      summary: Stripe leverages GPT-4 to streamline user experience and combat fraud.
      relevanceScore: 25
      topics:
        - applications
        - fraud-detection
      entities: []
    - title: The power of continuous learning
      url: https://openai.com/index/the-power-of-continuous-learning
      sourceId: openai-blog
      publishedAt: Fri, 23 Dec 2022 08:00:00 GMT
      summary: Lilian Weng works on Applied AI Research at OpenAI.
      relevanceScore: 25
      topics:
        - research
        - lab-behavior
      entities:
        - lab-behavior
    - title: New and improved embedding model
      url: https://openai.com/index/new-and-improved-embedding-model
      sourceId: openai-blog
      publishedAt: Thu, 15 Dec 2022 08:00:00 GMT
      summary: We are excited to announce a new embedding model which is significantly more capable, cost effective, and
        simpler to use.
      relevanceScore: 25
      topics:
        - capabilities
        - embeddings
      entities:
        - capabilities
    - title: DALL·E API now available in public beta
      url: https://openai.com/index/dall-e-api-now-available-in-public-beta
      sourceId: openai-blog
      publishedAt: Thu, 03 Nov 2022 07:00:00 GMT
      summary: Starting today, developers can begin building apps with the DALL·E API.
      relevanceScore: 25
      topics:
        - capabilities
        - image-generation
      entities:
        - capabilities
    - title: DALL·E now available in beta
      url: https://openai.com/index/dall-e-now-available-in-beta
      sourceId: openai-blog
      publishedAt: Wed, 20 Jul 2022 07:00:00 GMT
      summary: We’ll invite 1 million people from our waitlist over the coming weeks. Users can create with DALL·E using free
        credits that refill every month, and buy additional credits in 115-generation increments for $15.
      relevanceScore: 25
      topics:
        - capabilities
      entities: []
    - title: OpenAI standardizes on PyTorch
      url: https://openai.com/index/openai-pytorch
      sourceId: openai-blog
      publishedAt: Thu, 30 Jan 2020 08:00:00 GMT
      summary: We are standardizing OpenAI’s deep learning framework on PyTorch.
      relevanceScore: 25
      topics:
        - infrastructure
        - deep-learning
      entities:
        - deep-learning-era
    - title: MuseNet
      url: https://openai.com/index/musenet
      sourceId: openai-blog
      publishedAt: Thu, 25 Apr 2019 07:00:00 GMT
      summary: We’ve created MuseNet, a deep neural network that can generate 4-minute musical compositions with 10 different
        instruments, and can combine styles from country to Mozart to the Beatles. MuseNet was not explicitly programmed
        with our understanding of music, but instead discovered patterns of harmony, rhythm, and style by learning to
        predict the next token in hundreds of thousands of MIDI files. MuseNet uses the same general-purpose
        unsupervised technology as GPT-2, a large-scale transformer model
      relevanceScore: 25
      topics:
        - generative-models
        - capabilities
      entities:
        - capabilities
    - title: OpenAI hackathon
      url: https://openai.com/index/openai-hackathon
      sourceId: openai-blog
      publishedAt: Thu, 22 Feb 2018 08:00:00 GMT
      summary: Come to OpenAI’s office in San Francisco’s Mission District for talks and a hackathon on Saturday, March 3rd.
      relevanceScore: 25
      topics:
        - lab-behavior
      entities:
        - lab-behavior
    - title: Accelerating discovery in India through AI-powered science and education
      url: https://deepmind.google/blog/accelerating-discovery-in-india-through-ai-powered-science-and-education/
      sourceId: deepmind-blog
      publishedAt: Tue, 17 Feb 2026 13:42:20 +0000
      summary: Google DeepMind brings National Partnerships for AI initiative to India, scaling AI for science and education
      relevanceScore: 25
      topics:
        - scientific-research
        - capabilities
      entities:
        - scientific-research
    - title: "Veo 3.1 Ingredients to Video: More consistency, creativity and control"
      url: https://deepmind.google/blog/veo-3-1-ingredients-to-video-more-consistency-creativity-and-control/
      sourceId: deepmind-blog
      publishedAt: Tue, 13 Jan 2026 17:00:18 +0000
      summary: Our latest Veo update generates lively, dynamic clips that feel natural and engaging — and supports vertical
        video generation.
      relevanceScore: 25
      topics:
        - capabilities
      entities: []
    - title: Improved Gemini audio models for powerful voice experiences
      url: https://deepmind.google/blog/improved-gemini-audio-models-for-powerful-voice-experiences/
      sourceId: deepmind-blog
      publishedAt: Fri, 12 Dec 2025 17:50:50 +0000
      summary: ""
      relevanceScore: 25
      topics:
        - capabilities
      entities: []
    - title: "AlphaFold: Five years of impact"
      url: https://deepmind.google/blog/alphafold-five-years-of-impact/
      sourceId: deepmind-blog
      publishedAt: Tue, 25 Nov 2025 16:00:12 +0000
      summary: Explore how AlphaFold has accelerated science and fueled a global wave of biological discovery.
      relevanceScore: 25
      topics:
        - scientific-research
        - capabilities
      entities:
        - scientific-research
    - title: Start building with Gemini 3
      url: https://deepmind.google/blog/start-building-with-gemini-3/
      sourceId: deepmind-blog
      publishedAt: Tue, 18 Nov 2025 17:49:13 +0000
      summary: ""
      relevanceScore: 25
      topics:
        - capabilities
      entities: []
    - title: "Behind “ANCESTRA”: combining Veo with live-action filmmaking"
      url: https://deepmind.google/blog/behind-ancestra-combining-veo-with-live-action-filmmaking/
      sourceId: deepmind-blog
      publishedAt: Sat, 25 Oct 2025 17:27:10 +0000
      summary: We partnered with Darren Aronofsky, Eliza McNitt and a team of more than 200 people to make a film using Veo
        and live-action filmmaking.
      relevanceScore: 25
      topics:
        - capabilities
      entities:
        - capabilities
    - title: GenCast predicts weather and the risks of extreme conditions with state-of-the-art accuracy
      url: https://deepmind.google/blog/gencast-predicts-weather-and-the-risks-of-extreme-conditions-with-sota-accuracy/
      sourceId: deepmind-blog
      publishedAt: Wed, 04 Dec 2024 15:59:00 +0000
      summary: New AI model advances the prediction of weather uncertainties and risks, delivering faster, more accurate
        forecasts up to 15 days ahead
      relevanceScore: 25
      topics:
        - scientific-research
        - capabilities
      entities:
        - scientific-research
    - title: Competing Priorities in University Organizing
      url: https://forum.effectivealtruism.org/posts/5YxPQhLPp984jcouZ/competing-priorities-in-university-organizing
      sourceId: ea-forum
      publishedAt: Wed, 18 Feb 2026 21:11:15 GMT
      summary: Published on February 18, 2026 9:11 PM GMTIn university group organizing, there is often a substantial gap
        between the potential of a campus EA group and how successful such a group manages to be in practice, given that
        it exists at all. Organizers are the primary driver of group success, and I think that difficulties with
        recruiting and retaining skilled organizers are the source of much of this gap. Often, potential organizers have
        a variety of other opportunities available to them, and organi
      relevanceScore: 25
      topics:
        - community-building
        - ea-movement
      entities: []
    - title: What Persona Are We Missing? Identifying Unknown Relevant Personas for Faithful User Simulation
      url: https://arxiv.org/abs/2602.15832
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15832v1 Announce Type: cross Abstract: Existing user simulations, where models generate user-like
        responses in dialogue, often lack verification that sufficient user personas are provided, questioning the
        validity of the simulations. To address this core concern, this work explores the task of identifying relevant
        but unknown personas of the simulation target for a given simulation context. We introduce PICQ, a novel dataset
        of context-aware choice questions, annotated with unknown pe"
      relevanceScore: 25
      topics:
        - language-models
        - user-simulation
      entities:
        - language-models
    - title: Language Model Representations for Efficient Few-Shot Tabular Classification
      url: https://arxiv.org/abs/2602.15844
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15844v1 Announce Type: cross Abstract: The Web is a rich source of structured data in the form of
        tables, from product catalogs and knowledge bases to scientific datasets. However, the heterogeneity of the
        structure and semantics of these tables makes it challenging to build a unified method that can effectively
        leverage the information they contain. Meanwhile, Large language models (LLMs) are becoming an increasingly
        integral component of web infrastructure for tasks like semantic se"
      relevanceScore: 25
      topics:
        - language-models
        - classification
      entities:
        - language-models
    - title: "Resp-Agent: An Agent-Based System for Multimodal Respiratory Sound Generation and Disease Diagnosis"
      url: https://arxiv.org/abs/2602.15909
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15909v1 Announce Type: cross Abstract: Deep learning-based respiratory auscultation is currently
        hindered by two fundamental challenges: (i) inherent information loss, as converting signals into spectrograms
        discards transient acoustic events and clinical context; (ii) limited data availability, exacerbated by severe
        class imbalance. To bridge these gaps, we present Resp-Agent, an autonomous multimodal system orchestrated by a
        novel Active Adversarial Curriculum Agent (Thinker-A$^2$CA"
      relevanceScore: 25
      topics:
        - agentic-ai
        - medical-ai
        - multimodal
      entities:
        - agentic-ai
    - title: Hybrid Model Predictive Control with Physics-Informed Neural Network for Satellite Attitude Control
      url: https://arxiv.org/abs/2602.15954
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15954v1 Announce Type: cross Abstract: Reliable spacecraft attitude control depends on accurate
        prediction of attitude dynamics, particularly when model-based strategies such as Model Predictive Control (MPC)
        are employed, where performance is limited by the quality of the internal system model. For spacecraft with
        complex dynamics, obtaining accurate physics-based models can be difficult, time-consuming, or computationally
        heavy. Learning-based system identification presents a compel"
      relevanceScore: 25
      topics:
        - neural-networks
        - control-systems
      entities: []
    - title: "B-DENSE: Branching For Dense Ensemble Network Learning"
      url: https://arxiv.org/abs/2602.15971
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15971v1 Announce Type: cross Abstract: Inspired by non-equilibrium thermodynamics, diffusion models
        have achieved state-of-the-art performance in generative modeling. However, their iterative sampling nature
        results in high inference latency. While recent distillation techniques accelerate sampling, they discard
        intermediate trajectory steps. This sparse supervision leads to a loss of structural information and introduces
        significant discretization errors. To mitigate this, we propose"
      relevanceScore: 25
      topics:
        - diffusion-models
        - generative-models
      entities: []
    - title: "MAEB: Massive Audio Embedding Benchmark"
      url: https://arxiv.org/abs/2602.16008
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16008v1 Announce Type: cross Abstract: We introduce the Massive Audio Embedding Benchmark (MAEB), a
        large-scale benchmark covering 30 tasks across speech, music, environmental sounds, and cross-modal audio-text
        reasoning in 100+ languages. We evaluate 50+ models and find that no single model dominates across all tasks:
        contrastive audio-text models excel at environmental sound classification (e.g., ESC50) but score near random on
        multilingual speech tasks (e.g., SIB-FLEURS), while spe"
      relevanceScore: 25
      topics:
        - benchmarking
        - audio-models
      entities: []
    - title: "ASPEN: Spectral-Temporal Fusion for Cross-Subject Brain Decoding"
      url: https://arxiv.org/abs/2602.16147
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16147v1 Announce Type: cross Abstract: Cross-subject generalization in EEG-based brain-computer
        interfaces (BCIs) remains challenging due to individual variability in neural signals. We investigate whether
        spectral representations offer more stable features for cross-subject transfer than temporal waveforms. Through
        correlation analyses across three EEG paradigms (SSVEP, P300, and Motor Imagery), we find that spectral features
        exhibit consistently higher cross-subject similarity than "
      relevanceScore: 25
      topics:
        - brain-computer-interfaces
      entities:
        - brain-computer-interfaces
    - title: "UCTECG-Net: Uncertainty-aware Convolution Transformer ECG Network for Arrhythmia Detection"
      url: https://arxiv.org/abs/2602.16216
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16216v1 Announce Type: cross Abstract: Deep learning has improved automated electrocardiogram (ECG)
        classification, but limited insight into prediction reliability hinders its use in safety-critical settings.
        This paper proposes UCTECG-Net, an uncertainty-aware hybrid architecture that combines one-dimensional
        convolutions and Transformer encoders to process raw ECG signals and their spectrograms jointly. Evaluated on
        the MIT-BIH Arrhythmia and PTB Diagnostic datasets, UCTECG-Net outp"
      relevanceScore: 25
      topics:
        - safety-research
      entities:
        - safety-research
    - title: A Graph Meta-Network for Learning on Kolmogorov-Arnold Networks
      url: https://arxiv.org/abs/2602.16316
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16316v1 Announce Type: cross Abstract: Weight-space models learn directly from the parameters of
        neural networks, enabling tasks such as predicting their accuracy on new datasets. Naive methods -- like
        applying MLPs to flattened parameters -- perform poorly, making the design of better weight-space architectures
        a central challenge. While prior work leveraged permutation symmetries in standard networks to guide such
        designs, no analogous analysis or tailored architecture yet exists fo"
      relevanceScore: 25
      topics:
        - language-models
      entities:
        - language-models
    - title: Articulated 3D Scene Graphs for Open-World Mobile Manipulation
      url: https://arxiv.org/abs/2602.16356
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16356v1 Announce Type: cross Abstract: Semantics has enabled 3D scene understanding and
        affordance-driven object interaction. However, robots operating in real-world environments face a critical
        limitation: they cannot anticipate how objects move. Long-horizon mobile manipulation requires closing the gap
        between semantics, geometry, and kinematics. In this work, we present MoMa-SG, a novel framework for building
        semantic-kinematic 3D scene graphs of articulated scenes containing a myr"
      relevanceScore: 25
      topics:
        - tool-use
        - agentic-ai
      entities:
        - tool-use
        - agentic-ai
    - title: "GICDM: Mitigating Hubness for Reliable Distance-Based Generative Model Evaluation"
      url: https://arxiv.org/abs/2602.16449
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16449v1 Announce Type: cross Abstract: Generative model evaluation commonly relies on
        high-dimensional embedding spaces to compute distances between samples. We show that dataset representations in
        these spaces are affected by the hubness phenomenon, which distorts nearest neighbor relationships and biases
        distance-based metrics. Building on the classical Iterative Contextual Dissimilarity Measure (ICDM), we
        introduce Generative ICDM (GICDM), a method to correct neighborhood estimatio"
      relevanceScore: 25
      topics:
        - capabilities
      entities:
        - capabilities
    - title: "Retrieval Augmented Generation of Literature-derived Polymer Knowledge: The Example of a Biodegradable Polymer
        Expert System"
      url: https://arxiv.org/abs/2602.16650
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16650v1 Announce Type: cross Abstract: Polymer literature contains a large and growing body of
        experimental knowledge, yet much of it is buried in unstructured text and inconsistent terminology, making
        systematic retrieval and reasoning difficult. Existing tools typically extract narrow, study-specific facts in
        isolation, failing to preserve the cross-study context required to answer broader scientific questions.
        Retrieval-augmented generation (RAG) offers a promising way to overcome "
      relevanceScore: 25
      topics:
        - scientific-research
      entities:
        - scientific-research
    - title: "Prompt When the Animal is: Temporal Animal Behavior Grounding with Positional Recovery Training"
      url: https://arxiv.org/abs/2405.05523
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2405.05523v2 Announce Type: replace-cross Abstract: Temporal grounding is crucial in multimodal
        learning, but it poses challenges when applied to animal behavior data due to the sparsity and uniform
        distribution of moments. To address these challenges, we propose a novel Positional Recovery Training framework
        (Port), which prompts the model with the start and end times of specific animal behaviors during training.
        Specifically, \\port{} enhances the baseline model with a Recovering branch t"
      relevanceScore: 25
      topics:
        - language-models
      entities:
        - language-models
    - title: "A Survey: Spatiotemporal Consistency in Video Generation"
      url: https://arxiv.org/abs/2502.17863
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2502.17863v2 Announce Type: replace-cross Abstract: Video generation aims to produce temporally coherent
        sequences of visual frames, representing a pivotal advancement in Artificial Intelligence Generated Content
        (AIGC). Compared to static image generation, video generation poses unique challenges: it demands not only
        high-quality individual frames but also strong temporal coherence to ensure consistency throughout the
        spatiotemporal sequence. Although research addressing spatiotemporal co"
      relevanceScore: 25
      topics:
        - video-generation
        - generative-models
      entities: []
    - title: Model-Agnostic Dynamic Feature Selection with Uncertainty Quantification
      url: https://arxiv.org/abs/2508.02566
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2508.02566v3 Announce Type: replace-cross Abstract: Dynamic feature selection (DFS) addresses budget
        constraints in decision-making by sequentially acquiring features for each instance, making it appealing for
        resource-limited scenarios. However, existing DFS methods require models specifically designed for the
        sequential acquisition setting, limiting compatibility with models already deployed in practice. Furthermore,
        they provide limited uncertainty quantification, undermining trust in h"
      relevanceScore: 25
      topics:
        - feature-selection
        - uncertainty-quantification
      entities: []
    - title: "FairTabGen: High-Fidelity and Fair Synthetic Health Data Generation from Limited Samples"
      url: https://arxiv.org/abs/2508.11810
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2508.11810v2 Announce Type: replace-cross Abstract: Synthetic healthcare data generation offers a
        promising solution to research limitations in clinical settings caused by privacy and regulatory constraints.
        However, current synthetic data generation approaches require specialized knowledge about training generative
        models and require high computational resources. In this paper, we propose FairTabGen, an LLM-based tabular data
        generation framework that produces high-quality synthetic healt"
      relevanceScore: 25
      topics:
        - synthetic-data
        - fairness
        - privacy
      entities: []
    - title: Transformers can do Bayesian Clustering
      url: https://arxiv.org/abs/2510.24318
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2510.24318v3 Announce Type: replace-cross Abstract: Bayesian clustering accounts for uncertainty but is
        computationally demanding at scale. Furthermore, real-world datasets often contain missing values, and simple
        imputation ignores the associated uncertainty, resulting in suboptimal results. We present Cluster-PFN, a
        Transformer-based model that extends Prior-Data Fitted Networks (PFNs) to unsupervised Bayesian clustering.
        Trained entirely on synthetic datasets generated from a finite Gau"
      relevanceScore: 25
      topics:
        - transformers
        - machine-learning
        - uncertainty
      entities:
        - architecture-scenarios-table
    - title: "Learning to Select Like Humans: Explainable Active Learning for Medical Imaging"
      url: https://arxiv.org/abs/2602.13308
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.13308v2 Announce Type: replace-cross Abstract: Medical image analysis requires substantial labeled
        data for model training, yet expert annotation is expensive and time-consuming. Active learning (AL) addresses
        this challenge by strategically selecting the most informative samples for the annotation purpose, but
        traditional methods solely rely on predictive uncertainty while ignoring whether models learn from clinically
        meaningful features a critical requirement for clinical deployment"
      relevanceScore: 25
      topics:
        - active-learning
        - medical-imaging
        - interpretability
      entities:
        - interpretability-sufficient
    - title: "AI-Paging: Lease-Based Execution Anchoring for Network-Exposed AI-as-a-Service"
      url: https://arxiv.org/abs/2602.15286
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15286v2 Announce Type: replace-cross Abstract: With AI-as-a-Service (AIaaS) now deployed across
        multiple providers and model tiers, selecting the appropriate model instance at run time is increasingly outside
        the end user's knowledge and operational control. Accordingly, the 6G service providers are envisioned to play a
        crucial role in exposing AIaaS in a setting where users submit only an intent while the network helps in the
        intent-to-model matching (resolution) and execution placem"
      relevanceScore: 25
      topics:
        - ai-infrastructure
        - model-serving
        - deployment
      entities:
        - deployment-architectures-table
    - title: "KD4MT: A Survey of Knowledge Distillation for Machine Translation"
      url: https://arxiv.org/abs/2602.15845
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15845v1 Announce Type: new Abstract: Knowledge Distillation (KD) as a research area has gained a
        lot of traction in recent years as a compression tool to address challenges related to ever-larger models in
        NLP. Remarkably, Machine Translation (MT) offers a much more nuanced take on this narrative: in MT, KD also
        functions as a general-purpose knowledge transfer mechanism that shapes supervision and translation quality as
        well as efficiency. This survey synthesizes KD for MT (KD4MT) ac"
      relevanceScore: 25
      topics:
        - knowledge distillation
        - model compression
      entities:
        - language-models
    - title: "Aladdin-FTI @ AMIYA Three Wishes for Arabic NLP: Fidelity, Diglossia, and Multidialectal Generation"
      url: https://arxiv.org/abs/2602.16290
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16290v1 Announce Type: new Abstract: Arabic dialects have long been under-represented in Natural
        Language Processing (NLP) research due to their non-standardization and high variability, which pose challenges
        for computational modeling. Recent advances in the field, such as Large Language Models (LLMs), offer promising
        avenues to address this gap by enabling Arabic to be modeled as a pluricentric language rather than a monolithic
        system. This paper presents Aladdin-FTI, our submission"
      relevanceScore: 25
      topics:
        - Arabic NLP
        - multilingual
      entities:
        - language-models
    - title: Training Models on Dialects of Translationese Shows How Lexical Diversity and Source-Target Syntactic Similarity
        Shape Learning
      url: https://arxiv.org/abs/2602.16469
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16469v1 Announce Type: new Abstract: Machine-translated data is widely used in multilingual NLP,
        particularly when native text is scarce. However, translated text differs systematically from native text. This
        phenomenon is known as translationese, and it reflects both traces of the source language and characteristic
        properties of translation itself. In this paper, we study how training on machine-translated data affects small
        English language models, focusing on how translationese fro"
      relevanceScore: 25
      topics:
        - language-models
        - multilingual-nlp
      entities: []
    - title: "Quecto-V1: Empirical Analysis of 8-bit Quantized Small Language Models for On-Device Legal Retrieval"
      url: https://arxiv.org/abs/2602.16640
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: 'arXiv:2602.16640v1 Announce Type: new Abstract: The rapid proliferation of Large Language Models (LLMs) has
        revolutionized Natural Language Processing (NLP) but has simultaneously created a "resource divide."
        State-of-the-art legal intelligence systems typically rely on massive parameter counts (7B+) and cloud-based
        inference, rendering them inaccessible to practitioners in resource-constrained environments and posing
        significant data sovereignty risks. This paper introduces Quecto-V1, a domain-'
      relevanceScore: 25
      topics:
        - language-models
        - compute-hardware
        - efficiency
      entities:
        - language-models
        - compute-hardware
    - title: "Why Any-Order Autoregressive Models Need Two-Stream Attention: A Structural-Semantic Tradeoff"
      url: https://arxiv.org/abs/2602.16092
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16092v1 Announce Type: cross Abstract: Any-order autoregressive models (AO-ARMs) offer a promising
        path toward efficient masked diffusion by enabling native key-value caching, but competitive performance has so
        far required two-stream attention, typically motivated as a means of decoupling token content from position. In
        this work, we argue that two-stream attention may be serving a more subtle role. We identify a
        structural-semantic tradeoff in any-order generation: the hidden repres"
      relevanceScore: 25
      topics:
        - language-models
        - architecture
      entities:
        - language-models
    - title: Scaling Open Discrete Audio Foundation Models with Interleaved Semantic, Acoustic, and Text Tokens
      url: https://arxiv.org/abs/2602.16687
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16687v1 Announce Type: cross Abstract: Current audio language models are predominantly text-first,
        either extending pre-trained text LLM backbones or relying on semantic-only audio tokens, limiting general audio
        modeling. This paper presents a systematic empirical study of native audio foundation models that apply
        next-token prediction to audio at scale, jointly modeling semantic content, acoustic details, and text to
        support both general audio generation and cross-modal capabilities."
      relevanceScore: 25
      topics:
        - language-models
        - multimodal
        - scaling
      entities:
        - language-models
    - title: Pretraining Language Models for Diachronic Linguistic Change Discovery
      url: https://arxiv.org/abs/2504.05523
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2504.05523v3 Announce Type: replace Abstract: Large language models (LLMs) have shown potential as tools
        for scientific discovery. This has engendered growing interest in their use in humanistic disciplines, such as
        historical linguistics and literary studies. These fields often construct arguments on the basis of delineations
        like genre, or more inflexibly, time period. Although efforts have been made to restrict inference to specific
        domains via fine-tuning or model editing, we posit tha"
      relevanceScore: 25
      topics:
        - language-models
        - scientific-research
      entities:
        - language-models
        - scientific-research
    - title: "PRoH: Dynamic Planning and Reasoning over Knowledge Hypergraphs for Retrieval-Augmented Generation"
      url: https://arxiv.org/abs/2510.12434
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2510.12434v2 Announce Type: replace Abstract: Knowledge Hypergraphs (KHs) have recently emerged as a
        knowledge representation for retrieval-augmented generation (RAG), offering a paradigm to model multi-entity
        relations into a structured form. However, existing KH-based RAG methods suffer from three major limitations:
        static retrieval planning, non-adaptive retrieval execution, and superficial use of KH structure and semantics,
        which constrain their ability to perform effective multi-hop q"
      relevanceScore: 25
      topics:
        - language-models
        - tool-use
        - reasoning
      entities:
        - language-models
        - tool-use
        - reasoning
    - title: Flatter Tokens are More Valuable for Speculative Draft Model Training
      url: https://arxiv.org/abs/2601.18902
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2601.18902v2 Announce Type: replace Abstract: Speculative Decoding (SD) is a key technique for
        accelerating Large Language Model (LLM) inference, but it typically requires training a draft model on a large
        dataset. We approach this problem from a data-centric perspective, finding that not all training samples
        contribute equally to the SD acceptance rate. Specifically, our theoretical analysis and empirical validation
        reveals that tokens inducing flatter predictive distributions from the ta"
      relevanceScore: 25
      topics:
        - language-models
        - compute-hardware
        - efficiency
      entities:
        - language-models
        - compute-hardware
    - title: Training-Free Adaptation of Diffusion Models via Doob's $h$-Transform
      url: https://arxiv.org/abs/2602.16198
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16198v1 Announce Type: new Abstract: Adaptation methods have been a workhorse for unlocking the
        transformative power of pre-trained diffusion models in diverse applications. Existing approaches often abstract
        adaptation objectives as a reward function and steer diffusion models to generate high-reward samples. However,
        these approaches can incur high computational overhead due to additional training, or rely on stringent
        assumptions on the reward such as differentiability. Moreover, d"
      relevanceScore: 25
      topics:
        - diffusion-models
        - adaptation
      entities: []
    - title: Factored Latent Action World Models
      url: https://arxiv.org/abs/2602.16229
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16229v1 Announce Type: new Abstract: Learning latent actions from action-free video has emerged as
        a powerful paradigm for scaling up controllable world model learning. Latent actions provide a natural interface
        for users to iteratively generate and manipulate videos. However, most existing approaches rely on monolithic
        inverse and forward dynamics models that learn a single latent action to control the entire scene, and therefore
        struggle in complex environments where multiple entiti"
      relevanceScore: 25
      topics:
        - world-models
        - reinforcement-learning
        - latent-representations
      entities:
        - world-models
    - title: "MARVL: Multi-Stage Guidance for Robotic Manipulation via Vision-Language Models"
      url: https://arxiv.org/abs/2602.15872
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15872v1 Announce Type: cross Abstract: Designing dense reward functions is pivotal for efficient
        robotic Reinforcement Learning (RL). However, most dense rewards rely on manual engineering, which fundamentally
        limits the scalability and automation of reinforcement learning. While Vision-Language Models (VLMs) offer a
        promising path to reward design, naive VLM rewards often misalign with task progress, struggle with spatial
        grounding, and show limited understanding of task semantics. T"
      relevanceScore: 25
      topics:
        - reinforcement-learning
        - robotics
        - vision-language-models
        - tool-use
      entities:
        - tool-use
        - agentic-ai
    - title: "CHAI: CacHe Attention Inference for text2video"
      url: https://arxiv.org/abs/2602.16132
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16132v1 Announce Type: cross Abstract: Text-to-video diffusion models deliver impressive results
        but remain slow because of the sequential denoising of 3D latents. Existing approaches to speed up inference
        either require expensive model retraining or use heuristic-based step skipping, which struggles to maintain
        video quality as the number of denoising steps decreases. Our work, CHAI, aims to use cross-inference caching to
        reduce latency while maintaining video quality. We introduce C"
      relevanceScore: 25
      topics:
        - capabilities
      entities:
        - capabilities
    - title: Machine Learning in Epidemiology
      url: https://arxiv.org/abs/2602.16352
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16352v1 Announce Type: cross Abstract: In the age of digital epidemiology, epidemiologists are
        faced by an increasing amount of data of growing complexity and dimensionality. Machine learning is a set of
        powerful tools that can help to analyze such enormous amounts of data. This chapter lays the methodological
        foundations for successfully applying machine learning in epidemiology. It covers the principles of supervised
        and unsupervised learning and discusses the most important machine"
      relevanceScore: 25
      topics:
        - scientific-research
      entities:
        - scientific-research
    - title: "Let's Split Up: Zero-Shot Classifier Edits for Fine-Grained Video Understanding"
      url: https://arxiv.org/abs/2602.16545
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16545v1 Announce Type: cross Abstract: Video recognition models are typically trained on fixed
        taxonomies which are often too coarse, collapsing distinctions in object, manner or outcome under a single
        label. As tasks and definitions evolve, such models cannot accommodate emerging distinctions and collecting new
        annotations and retraining to accommodate such changes is costly. To address these challenges, we introduce
        category splitting, a new task where an existing classifier is edit"
      relevanceScore: 25
      topics:
        - capabilities
      entities:
        - capabilities
    - title: Parameter-free representations outperform single-cell foundation models on downstream benchmarks
      url: https://arxiv.org/abs/2602.16696
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16696v1 Announce Type: cross Abstract: Single-cell RNA sequencing (scRNA-seq) data exhibit strong
        and reproducible statistical structure. This has motivated the development of large-scale foundation models,
        such as TranscriptFormer, that use transformer-based architectures to learn a generative model for gene
        expression by embedding genes into a latent vector space. These embeddings have been used to obtain
        state-of-the-art (SOTA) performance on downstream tasks such as cell-type clas"
      relevanceScore: 25
      topics:
        - capabilities
      entities:
        - capabilities
    - title: "FedMerge: Federated Personalization via Model Merging"
      url: https://arxiv.org/abs/2504.06768
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2504.06768v3 Announce Type: replace Abstract: One global model in federated learning (FL) might not be
        sufficient to serve many clients with non-IID tasks and distributions. While there has been advances in FL to
        train multiple global models for better personalization, they only provide limited choices to clients so local
        finetuning is still indispensable. In this paper, we propose a novel ``FedMerge'' approach that can create a
        personalized model per client by simply merging multiple glob"
      relevanceScore: 25
      topics:
        - federated-learning
        - model-personalization
      entities: []
    - title: Robust Causal Discovery in Real-World Time Series with Power-Laws
      url: https://arxiv.org/abs/2507.12257
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2507.12257v3 Announce Type: replace Abstract: Exploring causal relationships in stochastic time series
        is a challenging yet crucial task with a vast range of applications, including finance, economics, neuroscience,
        and climate science. Many algorithms for Causal Discovery (CD) have been proposed; however, they often exhibit a
        high sensitivity to noise, resulting in spurious causal inferences in real data. In this paper, we observe that
        the frequency spectra of many real-world time series "
      relevanceScore: 25
      topics:
        - causal-discovery
        - time-series
      entities: []
    - title: Communication Compression for Distributed Learning with Aggregate and Server-Guided Feedback
      url: https://arxiv.org/abs/2512.22623
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2512.22623v2 Announce Type: replace Abstract: Distributed learning, particularly Federated Learning
        (FL), faces a significant bottleneck in the communication cost, particularly the uplink transmission of
        client-to-server updates, which is often constrained by asymmetric bandwidth limits at the edge. Biased
        compression techniques are effective in practice, but require error feedback mechanisms to provide theoretical
        guarantees and to ensure convergence when compression is aggressive. Standa"
      relevanceScore: 25
      topics:
        - federated-learning
        - communication-efficiency
      entities: []
    - title: Adaptive Exploration for Latent-State Bandits
      url: https://arxiv.org/abs/2602.05139
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.05139v2 Announce Type: replace Abstract: The multi-armed bandit problem is a core framework for
        sequential decision-making under uncertainty, but classical algorithms often fail in environments with hidden,
        time-varying states that confound reward estimation and optimal action selection. We address key challenges
        arising from unobserved confounders, such as biased reward estimates and limited state information, by
        introducing a family of state-model-free bandit algorithms that leverag"
      relevanceScore: 25
      topics:
        - multi-armed-bandits
        - exploration
        - sequential-decision-making
      entities: []
    - title: "LMSeg: Unleashing the Power of Large-Scale Models for Open-Vocabulary Semantic Segmentation"
      url: https://arxiv.org/abs/2412.00364
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2412.00364v2 Announce Type: replace-cross Abstract: It is widely agreed that open-vocabulary-based
        approaches outperform classical closed-set training solutions for recognizing unseen objects in images for
        semantic segmentation. Existing open-vocabulary approaches leverage vision-language models, such as CLIP, to
        align visual features with rich semantic features acquired through pre-training on large-scale vision-language
        datasets. However, the text prompts employed in these methods are sh"
      relevanceScore: 25
      topics:
        - vision-language-models
        - semantic-segmentation
      entities:
        - language-models
    - title: View Invariant Learning for Vision-Language Navigation in Continuous Environments
      url: https://arxiv.org/abs/2507.08831
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2507.08831v3 Announce Type: replace-cross Abstract: Vision-Language Navigation in Continuous
        Environments (VLNCE), where an agent follows instructions and moves freely to reach a destination, is a key
        research problem in embodied AI. However, most navigation policies are sensitive to viewpoint changes, i.e.,
        variations in camera height and viewing angle that alter the agent's observation. In this paper, we introduce a
        generalized scenario, V2-VLNCE (VLNCE with Varied Viewpoints), and propo"
      relevanceScore: 25
      topics:
        - vision-language-models
        - navigation
        - embodied-ai
      entities:
        - language-models
    - title: "Beyond Reinforcement Learning: Fast and Scalable Quantum Circuit Synthesis"
      url: https://arxiv.org/abs/2602.15146
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15146v2 Announce Type: replace-cross Abstract: Quantum unitary synthesis addresses the problem of
        translating abstract quantum algorithms into sequences of hardware-executable quantum gates. Solving this task
        exactly is infeasible in general due to the exponential growth of the underlying combinatorial search space.
        Existing approaches suffer from misaligned optimization objectives, substantial training costs and limited
        generalization across different qubit counts. We mitigate these "
      relevanceScore: 25
      topics:
        - quantum-computing
        - circuit-synthesis
      entities: []
    - title: "FEKAN: Feature-Enriched Kolmogorov-Arnold Networks"
      url: https://arxiv.org/abs/2602.16530
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16530v1 Announce Type: new Abstract: Kolmogorov-Arnold Networks (KANs) have recently emerged as a
        compelling alternative to multilayer perceptrons, offering enhanced interpretability via functional
        decomposition. However, existing KAN architectures, including spline-, wavelet-, radial-basis variants, etc.,
        suffer from high computational cost and slow convergence, limiting scalability and practical applicability.
        Here, we introduce Feature-Enriched Kolmogorov-Arnold Networks (FEKAN), a"
      relevanceScore: 24
      topics:
        - interpretability
        - neural-networks
        - kolmogorov-arnold
      entities: []
    - title: The Implicit Bias of Adam and Muon on Smooth Homogeneous Neural Networks
      url: https://arxiv.org/abs/2602.16340
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16340v1 Announce Type: new Abstract: We study the implicit bias of momentum-based optimizers on
        homogeneous models. We first extend existing results on the implicit bias of steepest descent in homogeneous
        models to normalized steepest descent with an optional learning rate schedule. We then show that for smooth
        homogeneous models, momentum steepest descent algorithms like Muon (spectral norm), MomentumGD ($\\ell_2$ norm),
        and Signum ($\\ell_\\infty$ norm) are approximate steepest descent"
      relevanceScore: 22
      topics:
        - optimization
        - neural-networks
        - implicit-bias
      entities: []
    - title: Improved Bounds for Reward-Agnostic and Reward-Free Exploration
      url: https://arxiv.org/abs/2602.16363
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16363v1 Announce Type: new Abstract: We study reward-free and reward-agnostic exploration in
        episodic finite-horizon Markov decision processes (MDPs), where an agent explores an unknown environment without
        observing external rewards. Reward-free exploration aims to enable $\\epsilon$-optimal policies for any reward
        revealed after exploration, while reward-agnostic exploration targets $\\epsilon$-optimality for rewards drawn
        from a small finite class. In the reward-agnostic setting, Li, "
      relevanceScore: 22
      topics:
        - reinforcement-learning
        - exploration
        - reward-free
      entities: []
    - title: "KANEL\\'E: Kolmogorov-Arnold Networks for Efficient LUT-based Evaluation"
      url: https://arxiv.org/abs/2512.12850
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2512.12850v2 Announce Type: replace-cross Abstract: Low-latency, resource-efficient neural network
        inference on FPGAs is essential for applications demanding real-time capability and low power. Lookup table
        (LUT)-based neural networks are a common solution, combining strong representational power with efficient FPGA
        implementation. In this work, we introduce KANEL\\'E, a framework that exploits the unique properties of
        Kolmogorov-Arnold Networks (KANs) for FPGA deployment. Unlike traditiona"
      relevanceScore: 22
      topics:
        - neural-networks
        - efficient-inference
        - hardware
      entities:
        - compute-hardware
    - title: Retiring GPT-4o, GPT-4.1, GPT-4.1 mini, and OpenAI o4-mini in ChatGPT
      url: https://openai.com/index/retiring-gpt-4o-and-older-models
      sourceId: openai-blog
      publishedAt: Thu, 29 Jan 2026 00:00:00 GMT
      summary: On February 13, 2026, alongside the previously announced retirement⁠ of GPT‑5 (Instant, Thinking, and Pro), we
        will retire GPT‑4o, GPT‑4.1, GPT‑4.1 mini, and OpenAI o4-mini from ChatGPT. In the API, there are no changes at
        this time.
      relevanceScore: 20
      topics:
        - deployment
      entities: []
    - title: How Higgsfield turns simple ideas into cinematic social videos
      url: https://openai.com/index/higgsfield
      sourceId: openai-blog
      publishedAt: Wed, 21 Jan 2026 10:00:00 GMT
      summary: Discover how Higgsfield gives creators cinematic, social-first video output from simple inputs using OpenAI
        GPT-4.1, GPT-5, and Sora 2.
      relevanceScore: 20
      topics:
        - capabilities
      entities:
        - capabilities
    - title: OpenAI appoints Denise Dresser as Chief Revenue Officer
      url: https://openai.com/index/openai-appoints-denise-dresser
      sourceId: openai-blog
      publishedAt: Tue, 09 Dec 2025 00:00:00 GMT
      summary: Denise Dresser is joining as Chief Revenue Officer, overseeing OpenAI’s global revenue strategy across
        enterprise and customer success. She will help more businesses put AI to work in their day-to-day operations as
        OpenAI continues to scale.
      relevanceScore: 20
      topics:
        - lab-behavior
      entities:
        - lab-behavior
    - title: Introducing ChatGPT Atlas, the browser with ChatGPT built in
      url: https://openai.com/index/introducing-chatgpt-atlas
      sourceId: openai-blog
      publishedAt: Tue, 21 Oct 2025 00:00:00 GMT
      summary: ChatGPT Atlas, the browser with ChatGPT built it. Get instant answers, summaries, and smart web help—right from
        any page. With privacy settings you can control. Available now for MacOS.
      relevanceScore: 20
      topics:
        - tool-use
        - capabilities
      entities:
        - tool-use
    - title: Plex Coffee delivers fast service and personal connections with ChatGPT Business
      url: https://openai.com/index/plex-coffee
      sourceId: openai-blog
      publishedAt: Wed, 15 Oct 2025 00:00:00 GMT
      summary: Learn how Plex Coffee uses ChatGPT Business to centralize knowledge, train staff faster, and preserve personal
        connections while expanding.
      relevanceScore: 20
      topics:
        - deployment-architectures-table
        - economic-labor
      entities:
        - deployment-architectures-table
    - title: Improving support with every interaction at OpenAI
      url: https://openai.com/index/openai-support-model
      sourceId: openai-blog
      publishedAt: Mon, 29 Sep 2025 13:30:00 GMT
      summary: Learn how OpenAI uses AI to enhance support, cutting response times, improving quality, and scaling to meet
        hypergrowth.
      relevanceScore: 20
      topics:
        - lab-behavior
      entities: []
    - title: Empowering teams to unlock insights faster at OpenAI
      url: https://openai.com/index/openai-research-assistant
      sourceId: openai-blog
      publishedAt: Mon, 29 Sep 2025 13:30:00 GMT
      summary: OpenAI’s research assistant helps teams analyze millions of support tickets, surface insights faster, and scale
        curiosity across the company.
      relevanceScore: 20
      topics:
        - lab-behavior
      entities: []
    - title: Converting inbound leads into customers at OpenAI
      url: https://openai.com/index/openai-inbound-sales-assistant
      sourceId: openai-blog
      publishedAt: Mon, 29 Sep 2025 13:30:00 GMT
      summary: Learn how OpenAI used AI to deliver personalized answers at scale, converting inbound leads into customers.
      relevanceScore: 20
      topics:
        - lab-behavior
      entities: []
    - title: Driving sales productivity and customer success at OpenAI
      url: https://openai.com/index/openai-gtm-assistant
      sourceId: openai-blog
      publishedAt: Mon, 29 Sep 2025 13:30:00 GMT
      summary: Learn how OpenAI boosts sales productivity by automating prep, centralizing knowledge, and scaling top-selling
        practices.
      relevanceScore: 20
      topics:
        - lab-behavior
      entities: []
    - title: Figma uses AI to transform digital design
      url: https://openai.com/index/figma-david-kossnick
      sourceId: openai-blog
      publishedAt: Fri, 01 Aug 2025 00:00:00 GMT
      summary: Discover how Figma is transforming digital design with AI. David Kossnick shares how tools like Figma Make
        empower teams to prototype, collaborate, and build with AI—reshaping workflows for designers, developers, and
        non-technical creators alike.
      relevanceScore: 20
      topics:
        - tool-use
        - capabilities
      entities:
        - tool-use
    - title: Introducing study mode in ChatGPT
      url: https://openai.com/index/chatgpt-study-mode
      sourceId: openai-blog
      publishedAt: Tue, 29 Jul 2025 10:00:00 GMT
      summary: Introducing study mode in ChatGPT, a new learning experience that helps you work through problems step by step,
        guiding students with questions, scaffolding, and feedback for deeper learning.
      relevanceScore: 20
      topics:
        - tool-use
        - capabilities
      entities:
        - tool-use
    - title: OpenAI nonprofit jam
      url: https://openai.com/global-affairs/openai-nonprofit-jam
      sourceId: openai-blog
      publishedAt: Thu, 17 Jul 2025 00:00:00 GMT
      summary: At OpenAI, we build tools to help people solve hard problems—including nonprofits working on the frontlines of
        their communities. The OpenAI Academy is teaming up with the Walton Family Foundation, Emerson Collective, and a
        network of local nonprofit organizations to host the Nonprofit Jam—a one-day, nationwide event bringing together
        more than 1,000 nonprofit leaders across 10 locations.
      relevanceScore: 20
      topics:
        - capabilities
      entities: []
    - title: Sam & Jony
      url: https://openai.com/sam-and-jony
      sourceId: openai-blog
      publishedAt: Wed, 09 Jul 2025 00:00:00 GMT
      summary: Building a family of AI products for everyone.
      relevanceScore: 20
      topics:
        - capabilities
      entities: []
    - title: Creating websites in minutes with AI Website Builder
      url: https://openai.com/index/wix
      sourceId: openai-blog
      publishedAt: Thu, 29 May 2025 00:00:00 GMT
      summary: Wix’s AI Website Builder, powered by OpenAI, lets anyone create a full website in minutes—just by describing
        their idea in a conversation.
      relevanceScore: 20
      topics:
        - capabilities
        - tool-use
      entities:
        - tool-use
    - title: OpenAI Expands Leadership with Fidji Simo
      url: https://openai.com/index/leadership-expansion-with-fidji-simo
      sourceId: openai-blog
      publishedAt: Wed, 07 May 2025 21:00:00 GMT
      summary: Read the message Sam shared with the company earlier today.
      relevanceScore: 20
      topics:
        - lab-behavior
      entities:
        - lab-behavior
    - title: The San Antonio Spurs use ChatGPT to scale impact on and off the court
      url: https://openai.com/index/san-antonio-spurs
      sourceId: openai-blog
      publishedAt: Wed, 07 May 2025 09:00:00 GMT
      summary: Discover how the San Antonio Spurs are using custom GPTs to enhance fan engagement, streamline operations, and
        drive innovation across teams.
      relevanceScore: 20
      topics:
        - capabilities
        - tool-use
      entities:
        - tool-use
    - title: "New in ChatGPT for Business: April 2025"
      url: https://openai.com/business/new-in-chatgpt-for-business-april-updates-2025
      sourceId: openai-blog
      publishedAt: Thu, 24 Apr 2025 00:00:00 GMT
      summary: "Watch hands-on demos of the lastest in ChatGPT for Business: o3, image generation, enhanced memory, and
        internal knowledge."
      relevanceScore: 20
      topics:
        - product-release
        - capabilities
      entities: []
    - title: Speak is personalizing language learning with AI
      url: https://openai.com/index/speak-connor-zwick
      sourceId: openai-blog
      publishedAt: Tue, 22 Apr 2025 10:00:00 GMT
      summary: A conversation with Connor Zwick, CEO & Co-founder of Speak.
      relevanceScore: 20
      topics:
        - ai-applications
      entities: []
    - title: Canva enables creativity with AI
      url: https://openai.com/index/canva-cam-adams
      sourceId: openai-blog
      publishedAt: Mon, 07 Apr 2025 00:00:00 GMT
      summary: A conversation with Cameron Adams, Chief Product Officer and Co-founder of Canva.
      relevanceScore: 20
      topics:
        - ai-applications
      entities: []
    - title: Introducing next-generation audio models in the API
      url: https://openai.com/index/introducing-our-next-generation-audio-models
      sourceId: openai-blog
      publishedAt: Thu, 20 Mar 2025 11:00:00 GMT
      summary: For the first time, developers can also instruct the text-to-speech model to speak in a specific way—for
        example, “talk like a sympathetic customer service agent”—unlocking a new level of customization for voice
        agents.
      relevanceScore: 20
      topics:
        - capabilities
        - tool-use
      entities:
        - tool-use
    - title: OpenAI and Guardian Media Group launch content partnership
      url: https://openai.com/index/openai-and-guardian-media-group-launch-content-partnership
      sourceId: openai-blog
      publishedAt: Fri, 14 Feb 2025 07:00:00 GMT
      summary: OpenAI and Guardian Media Group announce content partnership to bring Guardian news content to ChatGPT.
      relevanceScore: 20
      topics:
        - deployment
        - geopolitics
      entities:
        - geopolitics
    - title: OpenAI partners with Schibsted Media Group
      url: https://openai.com/index/openai-partners-with-schibsted-media-group
      sourceId: openai-blog
      publishedAt: Mon, 10 Feb 2025 06:00:00 GMT
      summary: OpenAI and Schibsted Media Group announce content partnership to bring Guardian news and archive content to
        ChatGPT.
      relevanceScore: 20
      topics:
        - deployment
        - geopolitics
      entities:
        - geopolitics
    - title: "Put AI to work: Automate and scale financial operations"
      url: https://openai.com/business/put-ai-to-work-automate-and-scale-financial-operations
      sourceId: openai-blog
      publishedAt: Mon, 30 Sep 2024 00:00:00 GMT
      summary: "Put AI to work: Automate and Scale Financial Operations"
      relevanceScore: 20
      topics:
        - capabilities
        - economic-labor
      entities:
        - economic-labor
    - title: Introducing Verdi, an AI dev platform powered by GPT-4o
      url: https://openai.com/index/mercado-libre
      sourceId: openai-blog
      publishedAt: Tue, 24 Sep 2024 07:00:00 GMT
      summary: Mercado Libre introduces Verdi, an AI developer platform powered by GPT-4o
      relevanceScore: 20
      topics:
        - capabilities
        - tool-use
      entities:
        - tool-use
    - title: Using GPT-4 to improve teaching and learning in Brazil
      url: https://openai.com/index/arco-education
      sourceId: openai-blog
      publishedAt: Tue, 17 Sep 2024 05:00:00 GMT
      summary: Improving teaching and learning in Brazil
      relevanceScore: 20
      topics:
        - capabilities
      entities: []
    - title: Using GPT-4 to deliver a new customer service standard
      url: https://openai.com/index/ada
      sourceId: openai-blog
      publishedAt: Thu, 05 Sep 2024 08:00:00 GMT
      summary: Ada uses GPT-4 to deliver a new customer service standard
      relevanceScore: 20
      topics:
        - capabilities
      entities:
        - capabilities
    - title: OpenAI partners with Condé Nast
      url: https://openai.com/index/conde-nast
      sourceId: openai-blog
      publishedAt: Tue, 20 Aug 2024 11:00:00 GMT
      summary: Condé Nast
      relevanceScore: 20
      topics:
        - partnerships
        - deployment
      entities:
        - language-models
    - title: Putting AI to work at Upwork
      url: https://openai.com/index/upwork
      sourceId: openai-blog
      publishedAt: Tue, 20 Aug 2024 10:00:00 GMT
      summary: Upwork puts AI to work, uniting team members, operations and product development
      relevanceScore: 20
      topics:
        - deployment
        - labor-automation
      entities:
        - economic-labor
    - title: Delivering contextual job matching for millions with OpenAI
      url: https://openai.com/index/indeed
      sourceId: openai-blog
      publishedAt: Thu, 15 Aug 2024 07:00:00 GMT
      summary: "Indeed, whose mission is to help people get jobs, is the world’s #1 job site. Over 350 million unique visitors
        come to Indeed every month to connect with more than 3.5 million employers and over 32 million jobs. But what’s
        more is that every three seconds someone gets hired on Indeed."
      relevanceScore: 20
      topics:
        - deployment
        - labor-automation
      entities:
        - economic-labor
    - title: Enabling a data-driven workforce
      url: https://openai.com/business/enabling-a-data-driven-workforce-webinar
      sourceId: openai-blog
      publishedAt: Thu, 08 Aug 2024 00:00:00 GMT
      summary: In this video, we share practical examples of how employees can use ChatGPT Enterprise to efficiently analyze
        data and uncover insights.
      relevanceScore: 20
      topics:
        - deployment
        - enterprise
      entities:
        - language-models
    - title: Pairing data with APIs to unlock customer value
      url: https://openai.com/index/rakuten
      sourceId: openai-blog
      publishedAt: Wed, 07 Aug 2024 16:00:00 GMT
      summary: Rakuten Pairs Data with AI to Unlock Customer Insights and Value
      relevanceScore: 20
      topics:
        - deployment
        - business-applications
      entities:
        - language-models
    - title: Strategic Content Partnership with TIME
      url: https://openai.com/index/strategic-content-partnership-with-time
      sourceId: openai-blog
      publishedAt: Thu, 27 Jun 2024 06:00:00 GMT
      summary: We’re partnering with TIME and its 101 years of archival content to enhance responses and provide links to
        stories on Time.com
      relevanceScore: 20
      topics:
        - partnerships
        - deployment
      entities:
        - language-models
    - title: Improving India’s critical care infrastructure
      url: https://openai.com/index/10bedicu
      sourceId: openai-blog
      publishedAt: Thu, 06 Jun 2024 10:00:00 GMT
      summary: ""
      relevanceScore: 20
      topics:
        - capabilities
      entities:
        - capabilities
    - title: How the voices for ChatGPT were chosen
      url: https://openai.com/index/how-the-voices-for-chatgpt-were-chosen
      sourceId: openai-blog
      publishedAt: Sun, 19 May 2024 23:30:00 GMT
      summary: How the voices for ChatGPT were chosen We worked with industry-leading casting and directing professionals to
        narrow down over 400 submissions before selecting the 5 voices.
      relevanceScore: 20
      topics:
        - capabilities
      entities:
        - capabilities
    - title: Introducing OpenAI Japan
      url: https://openai.com/index/introducing-openai-japan
      sourceId: openai-blog
      publishedAt: Sun, 14 Apr 2024 00:00:00 GMT
      summary: We are excited to announce our first office in Asia and we’re releasing a GPT-4 custom model optimized for the
        Japanese language.
      relevanceScore: 20
      topics:
        - deployment
        - geopolitics
      entities:
        - geopolitics
    - title: Powering virtual education for the classroom
      url: https://openai.com/index/khan-academy
      sourceId: openai-blog
      publishedAt: Tue, 14 Mar 2023 07:00:00 GMT
      summary: Khan Academy explores the potential for GPT-4 in a limited pilot program.
      relevanceScore: 20
      topics:
        - applications
        - education
      entities: []
    - title: Transforming visual accessibility
      url: https://openai.com/index/be-my-eyes
      sourceId: openai-blog
      publishedAt: Tue, 14 Mar 2023 07:00:00 GMT
      summary: Be My Eyes uses GPT-4 to transform visual accessibility.
      relevanceScore: 20
      topics:
        - applications
        - accessibility
      entities: []
    - title: Introducing ChatGPT Plus
      url: https://openai.com/index/chatgpt-plus
      sourceId: openai-blog
      publishedAt: Wed, 01 Feb 2023 08:00:00 GMT
      summary: We’re launching a pilot subscription plan for ChatGPT, a conversational AI that can chat with you, answer
        follow-up questions, and challenge incorrect assumptions.
      relevanceScore: 20
      topics:
        - product-launch
        - commercialization
      entities: []
    - title: Discovering the minutiae of backend systems
      url: https://openai.com/index/discovering-the-minutiae-of-backend-systems
      sourceId: openai-blog
      publishedAt: Thu, 08 Dec 2022 08:00:00 GMT
      summary: Christian Gibson is an engineer on the Supercomputing team at OpenAI.
      relevanceScore: 20
      topics:
        - infrastructure
        - compute
      entities:
        - compute-hardware
    - title: "DALL·E: Introducing outpainting"
      url: https://openai.com/index/dall-e-introducing-outpainting
      sourceId: openai-blog
      publishedAt: Wed, 31 Aug 2022 07:00:00 GMT
      summary: Extend creativity and tell a bigger story with DALL·E images of any size.
      relevanceScore: 20
      topics:
        - capabilities
      entities: []
    - title: "DALL·E 2: Extending creativity"
      url: https://openai.com/index/dall-e-2-extending-creativity
      sourceId: openai-blog
      publishedAt: Thu, 14 Jul 2022 07:00:00 GMT
      summary: As part of our DALL·E 2 research preview, more than 3,000 artists from more than 118 countries have
        incorporated DALL·E into their creative workflows. The artists in our early access group have helped us discover
        new uses for DALL·E and have served as key voices as we’ve made decisions about DALL·E’s features.
      relevanceScore: 20
      topics:
        - capabilities
      entities: []
    - title: "OpenAI Scholars 2020: Applications open"
      url: https://openai.com/index/openai-scholars-2020
      sourceId: openai-blog
      publishedAt: Fri, 11 Oct 2019 07:00:00 GMT
      summary: We are now accepting applications for our third class of OpenAI Scholars.
      relevanceScore: 20
      topics:
        - talent
        - education
      entities: []
    - title: "OpenAI Scholars 2019: Final projects"
      url: https://openai.com/index/openai-scholars-2019-final-projects
      sourceId: openai-blog
      publishedAt: Thu, 23 May 2019 07:00:00 GMT
      summary: Our second class of OpenAI Scholars has concluded, with all eight scholars producing an exciting final project
        showcased at Scholars Demo Day at OpenAI.
      relevanceScore: 20
      topics:
        - talent
        - education
      entities: []
    - title: "OpenAI Fellows Fall 2018: Final projects"
      url: https://openai.com/index/openai-fellows-fall-2018
      sourceId: openai-blog
      publishedAt: Fri, 17 May 2019 07:00:00 GMT
      summary: Our second class of OpenAI Fellows has wrapped up, with each Fellow going from a machine learning beginner to
        core OpenAI contributor in the course of a 6-month apprenticeship. We are currently reviewing applications on a
        rolling basis for our next round of OpenAI Fellows Summer 2019.
      relevanceScore: 20
      topics:
        - talent
        - education
      entities: []
    - title: "A new way to express yourself: Gemini can now create music"
      url: https://deepmind.google/blog/a-new-way-to-express-yourself-gemini-can-now-create-music/
      sourceId: deepmind-blog
      publishedAt: Wed, 18 Feb 2026 16:01:38 +0000
      summary: The Gemini app now features our most advanced music generation model Lyria 3, empowering anyone to make
        30-second tracks using text or images.
      relevanceScore: 20
      topics:
        - capabilities
      entities: []
    - title: Engineering more resilient crops for a warming climate
      url: https://deepmind.google/blog/engineering-more-resilient-crops-for-a-warming-climate/
      sourceId: deepmind-blog
      publishedAt: Thu, 04 Dec 2025 16:23:24 +0000
      summary: Scientists are using AlphaFold to strengthen a photosynthesis enzyme for resilient, heat-tolerant crops.
      relevanceScore: 20
      topics:
        - scientific-research
      entities:
        - scientific-research
    - title: Revealing a key protein behind heart disease
      url: https://deepmind.google/blog/revealing-a-key-protein-behind-heart-disease/
      sourceId: deepmind-blog
      publishedAt: Tue, 25 Nov 2025 15:52:51 +0000
      summary: AlphaFold has revealed the structure of a key protein behind heart disease
      relevanceScore: 20
      topics:
        - scientific-research
      entities:
        - scientific-research
    - title: Pushing the frontiers of audio generation
      url: https://deepmind.google/blog/pushing-the-frontiers-of-audio-generation/
      sourceId: deepmind-blog
      publishedAt: Wed, 30 Oct 2024 15:00:00 +0000
      summary: Our pioneering speech generation technologies are helping people around the world interact with more natural,
        conversational and intuitive digital assistants and AI tools.
      relevanceScore: 20
      topics:
        - capabilities
      entities: []
    - title: Altruism Survey
      url: https://forum.effectivealtruism.org/posts/4bKbWn2dXCgddC22d/altruism-survey
      sourceId: ea-forum
      publishedAt: Wed, 18 Feb 2026 18:40:56 GMT
      summary: Published on February 18, 2026 6:40 PM GMTI wrote a survey about social influences on people's level of
        altruism. Please take it!(I am deliberately oversampling extremely altruistic people because they are an
        interesting demographic for my research question.)I will report my findings on the Effective Altruism Forum and
        LessWrong when I am done.Discuss
      relevanceScore: 20
      topics:
        - altruism
        - social-science
      entities: []
    - title: "Narrative Theory-Driven LLM Methods for Automatic Story Generation and Understanding: A Survey"
      url: https://arxiv.org/abs/2602.15851
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15851v1 Announce Type: cross Abstract: Applications of narrative theories using large language
        models (LLMs) deliver promising use-cases in automatic story generation and understanding tasks. Our survey
        examines how natural language processing (NLP) research engages with fields of narrative studies, and proposes a
        taxonomy for ongoing efforts that reflect established distinctions in narratology. We discover patterns in the
        following: narrative datasets and tasks, narrative theories an"
      relevanceScore: 20
      topics:
        - language-models
        - story-generation
      entities:
        - language-models
    - title: Enhancing Action and Ingredient Modeling for Semantically Grounded Recipe Generation
      url: https://arxiv.org/abs/2602.15862
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15862v1 Announce Type: cross Abstract: Recent advances in Multimodal Large Language Models (MLMMs)
        have enabled recipe generation from food images, yet outputs often contain semantically incorrect actions or
        ingredients despite high lexical scores (e.g., BLEU, ROUGE). To address this gap, we propose a semantically
        grounded framework that predicts and validates actions and ingredients as internal context for instruction
        generation. Our two-stage pipeline combines supervised fine-tuning"
      relevanceScore: 20
      topics:
        - multimodal-models
        - generation
      entities:
        - language-models
    - title: Genetic Generalized Additive Models
      url: https://arxiv.org/abs/2602.15877
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15877v1 Announce Type: cross Abstract: Generalized Additive Models (GAMs) balance predictive
        accuracy and interpretability, but manually configuring their structure is challenging. We propose using the
        multi-objective genetic algorithm NSGA-II to automatically optimize GAMs, jointly minimizing prediction error
        (RMSE) and a Complexity Penalty that captures sparsity, smoothness, and uncertainty. Experiments on the
        California Housing dataset show that NSGA-II discovers GAMs that outperfo"
      relevanceScore: 20
      topics:
        - interpretability
        - machine-learning
      entities:
        - interpretability-sufficient
    - title: "Surrogate Modeling for Neutron Transport: A Neural Operator Approach"
      url: https://arxiv.org/abs/2602.15890
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15890v1 Announce Type: cross Abstract: This work introduces a neural operator based surrogate
        modeling framework for neutron transport computation. Two architectures, the Deep Operator Network (DeepONet)
        and the Fourier Neural Operator (FNO), were trained for fixed source problems to learn the mapping from
        anisotropic neutron sources, Q(x,{\\mu}), to the corresponding angular fluxes, {\\psi}(x,{\\mu}), in a
        one-dimensional slab geometry. Three distinct models were trained for each neural"
      relevanceScore: 20
      topics:
        - neural-networks
        - scientific-research
      entities:
        - scientific-research
    - title: A fully differentiable framework for training proxy Exchange Correlation Functionals for periodic systems
      url: https://arxiv.org/abs/2602.15923
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15923v1 Announce Type: cross Abstract: Density Functional Theory (DFT) is widely used for
        first-principles simulations in chemistry and materials science, but its computational cost remains a key
        limitation for large systems. Motivated by recent advances in ML-based exchange-correlation (XC) functionals,
        this paper introduces a differentiable framework that integrates machine learning models into density functional
        theory (DFT) for solids and other periodic systems. The framework defi"
      relevanceScore: 20
      topics:
        - scientific-research
        - neural-networks
      entities:
        - scientific-research
    - title: "ODYN: An All-Shifted Non-Interior-Point Method for Quadratic Programming in Robotics and AI"
      url: https://arxiv.org/abs/2602.16005
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16005v1 Announce Type: cross Abstract: We introduce ODYN, a novel all-shifted primal-dual
        non-interior-point quadratic programming (QP) solver designed to efficiently handle challenging dense and sparse
        QPs. ODYN combines all-shifted nonlinear complementarity problem (NCP) functions with proximal method of
        multipliers to robustly address ill-conditioned and degenerate problems, without requiring linear independence
        of the constraints. It exhibits strong warm-start performance and is w"
      relevanceScore: 20
      topics:
        - optimization
        - robotics
      entities: []
    - title: "Omni-iEEG: A Large-Scale, Comprehensive iEEG Dataset and Benchmark for Epilepsy Research"
      url: https://arxiv.org/abs/2602.16072
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16072v1 Announce Type: cross Abstract: Epilepsy affects over 50 million people worldwide, and
        one-third of patients suffer drug-resistant seizures where surgery offers the best chance of seizure freedom.
        Accurate localization of the epileptogenic zone (EZ) relies on intracranial EEG (iEEG). Clinical workflows,
        however, remain constrained by labor-intensive manual review. At the same time, existing data-driven approaches
        are typically developed on single-center datasets that are incons"
      relevanceScore: 20
      topics:
        - medical-ai
        - benchmarking
        - epilepsy
      entities: []
    - title: Surrogate-Based Prevalence Measurement for Large-Scale A/B Testing
      url: https://arxiv.org/abs/2602.16111
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16111v1 Announce Type: cross Abstract: Online media platforms often need to measure how frequently
        users are exposed to specific content attributes in order to evaluate trade-offs in A/B experiments. A direct
        approach is to sample content, label it using a high-quality rubric (e.g., an expert-reviewed LLM prompt), and
        estimate impression-weighted prevalence. However, repeatedly running such labeling for every experiment arm and
        segment is too costly and slow to serve as a default meas"
      relevanceScore: 20
      topics:
        - language-models
      entities:
        - language-models
    - title: Edge Learning via Federated Split Decision Transformers for Metaverse Resource Allocation
      url: https://arxiv.org/abs/2602.16174
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16174v1 Announce Type: cross Abstract: Mobile edge computing (MEC) based wireless metaverse
        services offer an untethered, immersive experience to users, where the superior quality of experience (QoE)
        needs to be achieved under stringent latency constraints and visual quality demands. To achieve this, MEC-based
        intelligent resource allocation for virtual reality users needs to be supported by coordination across MEC
        servers to harness distributed data. Federated learning (FL) is a prom"
      relevanceScore: 20
      topics:
        - language-models
      entities:
        - language-models
    - title: A Self-Supervised Approach for Enhanced Feature Representations in Object Detection Tasks
      url: https://arxiv.org/abs/2602.16322
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16322v1 Announce Type: cross Abstract: In the fast-evolving field of artificial intelligence, where
        models are increasingly growing in complexity and size, the availability of labeled data for training deep
        learning models has become a significant challenge. Addressing complex problems like object detection demands
        considerable time and resources for data labeling to achieve meaningful results. For companies developing such
        applications, this entails extensive investment in highly ski"
      relevanceScore: 20
      topics:
        - language-models
      entities:
        - language-models
    - title: Automated Histopathology Report Generation via Pyramidal Feature Extraction and the UNI Foundation Model
      url: https://arxiv.org/abs/2602.16422
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16422v1 Announce Type: cross Abstract: Generating diagnostic text from histopathology whole slide
        images (WSIs) is challenging due to the gigapixel scale of the input and the requirement for precise, domain
        specific language. We propose a hierarchical vision language framework that combines a frozen pathology
        foundation model with a Transformer decoder for report generation. To make WSI processing tractable, we perform
        multi resolution pyramidal patch selection (downsampling factors 2"
      relevanceScore: 20
      topics:
        - capabilities
      entities:
        - capabilities
    - title: "Designing Production-Scale OCR for India: Multilingual and Domain-Specific Systems"
      url: https://arxiv.org/abs/2602.16430
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16430v1 Announce Type: cross Abstract: Designing Optical Character Recognition (OCR) systems for
        India requires balancing linguistic diversity, document heterogeneity, and deployment constraints. In this
        paper, we study two training strategies for building multilingual OCR systems with Vision-Language Models
        through the Chitrapathak series. We first follow a popular multimodal approach, pairing a generic vision encoder
        with a strong multilingual language model and training the system "
      relevanceScore: 20
      topics:
        - capabilities
      entities:
        - capabilities
    - title: Fast and Scalable Analytical Diffusion
      url: https://arxiv.org/abs/2602.16498
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16498v1 Announce Type: cross Abstract: Analytical diffusion models offer a mathematically
        transparent path to generative modeling by formulating the denoising score as an empirical-Bayes posterior mean.
        However, this interpretability comes at a prohibitive cost: the standard formulation necessitates a full-dataset
        scan at every timestep, scaling linearly with dataset size. In this work, we present the first systematic study
        addressing this scalability bottleneck. We challenge the prev"
      relevanceScore: 20
      topics:
        - capabilities
      entities:
        - capabilities
    - title: A Contrastive Learning Framework Empowered by Attention-based Feature Adaptation for Street-View Image
        Classification
      url: https://arxiv.org/abs/2602.16590
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16590v1 Announce Type: cross Abstract: Street-view image attribute classification is a vital
        downstream task of image classification, enabling applications such as autonomous driving, urban analytics, and
        high-definition map construction. It remains computationally demanding whether training from scratch,
        initialising from pre-trained weights, or fine-tuning large models. Although pre-trained vision-language models
        such as CLIP offer rich image representations, existing adaptation or "
      relevanceScore: 20
      topics:
        - capabilities
      entities:
        - capabilities
    - title: "CARL: Camera-Agnostic Representation Learning for Spectral Image Analysis"
      url: https://arxiv.org/abs/2504.19223
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2504.19223v4 Announce Type: replace-cross Abstract: Spectral imaging offers promising applications
        across diverse domains, including medicine and urban scene understanding, and is already established as a
        critical modality in remote sensing. However, variability in channel dimensionality and captured wavelengths
        among spectral cameras impede the development of AI-driven methodologies, leading to camera-specific models with
        limited generalizability and inadequate cross-camera applicability."
      relevanceScore: 20
      topics:
        - computer-vision
        - representation-learning
      entities: []
    - title: "Q3R: Quadratic Reweighted Rank Regularizer for Effective Low-Rank Training"
      url: https://arxiv.org/abs/2511.04485
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2511.04485v2 Announce Type: replace-cross Abstract: Parameter-efficient training based on low-rank
        optimization has become a highly successful tool for fine-tuning large deep learning models. However, these
        methods often fail for low-rank pre-training, where simultaneously maintaining low-rank weight structure and
        optimizing the task objective remains challenging. We propose the $\\textit{Quadratic Reweighted Rank
        Regularizer}$ ($\\texttt{Q3R}$), which leads to a novel low-rank-inducing trai"
      relevanceScore: 20
      topics:
        - model-training
        - efficiency
        - deep-learning
      entities: []
    - title: Cardinality-Preserving Attention Channels for Graph Transformers in Molecular Property Prediction
      url: https://arxiv.org/abs/2602.02201
      sourceId: arxiv-cs-ai
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.02201v5 Announce Type: replace-cross Abstract: Molecular property prediction is crucial for drug
        discovery when labeled data are scarce. This work presents CardinalGraphFormer, a graph transformer augmented
        with a query-conditioned cardinality-preserving attention (CPA) channel that retains dynamic support-size
        signals complementary to static centrality embeddings. The approach combines structured sparse attention with
        Graphormer-inspired biases (shortest-path distance, centrality, di"
      relevanceScore: 20
      topics:
        - graph-transformers
        - molecular-prediction
      entities: []
    - title: Large Language Models for Assisting American College Applications
      url: https://arxiv.org/abs/2602.15850
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15850v1 Announce Type: new Abstract: American college applications require students to navigate
        fragmented admissions policies, repetitive and conditional forms, and ambiguous questions that often demand
        cross-referencing multiple sources. We present EZCollegeApp, a large language model (LLM)-powered system that
        assists high-school students by structuring application forms, grounding suggested answers in authoritative
        admissions documents, and maintaining full human control over final"
      relevanceScore: 20
      topics:
        - LLM applications
        - education
      entities:
        - language-models
    - title: "Supercharging Agenda Setting Research: The ParlaCAP Dataset of 28 European Parliaments and a Scalable
        Multilingual LLM-Based Classification"
      url: https://arxiv.org/abs/2602.16516
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16516v1 Announce Type: new Abstract: This paper introduces ParlaCAP, a large-scale dataset for
        analyzing parliamentary agenda setting across Europe, and proposes a cost-effective method for building
        domain-specific policy topic classifiers. Applying the Comparative Agendas Project (CAP) schema to the
        multilingual ParlaMint corpus of over 8 million speeches from 28 parliaments of European countries and
        autonomous regions, we follow a teacher-student framework in which a high-performing"
      relevanceScore: 20
      topics:
        - language-models
        - nlp
      entities:
        - language-models
    - title: "ColBERT-Zero: To Pre-train Or Not To Pre-train ColBERT models"
      url: https://arxiv.org/abs/2602.16609
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16609v1 Announce Type: new Abstract: Current state-of-the-art multi-vector models are obtained
        through a small Knowledge Distillation (KD) training step on top of strong single-vector models, leveraging the
        large-scale pre-training of these models. In this paper, we study the pre-training of multi-vector models and
        show that large-scale multi-vector pre-training yields much stronger multi-vector models. Notably, a fully
        ColBERT-pre-trained model, ColBERT-Zero, trained only on public d"
      relevanceScore: 20
      topics:
        - language-models
        - training
      entities:
        - language-models
    - title: A Methodology for Identifying Evaluation Items for Practical Dialogue Systems Based on Business-Dialogue System
        Alignment Models
      url: https://arxiv.org/abs/2602.15835
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15835v1 Announce Type: cross Abstract: This paper proposes a methodology for identifying evaluation
        items for practical dialogue systems. Traditionally, user satisfaction and user experiences have been the
        primary metrics for evaluating dialogue systems. However, there are various other evaluation items to consider
        when developing and operating practical dialogue systems, and such evaluation items are expected to lead to new
        research topics. So far, there has been no methodology for i"
      relevanceScore: 20
      topics:
        - language-models
        - evaluation
      entities:
        - language-models
    - title: Discrete Stochastic Localization for Non-autoregressive Generation
      url: https://arxiv.org/abs/2602.16169
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16169v1 Announce Type: cross Abstract: Non-autoregressive (NAR) generation reduces decoding latency
        by predicting many tokens in parallel, but iterative refinement often suffers from error accumulation and
        distribution shift under self-generated drafts. Masked diffusion language models (MDLMs) and their remasking
        samplers (e.g., ReMDM) can be viewed as modern NAR iterative refinement, where generation repeatedly revises a
        partially observed draft. In this work we show that \\emph{train"
      relevanceScore: 20
      topics:
        - language-models
        - generation
      entities:
        - language-models
    - title: Variable-Length Semantic IDs for Recommender Systems
      url: https://arxiv.org/abs/2602.16375
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16375v1 Announce Type: cross Abstract: Generative models are increasingly used in recommender
        systems, both for modeling user behavior as event sequences and for integrating large language models into
        recommendation pipelines. A key challenge in this setting is the extremely large cardinality of item spaces,
        which makes training generative models difficult and introduces a vocabulary gap between natural language and
        item identifiers. Semantic identifiers (semantic IDs), which represen"
      relevanceScore: 20
      topics:
        - language-models
        - nlp
      entities:
        - language-models
    - title: "Toward Beginner-Friendly LLMs for Language Learning: Controlling Difficulty in Conversation"
      url: https://arxiv.org/abs/2506.04072
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2506.04072v2 Announce Type: replace Abstract: Practicing conversations with large language models (LLMs)
        presents a promising alternative to traditional in-person language learning. However, most LLMs generate text at
        a near-native level of complexity, making them ill-suited for first and second-year beginner learners (CEFR:
        A1-A2). In this paper, we investigate whether controllable generation techniques can adapt LLM outputs to better
        support beginners. We evaluate these methods through b"
      relevanceScore: 20
      topics:
        - language-models
        - nlp
      entities:
        - language-models
    - title: "PoeTone: A Framework for Constrained Generation of Structured Chinese Songci with LLMs"
      url: https://arxiv.org/abs/2508.02515
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2508.02515v2 Announce Type: replace Abstract: This paper presents a systematic investigation into the
        constrained generation capabilities of large language models (LLMs) in producing Songci, a classical Chinese
        poetry form characterized by strict structural, tonal, and rhyme constraints defined by Cipai templates. We
        first develop a comprehensive, multi-faceted evaluation framework that includes: (i) a formal conformity score,
        (ii) automated quality assessment using LLMs, (iii) human evalu"
      relevanceScore: 20
      topics:
        - language-models
        - generation
      entities:
        - language-models
    - title: Large Language Models as Automatic Annotators and Annotation Adjudicators for Fine-Grained Opinion Analysis
      url: https://arxiv.org/abs/2601.16800
      sourceId: arxiv-cs-cl
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2601.16800v2 Announce Type: replace Abstract: Fine-grained opinion analysis of text provides a detailed
        understanding of expressed sentiments, including the addressed entity. Although this level of detail is sound,
        it requires considerable human effort and substantial cost to annotate opinions in datasets for training models,
        especially across diverse domains and real-world applications. We explore the feasibility of LLMs as automatic
        annotators for fine-grained opinion analysis, addressin"
      relevanceScore: 20
      topics:
        - language-models
        - nlp
      entities:
        - language-models
    - title: Regret and Sample Complexity of Online Q-Learning via Concentration of Stochastic Approximation with
        Time-Inhomogeneous Markov Chains
      url: https://arxiv.org/abs/2602.16274
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16274v1 Announce Type: new Abstract: We present the first high-probability regret bound for
        classical online Q-learning in infinite-horizon discounted Markov decision processes, without relying on
        optimism or bonus terms. We first analyze Boltzmann Q-learning with decaying temperature and show that its
        regret depends critically on the suboptimality gap of the MDP: for sufficiently large gaps, the regret is
        sublinear, while for small gaps it deteriorates and can approach linear growth."
      relevanceScore: 20
      topics:
        - reinforcement-learning
        - q-learning
        - regret-bounds
      entities: []
    - title: A Scalable Approach to Solving Simulation-Based Network Security Games
      url: https://arxiv.org/abs/2602.16564
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16564v1 Announce Type: new Abstract: We introduce MetaDOAR, a lightweight meta-controller that
        augments the Double Oracle / PSRO paradigm with a learned, partition-aware filtering layer and Q-value caching
        to enable scalable multi-agent reinforcement learning on very large cyber-network environments. MetaDOAR learns
        a compact state projection from per node structural embeddings to rapidly score and select a small subset of
        devices (a top-k partition) on which a conventional low-level "
      relevanceScore: 20
      topics:
        - game-theory
        - security
        - reinforcement-learning
      entities: []
    - title: "MadEvolve: Evolutionary Optimization of Cosmological Algorithms with Large Language Models"
      url: https://arxiv.org/abs/2602.15951
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.15951v1 Announce Type: cross Abstract: We develop a general framework to discover scientific
        algorithms and apply it to three problems in computational cosmology. Our code, MadEvolve, is similar to
        Google's AlphaEvolve, but places a stronger emphasis on free parameters and their optimization. Our code starts
        with a baseline human algorithm implementation, and then optimizes its performance metrics by making iterative
        changes to its code. As a further convenient feature, MadEvolve auto"
      relevanceScore: 20
      topics:
        - llm
        - algorithm-discovery
        - scientific-research
      entities:
        - scientific-research
        - language-models
    - title: "Harnessing Implicit Cooperation: A Multi-Agent Reinforcement Learning Approach Towards Decentralized Local
        Energy Markets"
      url: https://arxiv.org/abs/2602.16062
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16062v1 Announce Type: cross Abstract: This paper proposes implicit cooperation, a framework
        enabling decentralized agents to approximate optimal coordination in local energy markets without explicit
        peer-to-peer communication. We formulate the problem as a decentralized partially observable Markov decision
        problem that is solved through a multi-agent reinforcement learning task in which agents use stigmergic signals
        (key performance indicators at the system level) to infer and react "
      relevanceScore: 20
      topics:
        - multi-agent-reinforcement-learning
        - cooperation
        - decentralized-systems
      entities:
        - agentic-ai
    - title: "MARLEM: A Multi-Agent Reinforcement Learning Simulation Framework for Implicit Cooperation in Decentralized
        Local Energy Markets"
      url: https://arxiv.org/abs/2602.16063
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16063v1 Announce Type: cross Abstract: This paper introduces a novel, open-source MARL simulation
        framework for studying implicit cooperation in LEMs, modeled as a decentralized partially observable Markov
        decision process and implemented as a Gymnasium environment for MARL. Our framework features a modular market
        platform with plug-and-play clearing mechanisms, physically constrained agent models (including battery
        storage), a realistic grid network, and a comprehensive analytics sui"
      relevanceScore: 20
      topics:
        - multi-agent-reinforcement-learning
        - simulation
        - cooperation
      entities:
        - agentic-ai
    - title: Collaborative Zone-Adaptive Zero-Day Intrusion Detection for IoBT
      url: https://arxiv.org/abs/2602.16098
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.16098v1 Announce Type: cross Abstract: The Internet of Battlefield Things (IoBT) relies on
        heterogeneous, bandwidth-constrained, and intermittently connected tactical networks that face rapidly evolving
        cyber threats. In this setting, intrusion detection cannot depend on continuous central collection of raw
        traffic due to disrupted links, latency, operational security limits, and non-IID traffic across zones. We
        present Zone-Adaptive Intrusion Detection (ZAID), a collaborative detecti"
      relevanceScore: 20
      topics:
        - intrusion-detection
        - security
        - machine-learning
      entities:
        - misuse-risks
    - title: "ReaCritic: Reasoning Transformer-based DRL Critic-model Scaling For Wireless Networks"
      url: https://arxiv.org/abs/2505.10992
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2505.10992v2 Announce Type: replace Abstract: Heterogeneous Networks (HetNets) pose critical challenges
        for intelligent management due to the diverse user requirements and time-varying wireless conditions. These
        factors introduce significant decision complexity, which limits the adaptability of existing Deep Reinforcement
        Learning (DRL) methods. In many DRL algorithms, especially those involving value-based or actor-critic
        structures, the critic component plays a key role in guiding policy"
      relevanceScore: 20
      topics:
        - reinforcement-learning
        - wireless-networks
      entities: []
    - title: "Still Competitive: Revisiting Recurrent Models for Irregular Time Series Prediction"
      url: https://arxiv.org/abs/2510.16161
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2510.16161v2 Announce Type: replace Abstract: Modeling irregularly sampled multivariate time series is a
        persistent challenge in domains like healthcare and sensor networks. While recent works have explored a variety
        of complex learning architectures to solve the prediction problems for irregularly sampled time series, it
        remains unclear what the true benefits of some of these architectures are, and whether clever modifications of
        simpler and more efficient RNN-based algorithms are still c"
      relevanceScore: 20
      topics:
        - time-series
        - recurrent-models
      entities: []
    - title: Adaptive Aggregation with Two Gains in QFL
      url: https://arxiv.org/abs/2512.03363
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2512.03363v2 Announce Type: replace Abstract: Federated learning (FL) deployed over quantum enabled and
        heterogeneous classical networks faces significant performance degradation due to uneven client quality,
        stochastic teleportation fidelity, device instability, and geometric mismatch between local and global models.
        Classical aggregation rules assume euclidean topology and uniform communication reliability, limiting their
        suitability for emerging quantum federated systems. This paper int"
      relevanceScore: 20
      topics:
        - federated-learning
        - quantum-computing
      entities: []
    - title: Inverting Non-Injective Functions with Twin Neural Network Regression
      url: https://arxiv.org/abs/2601.05378
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2601.05378v2 Announce Type: replace Abstract: Non-injective functions are not globally invertible.
        However, they can often be restricted to locally injective subdomains where the inversion is well-defined. In
        many settings a preferred solution can be selected even when multiple valid preimages exist or input and output
        dimensions differ. This manuscript describes a natural reformulation of the inverse learning problem for
        non-injective functions as a collection of locally invertible proble"
      relevanceScore: 20
      topics:
        - neural-networks
        - function-inversion
      entities: []
    - title: Stochastic Parroting in Temporal Attention -- Regulating the Diagonal Sink
      url: https://arxiv.org/abs/2602.10956
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2602.10956v2 Announce Type: replace Abstract: Spatio-temporal models analyze spatial structures and
        temporal dynamics, which makes them prone to information degeneration among space and time. Prior literature has
        demonstrated that over-squashing in causal attention or temporal convolutions creates a bias on the first
        tokens. To analyze whether such a bias is present in temporal attention mechanisms, we derive sensitivity bounds
        on the expected value of the Jacobian of a temporal attention "
      relevanceScore: 20
      topics:
        - neural-networks
        - attention-mechanisms
      entities: []
    - title: Weight transport through spike timing for robust local gradients
      url: https://arxiv.org/abs/2503.02642
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2503.02642v2 Announce Type: replace-cross Abstract: In both machine learning and in computational
        neuroscience, plasticity in functional neural networks is frequently expressed as gradient descent on a cost.
        Often, this imposes symmetry constraints that are difficult to reconcile with local computation, as is required
        for biological networks or neuromorphic hardware. For example, wake-sleep learning in networks characterized by
        Boltzmann distributions assumes symmetric connectivity. Simila"
      relevanceScore: 20
      topics:
        - neural-networks
        - learning-algorithms
      entities: []
    - title: "High-dimensional limit theorems for SGD: Momentum and Adaptive Step-sizes"
      url: https://arxiv.org/abs/2511.03952
      sourceId: arxiv-cs-lg
      publishedAt: Thu, 19 Feb 2026 00:00:00 -0500
      summary: "arXiv:2511.03952v2 Announce Type: replace-cross Abstract: We develop a high-dimensional scaling limit for
        Stochastic Gradient Descent with Polyak Momentum (SGD-M) and adaptive step-sizes. This provides a framework to
        rigourously compare online SGD with some of its popular variants. We show that the scaling limits of SGD-M
        coincide with those of online SGD after an appropriate time rescaling and a specific choice of step-size.
        However, if the step-size is kept the same between the two algorithms,"
      relevanceScore: 20
      topics:
        - optimization
        - stochastic-gradient-descent
      entities: []
  fetchedSources:
    - openai-blog
    - anthropic-blog
    - deepmind-blog
    - meta-ai-blog
    - alignment-forum
    - lesswrong
    - ea-forum
    - aisafety-news-search
    - ai-executive-orders
    - ml-safety-newsletter
    - cais-newsletter
    - last-week-in-ai
    - navigating-ai-risks
    - arxiv-cs-ai
    - arxiv-cs-cl
    - arxiv-cs-lg
    - ai-industry-news
  failedSources:
    - import-ai
    - the-gradient
    - zvi-ai
plan:
  date: 2026-02-19
  pageUpdates:
    - pageId: alignment
      pageTitle: AI Alignment
      reason: 2 news item(s) mention this entity directly
      suggestedTier: standard
      relevantNews:
        - title: "Targeting Alignment: Extracting Safety Classifiers of Aligned LLMs"
          url: https://arxiv.org/abs/2501.16534
          summary: "arXiv:2501.16534v5 Announce Type: replace-cross Abstract: Alignment in large language models (LLMs) is used to
            enforce guidelines such as safety. Yet, alignment fails in the face of jailbreak attacks "
        - title: Introducing the Anthropic National Security and Public Sector Advisory Council
          url: https://www.anthropic.com/news/introducing-the-anthropic-national-security-and-public-sector-advisory-council
          summary: This announcement introduces a new advisory council, as part of Anthropic's broader mission to build reliable,
            interpretable, and steerable AI systems for national security and public sector applicati
      directions: "Review and incorporate recent developments: Targeting Alignment: Extracting Safety Classifiers of Aligned
        LLMs; Introducing the Anthropic National Security and Public Sector Advisory Council"
    - pageId: why-alignment-hard
      pageTitle: Why Alignment Might Be Hard
      reason: 8 news item(s) mention this entity directly
      suggestedTier: standard
      relevantNews:
        - title: "From hard refusals to safe-completions: toward output-centric safety training"
          url: https://openai.com/index/gpt-5-safe-completions
          summary: Discover how OpenAI's new safe-completions approach in GPT-5 improves both safety and helpfulness in AI
            responses—moving beyond hard refusals to nuanced, output-centric safety training for handling du
        - title: "ML Safety Newsletter #8"
          url: https://newsletter.mlsafety.org/p/ml-safety-newsletter-8
          summary: Interpretability, using law to inform AI alignment, scaling laws for proxy gaming
        - title: "Collective alignment: public input on our Model Spec"
          url: https://openai.com/index/collective-alignment-aug-2025-updates
          summary: OpenAI surveyed over 1,000 people worldwide on how AI should behave and compared their views to our Model Spec.
            Learn how collective alignment is shaping AI defaults to better reflect diverse human va
        - title: Learning from human preferences
          url: https://openai.com/index/learning-from-human-preferences
          summary: "One step towards building safe AI systems is to remove the need for humans to write goal functions, since
            using a simple proxy for a complex goal, or getting the complex goal a bit wrong, can lead to "
        - title: "ML Safety Newsletter #2"
          url: https://newsletter.mlsafety.org/p/ml-safety-newsletter-2
          summary: Adversarial Training, Feature Visualization, and Machine Ethics
        - title: Toward understanding and preventing misalignment generalization
          url: https://openai.com/index/emergent-misalignment
          summary: We study how training on incorrect responses can cause broader misalignment in language models and identify an
            internal feature driving this behavior—one that can be reversed with minimal fine-tuning.
        - title: Faulty reward functions in the wild
          url: https://openai.com/index/faulty-reward-functions
          summary: Reinforcement learning algorithms can break in surprising, counterintuitive ways. In this post we’ll explore
            one failure mode, which is where you misspecify your reward function.
        - title: "ML Safety Newsletter #3"
          url: https://newsletter.mlsafety.org/p/ml-safety-newsletter-3
          summary: Transformer adversarial robustness, fractals, preference learning
      directions: "Review and incorporate recent developments: From hard refusals to safe-completions: toward output-centric
        safety training; ML Safety Newsletter #8; Collective alignment: public input on our Model Spec; Learning from
        human preferences; ML Safety Newsletter #2; Toward understanding and preventing misalignment generalization;
        Faulty reward functions in the wild; ML Safety Newsletter #3"
    - pageId: language-models
      pageTitle: Large Language Models
      reason: 256 news item(s) mention this entity directly
      suggestedTier: standard
      relevantNews:
        - title: Fine-tuning GPT-2 from human preferences
          url: https://openai.com/index/fine-tuning-gpt-2
          summary: "We’ve fine-tuned the 774M parameter GPT-2 language model using human feedback for various tasks, successfully
            matching the preferences of the external human labelers, though those preferences did not "
        - title: "Gemma Scope 2: helping the AI safety community deepen understanding of complex language model behavior"
          url: https://deepmind.google/blog/gemma-scope-2-helping-the-ai-safety-community-deepen-understanding-of-complex-language-model-behavior/
          summary: Open interpretability tools for language models are now available across the entire Gemma 3 family with the
            release of Gemma Scope 2.
        - title: Why language models hallucinate
          url: https://openai.com/index/why-language-models-hallucinate
          summary: OpenAI’s new research explains why language models hallucinate. The findings show how improved evaluations can
            enhance AI reliability, honesty, and safety.
        - title: "Addendum to GPT-5 System Card: Sensitive conversations"
          url: https://openai.com/index/gpt-5-system-card-sensitive-conversations
          summary: This system card details GPT-5’s improvements in handling sensitive conversations, including new benchmarks for
            emotional reliance, mental health, and jailbreak resistance.
        - title: Language models can explain neurons in language models
          url: https://openai.com/index/language-models-can-explain-neurons-in-language-models
          summary: We use GPT-4 to automatically write explanations for the behavior of neurons in large language models and to
            score those explanations. We release a dataset of these (imperfect) explanations and scores
        - title: "FACTS Benchmark Suite: Systematically evaluating the factuality of large language models"
          url: https://deepmind.google/blog/facts-benchmark-suite-systematically-evaluating-the-factuality-of-large-language-models/
          summary: Systematically evaluating the factuality of large language models with the FACTS Benchmark Suite.
        - title: "ML Safety Newsletter #10"
          url: https://newsletter.mlsafety.org/p/ml-safety-newsletter-10
          summary: Adversarial attacks against language and vision models, improving LLM honesty, and tracing the influence of LLM
            training data
        - title: Surgical Activation Steering via Generative Causal Mediation
          url: https://arxiv.org/abs/2602.16080
          summary: "arXiv:2602.16080v1 Announce Type: new Abstract: Where should we intervene in a language model (LM) to control
            behaviors that are diffused across many tokens of a long-form response? We introduce Gener"
        - title: "Helpful to a Fault: Measuring Illicit Assistance in Multi-Turn, Multilingual LLM Agents"
          url: https://arxiv.org/abs/2602.16346
          summary: "arXiv:2602.16346v1 Announce Type: new Abstract: LLM-based agents execute real-world workflows via tools and
            memory. These affordances enable ill-intended adversaries to also use these agents to carry "
        - title: Mechanistic Indicators of Steering Effectiveness in Large Language Models
          url: https://arxiv.org/abs/2602.01716
          summary: "arXiv:2602.01716v2 Announce Type: replace Abstract: Activation-based steering enables Large Language Models
            (LLMs) to exhibit targeted behaviors by intervening on intermediate activations without retr"
        - title: Random Scaling of Emergent Capabilities
          url: https://arxiv.org/abs/2502.17356
          summary: "arXiv:2502.17356v5 Announce Type: replace Abstract: Language models famously improve under a smooth scaling
            law, but some specific capabilities exhibit sudden breakthroughs in performance. Advocates o"
        - title: A Content-Based Framework for Cybersecurity Refusal Decisions in Large Language Models
          url: https://arxiv.org/abs/2602.15689
          summary: "arXiv:2602.15689v2 Announce Type: replace-cross Abstract: Large language models and LLM-based agents are
            increasingly used for cybersecurity tasks that are inherently dual-use. Existing approaches to "
        - title: Strengthening ChatGPT’s responses in sensitive conversations
          url: https://openai.com/index/strengthening-chatgpt-responses-in-sensitive-conversations
          summary: OpenAI collaborated with 170+ mental health experts to improve ChatGPT’s ability to recognize distress, respond
            empathetically, and guide users toward real-world support—reducing unsafe responses by u
        - title: Shipping smarter agents with every new model
          url: https://openai.com/index/safetykit
          summary: Discover how SafetyKit leverages OpenAI GPT-5 to enhance content moderation, enforce compliance, and outpace
            legacy safety systems with greater accuracy .
        - title: GPT-5 System Card
          url: https://openai.com/index/gpt-5-system-card
          summary: This GPT-5 system card explains how a unified model routing system powers fast and smart responses using
            gpt-5-main, gpt-5-thinking, and lightweight versions like gpt-5-thinking-nano, optimized for di
        - title: Better language models and their implications
          url: https://openai.com/index/better-language-models
          summary: We’ve trained a large-scale unsupervised language model which generates coherent paragraphs of text, achieves
            state-of-the-art performance on many language modeling benchmarks, and performs rudimentar
        - title: "Gemini 2.5: Our most intelligent AI model"
          url: https://deepmind.google/blog/gemini-2-5-our-most-intelligent-ai-model/
          summary: Gemini 2.5 is our most intelligent AI model, now with thinking built in.
        - title: "FACTS Grounding: A new benchmark for evaluating the factuality of large language models"
          url: https://deepmind.google/blog/facts-grounding-a-new-benchmark-for-evaluating-the-factuality-of-large-language-models/
          summary: Our comprehensive benchmark and online leaderboard offer a much-needed measure of how accurately LLMs ground
            their responses in provided source material and avoid hallucinations
        - title: Does GPT-2 Represent Controversy? A Small Mech Interp Investigation
          url: https://www.lesswrong.com/posts/JNjXRBCQJ8RAuqw9n/does-gpt-2-represent-controversy-a-small-mech-interp
          summary: "Published on February 19, 2026 1:36 AM GMTIn thinking about how RLHF-trained models clearly hedge on
            politically controversial topics, I started wondering about if LLMs would encode these politically "
        - title: "Align Once, Benefit Multilingually: Enforcing Multilingual Consistency for LLM Safety Alignment"
          url: https://arxiv.org/abs/2602.16660
          summary: "arXiv:2602.16660v1 Announce Type: cross Abstract: The widespread deployment of large language models (LLMs)
            across linguistic communities necessitates reliable multilingual safety alignment. However, "
        - title: "PolicyPad: Collaborative Prototyping of LLM Policies"
          url: https://arxiv.org/abs/2509.19680
          summary: "arXiv:2509.19680v2 Announce Type: replace-cross Abstract: As LLMs gain adoption in high-stakes domains like
            mental health, domain experts are increasingly consulted to provide input into policies gove"
        - title: Mitigating Gradient Inversion Risks in Language Models via Token Obfuscation
          url: https://arxiv.org/abs/2602.15897
          summary: "arXiv:2602.15897v1 Announce Type: new Abstract: Training and fine-tuning large-scale language models largely
            benefit from collaborative learning, but the approach has been proven vulnerable to gradien"
        - title: "Evolving Language Models without Labels: Majority Drives Selection, Novelty Promotes Variation"
          url: https://arxiv.org/abs/2509.15194
          summary: "arXiv:2509.15194v3 Announce Type: replace-cross Abstract: Large language models (LLMs) are increasingly
            trained with reinforcement learning from verifiable rewards (RLVR), yet real-world deployment de"
        - title: Building more helpful ChatGPT experiences for everyone
          url: https://openai.com/index/building-more-helpful-chatgpt-experiences-for-everyone
          summary: We’re partnering with experts, strengthening protections for teens with parental controls, and routing
            sensitive conversations to reasoning models in ChatGPT.
        - title: Introducing GPT-5 for developers
          url: https://openai.com/index/introducing-gpt-5-for-developers
          summary: Introducing GPT-5 in our API platform—offering high reasoning performance, new controls for devs, and
            best-in-class results on real coding tasks.
        - title: Introducing gpt-oss
          url: https://openai.com/index/introducing-gpt-oss
          summary: We’re releasing gpt-oss-120b and gpt-oss-20b—two state-of-the-art open-weight language models that deliver
            strong real-world performance at low cost. Available under the flexible Apache 2.0 license, t
        - title: Improving language understanding with unsupervised learning
          url: https://openai.com/index/language-unsupervised
          summary: "We’ve obtained state-of-the-art results on a suite of diverse language tasks with a scalable, task-agnostic
            system, which we’re also releasing. Our approach is a combination of two existing ideas: tra"
        - title: "Gemini 2.5: Updates to our family of thinking models"
          url: https://deepmind.google/blog/gemini-25-updates-to-our-family-of-thinking-models/
          summary: "Explore the latest Gemini 2.5 model updates with enhanced performance and accuracy: Gemini 2.5 Pro now stable,
            Flash generally available, and the new Flash-Lite in preview."
        - title: Introducing Gemini 2.5 Flash
          url: https://deepmind.google/blog/introducing-gemini-2-5-flash/
          summary: Gemini 2.5 Flash is our first fully hybrid reasoning model, giving developers the ability to turn thinking on
            or off.
        - title: "ReLoop: Structured Modeling and Behavioral Verification for Reliable LLM-Based Optimization"
          url: https://arxiv.org/abs/2602.15983
          summary: "arXiv:2602.15983v1 Announce Type: cross Abstract: Large language models (LLMs) can translate natural language
            into optimization code, but silent failures pose a critical risk: code that executes and r"
        - title: "VerifyBench: Benchmarking Reference-based Reward Systems for Large Language Models"
          url: https://arxiv.org/abs/2505.15801
          summary: "arXiv:2505.15801v4 Announce Type: replace-cross Abstract: Large reasoning models such as OpenAI o1 and
            DeepSeek-R1 have demonstrated remarkable performance in complex reasoning tasks. A critical compo"
        - title: SecCodeBench-V2 Technical Report
          url: https://arxiv.org/abs/2602.15485
          summary: "arXiv:2602.15485v2 Announce Type: replace-cross Abstract: We introduce SecCodeBench-V2, a publicly released
            benchmark for evaluating Large Language Model (LLM) copilots' capabilities of generating sec"
        - title: "CheckIfExist: Detecting Citation Hallucinations in the Era of AI-Generated Content"
          url: https://arxiv.org/abs/2602.15871
          summary: "arXiv:2602.15871v1 Announce Type: new Abstract: The proliferation of large language models (LLMs) in academic
            workflows has introduced unprecedented challenges to bibliographic integrity, particularly"
        - title: Multi-Objective Alignment of Language Models for Personalized Psychotherapy
          url: https://arxiv.org/abs/2602.16053
          summary: "arXiv:2602.16053v1 Announce Type: new Abstract: Mental health disorders affect over 1 billion people
            worldwide, yet access to care remains limited by workforce shortages and cost constraints. While AI"
        - title: Evolutionary Context Search for Automated Skill Acquisition
          url: https://arxiv.org/abs/2602.16113
          summary: "arXiv:2602.16113v1 Announce Type: cross Abstract: Large Language Models cannot reliably acquire new knowledge
            post-deployment -- even when relevant text resources exist, models fail to transform them "
        - title: Introducing GPT-5
          url: https://openai.com/index/introducing-gpt-5
          summary: We are introducing GPT‑5, our best AI system yet. GPT‑5 is a significant leap in intelligence over all our
            previous models, featuring state-of-the-art performance across coding, math, writing, health,
        - title: Hello GPT-4o
          url: https://openai.com/index/hello-gpt-4o
          summary: We’re announcing GPT-4 Omni, our new flagship model which can reason across audio, vision, and text in real
            time.
        - title: Using GPT-4 for content moderation
          url: https://openai.com/index/using-gpt-4-for-content-moderation
          summary: We use GPT-4 for content policy development and content moderation decisions, enabling more consistent
            labeling, a faster feedback loop for policy refinement, and less involvement from human moderator
        - title: Language models are few-shot learners
          url: https://openai.com/index/language-models-are-few-shot-learners
          summary: ""
        - title: "GPT-2: 1.5B release"
          url: https://openai.com/index/gpt-2-1-5b-release
          summary: As the final model release of GPT-2’s staged release, we’re releasing the largest version (1.5B parameters) of
            GPT-2 along with code and model weights to facilitate detection of outputs of GPT-2 model
        - title: "T5Gemma: A new collection of encoder-decoder Gemma models"
          url: https://deepmind.google/blog/t5gemma-a-new-collection-of-encoder-decoder-gemma-models/
          summary: Introducing T5Gemma, a new collection of encoder-decoder LLMs.
        - title: We’re expanding our Gemini 2.5 family of models
          url: https://deepmind.google/blog/were-expanding-our-gemini-25-family-of-models/
          summary: Gemini 2.5 Flash and Pro are now generally available, and we’re introducing 2.5 Flash-Lite, our most
            cost-efficient and fastest 2.5 model yet.
        - title: "Gemini 2.5: Our most intelligent models are getting even better"
          url: https://deepmind.google/blog/gemini-25-our-world-leading-model-is-getting-even-better/
          summary: Gemini 2.5 Pro continues to be loved by developers as the best model for coding, and 2.5 Flash is getting even
            better with a new update. We’re bringing new capabilities to our models, including Deep T
        - title: "Last Week in AI #328 - DeepSeek 3.2, Mistral 3, Trainium3, Runway Gen-4.5"
          url: https://lastweekin.ai/p/last-week-in-ai-328-deepseek-32-mistral
          summary: DeepSeek Releases New Reasoning Models, Mistral closes in on Big AI rivals with new open-weight frontier and
            small models, and more!
        - title: "Language Statistics and False Belief Reasoning: Evidence from 41 Open-Weight LMs"
          url: https://arxiv.org/abs/2602.16085
          summary: "arXiv:2602.16085v1 Announce Type: cross Abstract: Research on mental state reasoning in language models (LMs)
            has the potential to inform theories of human social cognition--such as the theory that me"
        - title: "Understanding LLM Failures: A Multi-Tape Turing Machine Analysis of Systematic Errors in Language Model
            Reasoning"
          url: https://arxiv.org/abs/2602.15868
          summary: "arXiv:2602.15868v1 Announce Type: new Abstract: Large language models (LLMs) exhibit failure modes on
            seemingly trivial tasks. We propose a formalisation of LLM interaction using a deterministic multi"
        - title: "Missing-by-Design: Certifiable Modality Deletion for Revocable Multimodal Sentiment Analysis"
          url: https://arxiv.org/abs/2602.16144
          summary: "arXiv:2602.16144v1 Announce Type: new Abstract: As multimodal systems increasingly process sensitive personal
            data, the ability to selectively revoke specific data modalities has become a critical req"
        - title: "MemoryArena: Benchmarking Agent Memory in Interdependent Multi-Session Agentic Tasks"
          url: https://arxiv.org/abs/2602.16313
          summary: "arXiv:2602.16313v1 Announce Type: new Abstract: Existing evaluations of agents with memory typically assess
            memorization and action in isolation. One class of benchmarks evaluates memorization by test"
        - title: Empirical Cumulative Distribution Function Clustering for LLM-based Agent System Analysis
          url: https://arxiv.org/abs/2602.16131
          summary: "arXiv:2602.16131v1 Announce Type: cross Abstract: Large language models (LLMs) are increasingly used as agents
            to solve complex tasks such as question answering (QA), scientific debate, and software d"
        - title: Transformers Provably Learn Algorithmic Solutions for Graph Connectivity, But Only with the Right Data
          url: https://arxiv.org/abs/2510.19753
          summary: "arXiv:2510.19753v2 Announce Type: replace Abstract: Transformers often fail to learn generalizable algorithms,
            instead relying on brittle heuristics. Using graph connectivity as a testbed, we explain "
        - title: Introducing gpt-realtime and Realtime API updates
          url: https://openai.com/index/introducing-gpt-realtime
          summary: We’re releasing a more advanced speech-to-speech model and new API capabilities including MCP server support,
            image input, and SIP phone calling support.
        - title: gpt-oss-120b & gpt-oss-20b Model Card
          url: https://openai.com/index/gpt-oss-model-card
          summary: We introduce gpt-oss-120b and gpt-oss-20b, two open-weight reasoning models available under the Apache 2.0
            license and our gpt-oss usage policy.
        - title: Introducing OpenAI o1
          url: https://openai.com/index/introducing-openai-o1-preview
          summary: Introducing OpenAI o1
        - title: Introducing GPT-4o and more tools to ChatGPT free users
          url: https://openai.com/index/gpt-4o-and-more-tools-to-chatgpt-free
          summary: Introducing GPT-4o and more tools to ChatGPT free users We are launching our newest flagship model and making
            more capabilities available for free in ChatGPT.
        - title: Techniques for training large neural networks
          url: https://openai.com/index/techniques-for-training-large-neural-networks
          summary: Large neural networks are at the core of many recent advances in AI, but training them is a difficult
            engineering and research challenge which requires orchestrating a cluster of GPUs to perform a sin
        - title: Solving math word problems
          url: https://openai.com/index/solving-math-word-problems
          summary: "We’ve trained a system that solves grade school math problems with nearly twice the accuracy of a fine-tuned
            GPT-3 model. It solves about 90% as many problems as real kids: a small sample of 9-12 year"
        - title: "GPT-2: 6-month follow-up"
          url: https://openai.com/index/gpt-2-6-month-follow-up
          summary: We’re releasing the 774 million parameter GPT-2 language model after the release of our small 124M model in
            February, staged release of our medium 355M model in May, and subsequent research with partn
        - title: "MedGemma: Our most capable open models for health AI development"
          url: https://deepmind.google/blog/medgemma-our-most-capable-open-models-for-health-ai-development/
          summary: We’re announcing new multimodal models in the MedGemma collection, our most capable open models for health AI
            development.
        - title: Gemini 2.5 Flash-Lite is now ready for scaled production use
          url: https://deepmind.google/blog/gemini-25-flash-lite-is-now-ready-for-scaled-production-use/
          summary: Gemini 2.5 Flash-Lite, previously in preview, is now stable and generally available. This cost-efficient model
            provides high quality in a small size, and includes 2.5 family features like a 1 million-
        - title: "Introducing Gemma 3 270M: The compact model for hyper-efficient AI"
          url: https://deepmind.google/blog/introducing-gemma-3-270m-the-compact-model-for-hyper-efficient-ai/
          summary: "Today, we're adding a new, highly specialized tool to the Gemma 3 toolkit: Gemma 3 270M, a compact,
            270-million parameter model."
        - title: "Announcing Gemma 3n preview: Powerful, efficient, mobile-first AI"
          url: https://deepmind.google/blog/announcing-gemma-3n-preview-powerful-efficient-mobile-first-ai/
          summary: Gemma 3n is a cutting-edge open model designed for fast, multimodal AI on devices, featuring optimized
            performance, unique flexibility with a 2-in-1 model, and expanded multimodal understanding with a
        - title: "Gemini 2.5 Pro Preview: even better coding performance"
          url: https://deepmind.google/blog/gemini-25-pro-preview-even-better-coding-performance/
          summary: We’ve seen developers doing amazing things with Gemini 2.5 Pro, so we decided to release an updated version a
            couple of weeks early to get into developers hands sooner.
        - title: Introducing Gemma 3
          url: https://deepmind.google/blog/introducing-gemma-3/
          summary: The most capable model you can run on a single GPU or TPU.
        - title: "The Llama 4 Herd: The Beginning of a New Era of Natively Multimodal AI Innovation"
          url: https://ai.meta.com/blog/llama-4-multimodal-intelligence/
          summary: "  Introduces Llama 4 Scout and Llama 4 Maverick — the first open-weight, natively multimodal models with
            unprecedented context support, and Meta's first models built using a mixture-of-experts (MoE) a"
        - title: "LWiAI Podcast #232 - ChatGPT Ads, Thinking Machines Drama, STEM"
          url: https://lastweekin.ai/p/lwiai-podcast-232-chatgpt-ads-thinking
          summary: "OpenAI to test ads in ChatGPT as it burns through billions, The Drama at Thinking Machines, STEM: Scaling
            Transformers with Embedding Modules"
        - title: "LWiAI Podcast #226 - Gemini 3, Claude Opus 4.5, Nano Banana Pro, LeJEPA"
          url: https://lastweekin.ai/p/lwiai-podcast-226-gemini-3-claude
          summary: Google launches Gemini 3 & Nano Banana Pro, Anthropic releases Opus 4.5, and more!
        - title: "LWiAI Podcast #225 - GPT 5.1, Kimi K2 Thinking, Remote Labor Index"
          url: https://lastweekin.ai/p/lwiai-podcast-225-gpt-51-kimi-k2
          summary: OpenAI says the brand-new GPT-5.1 is &#8216;warmer&#8217;, Baidu Unveils ERNIE 5.0, and more!
        - title: Do Personality Traits Interfere? Geometric Limitations of Steering in Large Language Models
          url: https://arxiv.org/abs/2602.15847
          summary: "arXiv:2602.15847v1 Announce Type: cross Abstract: Personality steering in large language models (LLMs)
            commonly relies on injecting trait-specific steering vectors, implicitly assuming that personalit"
        - title: Evidence for Daily and Weekly Periodic Variability in GPT-4o Performance
          url: https://arxiv.org/abs/2602.15889
          summary: "arXiv:2602.15889v1 Announce Type: cross Abstract: Large language models (LLMs) are increasingly used in
            research both as tools and as objects of investigation. Much of this work implicitly assumes tha"
        - title: Can Generative Artificial Intelligence Survive Data Contamination? Theoretical Guarantees under Contaminated
            Recursive Training
          url: https://arxiv.org/abs/2602.16065
          summary: "arXiv:2602.16065v1 Announce Type: cross Abstract: Generative Artificial Intelligence (AI), such as large
            language models (LLMs), has become a transformative force across science, industry, and society"
        - title: "Software Dependencies 2.0: An Empirical Study of Reuse and Integration of Pre-Trained Models in Open-Source
            Projects"
          url: https://arxiv.org/abs/2509.06085
          summary: "arXiv:2509.06085v2 Announce Type: replace-cross Abstract: Pre-trained models (PTMs) are machine learning
            models that have been trained in advance, often on large-scale data, and can be reused for new "
        - title: Multilingual Routing in Mixture-of-Experts
          url: https://arxiv.org/abs/2510.04694
          summary: "arXiv:2510.04694v2 Announce Type: replace-cross Abstract: Mixture-of-Experts (MoE) architectures have become
            the key to scaling modern LLMs, yet little is understood about how their sparse routing dyn"
        - title: Reasoning Up the Instruction Ladder for Controllable Language Models
          url: https://arxiv.org/abs/2511.04694
          summary: "arXiv:2511.04694v4 Announce Type: replace-cross Abstract: As large language model (LLM) based systems take on
            high-stakes roles in real-world decision-making, they must reconcile competing instruction"
        - title: "STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious Tokens"
          url: https://arxiv.org/abs/2602.15620
          summary: "arXiv:2602.15620v2 Announce Type: replace-cross Abstract: Reinforcement Learning (RL) has significantly
            improved large language model reasoning, but existing RL fine-tuning methods rely heavily on heu"
        - title: Quality-constrained Entropy Maximization Policy Optimization for LLM Diversity
          url: https://arxiv.org/abs/2602.15894
          summary: "arXiv:2602.15894v1 Announce Type: new Abstract: Recent research indicates that while alignment methods
            significantly improve the quality of large language model(LLM) outputs, they simultaneously reduc"
        - title: "MultiCW: A Large-Scale Balanced Benchmark Dataset for Training Robust Check-Worthiness Detection Models"
          url: https://arxiv.org/abs/2602.16298
          summary: "arXiv:2602.16298v1 Announce Type: new Abstract: Large Language Models (LLMs) are beginning to reshape how
            media professionals verify information, yet automated support for detecting check-worthy claim"
        - title: "AREG: Adversarial Resource Extraction Game for Evaluating Persuasion and Resistance in Large Language Models"
          url: https://arxiv.org/abs/2602.16639
          summary: "arXiv:2602.16639v1 Announce Type: new Abstract: Evaluating the social intelligence of Large Language Models
            (LLMs) increasingly requires moving beyond static text generation toward dynamic, adversaria"
        - title: "MoE-Spec: Expert Budgeting for Efficient Speculative Decoding"
          url: https://arxiv.org/abs/2602.16052
          summary: "arXiv:2602.16052v1 Announce Type: new Abstract: Speculative decoding accelerates Large Language Model (LLM)
            inference by verifying multiple drafted tokens in parallel. However, for Mixture-of-Experts "
        - title: Causality is Key for Interpretability Claims to Generalise
          url: https://arxiv.org/abs/2602.16698
          summary: "arXiv:2602.16698v1 Announce Type: new Abstract: Interpretability research on large language models (LLMs) has
            yielded important insights into model behaviour, yet recurring pitfalls persist: findings "
        - title: "Features as Rewards: Scalable Supervision for Open-Ended Tasks via Interpretability"
          url: https://arxiv.org/abs/2602.10067
          summary: "arXiv:2602.10067v3 Announce Type: replace Abstract: Language models trained on large-scale datasets have been
            shown to learn features that encode abstract concepts such as factuality or intent. Such f"
        - title: Introducing IndQA
          url: https://openai.com/index/introducing-indqa
          summary: OpenAI introduces IndQA, a new benchmark for evaluating AI systems in Indian languages. Built with domain
            experts, IndQA tests cultural understanding and reasoning across 12 languages and 10 knowledge
        - title: Spring Update
          url: https://openai.com/index/spring-update
          summary: Introducing GPT-4o and making more capabilities available for free in ChatGPT.
        - title: GPT-4V(ision) system card
          url: https://openai.com/index/gpt-4v-system-card
          summary: ""
        - title: Introducing ChatGPT
          url: https://openai.com/index/chatgpt
          summary: We’ve trained a model called ChatGPT which interacts in a conversational way. The dialogue format makes it
            possible for ChatGPT to answer followup questions, admit its mistakes, challenge incorrect pr
        - title: Evaluating large language models trained on code
          url: https://openai.com/index/evaluating-large-language-models-trained-on-code
          summary: ""
        - title: "Introducing Gemma 3n: The developer guide"
          url: https://deepmind.google/blog/introducing-gemma-3n-the-developer-guide/
          summary: Gemma 3n is designed for the developer community that helped shape Gemma.
        - title: Advanced audio dialog and generation with Gemini 2.5
          url: https://deepmind.google/blog/advanced-audio-dialog-and-generation-with-gemini-25/
          summary: Gemini 2.5 has new capabilities in AI-powered audio dialog and generation.
        - title: Build rich, interactive web apps with an updated Gemini 2.5 Pro
          url: https://deepmind.google/blog/build-rich-interactive-web-apps-with-an-updated-gemini-25-pro/
          summary: Our updated version of Gemini 2.5 Pro Preview has improved capabilities for coding.
        - title: Start building with Gemini 2.0 Flash and Flash-Lite
          url: https://deepmind.google/blog/start-building-with-gemini-20-flash-and-flash-lite/
          summary: Gemini 2.0 Flash-Lite is now generally available in the Gemini API for production use in Google AI Studio and
            for enterprise customers on Vertex AI
        - title: "Introducing Gemini 2.0: our new AI model for the agentic era"
          url: https://deepmind.google/blog/introducing-gemini-20-our-new-ai-model-for-the-agentic-era/
          summary: Today, we’re announcing Gemini 2.0, our most capable multimodal AI model yet.
        - title: "Last Week in AI #334 - Kimi K2.5 & Code, Genie 3, OpenClaw & Moltbook"
          url: https://lastweekin.ai/p/last-week-in-ai-334-kimi-k25-and
          summary: China&#8217;s Moonshot releases a new open source model Kimi K2.5 and a coding agent, Google Brings Genie
            3&#8217;s Interactive World-Building Prototype to AI Ultra Subscribers, and more!
        - title: "LWiAI Podcast #229 - Gemini 3 Flash, ChatGPT Apps, Nemotron 3"
          url: https://lastweekin.ai/p/lwiai-podcast-229-gemini-3-flash
          summary: Google launches Gemini 3 Flash, ChatGPT launches an app store, Introducing GPT-5.2-Codex
        - title: "Last Week in AI #327 - Gemini 3, Opus 4.5, Nano Banana Pro, GPT-5.1-Codex-Max"
          url: https://lastweekin.ai/p/last-week-in-ai-327-gemini-3-opus
          summary: It's a big week! Lots of exciting releases, plus nvidia earnings and a whole bunch of cool research.
        - title: "Agent Skill Framework: Perspectives on the Potential of Small Language Models in Industrial Environments"
          url: https://arxiv.org/abs/2602.16653
          summary: "arXiv:2602.16653v1 Announce Type: new Abstract: Agent Skill framework, now widely and officially supported by
            major players such as GitHub Copilot, LangChain, and OpenAI, performs especially well with"
        - title: "State Design Matters: How Representations Shape Dynamic Reasoning in Large Language Models"
          url: https://arxiv.org/abs/2602.15858
          summary: "arXiv:2602.15858v1 Announce Type: cross Abstract: As large language models (LLMs) move from static reasoning
            tasks toward dynamic environments, their success depends on the ability to navigate and res"
        - title: "Doc-to-LoRA: Learning to Instantly Internalize Contexts"
          url: https://arxiv.org/abs/2602.15902
          summary: "arXiv:2602.15902v1 Announce Type: cross Abstract: Long input sequences are central to in-context learning,
            document understanding, and multi-step reasoning of Large Language Models (LLMs). However, th"
        - title: Balancing Faithfulness and Performance in Reasoning via Multi-Listener Soft Execution
          url: https://arxiv.org/abs/2602.16154
          summary: "arXiv:2602.16154v1 Announce Type: cross Abstract: Chain-of-thought (CoT) reasoning sometimes fails to
            faithfully reflect the true computation of a large language model (LLM), hampering its utility in "
        - title: "Long-Tail Knowledge in Large Language Models: Taxonomy, Mechanisms, Interventions and Implications"
          url: https://arxiv.org/abs/2602.16201
          summary: "arXiv:2602.16201v1 Announce Type: cross Abstract: Large language models (LLMs) are trained on web-scale
            corpora that exhibit steep power-law distributions, in which the distribution of knowledge is hi"
        - title: Learning to Learn from Language Feedback with Social Meta-Learning
          url: https://arxiv.org/abs/2602.16488
          summary: "arXiv:2602.16488v1 Announce Type: cross Abstract: Large language models (LLMs) often struggle to learn from
            corrective feedback within a conversational context. They are rarely proactive in soliciting"
        - title: Who can we trust? LLM-as-a-jury for Comparative Assessment
          url: https://arxiv.org/abs/2602.16610
          summary: "arXiv:2602.16610v1 Announce Type: cross Abstract: Large language models (LLMs) are increasingly applied as
            automatic evaluators for natural language generation assessment often using pairwise comparat"
        - title: "m1: Unleash the Potential of Test-Time Scaling for Medical Reasoning with Large Language Models"
          url: https://arxiv.org/abs/2504.00869
          summary: "arXiv:2504.00869v2 Announce Type: replace-cross Abstract: Test-time scaling has emerged as a powerful
            technique for enhancing the reasoning capabilities of large language models. However, its effectiv"
        - title: Experience-based Knowledge Correction for Robust Planning in Minecraft
          url: https://arxiv.org/abs/2505.24157
          summary: "arXiv:2505.24157v3 Announce Type: replace-cross Abstract: Large Language Model (LLM)-based planning has
            advanced embodied agents in long-horizon environments such as Minecraft, where acquiring latent "
        - title: Expressive Power of Graph Transformers via Logic
          url: https://arxiv.org/abs/2508.01067
          summary: "arXiv:2508.01067v2 Announce Type: replace-cross Abstract: Transformers are the basis of modern large language
            models, but relatively little is known about their precise expressive power on graphs. We "
        - title: Predicting Training Re-evaluation Curves Enables Effective Data Curriculums for LLMs
          url: https://arxiv.org/abs/2509.25380
          summary: "arXiv:2509.25380v2 Announce Type: replace-cross Abstract: Data curriculums have become central to successful
            LLM training, yet principles governing optimal data placement remain unclear. We introduce "
        - title: "From Transcripts to AI Agents: Knowledge Extraction, RAG Integration, and Robust Evaluation of Conversational AI
            Assistants"
          url: https://arxiv.org/abs/2602.15859
          summary: "arXiv:2602.15859v1 Announce Type: new Abstract: Building reliable conversational AI assistants for
            customer-facing industries remains challenging due to noisy conversational data, fragmented knowledge"
        - title: "Towards Fair and Efficient De-identification: Quantifying the Efficiency and Generalizability of
            De-identification Approaches"
          url: https://arxiv.org/abs/2602.15869
          summary: "arXiv:2602.15869v1 Announce Type: new Abstract: Large language models (LLMs) have shown strong performance on
            clinical de-identification, the task of identifying sensitive identifiers to protect priva"
        - title: "CLAA: Cross-Layer Attention Aggregation for Accelerating LLM Prefill"
          url: https://arxiv.org/abs/2602.16054
          summary: "arXiv:2602.16054v1 Announce Type: new Abstract: The prefill stage in long-context LLM inference remains a
            computational bottleneck. Recent token-ranking heuristics accelerate inference by selectively "
        - title: "TabAgent: A Framework for Replacing Agentic Generative Components with Tabular-Textual Classifiers"
          url: https://arxiv.org/abs/2602.16429
          summary: "arXiv:2602.16429v1 Announce Type: new Abstract: Agentic systems, AI architectures that autonomously execute
            multi-step workflows to achieve complex goals, are often built using repeated large language"
        - title: "Randomized Masked Finetuning: An Efficient Way to Mitigate Memorization of PIIs in LLMs"
          url: https://arxiv.org/abs/2512.03310
          summary: "arXiv:2512.03310v3 Announce Type: replace Abstract: The current literature on memorization in Natural Language
            Models, especially Large Language Models (LLMs), poses severe security and privacy risks,"
        - title: "TimeOmni-1: Incentivizing Complex Reasoning with Time Series in Large Language Models"
          url: https://arxiv.org/abs/2509.24803
          summary: "arXiv:2509.24803v2 Announce Type: replace Abstract: Recent advances in multimodal time series learning
            underscore a paradigm shift from analytics centered on basic patterns toward advanced time series"
        - title: How Cursor uses GPT-5
          url: https://openai.com/index/gpt-5-cursor
          summary: Learn how Cursor uses GPT-5.
        - title: DALL·E 3 system card
          url: https://openai.com/index/dall-e-3-system-card
          summary: ""
        - title: Efficient training of language models to fill in the middle
          url: https://openai.com/index/efficient-training-of-language-models-to-fill-in-the-middle
          summary: ""
        - title: "New GPT-3 capabilities: Edit & insert"
          url: https://openai.com/index/gpt-3-edit-insert
          summary: We’ve released new versions of GPT-3 and Codex which can edit or insert content into existing text, rather than
            just completing existing text.
        - title: Customizing GPT-3 for your application
          url: https://openai.com/index/customizing-gpt-3
          summary: Fine-tune with a single command.
        - title: "DALL·E: Creating images from text"
          url: https://openai.com/index/dall-e
          summary: We’ve trained a neural network called DALL·E that creates images from text captions for a wide range of
            concepts expressible in natural language.
        - title: Unsupervised sentiment neuron
          url: https://openai.com/index/unsupervised-sentiment-neuron
          summary: We’ve developed an unsupervised system which learns an excellent representation of sentiment, despite being
            trained only to predict the next character in the text of Amazon reviews.
        - title: With 10x Growth Since 2023, Llama Is the Leading Engine of AI Innovation
          url: https://ai.meta.com/blog/llama-usage-doubled-may-through-july-2024/
          summary: "  Highlights Llama's explosive growth, with models approaching 350 million downloads to date and over 20
            million downloads in a single month, cementing Llama as the leading open-source model family."
        - title: "LWiAI Podcast #233 - Moltbot, Genie 3, Qwen3-Max-Thinking"
          url: https://lastweekin.ai/p/lwiai-podcast-233-moltbot-genie-3
          summary: Google adds Gemini AI-powered &#8216;auto browse&#8217; to Chrome, Users flock to open source Moltbot for
            always-on AI, Qwen3-Max-Thinking debuts, and more!
        - title: "Framework of Thoughts: A Foundation Framework for Dynamic and Optimized Reasoning based on Chains, Trees, and
            Graphs"
          url: https://arxiv.org/abs/2602.16512
          summary: "arXiv:2602.16512v1 Announce Type: new Abstract: Prompting schemes such as Chain of Thought, Tree of Thoughts,
            and Graph of Thoughts can significantly enhance the reasoning capabilities of large langua"
        - title: Updating Parametric Knowledge with Context Distillation Retains Post-Training Capabilities
          url: https://arxiv.org/abs/2602.16093
          summary: "arXiv:2602.16093v1 Announce Type: cross Abstract: Post-training endows pretrained LLMs with a variety of
            desirable skills, including instruction-following, reasoning, and others. However, these post-t"
        - title: Understanding Transformer Optimization via Gradient Heterogeneity
          url: https://arxiv.org/abs/2502.00213
          summary: "arXiv:2502.00213v4 Announce Type: replace-cross Abstract: Transformers are difficult to optimize with
            stochastic gradient descent (SGD) and largely rely on adaptive optimizers such as Adam. Despite th"
        - title: "MedReasoner: Reinforcement Learning Drives Reasoning Grounding from Clinical Thought to Pixel-Level Precision"
          url: https://arxiv.org/abs/2508.08177
          summary: "arXiv:2508.08177v3 Announce Type: replace-cross Abstract: Accurately grounding regions of interest (ROIs) is
            critical for diagnosis and treatment planning in medical imaging. While multimodal large la"
        - title: "FeatBench: Towards More Realistic Evaluation of Feature-level Code Generation"
          url: https://arxiv.org/abs/2509.22237
          summary: "arXiv:2509.22237v2 Announce Type: replace-cross Abstract: Evaluating Large Language Models (LLMs) on
            repository-level feature implementation is a critical frontier in software engineering. However, es"
        - title: "Multi-source Heterogeneous Public Opinion Analysis via Collaborative Reasoning and Adaptive Fusion: A
            Systematically Integrated Approach"
          url: https://arxiv.org/abs/2602.15857
          summary: "arXiv:2602.15857v1 Announce Type: new Abstract: The analysis of public opinion from multiple heterogeneous
            sources presents significant challenges due to structural differences, semantic variations, a"
        - title: "VDLM: Variable Diffusion LMs via Robust Latent-to-Text Rendering"
          url: https://arxiv.org/abs/2602.15870
          summary: "arXiv:2602.15870v1 Announce Type: new Abstract: Autoregressive language models decode left-to-right with
            irreversible commitments, limiting revision during multi-step reasoning. We propose \\textbf{VDL"
        - title: LLMs Exhibit Significantly Lower Uncertainty in Creative Writing Than Professional Writers
          url: https://arxiv.org/abs/2602.16162
          summary: "arXiv:2602.16162v1 Announce Type: new Abstract: We argue that uncertainty is a key and understudied limitation
            of LLMs' performance in creative writing, which is often characterized as trite and clich"
        - title: "When Stereotypes GTG: The Impact of Predictive Text Suggestions on Gender Bias in Human-AI Co-Writing"
          url: https://arxiv.org/abs/2409.20390
          summary: "arXiv:2409.20390v2 Announce Type: replace Abstract: AI-based systems such as language models have been shown
            to replicate and even amplify social biases reflected in their training data. Among other q"
        - title: Visual Memory Injection Attacks for Multi-Turn Conversations
          url: https://arxiv.org/abs/2602.15927
          summary: "arXiv:2602.15927v1 Announce Type: cross Abstract: Generative large vision-language models (LVLMs) have
            recently achieved impressive performance gains, and their user base is growing rapidly. However, "
        - title: Introducing GPT-5.1 for developers
          url: https://openai.com/index/gpt-5-1-for-developers
          summary: GPT-5.1 is now available in the API, bringing faster adaptive reasoning, extended prompt caching, improved
            coding performance, and new apply_patch and shell tools.
        - title: Fine-tuning now available for GPT-4o
          url: https://openai.com/index/gpt-4o-fine-tuning
          summary: Fine-tune custom versions of GPT-4o to increase performance and accuracy for your applications
        - title: "GPT-4o mini: advancing cost-efficient intelligence"
          url: https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence
          summary: Introducing the most cost-efficient small model in the market
        - title: Improved Techniques for Training Consistency Models
          url: https://openai.com/index/improved-techniques-for-training-consistency-models
          summary: Consistency models are a nascent family of generative models that can sample high quality data in one step
            without the need for adversarial training.
        - title: ChatGPT can now see, hear, and speak
          url: https://openai.com/index/chatgpt-can-now-see-hear-and-speak
          summary: We are beginning to roll out new voice and image capabilities in ChatGPT. They offer a new, more intuitive type
            of interface by allowing you to have a voice conversation or show ChatGPT what you’re ta
        - title: Teaching with AI
          url: https://openai.com/index/teaching-with-ai
          summary: We’re releasing a guide for teachers using ChatGPT in their classroom—including suggested prompts, an
            explanation of how ChatGPT works and its limitations, the efficacy of AI detectors, and bias.
        - title: Introducing text and code embeddings
          url: https://openai.com/index/introducing-text-and-code-embeddings
          summary: We are introducing embeddings, a new endpoint in the OpenAI API that makes it easy to perform natural language
            and code tasks like semantic search, clustering, topic modeling, and classification.
        - title: GPT-3 powers the next generation of apps
          url: https://openai.com/index/gpt-3-apps
          summary: Over 300 applications are delivering GPT-3–powered search, conversation, text completion, and other advanced AI
            features through our API.
        - title: OpenAI API
          url: https://openai.com/index/openai-api
          summary: We’re releasing an API for accessing new AI models developed by OpenAI.
        - title: Discovering types for entity disambiguation
          url: https://openai.com/index/discovering-types-for-entity-disambiguation
          summary: We’ve built a system for automatically figuring out which object is meant by a word by having a neural network
            decide if the word belongs to each of about 100 automatically-discovered “types” (non-exc
        - title: "Gemini 3 Flash: frontier intelligence built for speed"
          url: https://deepmind.google/blog/gemini-3-flash-frontier-intelligence-built-for-speed/
          summary: Gemini 3 Flash offers frontier intelligence built for speed at a fraction of the cost.
        - title: How a Gemma model helped discover a new potential cancer therapy pathway
          url: https://deepmind.google/blog/how-a-gemma-model-helped-discover-a-new-potential-cancer-therapy-pathway/
          summary: We’re launching a new 27 billion parameter foundation model for single-cell analysis built on the Gemma family
            of open models.
        - title: "AlphaGenome: AI for better understanding the genome"
          url: https://deepmind.google/blog/alphagenome-ai-for-better-understanding-the-genome/
          summary: Introducing a new, unifying DNA sequence model that advances regulatory variant-effect prediction and promises
            to shed new light on genome function — now available via API.
        - title: "DolphinGemma: How Google AI is helping decode dolphin communication"
          url: https://deepmind.google/blog/dolphingemma-how-google-ai-is-helping-decode-dolphin-communication/
          summary: DolphinGemma, a large language model developed by Google, is helping scientists study how dolphins communicate
            — and hopefully find out what they're saying, too.
        - title: Updated production-ready Gemini models, reduced 1.5 Pro pricing, increased rate limits, and more
          url: https://deepmind.google/blog/updated-production-ready-gemini-models-reduced-15-pro-pricing-increased-rate-limits-and-more/
          summary: We’re releasing two updated production-ready Gemini models
        - title: How Uncertain Is the Grade? A Benchmark of Uncertainty Metrics for LLM-Based Automatic Assessment
          url: https://arxiv.org/abs/2602.16039
          summary: "arXiv:2602.16039v1 Announce Type: new Abstract: The rapid rise of large language models (LLMs) is reshaping
            the landscape of automatic assessment in education. While these systems demonstrate substant"
        - title: "GPSBench: Do Large Language Models Understand GPS Coordinates?"
          url: https://arxiv.org/abs/2602.16105
          summary: "arXiv:2602.16105v1 Announce Type: new Abstract: Large Language Models (LLMs) are increasingly deployed in
            applications that interact with the physical world, such as navigation, robotics, or mapping, "
        - title: "Leveraging Large Language Models for Causal Discovery: a Constraint-based, Argumentation-driven Approach"
          url: https://arxiv.org/abs/2602.16481
          summary: "arXiv:2602.16481v1 Announce Type: new Abstract: Causal discovery seeks to uncover causal relations from data,
            typically represented as causal graphs, and is essential for predicting the effects of int"
        - title: Decoupling Strategy and Execution in Task-Focused Dialogue via Goal-Oriented Preference Optimization
          url: https://arxiv.org/abs/2602.15854
          summary: "arXiv:2602.15854v1 Announce Type: cross Abstract: Large language models show potential in task-oriented
            dialogue systems, yet existing training methods often rely on token-level likelihood or preferen"
        - title: "Not the Example, but the Process: How Self-Generated Examples Enhance LLM Reasoning"
          url: https://arxiv.org/abs/2602.15863
          summary: "arXiv:2602.15863v1 Announce Type: cross Abstract: Recent studies have shown that Large Language Models (LLMs)
            can improve their reasoning performance through self-generated few-shot examples, achievin"
        - title: "Understand Then Memory: A Cognitive Gist-Driven RAG Framework with Global Semantic Diffusion"
          url: https://arxiv.org/abs/2602.15895
          summary: "arXiv:2602.15895v1 Announce Type: cross Abstract: Retrieval-Augmented Generation (RAG) effectively mitigates
            hallucinations in LLMs by incorporating external knowledge. However, the inherent discrete "
        - title: "Conjugate Learning Theory: Uncovering the Mechanisms of Trainability and Generalization in Deep Neural Networks"
          url: https://arxiv.org/abs/2602.16177
          summary: "arXiv:2602.16177v1 Announce Type: cross Abstract: In this work, we propose a notion of practical learnability
            grounded in finite sample settings, and develop a conjugate learning theoretical framework"
        - title: Are LLMs Ready to Replace Bangla Annotators?
          url: https://arxiv.org/abs/2602.16241
          summary: "arXiv:2602.16241v1 Announce Type: cross Abstract: Large Language Models (LLMs) are increasingly used as
            automated annotators to scale dataset creation, yet their reliability as unbiased annotators--es"
        - title: "IndicEval: A Bilingual Indian Educational Evaluation Framework for Large Language Models"
          url: https://arxiv.org/abs/2602.16467
          summary: "arXiv:2602.16467v1 Announce Type: cross Abstract: The rapid advancement of large language models (LLMs)
            necessitates evaluation frameworks that reflect real-world academic rigor and multilingual compl"
        - title: "FlowPrefill: Decoupling Preemption from Prefill Scheduling Granularity to Mitigate Head-of-Line Blocking in LLM
            Serving"
          url: https://arxiv.org/abs/2602.16603
          summary: "arXiv:2602.16603v1 Announce Type: cross Abstract: The growing demand for large language models (LLMs) requires
            serving systems to handle many concurrent requests with diverse service level objectives "
        - title: "Earth AI: Unlocking Geospatial Insights with Foundation Models and Cross-Modal Reasoning"
          url: https://arxiv.org/abs/2510.18318
          summary: "arXiv:2510.18318v4 Announce Type: replace Abstract: Geospatial data offers immense potential for understanding
            our planet. However, the sheer volume and diversity of this data along with its varied re"
        - title: Integrating Chain-of-Thought and Retrieval Augmented Generation Enhances Rare Disease Diagnosis from Clinical
            Notes
          url: https://arxiv.org/abs/2503.12286
          summary: "arXiv:2503.12286v2 Announce Type: replace-cross Abstract: Background: Several studies show that large language
            models (LLMs) struggle with phenotype-driven gene prioritization for rare diseases. These"
        - title: "WINA: Weight Informed Neuron Activation for Accelerating Large Language Model Inference"
          url: https://arxiv.org/abs/2505.19427
          summary: "arXiv:2505.19427v2 Announce Type: replace-cross Abstract: The growing computational demands of large language
            models (LLMs) make efficient inference and activation strategies increasingly critical. Wh"
        - title: Lossless Vocabulary Reduction for Auto-Regressive Language Models
          url: https://arxiv.org/abs/2510.08102
          summary: "arXiv:2510.08102v2 Announce Type: replace-cross Abstract: Tokenization -- the process of decomposing a given
            text into a sequence of subwords called tokens -- is one of the key components in the devel"
        - title: "Indic-TunedLens: Interpreting Multilingual Models in Indian Languages"
          url: https://arxiv.org/abs/2602.15038
          summary: "arXiv:2602.15038v2 Announce Type: replace-cross Abstract: Multilingual large language models (LLMs) are
            increasingly deployed in linguistically diverse regions like India, yet most interpretability to"
        - title: Reranker Optimization via Geodesic Distances on k-NN Manifolds
          url: https://arxiv.org/abs/2602.15860
          summary: "arXiv:2602.15860v1 Announce Type: new Abstract: Current neural reranking approaches for retrieval-augmented
            generation (RAG) rely on cross-encoders or large language models (LLMs), requiring substanti"
        - title: "P-RAG: Prompt-Enhanced Parametric RAG with LoRA and Selective CoT for Biomedical and Multi-Hop QA"
          url: https://arxiv.org/abs/2602.15874
          summary: "arXiv:2602.15874v1 Announce Type: new Abstract: Large Language Models (LLMs) demonstrate remarkable
            capabilities but remain limited by their reliance on static training data. Retrieval-Augmented Gener"
        - title: MultiCube-RAG for Multi-hop Question Answering
          url: https://arxiv.org/abs/2602.15898
          summary: "arXiv:2602.15898v1 Announce Type: new Abstract: Multi-hop question answering (QA) necessitates multi-step
            reasoning and retrieval across interconnected subjects, attributes, and relations. Existing re"
        - title: Label-Consistent Data Generation for Aspect-Based Sentiment Analysis Using LLM Agents
          url: https://arxiv.org/abs/2602.16379
          summary: "arXiv:2602.16379v1 Announce Type: new Abstract: We propose an agentic data augmentation method for
            Aspect-Based Sentiment Analysis (ABSA) that uses iterative generation and verification to produce hig"
        - title: "SPELL: Self-Play Reinforcement Learning for Evolving Long-Context Language Models"
          url: https://arxiv.org/abs/2509.23863
          summary: "arXiv:2509.23863v3 Announce Type: replace Abstract: Progress in long-context reasoning for large language
            models (LLMs) has lagged behind other recent advances. This gap arises not only from the intri"
        - title: Can Vision-Language Models See Squares? Text-Recognition Mediates Spatial Reasoning Across Three Model Families
          url: https://arxiv.org/abs/2602.15950
          summary: "arXiv:2602.15950v1 Announce Type: cross Abstract: We present a simple experiment that exposes a fundamental
            limitation in vision-language models (VLMs): the inability to accurately localize filled cel"
        - title: How Tolan builds voice-first AI with GPT-5.1
          url: https://openai.com/index/tolan
          summary: Tolan built a voice-first AI companion with GPT-5.1, combining low-latency responses, real-time context
            reconstruction, and memory-driven personalities for natural conversations.
        - title: "GPT-5.1: A smarter, more conversational ChatGPT"
          url: https://openai.com/index/gpt-5-1
          summary: We’re upgrading the GPT-5 series with warmer, more capable models and new ways to customize ChatGPT’s tone and
            style. GPT-5.1 starts rolling out today to paid users.
        - title: Introducing vision to the fine-tuning API
          url: https://openai.com/index/introducing-vision-to-the-fine-tuning-api
          summary: Developers can now fine-tune GPT-4o with images and text to improve vision capabilities
        - title: Fine-tuning GPT-4o webinar
          url: https://openai.com/business/fine-tuning-gpt-4o-webinar
          summary: Fine-Tuning GPT-4o Webinar
        - title: Introducing Structured Outputs in the API
          url: https://openai.com/index/introducing-structured-outputs-in-the-api
          summary: We are introducing Structured Outputs in the API—model outputs now reliably adhere to developer-supplied JSON
            Schemas.
        - title: Consistency Models
          url: https://openai.com/index/consistency-models
          summary: Diffusion models have significantly advanced the fields of image, audio, and video generation, but they depend
            on an iterative sampling process that causes slow generation.
        - title: GPT-4 API general availability and deprecation of older models in the Completions API
          url: https://openai.com/index/gpt-4-api-general-availability
          summary: GPT-3.5 Turbo, DALL·E and Whisper APIs are also generally available, and we are releasing a deprecation plan
            for older models of the Completions API, which will retire at the beginning of 2024.
        - title: Simplifying contract reviews with AI
          url: https://openai.com/index/ironclad
          summary: Ironclad uses GPT-4 to simplify the contract review process.
        - title: OpenAI partners with Scale to provide support for enterprises fine-tuning models
          url: https://openai.com/index/openai-partners-with-scale-to-provide-support-for-enterprises-fine-tuning-models
          summary: OpenAI’s customers can leverage Scale’s AI expertise to customize our most advanced models.
        - title: GPT-3.5 Turbo fine-tuning and API updates
          url: https://openai.com/index/gpt-3-5-turbo-fine-tuning-and-api-updates
          summary: Developers can now bring their own data to customize GPT-3.5 Turbo for their use cases.
        - title: Partnership with American Journalism Project to support local news
          url: https://openai.com/index/partnership-with-american-journalism-project-to-support-local-news
          summary: A new $5+ million partnership aims to explore ways the development of artificial intelligence (AI) can support
            a thriving, innovative local news field, and ensure local news organizations shape the fu
        - title: Function calling and other API updates
          url: https://openai.com/index/function-calling-and-other-api-updates
          summary: We’re announcing updates including more steerable API models, function calling capabilities, longer context,
            and lower prices.
        - title: Introducing Whisper
          url: https://openai.com/index/whisper
          summary: We’ve trained and are open-sourcing a neural net called Whisper that approaches human level robustness and
            accuracy on English speech recognition.
        - title: Text and code embeddings by contrastive pre-training
          url: https://openai.com/index/text-and-code-embeddings-by-contrastive-pre-training
          summary: ""
        - title: Everything We Announced at Our First-Ever LlamaCon
          url: https://ai.meta.com/blog/llamacon-llama-news/
          summary: "  A comprehensive roundup of everything announced at LlamaCon, including how to get started with Meta's newest
            releases."
        - title: "Evidence-Grounded Subspecialty Reasoning: Evaluating a Curated Clinical Intelligence Layer on the 2025
            Endocrinology Board-Style Examination"
          url: https://arxiv.org/abs/2602.16050
          summary: "arXiv:2602.16050v1 Announce Type: new Abstract: Background: Large language models have demonstrated strong
            performance on general medical examinations, but subspecialty clinical reasoning remains chal"
        - title: "The Perplexity Paradox: Why Code Compresses Better Than Math in LLM Prompts"
          url: https://arxiv.org/abs/2602.15843
          summary: 'arXiv:2602.15843v1 Announce Type: cross Abstract: In "Compress or Route?" (Johnson, 2026), we found that code
            generation tolerates aggressive prompt compression (r >= 0.6) while chain-of-thought reaso'
        - title: Preference Optimization for Review Question Generation Improves Writing Quality
          url: https://arxiv.org/abs/2602.15849
          summary: "arXiv:2602.15849v1 Announce Type: cross Abstract: Peer review relies on substantive, evidence-based questions,
            yet existing LLM-based approaches often generate surface-level queries, drawing over 50\\%"
        - title: "Rethinking Soft Compression in Retrieval-Augmented Generation: A Query-Conditioned Selector Perspective"
          url: https://arxiv.org/abs/2602.15856
          summary: "arXiv:2602.15856v1 Announce Type: cross Abstract: Retrieval-Augmented Generation (RAG) effectively grounds
            Large Language Models (LLMs) with external knowledge and is widely applied to Web-related tas"
        - title: "Playing With AI: How Do State-Of-The-Art Large Language Models Perform in the 1977 Text-Based Adventure Game
            Zork?"
          url: https://arxiv.org/abs/2602.15867
          summary: "arXiv:2602.15867v1 Announce Type: cross Abstract: In this positioning paper, we evaluate the problem-solving
            and reasoning capabilities of contemporary Large Language Models (LLMs) through their perfo"
        - title: "Fly0: Decoupling Semantic Grounding from Geometric Planning for Zero-Shot Aerial Navigation"
          url: https://arxiv.org/abs/2602.15875
          summary: "arXiv:2602.15875v1 Announce Type: cross Abstract: Current Visual-Language Navigation (VLN) methodologies face
            a trade-off between semantic understanding and control precision. While Multimodal Large L"
        - title: "Generative AI Usage of University Students: Navigating Between Education and Business"
          url: https://arxiv.org/abs/2602.16307
          summary: "arXiv:2602.16307v1 Announce Type: cross Abstract: This study investigates generative artificial intelligence
            (GenAI) usage of university students who study alongside their professional career. Previou"
        - title: "From Growing to Looping: A Unified View of Iterative Computation in LLMs"
          url: https://arxiv.org/abs/2602.16490
          summary: "arXiv:2602.16490v1 Announce Type: cross Abstract: Looping, reusing a block of layers across depth, and depth
            growing, training shallow-to-deep models by duplicating middle layers, have both been linke"
        - title: "MC-LLaVA: Multi-Concept Personalized Vision-Language Model"
          url: https://arxiv.org/abs/2411.11706
          summary: "arXiv:2411.11706v4 Announce Type: replace-cross Abstract: Current vision-language models (VLMs) show
            exceptional abilities across diverse tasks, such as visual question answering. To enhance user expe"
        - title: Adaptive Rank Allocation for Federated Parameter-Efficient Fine-Tuning of Language Models
          url: https://arxiv.org/abs/2501.14406
          summary: "arXiv:2501.14406v4 Announce Type: replace-cross Abstract: Pre-trained Language Models (PLMs) have demonstrated
            their superiority and versatility in modern Natural Language Processing (NLP), effectivel"
        - title: "CreativityPrism: A Holistic Evaluation Framework for Large Language Model Creativity"
          url: https://arxiv.org/abs/2510.20091
          summary: "arXiv:2510.20091v2 Announce Type: replace-cross Abstract: Creativity is often seen as a hallmark of human
            intelligence. While large language models (LLMs) are increasingly perceived as generating crea"
        - title: "Far Out: Evaluating Language Models on Slang in Australian and Indian English"
          url: https://arxiv.org/abs/2602.15373
          summary: "arXiv:2602.15373v2 Announce Type: replace-cross Abstract: Language models exhibit systematic performance gaps
            when processing text in non-standard language varieties, yet their ability to comprehend v"
        - title: Gated Tree Cross-attention for Checkpoint-Compatible Syntax Injection in Decoder-Only LLMs
          url: https://arxiv.org/abs/2602.15846
          summary: "arXiv:2602.15846v1 Announce Type: new Abstract: Decoder-only large language models achieve strong broad
            performance but are brittle to minor grammatical perturbations, undermining reliability for down"
        - title: The Validity of Coreference-based Evaluations of Natural Language Understanding
          url: https://arxiv.org/abs/2602.16200
          summary: "arXiv:2602.16200v1 Announce Type: new Abstract: In this thesis, I refine our understanding as to what
            conclusions we can reach from coreference-based evaluations by expanding existing evaluation pract"
        - title: "Utility-Preserving De-Identification for Math Tutoring: Investigating Numeric Ambiguity in the MathEd-PII
            Benchmark Dataset"
          url: https://arxiv.org/abs/2602.16571
          summary: "arXiv:2602.16571v1 Announce Type: new Abstract: Large-scale sharing of dialogue-based data is instrumental for
            advancing the science of teaching and learning, yet rigorous de-identification remains a "
        - title: "ModalImmune: Immunity Driven Unlearning via Self Destructive Training"
          url: https://arxiv.org/abs/2602.16197
          summary: "arXiv:2602.16197v1 Announce Type: cross Abstract: Multimodal systems are vulnerable to partial or complete
            loss of input channels at deployment, which undermines reliability in real-world settings. Th"
        - title: "When Algorithms Meet Artists: Semantic Compression of Artists' Concerns in the Public AI-Art Debate"
          url: https://arxiv.org/abs/2508.03037
          summary: "arXiv:2508.03037v4 Announce Type: replace Abstract: Artists occupy a paradoxical position in generative AI:
            their work trains the models reshaping creative labor. We tested whether their concerns achi"
        - title: Embedding Inversion via Conditional Masked Diffusion Language Models
          url: https://arxiv.org/abs/2602.11047
          summary: "arXiv:2602.11047v3 Announce Type: replace Abstract: We frame embedding inversion as conditional masked
            diffusion, recovering all tokens in parallel through iterative denoising rather than sequential a"
        - title: Fast KV Compaction via Attention Matching
          url: https://arxiv.org/abs/2602.16284
          summary: "arXiv:2602.16284v1 Announce Type: new Abstract: Scaling language models to long contexts is often bottlenecked
            by the size of the key-value (KV) cache. In deployed settings, long contexts are typicall"
        - title: The Limits of Long-Context Reasoning in Automated Bug Fixing
          url: https://arxiv.org/abs/2602.16069
          summary: "arXiv:2602.16069v1 Announce Type: cross Abstract: Rapidly increasing context lengths have led to the
            assumption that large language models (LLMs) can directly reason over entire codebases. Concurrentl"
        - title: Logarithmic-time Schedules for Scaling Language Models with Momentum
          url: https://arxiv.org/abs/2602.05298
          summary: "arXiv:2602.05298v2 Announce Type: replace-cross Abstract: In practice, the hyperparameters $(\\beta_1,
            \\beta_2)$ and weight-decay $\\lambda$ in AdamW are typically kept at fixed values. Is there any rea"
        - title: Inside Praktika's conversational approach to language learning
          url: https://openai.com/index/praktika
          summary: How Praktika uses GPT-4.1 and GPT-5.2 to build adaptive AI tutors that personalize lessons, track progress, and
            help learners achieve real-world language fluency
        - title: SearchGPT is a prototype of new AI search features
          url: https://openai.com/index/searchgpt-prototype
          summary: We’re testing SearchGPT, a temporary prototype of new search features that give you fast and timely answers
            with clear and relevant sources.
        - title: Introducing ChatGPT Enterprise
          url: https://openai.com/index/introducing-chatgpt-enterprise
          summary: Get enterprise-grade security & privacy and the most powerful version of ChatGPT yet.
        - title: Accurately analyzing large scale qualitative data
          url: https://openai.com/index/viable
          summary: Viable uses GPT-4 to analyze qualitative data at a revolutionary scale with unparalleled accuracy.
        - title: "EdgeNav-QE: QLoRA Quantization and Dynamic Early Exit for LAM-based Navigation on Edge Devices"
          url: https://arxiv.org/abs/2602.15836
          summary: "arXiv:2602.15836v1 Announce Type: cross Abstract: Large Action Models (LAMs) have shown immense potential in
            autonomous navigation by bridging high-level reasoning with low-level control. However, dep"
        - title: Can LLMs Assess Personality? Validating Conversational AI for Trait Profiling
          url: https://arxiv.org/abs/2602.15848
          summary: "arXiv:2602.15848v1 Announce Type: cross Abstract: This study validates Large Language Models (LLMs) as a
            dynamic alternative to questionnaire-based personality assessment. Using a within-subjects expe"
        - title: "CAST: Achieving Stable LLM-based Text Analysis for Data Analytics"
          url: https://arxiv.org/abs/2602.15861
          summary: "arXiv:2602.15861v1 Announce Type: cross Abstract: Text analysis of tabular data relies on two core operations:
            \\emph{summarization} for corpus-level theme extraction and \\emph{tagging} for row-level l"
        - title: Test-Time Adaptation for Tactile-Vision-Language Models
          url: https://arxiv.org/abs/2602.15873
          summary: "arXiv:2602.15873v1 Announce Type: cross Abstract: Tactile-vision-language (TVL) models are increasingly
            deployed in real-world robotic and multimodal perception tasks, where test-time distribution shi"
        - title: "Human-AI Collaboration in Large Language Model-Integrated Building Energy Management Systems: The Role of User
            Domain Knowledge and AI Literacy"
          url: https://arxiv.org/abs/2602.16140
          summary: "arXiv:2602.16140v1 Announce Type: cross Abstract: This study aimed to comprehend how user domain knowledge and
            artificial intelligence (AI) literacy impact the effective use of human-AI interactive bu"
        - title: "Beyond Learning: A Training-Free Alternative to Model Adaptation"
          url: https://arxiv.org/abs/2602.16189
          summary: "arXiv:2602.16189v1 Announce Type: cross Abstract: Despite the continuous research and evolution of language
            models, they sometimes underperform previous versions. Existing approaches to overcome these"
        - title: "GDGB: A Benchmark for Generative Dynamic Text-Attributed Graph Learning"
          url: https://arxiv.org/abs/2507.03267
          summary: "arXiv:2507.03267v2 Announce Type: replace Abstract: Dynamic Text-Attributed Graphs (DyTAGs), which intricately
            integrate structural, temporal, and textual attributes, are crucial for modeling complex "
        - title: "Ctrl-GenAug: Controllable Generative Augmentation for Medical Sequence Classification"
          url: https://arxiv.org/abs/2409.17091
          summary: "arXiv:2409.17091v3 Announce Type: replace-cross Abstract: In the medical field, the limited availability of
            large-scale datasets and labor-intensive annotation processes hinder the performance of deep"
        - title: Semantic Chunking and the Entropy of Natural Language
          url: https://arxiv.org/abs/2602.13194
          summary: "arXiv:2602.13194v2 Announce Type: replace-cross Abstract: The entropy rate of printed English is famously
            estimated to be about one bit per character, a benchmark that modern large language models (LL"
        - title: "Every Little Helps: Building Knowledge Graph Foundation Model with Fine-grained Transferable Multi-modal Tokens"
          url: https://arxiv.org/abs/2602.15896
          summary: "arXiv:2602.15896v1 Announce Type: new Abstract: Multi-modal knowledge graph reasoning (MMKGR) aims to predict
            the missing links by exploiting both graph structure information and multi-modal entity co"
        - title: Optimizing Soft Prompt Tuning via Structural Evolution
          url: https://arxiv.org/abs/2602.16500
          summary: "arXiv:2602.16500v1 Announce Type: new Abstract: Soft prompt tuning leverages continuous embeddings to capture
            task-specific information in large pre-trained language models (LLMs), achieving competiti"
        - title: Reinforced Fast Weights with Next-Sequence Prediction
          url: https://arxiv.org/abs/2602.16704
          summary: "arXiv:2602.16704v1 Announce Type: new Abstract: Fast weight architectures offer a promising alternative to
            attention-based transformers for long-context modeling by maintaining constant memory overhea"
        - title: "Standardizing the Measurement of Text Diversity: A Tool and a Comparative Analysis of Scores"
          url: https://arxiv.org/abs/2403.00553
          summary: "arXiv:2403.00553v3 Announce Type: replace Abstract: The diversity across outputs generated by LLMs shapes
            perception of their quality and utility. High lexical diversity is often desirable, but there "
        - title: "DIAL: Direct Iterative Adversarial Learning for Realistic Multi-Turn Dialogue Simulation"
          url: https://arxiv.org/abs/2512.20773
          summary: "arXiv:2512.20773v3 Announce Type: replace Abstract: Realistic user simulation is crucial for training and
            evaluating multi-turn dialogue systems, yet creating simulators that accurately replicate huma"
        - title: "Deep TPC: Temporal-Prior Conditioning for Time Series Forecasting"
          url: https://arxiv.org/abs/2602.16188
          summary: "arXiv:2602.16188v1 Announce Type: new Abstract: LLM-for-time series (TS) methods typically treat time
            shallowly, injecting positional or prompt-based cues once at the input of a largely frozen decoder"
        - title: Heuristic Search as Language-Guided Program Optimization
          url: https://arxiv.org/abs/2602.16038
          summary: "arXiv:2602.16038v1 Announce Type: cross Abstract: Large Language Models (LLMs) have advanced Automated
            Heuristic Design (AHD) in combinatorial optimization (CO) in the past few years. However, existin"
        - title: "Beyond SGD, Without SVD: Proximal Subspace Iteration LoRA with Diagonal Fractional K-FAC"
          url: https://arxiv.org/abs/2602.16456
          summary: "arXiv:2602.16456v1 Announce Type: new Abstract: Low-Rank Adaptation (LoRA) fine-tunes large models by learning
            low-rank updates on top of frozen weights, dramatically reducing trainable parameters and"
        - title: Personalizing education with ChatGPT
          url: https://openai.com/index/asu
          summary: Arizona State University embraces ChatGPT campus-wide to personalize learning, advance research, and prepare
            students for the future
        - title: What Persona Are We Missing? Identifying Unknown Relevant Personas for Faithful User Simulation
          url: https://arxiv.org/abs/2602.15832
          summary: "arXiv:2602.15832v1 Announce Type: cross Abstract: Existing user simulations, where models generate user-like
            responses in dialogue, often lack verification that sufficient user personas are provided, "
        - title: Language Model Representations for Efficient Few-Shot Tabular Classification
          url: https://arxiv.org/abs/2602.15844
          summary: "arXiv:2602.15844v1 Announce Type: cross Abstract: The Web is a rich source of structured data in the form of
            tables, from product catalogs and knowledge bases to scientific datasets. However, the hete"
        - title: A Graph Meta-Network for Learning on Kolmogorov-Arnold Networks
          url: https://arxiv.org/abs/2602.16316
          summary: "arXiv:2602.16316v1 Announce Type: cross Abstract: Weight-space models learn directly from the parameters of
            neural networks, enabling tasks such as predicting their accuracy on new datasets. Naive met"
        - title: "Prompt When the Animal is: Temporal Animal Behavior Grounding with Positional Recovery Training"
          url: https://arxiv.org/abs/2405.05523
          summary: "arXiv:2405.05523v2 Announce Type: replace-cross Abstract: Temporal grounding is crucial in multimodal
            learning, but it poses challenges when applied to animal behavior data due to the sparsity and uni"
        - title: "KD4MT: A Survey of Knowledge Distillation for Machine Translation"
          url: https://arxiv.org/abs/2602.15845
          summary: "arXiv:2602.15845v1 Announce Type: new Abstract: Knowledge Distillation (KD) as a research area has gained a
            lot of traction in recent years as a compression tool to address challenges related to ever-"
        - title: "Aladdin-FTI @ AMIYA Three Wishes for Arabic NLP: Fidelity, Diglossia, and Multidialectal Generation"
          url: https://arxiv.org/abs/2602.16290
          summary: "arXiv:2602.16290v1 Announce Type: new Abstract: Arabic dialects have long been under-represented in Natural
            Language Processing (NLP) research due to their non-standardization and high variability, wh"
        - title: "Quecto-V1: Empirical Analysis of 8-bit Quantized Small Language Models for On-Device Legal Retrieval"
          url: https://arxiv.org/abs/2602.16640
          summary: 'arXiv:2602.16640v1 Announce Type: new Abstract: The rapid proliferation of Large Language Models (LLMs) has
            revolutionized Natural Language Processing (NLP) but has simultaneously created a "resource '
        - title: "Why Any-Order Autoregressive Models Need Two-Stream Attention: A Structural-Semantic Tradeoff"
          url: https://arxiv.org/abs/2602.16092
          summary: "arXiv:2602.16092v1 Announce Type: cross Abstract: Any-order autoregressive models (AO-ARMs) offer a promising
            path toward efficient masked diffusion by enabling native key-value caching, but competiti"
        - title: Scaling Open Discrete Audio Foundation Models with Interleaved Semantic, Acoustic, and Text Tokens
          url: https://arxiv.org/abs/2602.16687
          summary: "arXiv:2602.16687v1 Announce Type: cross Abstract: Current audio language models are predominantly text-first,
            either extending pre-trained text LLM backbones or relying on semantic-only audio tokens, "
        - title: Pretraining Language Models for Diachronic Linguistic Change Discovery
          url: https://arxiv.org/abs/2504.05523
          summary: "arXiv:2504.05523v3 Announce Type: replace Abstract: Large language models (LLMs) have shown potential as tools
            for scientific discovery. This has engendered growing interest in their use in humanistic"
        - title: "PRoH: Dynamic Planning and Reasoning over Knowledge Hypergraphs for Retrieval-Augmented Generation"
          url: https://arxiv.org/abs/2510.12434
          summary: "arXiv:2510.12434v2 Announce Type: replace Abstract: Knowledge Hypergraphs (KHs) have recently emerged as a
            knowledge representation for retrieval-augmented generation (RAG), offering a paradigm to mod"
        - title: Flatter Tokens are More Valuable for Speculative Draft Model Training
          url: https://arxiv.org/abs/2601.18902
          summary: "arXiv:2601.18902v2 Announce Type: replace Abstract: Speculative Decoding (SD) is a key technique for
            accelerating Large Language Model (LLM) inference, but it typically requires training a draft model"
        - title: "LMSeg: Unleashing the Power of Large-Scale Models for Open-Vocabulary Semantic Segmentation"
          url: https://arxiv.org/abs/2412.00364
          summary: "arXiv:2412.00364v2 Announce Type: replace-cross Abstract: It is widely agreed that open-vocabulary-based
            approaches outperform classical closed-set training solutions for recognizing unseen objects in"
        - title: View Invariant Learning for Vision-Language Navigation in Continuous Environments
          url: https://arxiv.org/abs/2507.08831
          summary: "arXiv:2507.08831v3 Announce Type: replace-cross Abstract: Vision-Language Navigation in Continuous
            Environments (VLNCE), where an agent follows instructions and moves freely to reach a destination, is"
        - title: OpenAI partners with Condé Nast
          url: https://openai.com/index/conde-nast
          summary: Condé Nast
        - title: Enabling a data-driven workforce
          url: https://openai.com/business/enabling-a-data-driven-workforce-webinar
          summary: In this video, we share practical examples of how employees can use ChatGPT Enterprise to efficiently analyze
            data and uncover insights.
        - title: Pairing data with APIs to unlock customer value
          url: https://openai.com/index/rakuten
          summary: Rakuten Pairs Data with AI to Unlock Customer Insights and Value
        - title: Strategic Content Partnership with TIME
          url: https://openai.com/index/strategic-content-partnership-with-time
          summary: We’re partnering with TIME and its 101 years of archival content to enhance responses and provide links to
            stories on Time.com
        - title: "Narrative Theory-Driven LLM Methods for Automatic Story Generation and Understanding: A Survey"
          url: https://arxiv.org/abs/2602.15851
          summary: "arXiv:2602.15851v1 Announce Type: cross Abstract: Applications of narrative theories using large language
            models (LLMs) deliver promising use-cases in automatic story generation and understanding task"
        - title: Enhancing Action and Ingredient Modeling for Semantically Grounded Recipe Generation
          url: https://arxiv.org/abs/2602.15862
          summary: "arXiv:2602.15862v1 Announce Type: cross Abstract: Recent advances in Multimodal Large Language Models (MLMMs)
            have enabled recipe generation from food images, yet outputs often contain semantically in"
        - title: Surrogate-Based Prevalence Measurement for Large-Scale A/B Testing
          url: https://arxiv.org/abs/2602.16111
          summary: "arXiv:2602.16111v1 Announce Type: cross Abstract: Online media platforms often need to measure how frequently
            users are exposed to specific content attributes in order to evaluate trade-offs in A/B ex"
        - title: Edge Learning via Federated Split Decision Transformers for Metaverse Resource Allocation
          url: https://arxiv.org/abs/2602.16174
          summary: "arXiv:2602.16174v1 Announce Type: cross Abstract: Mobile edge computing (MEC) based wireless metaverse
            services offer an untethered, immersive experience to users, where the superior quality of experi"
        - title: A Self-Supervised Approach for Enhanced Feature Representations in Object Detection Tasks
          url: https://arxiv.org/abs/2602.16322
          summary: "arXiv:2602.16322v1 Announce Type: cross Abstract: In the fast-evolving field of artificial intelligence, where
            models are increasingly growing in complexity and size, the availability of labeled data "
        - title: Large Language Models for Assisting American College Applications
          url: https://arxiv.org/abs/2602.15850
          summary: "arXiv:2602.15850v1 Announce Type: new Abstract: American college applications require students to navigate
            fragmented admissions policies, repetitive and conditional forms, and ambiguous questions tha"
        - title: "Supercharging Agenda Setting Research: The ParlaCAP Dataset of 28 European Parliaments and a Scalable
            Multilingual LLM-Based Classification"
          url: https://arxiv.org/abs/2602.16516
          summary: "arXiv:2602.16516v1 Announce Type: new Abstract: This paper introduces ParlaCAP, a large-scale dataset for
            analyzing parliamentary agenda setting across Europe, and proposes a cost-effective method for"
        - title: "ColBERT-Zero: To Pre-train Or Not To Pre-train ColBERT models"
          url: https://arxiv.org/abs/2602.16609
          summary: "arXiv:2602.16609v1 Announce Type: new Abstract: Current state-of-the-art multi-vector models are obtained
            through a small Knowledge Distillation (KD) training step on top of strong single-vector model"
        - title: A Methodology for Identifying Evaluation Items for Practical Dialogue Systems Based on Business-Dialogue System
            Alignment Models
          url: https://arxiv.org/abs/2602.15835
          summary: "arXiv:2602.15835v1 Announce Type: cross Abstract: This paper proposes a methodology for identifying evaluation
            items for practical dialogue systems. Traditionally, user satisfaction and user experienc"
        - title: Discrete Stochastic Localization for Non-autoregressive Generation
          url: https://arxiv.org/abs/2602.16169
          summary: "arXiv:2602.16169v1 Announce Type: cross Abstract: Non-autoregressive (NAR) generation reduces decoding latency
            by predicting many tokens in parallel, but iterative refinement often suffers from error "
        - title: Variable-Length Semantic IDs for Recommender Systems
          url: https://arxiv.org/abs/2602.16375
          summary: "arXiv:2602.16375v1 Announce Type: cross Abstract: Generative models are increasingly used in recommender
            systems, both for modeling user behavior as event sequences and for integrating large language "
        - title: "Toward Beginner-Friendly LLMs for Language Learning: Controlling Difficulty in Conversation"
          url: https://arxiv.org/abs/2506.04072
          summary: "arXiv:2506.04072v2 Announce Type: replace Abstract: Practicing conversations with large language models (LLMs)
            presents a promising alternative to traditional in-person language learning. However, mos"
        - title: "PoeTone: A Framework for Constrained Generation of Structured Chinese Songci with LLMs"
          url: https://arxiv.org/abs/2508.02515
          summary: "arXiv:2508.02515v2 Announce Type: replace Abstract: This paper presents a systematic investigation into the
            constrained generation capabilities of large language models (LLMs) in producing Songci, a c"
        - title: Large Language Models as Automatic Annotators and Annotation Adjudicators for Fine-Grained Opinion Analysis
          url: https://arxiv.org/abs/2601.16800
          summary: "arXiv:2601.16800v2 Announce Type: replace Abstract: Fine-grained opinion analysis of text provides a detailed
            understanding of expressed sentiments, including the addressed entity. Although this level"
        - title: "MadEvolve: Evolutionary Optimization of Cosmological Algorithms with Large Language Models"
          url: https://arxiv.org/abs/2602.15951
          summary: "arXiv:2602.15951v1 Announce Type: cross Abstract: We develop a general framework to discover scientific
            algorithms and apply it to three problems in computational cosmology. Our code, MadEvolve, is si"
      directions: "Review and incorporate recent developments: Fine-tuning GPT-2 from human preferences; Gemma Scope 2:
        helping the AI safety community deepen understanding of complex language model behavior; Why language models
        hallucinate; Addendum to GPT-5 System Card: Sensitive conversations; Language models can explain neurons in
        language models; FACTS Benchmark Suite: Systematically evaluating the factuality of large language models; ML
        Safety Newsletter #10; Surgical Activation Steering via Generative Causal Mediation; Helpful to a Fault:
        Measuring Illicit Assistance in Multi-Turn, Multilingual LLM Agents; Mechanistic Indicators of Steering
        Effectiveness in Large Language Models; Random Scaling of Emergent Capabilities; A Content-Based Framework for
        Cybersecurity Refusal Decisions in Large Language Models; Strengthening ChatGPT’s responses in sensitive
        conversations; Shipping smarter agents with every new model; GPT-5 System Card; Better language models and their
        implications; Gemini 2.5: Our most intelligent AI model; FACTS Grounding: A new benchmark for evaluating the
        factuality of large language models; Does GPT-2 Represent Controversy? A Small Mech Interp Investigation; Align
        Once, Benefit Multilingually: Enforcing Multilingual Consistency for LLM Safety Alignment; PolicyPad:
        Collaborative Prototyping of LLM Policies; Mitigating Gradient Inversion Risks in Language Models via Token
        Obfuscation; Evolving Language Models without Labels: Majority Drives Selection, Novelty Promotes Variation;
        Building more helpful ChatGPT experiences for everyone; Introducing GPT-5 for developers; Introducing gpt-oss;
        Improving language understanding with unsupervised learning; Gemini 2.5: Updates to our family of thinking
        models; Introducing Gemini 2.5 Flash; ReLoop: Structured Modeling and Behavioral Verification for Reliable
        LLM-Based Optimization; VerifyBench: Benchmarking Reference-based Reward Systems for Large Language Models;
        SecCodeBench-V2 Technical Report; CheckIfExist: Detecting Citation Hallucinations in the Era of AI-Generated
        Content; Multi-Objective Alignment of Language Models for Personalized Psychotherapy; Evolutionary Context
        Search for Automated Skill Acquisition; Introducing GPT-5; Hello GPT-4o; Using GPT-4 for content moderation;
        Language models are few-shot learners; GPT-2: 1.5B release; T5Gemma: A new collection of encoder-decoder Gemma
        models; We’re expanding our Gemini 2.5 family of models; Gemini 2.5: Our most intelligent models are getting
        even better; Last Week in AI #328 - DeepSeek 3.2, Mistral 3, Trainium3, Runway Gen-4.5; Language Statistics and
        False Belief Reasoning: Evidence from 41 Open-Weight LMs; Understanding LLM Failures: A Multi-Tape Turing
        Machine Analysis of Systematic Errors in Language Model Reasoning; Missing-by-Design: Certifiable Modality
        Deletion for Revocable Multimodal Sentiment Analysis; MemoryArena: Benchmarking Agent Memory in Interdependent
        Multi-Session Agentic Tasks; Empirical Cumulative Distribution Function Clustering for LLM-based Agent System
        Analysis; Transformers Provably Learn Algorithmic Solutions for Graph Connectivity, But Only with the Right
        Data; Introducing gpt-realtime and Realtime API updates; gpt-oss-120b & gpt-oss-20b Model Card; Introducing
        OpenAI o1; Introducing GPT-4o and more tools to ChatGPT free users; Techniques for training large neural
        networks; Solving math word problems; GPT-2: 6-month follow-up; MedGemma: Our most capable open models for
        health AI development; Gemini 2.5 Flash-Lite is now ready for scaled production use; Introducing Gemma 3 270M:
        The compact model for hyper-efficient AI; Announcing Gemma 3n preview: Powerful, efficient, mobile-first AI;
        Gemini 2.5 Pro Preview: even better coding performance; Introducing Gemma 3; The Llama 4 Herd: The Beginning of
        a New Era of Natively Multimodal AI Innovation; LWiAI Podcast #232 - ChatGPT Ads, Thinking Machines Drama, STEM;
        LWiAI Podcast #226 - Gemini 3, Claude Opus 4.5, Nano Banana Pro, LeJEPA; LWiAI Podcast #225 - GPT 5.1, Kimi K2
        Thinking, Remote Labor Index; Do Personality Traits Interfere? Geometric Limitations of Steering in Large
        Language Models; Evidence for Daily and Weekly Periodic Variability in GPT-4o Performance; Can Generative
        Artificial Intelligence Survive Data Contamination? Theoretical Guarantees under Contaminated Recursive
        Training; Software Dependencies 2.0: An Empirical Study of Reuse and Integration of Pre-Trained Models in
        Open-Source Projects; Multilingual Routing in Mixture-of-Experts; Reasoning Up the Instruction Ladder for
        Controllable Language Models; STAPO: Stabilizing Reinforcement Learning for LLMs by Silencing Rare Spurious
        Tokens; Quality-constrained Entropy Maximization Policy Optimization for LLM Diversity; MultiCW: A Large-Scale
        Balanced Benchmark Dataset for Training Robust Check-Worthiness Detection Models; AREG: Adversarial Resource
        Extraction Game for Evaluating Persuasion and Resistance in Large Language Models; MoE-Spec: Expert Budgeting
        for Efficient Speculative Decoding; Causality is Key for Interpretability Claims to Generalise; Features as
        Rewards: Scalable Supervision for Open-Ended Tasks via Interpretability; Introducing IndQA; Spring Update;
        GPT-4V(ision) system card; Introducing ChatGPT; Evaluating large language models trained on code; Introducing
        Gemma 3n: The developer guide; Advanced audio dialog and generation with Gemini 2.5; Build rich, interactive web
        apps with an updated Gemini 2.5 Pro; Start building with Gemini 2.0 Flash and Flash-Lite; Introducing Gemini
        2.0: our new AI model for the agentic era; Last Week in AI #334 - Kimi K2.5 & Code, Genie 3, OpenClaw &
        Moltbook; LWiAI Podcast #229 - Gemini 3 Flash, ChatGPT Apps, Nemotron 3; Last Week in AI #327 - Gemini 3, Opus
        4.5, Nano Banana Pro, GPT-5.1-Codex-Max; Agent Skill Framework: Perspectives on the Potential of Small Language
        Models in Industrial Environments; State Design Matters: How Representations Shape Dynamic Reasoning in Large
        Language Models; Doc-to-LoRA: Learning to Instantly Internalize Contexts; Balancing Faithfulness and Performance
        in Reasoning via Multi-Listener Soft Execution; Long-Tail Knowledge in Large Language Models: Taxonomy,
        Mechanisms, Interventions and Implications; Learning to Learn from Language Feedback with Social Meta-Learning;
        Who can we trust? LLM-as-a-jury for Comparative Assessment; m1: Unleash the Potential of Test-Time Scaling for
        Medical Reasoning with Large Language Models; Experience-based Knowledge Correction for Robust Planning in
        Minecraft; Expressive Power of Graph Transformers via Logic; Predicting Training Re-evaluation Curves Enables
        Effective Data Curriculums for LLMs; From Transcripts to AI Agents: Knowledge Extraction, RAG Integration, and
        Robust Evaluation of Conversational AI Assistants; Towards Fair and Efficient De-identification: Quantifying the
        Efficiency and Generalizability of De-identification Approaches; CLAA: Cross-Layer Attention Aggregation for
        Accelerating LLM Prefill; TabAgent: A Framework for Replacing Agentic Generative Components with Tabular-Textual
        Classifiers; Randomized Masked Finetuning: An Efficient Way to Mitigate Memorization of PIIs in LLMs;
        TimeOmni-1: Incentivizing Complex Reasoning with Time Series in Large Language Models; How Cursor uses GPT-5;
        DALL·E 3 system card; Efficient training of language models to fill in the middle; New GPT-3 capabilities: Edit
        & insert; Customizing GPT-3 for your application; DALL·E: Creating images from text; Unsupervised sentiment
        neuron; With 10x Growth Since 2023, Llama Is the Leading Engine of AI Innovation; LWiAI Podcast #233 - Moltbot,
        Genie 3, Qwen3-Max-Thinking; Framework of Thoughts: A Foundation Framework for Dynamic and Optimized Reasoning
        based on Chains, Trees, and Graphs; Updating Parametric Knowledge with Context Distillation Retains
        Post-Training Capabilities; Understanding Transformer Optimization via Gradient Heterogeneity; MedReasoner:
        Reinforcement Learning Drives Reasoning Grounding from Clinical Thought to Pixel-Level Precision; FeatBench:
        Towards More Realistic Evaluation of Feature-level Code Generation; Multi-source Heterogeneous Public Opinion
        Analysis via Collaborative Reasoning and Adaptive Fusion: A Systematically Integrated Approach; VDLM: Variable
        Diffusion LMs via Robust Latent-to-Text Rendering; LLMs Exhibit Significantly Lower Uncertainty in Creative
        Writing Than Professional Writers; When Stereotypes GTG: The Impact of Predictive Text Suggestions on Gender
        Bias in Human-AI Co-Writing; Visual Memory Injection Attacks for Multi-Turn Conversations; Introducing GPT-5.1
        for developers; Fine-tuning now available for GPT-4o; GPT-4o mini: advancing cost-efficient intelligence;
        Improved Techniques for Training Consistency Models; ChatGPT can now see, hear, and speak; Teaching with AI;
        Introducing text and code embeddings; GPT-3 powers the next generation of apps; OpenAI API; Discovering types
        for entity disambiguation; Gemini 3 Flash: frontier intelligence built for speed; How a Gemma model helped
        discover a new potential cancer therapy pathway; AlphaGenome: AI for better understanding the genome;
        DolphinGemma: How Google AI is helping decode dolphin communication; Updated production-ready Gemini models,
        reduced 1.5 Pro pricing, increased rate limits, and more; How Uncertain Is the Grade? A Benchmark of Uncertainty
        Metrics for LLM-Based Automatic Assessment; GPSBench: Do Large Language Models Understand GPS Coordinates?;
        Leveraging Large Language Models for Causal Discovery: a Constraint-based, Argumentation-driven Approach;
        Decoupling Strategy and Execution in Task-Focused Dialogue via Goal-Oriented Preference Optimization; Not the
        Example, but the Process: How Self-Generated Examples Enhance LLM Reasoning; Understand Then Memory: A Cognitive
        Gist-Driven RAG Framework with Global Semantic Diffusion; Conjugate Learning Theory: Uncovering the Mechanisms
        of Trainability and Generalization in Deep Neural Networks; Are LLMs Ready to Replace Bangla Annotators?;
        IndicEval: A Bilingual Indian Educational Evaluation Framework for Large Language Models; FlowPrefill:
        Decoupling Preemption from Prefill Scheduling Granularity to Mitigate Head-of-Line Blocking in LLM Serving;
        Earth AI: Unlocking Geospatial Insights with Foundation Models and Cross-Modal Reasoning; Integrating
        Chain-of-Thought and Retrieval Augmented Generation Enhances Rare Disease Diagnosis from Clinical Notes; WINA:
        Weight Informed Neuron Activation for Accelerating Large Language Model Inference; Lossless Vocabulary Reduction
        for Auto-Regressive Language Models; Indic-TunedLens: Interpreting Multilingual Models in Indian Languages;
        Reranker Optimization via Geodesic Distances on k-NN Manifolds; P-RAG: Prompt-Enhanced Parametric RAG with LoRA
        and Selective CoT for Biomedical and Multi-Hop QA; MultiCube-RAG for Multi-hop Question Answering;
        Label-Consistent Data Generation for Aspect-Based Sentiment Analysis Using LLM Agents; SPELL: Self-Play
        Reinforcement Learning for Evolving Long-Context Language Models; Can Vision-Language Models See Squares?
        Text-Recognition Mediates Spatial Reasoning Across Three Model Families; How Tolan builds voice-first AI with
        GPT-5.1; GPT-5.1: A smarter, more conversational ChatGPT; Introducing vision to the fine-tuning API; Fine-tuning
        GPT-4o webinar; Introducing Structured Outputs in the API; Consistency Models; GPT-4 API general availability
        and deprecation of older models in the Completions API; Simplifying contract reviews with AI; OpenAI partners
        with Scale to provide support for enterprises fine-tuning models; GPT-3.5 Turbo fine-tuning and API updates;
        Partnership with American Journalism Project to support local news; Function calling and other API updates;
        Introducing Whisper; Text and code embeddings by contrastive pre-training; Everything We Announced at Our
        First-Ever LlamaCon; Evidence-Grounded Subspecialty Reasoning: Evaluating a Curated Clinical Intelligence Layer
        on the 2025 Endocrinology Board-Style Examination; The Perplexity Paradox: Why Code Compresses Better Than Math
        in LLM Prompts; Preference Optimization for Review Question Generation Improves Writing Quality; Rethinking Soft
        Compression in Retrieval-Augmented Generation: A Query-Conditioned Selector Perspective; Playing With AI: How Do
        State-Of-The-Art Large Language Models Perform in the 1977 Text-Based Adventure Game Zork?; Fly0: Decoupling
        Semantic Grounding from Geometric Planning for Zero-Shot Aerial Navigation; Generative AI Usage of University
        Students: Navigating Between Education and Business; From Growing to Looping: A Unified View of Iterative
        Computation in LLMs; MC-LLaVA: Multi-Concept Personalized Vision-Language Model; Adaptive Rank Allocation for
        Federated Parameter-Efficient Fine-Tuning of Language Models; CreativityPrism: A Holistic Evaluation Framework
        for Large Language Model Creativity; Far Out: Evaluating Language Models on Slang in Australian and Indian
        English; Gated Tree Cross-attention for Checkpoint-Compatible Syntax Injection in Decoder-Only LLMs; The
        Validity of Coreference-based Evaluations of Natural Language Understanding; Utility-Preserving
        De-Identification for Math Tutoring: Investigating Numeric Ambiguity in the MathEd-PII Benchmark Dataset;
        ModalImmune: Immunity Driven Unlearning via Self Destructive Training; When Algorithms Meet Artists: Semantic
        Compression of Artists' Concerns in the Public AI-Art Debate; Embedding Inversion via Conditional Masked
        Diffusion Language Models; Fast KV Compaction via Attention Matching; The Limits of Long-Context Reasoning in
        Automated Bug Fixing; Logarithmic-time Schedules for Scaling Language Models with Momentum; Inside Praktika's
        conversational approach to language learning; SearchGPT is a prototype of new AI search features; Introducing
        ChatGPT Enterprise; Accurately analyzing large scale qualitative data; EdgeNav-QE: QLoRA Quantization and
        Dynamic Early Exit for LAM-based Navigation on Edge Devices; Can LLMs Assess Personality? Validating
        Conversational AI for Trait Profiling; CAST: Achieving Stable LLM-based Text Analysis for Data Analytics;
        Test-Time Adaptation for Tactile-Vision-Language Models; Human-AI Collaboration in Large Language
        Model-Integrated Building Energy Management Systems: The Role of User Domain Knowledge and AI Literacy; Beyond
        Learning: A Training-Free Alternative to Model Adaptation; GDGB: A Benchmark for Generative Dynamic
        Text-Attributed Graph Learning; Ctrl-GenAug: Controllable Generative Augmentation for Medical Sequence
        Classification; Semantic Chunking and the Entropy of Natural Language; Every Little Helps: Building Knowledge
        Graph Foundation Model with Fine-grained Transferable Multi-modal Tokens; Optimizing Soft Prompt Tuning via
        Structural Evolution; Reinforced Fast Weights with Next-Sequence Prediction; Standardizing the Measurement of
        Text Diversity: A Tool and a Comparative Analysis of Scores; DIAL: Direct Iterative Adversarial Learning for
        Realistic Multi-Turn Dialogue Simulation; Deep TPC: Temporal-Prior Conditioning for Time Series Forecasting;
        Heuristic Search as Language-Guided Program Optimization; Beyond SGD, Without SVD: Proximal Subspace Iteration
        LoRA with Diagonal Fractional K-FAC; Personalizing education with ChatGPT; What Persona Are We Missing?
        Identifying Unknown Relevant Personas for Faithful User Simulation; Language Model Representations for Efficient
        Few-Shot Tabular Classification; A Graph Meta-Network for Learning on Kolmogorov-Arnold Networks; Prompt When
        the Animal is: Temporal Animal Behavior Grounding with Positional Recovery Training; KD4MT: A Survey of
        Knowledge Distillation for Machine Translation; Aladdin-FTI @ AMIYA Three Wishes for Arabic NLP: Fidelity,
        Diglossia, and Multidialectal Generation; Quecto-V1: Empirical Analysis of 8-bit Quantized Small Language Models
        for On-Device Legal Retrieval; Why Any-Order Autoregressive Models Need Two-Stream Attention: A
        Structural-Semantic Tradeoff; Scaling Open Discrete Audio Foundation Models with Interleaved Semantic, Acoustic,
        and Text Tokens; Pretraining Language Models for Diachronic Linguistic Change Discovery; PRoH: Dynamic Planning
        and Reasoning over Knowledge Hypergraphs for Retrieval-Augmented Generation; Flatter Tokens are More Valuable
        for Speculative Draft Model Training; LMSeg: Unleashing the Power of Large-Scale Models for Open-Vocabulary
        Semantic Segmentation; View Invariant Learning for Vision-Language Navigation in Continuous Environments; OpenAI
        partners with Condé Nast; Enabling a data-driven workforce; Pairing data with APIs to unlock customer value;
        Strategic Content Partnership with TIME; Narrative Theory-Driven LLM Methods for Automatic Story Generation and
        Understanding: A Survey; Enhancing Action and Ingredient Modeling for Semantically Grounded Recipe Generation;
        Surrogate-Based Prevalence Measurement for Large-Scale A/B Testing; Edge Learning via Federated Split Decision
        Transformers for Metaverse Resource Allocation; A Self-Supervised Approach for Enhanced Feature Representations
        in Object Detection Tasks; Large Language Models for Assisting American College Applications; Supercharging
        Agenda Setting Research: The ParlaCAP Dataset of 28 European Parliaments and a Scalable Multilingual LLM-Based
        Classification; ColBERT-Zero: To Pre-train Or Not To Pre-train ColBERT models; A Methodology for Identifying
        Evaluation Items for Practical Dialogue Systems Based on Business-Dialogue System Alignment Models; Discrete
        Stochastic Localization for Non-autoregressive Generation; Variable-Length Semantic IDs for Recommender Systems;
        Toward Beginner-Friendly LLMs for Language Learning: Controlling Difficulty in Conversation; PoeTone: A
        Framework for Constrained Generation of Structured Chinese Songci with LLMs; Large Language Models as Automatic
        Annotators and Annotation Adjudicators for Fine-Grained Opinion Analysis; MadEvolve: Evolutionary Optimization
        of Cosmological Algorithms with Large Language Models"
    - pageId: agentic-ai
      pageTitle: Agentic AI
      reason: 152 news item(s) mention this entity directly
      suggestedTier: standard
      relevantNews:
        - title: "ML Safety Newsletter #15"
          url: https://newsletter.mlsafety.org/p/ml-safety-newsletter-15
          summary: Risks in Agentic Computer Use, Goal Drift, Shutdown Resistance, and Critiques of Scheming Research
        - title: Operator System Card
          url: https://openai.com/index/operator-system-card
          summary: Drawing from OpenAI’s established safety frameworks, this document highlights our multi-layered approach,
            including model and product mitigations we’ve implemented to protect against prompt engineerin
        - title: Practices for Governing Agentic AI Systems
          url: https://openai.com/index/practices-for-governing-agentic-ai-systems
          summary: ""
        - title: Introducing the Gemini 2.5 Computer Use model
          url: https://deepmind.google/blog/introducing-the-gemini-25-computer-use-model/
          summary: Available in preview via the API, our Computer Use model is a specialized model built on Gemini 2.5 Pro’s
            capabilities to power agents that can interact with user interfaces.
        - title: "AI Safety Newsletter #60: The AI Action Plan"
          url: https://newsletter.safe.ai/p/ai-safety-newsletter-60-the-ai-action
          summary: "Plus: ChatGPT Agent and IMO Gold"
        - title: Keeping your data safe when an AI agent clicks a link
          url: https://openai.com/index/ai-agent-link-safety
          summary: Learn how OpenAI protects user data when AI agents open links, preventing URL-based data exfiltration and
            prompt injection with built-in safeguards.
        - title: "Introducing Aardvark: OpenAI’s agentic security researcher"
          url: https://openai.com/index/introducing-aardvark
          summary: OpenAI introduces Aardvark, an AI-powered security researcher that autonomously finds, validates, and helps fix
            software vulnerabilities at scale. The system is in private beta—sign up to join early t
        - title: ChatGPT agent System Card
          url: https://openai.com/index/chatgpt-agent-system-card
          summary: "ChatGPT agent System Card: OpenAI’s agentic model unites research, browser automation, and code tools with
            safeguards under the Preparedness Framework."
        - title: OpenAI o3 and o4-mini System Card
          url: https://openai.com/index/o3-o4-mini-system-card
          summary: OpenAI o3 and OpenAI o4-mini combine state-of-the-art reasoning with full tool capabilities—web browsing,
            Python, image and file analysis, image generation, canvas, automations, file search, and memor
        - title: "PaperBench: Evaluating AI’s Ability to Replicate AI Research"
          url: https://openai.com/index/paperbench
          summary: We introduce PaperBench, a benchmark evaluating the ability of AI agents to replicate state-of-the-art AI
            research.
        - title: Introducing Operator
          url: https://openai.com/index/introducing-operator
          summary: A research preview of an agent that can use its own browser to perform tasks for you. Available to Pro users in
            the U.S.
        - title: Gemini Robotics 1.5 brings AI agents into the physical world
          url: https://deepmind.google/blog/gemini-robotics-15-brings-ai-agents-into-the-physical-world/
          summary: We’re powering an era of physical agents — enabling robots to perceive, plan, think, use tools and act to
            better solve complex, multi-step tasks.
        - title: Our vision for building a universal AI assistant
          url: https://deepmind.google/blog/our-vision-for-building-a-universal-ai-assistant/
          summary: We’re extending Gemini to become a world model that can make plans and imagine new experiences by simulating
            aspects of the world.
        - title: "Last Week in AI #329 - GPT 5.2, GenAI.mil, Disney in Sora"
          url: https://lastweekin.ai/p/last-week-in-ai-329-gpt-52-genaimil
          summary: GPT-5.2 is OpenAI&#8217;s latest move in the agentic AI battle, Google is powering a new US military AI
            platform, Trump Moves to Stop States From Regulating AI
        - title: Optimization Instability in Autonomous Agentic Workflows for Clinical Symptom Detection
          url: https://arxiv.org/abs/2602.16037
          summary: "arXiv:2602.16037v1 Announce Type: new Abstract: Autonomous agentic workflows that iteratively refine their own
            behavior hold considerable promise, yet their failure modes remain poorly characterized. "
        - title: "Toward Scalable Verifiable Reward: Proxy State-Based Evaluation for Multi-turn Tool-Calling LLM Agents"
          url: https://arxiv.org/abs/2602.16246
          summary: "arXiv:2602.16246v1 Announce Type: new Abstract: Interactive large language model (LLM) agents operating via
            multi-turn dialogue and multi-step tool calling are increasingly used in production. Benchma"
        - title: Verifiable Semantics for Agent-to-Agent Communication
          url: https://arxiv.org/abs/2602.16424
          summary: "arXiv:2602.16424v1 Announce Type: new Abstract: Multiagent AI systems require consistent communication, but we
            lack methods to verify that agents share the same understanding of the terms used. Natura"
        - title: "Recursive language models for jailbreak detection: a procedural defense for tool-augmented agents"
          url: https://arxiv.org/abs/2602.16520
          summary: "arXiv:2602.16520v1 Announce Type: cross Abstract: Jailbreak prompts are a practical and evolving threat to
            large language models (LLMs), particularly in agentic systems that execute tools over untrust"
        - title: Policy Compiler for Secure Agentic Systems
          url: https://arxiv.org/abs/2602.16708
          summary: "arXiv:2602.16708v1 Announce Type: cross Abstract: LLM-based agents are increasingly being deployed in contexts
            requiring complex authorization policies: customer service protocols, approval workflows,"
        - title: "Helpful to a Fault: Measuring Illicit Assistance in Multi-Turn, Multilingual LLM Agents"
          url: https://arxiv.org/abs/2602.16346
          summary: "arXiv:2602.16346v1 Announce Type: new Abstract: LLM-based agents execute real-world workflows via tools and
            memory. These affordances enable ill-intended adversaries to also use these agents to carry "
        - title: "Calibrate-Then-Act: Cost-Aware Exploration in LLM Agents"
          url: https://arxiv.org/abs/2602.16699
          summary: "arXiv:2602.16699v1 Announce Type: cross Abstract: LLMs are increasingly being used for complex problems which
            are not necessarily resolved in a single response, but require interacting with an environ"
        - title: GPT-5.3-Codex System Card
          url: https://openai.com/index/gpt-5-3-codex-system-card
          summary: GPT‑5.3-Codex is the most capable agentic coding model to date, combining the frontier coding performance of
            GPT‑5.2-Codex with the reasoning and professional knowledge capabilities of GPT‑5.2.
        - title: OpenAI co-founds Agentic AI Foundation, donates AGENTS.md
          url: https://openai.com/index/agentic-ai-foundation
          summary: OpenAI co-founds the Agentic AI Foundation under the Linux Foundation and donates AGENTS.md to support open,
            interoperable standards for safe agentic AI.
        - title: "Notion’s rebuild for agentic AI: How GPT‑5 helped unlock autonomous workflows"
          url: https://openai.com/index/notion
          summary: Discover how Notion rebuilt its AI architecture with GPT-5 to create autonomous agents that reason, act, and
            adapt across workflows. Learn how this shift unlocked smarter, faster, and more flexible pr
        - title: Introducing ChatGPT agent
          url: https://openai.com/index/introducing-chatgpt-agent
          summary: "Introducing ChatGPT agent: it thinks and acts, using tools to complete tasks like research, bookings, and
            slideshows—all with your guidance."
        - title: Introducing OpenAI o3 and o4-mini
          url: https://openai.com/index/introducing-o3-and-o4-mini
          summary: Our smartest and most capable models to date with full tool access
        - title: "BrowseComp: a benchmark for browsing agents"
          url: https://openai.com/index/browsecomp
          summary: "BrowseComp: a benchmark for browsing agents."
        - title: Computer-Using Agent
          url: https://openai.com/index/computer-using-agent
          summary: A universal interface for AI to interact with the digital world.
        - title: Solving complex problems with OpenAI o1 models
          url: https://openai.com/business/solving-complex-problems-with-openai-o1-models
          summary: In this video, we share how the o1 reasoning models can help in domains like coding, strategy, and research.
        - title: "MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering"
          url: https://openai.com/index/mle-bench
          summary: We introduce MLE-bench, a benchmark for measuring how well AI agents perform at machine learning engineering.
        - title: "SIMA 2: An Agent that Plays, Reasons, and Learns With You in Virtual 3D Worlds"
          url: https://deepmind.google/blog/sima-2-an-agent-that-plays-reasons-and-learns-with-you-in-virtual-3d-worlds/
          summary: Introducing SIMA 2, a Gemini-powered AI agent that can think, understand, and take actions in interactive
            environments.
        - title: Gemini Robotics On-Device brings AI to local robotic devices
          url: https://deepmind.google/blog/gemini-robotics-on-device-brings-ai-to-local-robotic-devices/
          summary: We’re introducing an efficient, on-device robotics model with general-purpose dexterity and fast task
            adaptation.
        - title: "AlphaEvolve: A Gemini-powered coding agent for designing advanced algorithms"
          url: https://deepmind.google/blog/alphaevolve-a-gemini-powered-coding-agent-for-designing-advanced-algorithms/
          summary: New AI agent evolves algorithms for math and practical applications in computing by combining the creativity of
            large language models with automated evaluators
        - title: Gemini Robotics brings AI into the physical world
          url: https://deepmind.google/blog/gemini-robotics-brings-ai-into-the-physical-world/
          summary: Introducing Gemini Robotics and Gemini Robotics-ER, AI models designed for robots to understand, act and react
            to the physical world.
        - title: "LWiAI Podcast #228 - GPT 5.2, Scaling Agents, Weird Generalization"
          url: https://lastweekin.ai/p/lwiai-podcast-228-gpt-52-scaling
          summary: GPT-5.2 is OpenAI&#8217;s latest move in the agentic AI battle, Towards a Science of Scaling Agent Systems, and
            more!
        - title: Learning Personalized Agents from Human Feedback
          url: https://arxiv.org/abs/2602.16173
          summary: "arXiv:2602.16173v1 Announce Type: new Abstract: Modern AI agents are powerful but often fail to align with the
            idiosyncratic, evolving preferences of individual users. Prior approaches typically rely "
        - title: Multi-agent cooperation through in-context co-player inference
          url: https://arxiv.org/abs/2602.16301
          summary: "arXiv:2602.16301v1 Announce Type: new Abstract: Achieving cooperation among self-interested agents remains a
            fundamental challenge in multi-agent reinforcement learning. Recent work showed that mutual"
        - title: "CaveAgent: Transforming LLMs into Stateful Runtime Operators"
          url: https://arxiv.org/abs/2601.01569
          summary: "arXiv:2601.01569v2 Announce Type: replace Abstract: LLM-based agents are increasingly capable of complex task
            execution, yet current agentic systems remain constrained by text-centric paradigms that s"
        - title: "AgentNoiseBench: Benchmarking Robustness of Tool-Using LLM Agents Under Noisy Condition"
          url: https://arxiv.org/abs/2602.11348
          summary: "arXiv:2602.11348v2 Announce Type: replace Abstract: Recent advances in large language models have enabled
            LLM-based agents to achieve strong performance on a variety of benchmarks. However, their perf"
        - title: "Cocoa: Co-Planning and Co-Execution with AI Agents"
          url: https://arxiv.org/abs/2412.10999
          summary: "arXiv:2412.10999v4 Announce Type: replace-cross Abstract: As AI agents take on increasingly long-running tasks
            involving sophisticated planning and execution, there is a corresponding need for novel i"
        - title: "EconEvals: Benchmarks and Litmus Tests for Economic Decision-Making by LLM Agents"
          url: https://arxiv.org/abs/2503.18825
          summary: "arXiv:2503.18825v4 Announce Type: replace Abstract: We develop evaluation methods for measuring the economic
            decision-making capabilities and tendencies of LLMs. First, we develop benchmarks derived f"
        - title: Rethinking the Role of Entropy in Optimizing Tool-Use Behaviors for Large Language Model Agents
          url: https://arxiv.org/abs/2602.02050
          summary: "arXiv:2602.02050v2 Announce Type: replace Abstract: Tool-using agents based on Large Language Models (LLMs)
            excel in tasks such as mathematical reasoning and multi-hop question answering. However, in "
        - title: Evaluating Language Model Agency through Negotiations
          url: https://arxiv.org/abs/2401.04536
          summary: "arXiv:2401.04536v3 Announce Type: replace-cross Abstract: We introduce an approach to evaluate language model
            (LM) agency using negotiation games. This approach better reflects real-world use cases an"
        - title: Introducing GPT-5.3-Codex
          url: https://openai.com/index/introducing-gpt-5-3-codex
          summary: GPT-5.3-Codex is a Codex-native agent that pairs frontier coding performance with general reasoning to support
            long-horizon, real-world technical work.
        - title: Introducing AgentKit, new Evals, and RFT for agents
          url: https://openai.com/index/introducing-agentkit
          summary: "Today, we’re releasing new tools to help developers go from prototype to production faster: AgentKit, expanded
            evals capabilities, and reinforcement fine-tuning for agents."
        - title: Moving from intent-based bots to proactive AI agents
          url: https://openai.com/index/zendesk
          summary: Moving from intent-based bots to proactive AI agents.
        - title: Introducing deep research
          url: https://openai.com/index/introducing-deep-research
          summary: An agent that uses reasoning to synthesize large amounts of online information and complete multi-step research
            tasks for you. Available to Pro users today, Plus and Team next.
        - title: ChatGPT plugins
          url: https://openai.com/index/chatgpt-plugins
          summary: We’ve implemented initial support for plugins in ChatGPT. Plugins are tools designed specifically for language
            models with safety as a core principle, and help ChatGPT access up-to-date information, r
        - title: Learning to cooperate, compete, and communicate
          url: https://openai.com/index/learning-to-cooperate-compete-and-communicate
          summary: "Multiagent environments where agents compete for resources are stepping stones on the path to AGI. Multiagent
            environments have two useful properties: first, there is a natural curriculum—the difficul"
        - title: Google DeepMind at NeurIPS 2024
          url: https://deepmind.google/blog/google-deepmind-at-neurips-2024/
          summary: Advancing adaptive AI agents, empowering 3D scene creation, and innovating LLM training for a smarter, safer
            future
        - title: "LWiAI Podcast #231 - Claude Cowork, Anthropic $10B, Deep Delta Learning"
          url: https://lastweekin.ai/p/lwiai-podcast-231-claude-cowork-anthropic
          summary: Anthropic&#8217;s new Cowork tool, Anthropic Raising $10 Billion at $350 Billion Value, Deep Delta Learning
        - title: "EnterpriseGym Corecraft: Training Generalizable Agents on High-Fidelity RL Environments"
          url: https://arxiv.org/abs/2602.16179
          summary: "arXiv:2602.16179v1 Announce Type: new Abstract: We show that training AI agents on high-fidelity reinforcement
            learning environments produces capabilities that generalize beyond the training distribut"
        - title: Towards a Science of AI Agent Reliability
          url: https://arxiv.org/abs/2602.16666
          summary: "arXiv:2602.16666v1 Announce Type: new Abstract: AI agents are increasingly deployed to execute important
            tasks. While rising accuracy scores on standard benchmarks suggest rapid progress, many agents "
        - title: "ReLoop: Structured Modeling and Behavioral Verification for Reliable LLM-Based Optimization"
          url: https://arxiv.org/abs/2602.15983
          summary: "arXiv:2602.15983v1 Announce Type: cross Abstract: Large language models (LLMs) can translate natural language
            into optimization code, but silent failures pose a critical risk: code that executes and r"
        - title: Graph Representation-based Model Poisoning on the Heterogeneous Internet of Agents
          url: https://arxiv.org/abs/2511.07176
          summary: "arXiv:2511.07176v2 Announce Type: replace-cross Abstract: Internet of Agents (IoA) envisions a unified,
            agent-centric paradigm where heterogeneous large language model (LLM) agents can interconnect an"
        - title: "Language and Experience: A Computational Model of Social Learning in Complex Tasks"
          url: https://arxiv.org/abs/2509.00074
          summary: "arXiv:2509.00074v2 Announce Type: replace Abstract: The ability to combine linguistic guidance from others
            with direct experience is central to human development, enabling safe and rapid learning in n"
        - title: Introducing OpenAI Frontier
          url: https://openai.com/index/introducing-openai-frontier
          summary: OpenAI Frontier is an enterprise platform for building, deploying, and managing AI agents with shared context,
            onboarding, permissions, and governance.
        - title: Unrolling the Codex agent loop
          url: https://openai.com/index/unrolling-the-codex-agent-loop
          summary: A technical deep dive into the Codex agent loop, explaining how Codex CLI orchestrates models, tools, prompts,
            and performance using the Responses API.
        - title: Netomi’s lessons for scaling agentic systems into the enterprise
          url: https://openai.com/index/netomi
          summary: How Netomi scales enterprise AI agents using GPT-4.1 and GPT-5.2—combining concurrency, governance, and
            multi-step reasoning for reliable production workflows.
        - title: "Neural MMO: A massively multiagent game environment"
          url: https://openai.com/index/neural-mmo
          summary: We’re releasing a Neural MMO, a massively multiagent game environment for reinforcement learning agents. Our
            platform supports a large, variable number of agents within a persistent and open-ended tas
        - title: Learning to model other minds
          url: https://openai.com/index/learning-to-model-other-minds
          summary: We’re releasing an algorithm which accounts for the fact that other agents are learning too, and discovers
            self-interested yet collaborative strategies like tit-for-tat in the iterated prisoner’s dile
        - title: "Genie 2: A large-scale foundation world model"
          url: https://deepmind.google/blog/genie-2-a-large-scale-foundation-world-model/
          summary: Generating unlimited diverse training environments for future general agents
        - title: "SEISMO: Increasing Sample Efficiency in Molecular Optimization with a Trajectory-Aware LLM Agent"
          url: https://arxiv.org/abs/2602.00663
          summary: "arXiv:2602.00663v2 Announce Type: replace Abstract: Optimizing the structure of molecules to achieve desired
            properties is a central bottleneck across the chemical sciences, particularly in the pharma"
        - title: Does Socialization Emerge in AI Agent Society? A Case Study of Moltbook
          url: https://arxiv.org/abs/2602.14299
          summary: "arXiv:2602.14299v2 Announce Type: replace-cross Abstract: As large language model agents increasingly populate
            networked environments, a fundamental question arises: do artificial intelligence (AI) ag"
        - title: "MemoryArena: Benchmarking Agent Memory in Interdependent Multi-Session Agentic Tasks"
          url: https://arxiv.org/abs/2602.16313
          summary: "arXiv:2602.16313v1 Announce Type: new Abstract: Existing evaluations of agents with memory typically assess
            memorization and action in isolation. One class of benchmarks evaluates memorization by test"
        - title: "CAST: Character-and-Scene Episodic Memory for Agents"
          url: https://arxiv.org/abs/2602.06051
          summary: "arXiv:2602.06051v3 Announce Type: replace Abstract: Episodic memory is a central component of human memory,
            which refers to the ability to recall coherent events grounded in who, when, and where. Howe"
        - title: Empirical Cumulative Distribution Function Clustering for LLM-based Agent System Analysis
          url: https://arxiv.org/abs/2602.16131
          summary: "arXiv:2602.16131v1 Announce Type: cross Abstract: Large language models (LLMs) are increasingly used as agents
            to solve complex tasks such as question answering (QA), scientific debate, and software d"
        - title: Introducing GPT-5.3-Codex-Spark
          url: https://openai.com/index/introducing-gpt-5-3-codex-spark
          summary: Introducing GPT-5.3-Codex-Spark—our first real-time coding model. 15x faster generation, 128k context, now in
            research preview for ChatGPT Pro users.
        - title: "Unlocking the Codex harness: how we built the App Server"
          url: https://openai.com/index/unlocking-the-codex-harness
          summary: Learn how to embed the Codex agent using the Codex App Server, a bidirectional JSON-RPC API powering streaming
            progress, tool use, approvals, and diffs.
        - title: Inside OpenAI’s in-house data agent
          url: https://openai.com/index/inside-our-in-house-data-agent
          summary: How OpenAI built an in-house AI data agent that uses GPT-5, Codex, and memory to reason over massive datasets
            and deliver reliable insights in minutes.
        - title: Cisco and OpenAI redefine enterprise engineering with AI agents
          url: https://openai.com/index/cisco
          summary: Cisco and OpenAI redefine enterprise engineering with Codex, an AI software agent embedded in workflows to
            speed builds, automate defect fixes, and enable AI-native development.
        - title: How we built OWL, the new architecture behind our ChatGPT-based browser, Atlas
          url: https://openai.com/index/building-chatgpt-atlas
          summary: A deep dive into OWL, the new architecture powering ChatGPT Atlas—decoupling Chromium, enabling fast startup,
            rich UI, and agentic browsing with ChatGPT.
        - title: Introducing Codex
          url: https://openai.com/index/introducing-codex
          summary: "Introducing Codex: a cloud-based software engineering agent that can work on many tasks in parallel, powered
            by codex-1. With Codex, developers can simultaneously deploy multiple agents to independent"
        - title: Understanding complex trends with deep research
          url: https://openai.com/index/deep-research
          summary: How OpenAI deep research helps Bain & Company understand complex industry trends.
        - title: Learning policy representations in multiagent systems
          url: https://openai.com/index/learning-policy-representations-in-multiagent-systems
          summary: ""
        - title: Competitive self-play
          url: https://openai.com/index/competitive-self-play
          summary: We’ve found that self-play allows simulated AIs to discover physical skills like tackling, ducking, faking,
            kicking, catching, and diving for the ball, without explicitly designing an environment with
        - title: Learning with opponent-learning awareness
          url: https://openai.com/index/learning-with-opponent-learning-awareness
          summary: ""
        - title: "Revolutionizing Long-Term Memory in AI: New Horizons with High-Capacity and High-Speed Storage"
          url: https://arxiv.org/abs/2602.16192
          summary: 'arXiv:2602.16192v1 Announce Type: new Abstract: Driven by our mission of "uplifting the world with memory,"
            this paper explores the design concept of "memory" that is essential for achieving artificia'
        - title: "From Tool Orchestration to Code Execution: A Study of MCP Design Choices"
          url: https://arxiv.org/abs/2602.15945
          summary: "arXiv:2602.15945v1 Announce Type: cross Abstract: Model Context Protocols (MCPs) provide a unified platform
            for agent systems to discover, select, and orchestrate tools across heterogeneous execution "
        - title: "HiPER: Hierarchical Reinforcement Learning with Explicit Credit Assignment for Large Language Model Agents"
          url: https://arxiv.org/abs/2602.16165
          summary: "arXiv:2602.16165v1 Announce Type: cross Abstract: Training LLMs as interactive agents for multi-turn
            decision-making remains challenging, particularly in long-horizon tasks with sparse and delayed rew"
        - title: "Team of Thoughts: Efficient Test-time Scaling of Agentic Systems through Orchestrated Tool Calling"
          url: https://arxiv.org/abs/2602.16485
          summary: "arXiv:2602.16485v1 Announce Type: cross Abstract: Existing Multi-Agent Systems (MAS) typically rely on static,
            homogeneous model configurations, limiting their ability to exploit the distinct strength"
        - title: "DIAGPaper: Diagnosing Valid and Specific Weaknesses in Scientific Papers via Multi-Agent Reasoning"
          url: https://arxiv.org/abs/2601.07611
          summary: "arXiv:2601.07611v2 Announce Type: replace Abstract: Paper weakness identification using single-agent or
            multi-agent LLMs has attracted increasing attention, yet existing approaches exhibit key limitat"
        - title: "From Pixels to Policies: Reinforcing Spatial Reasoning in Language Models for Content-Aware Layout Design"
          url: https://arxiv.org/abs/2602.13912
          summary: "arXiv:2602.13912v2 Announce Type: replace Abstract: We introduce LaySPA, a reinforcement learning framework
            that equips large language models (LLMs) with explicit and interpretable spatial reasoning f"
        - title: "PLAICraft: Large-Scale Time-Aligned Vision-Speech-Action Dataset for Embodied AI"
          url: https://arxiv.org/abs/2505.12707
          summary: "arXiv:2505.12707v2 Announce Type: replace-cross Abstract: Advances in deep generative modeling have made it
            increasingly plausible to train human-level embodied agents. Yet progress has been limited b"
        - title: "Harness engineering: leveraging Codex in an agent-first world"
          url: https://openai.com/index/harness-engineering
          summary: By Ryan Lopopolo, Member of the Technical Staff
        - title: Introducing the Codex app
          url: https://openai.com/index/introducing-the-codex-app
          summary: Introducing the Codex app for macOS—a command center for AI coding and software development with multiple
            agents, parallel workflows, and long-running tasks.
        - title: Datadog uses Codex for system-level code review
          url: https://openai.com/index/datadog
          summary: OpenAI and Datadog brand graphic with the OpenAI wordmark on the left, the Datadog logo on the right, and a
            central abstract brown fur-like texture panel on a white background.
        - title: Scaling accounting capacity with OpenAI
          url: https://openai.com/index/basis
          summary: Built with OpenAI o3, o3-Pro, GPT-4.1, and GPT-5, Basis’ AI agents help accounting firms save up to 30% of
            their time and expand capacity for advisory and growth.
        - title: "Addendum to OpenAI o3 and o4-mini system card: OpenAI o3 Operator"
          url: https://openai.com/index/o3-o4-mini-system-card-addendum-operator-o3
          summary: We are replacing the existing GPT-4o-based model for Operator with a version based on OpenAI o3. The API
            version will remain based on 4o.
        - title: "Addendum to o3 and o4-mini system card: Codex"
          url: https://openai.com/index/o3-o4-mini-codex-system-card-addendum
          summary: Codex is a cloud-based coding agent. Codex is powered by codex-1, a version of OpenAI o3 optimized for software
            engineering. codex-1 was trained using reinforcement learning on real-world coding tasks
        - title: Introducing the SWE-Lancer benchmark
          url: https://openai.com/index/swe-lancer
          summary: Can frontier LLMs earn $1 million from real-world freelance software engineering?
        - title: Meta-learning for wrestling
          url: https://openai.com/index/meta-learning-for-wrestling
          summary: We show that for the task of simulated robot wrestling, a meta-learning agent can learn to quickly defeat a
            stronger non-meta-learning agent, and also show that the meta-learning agent can adapt to ph
        - title: "Introducing Gemini 2.0: our new AI model for the agentic era"
          url: https://deepmind.google/blog/introducing-gemini-20-our-new-ai-model-for-the-agentic-era/
          summary: Today, we’re announcing Gemini 2.0, our most capable multimodal AI model yet.
        - title: "Last Week in AI #334 - Kimi K2.5 & Code, Genie 3, OpenClaw & Moltbook"
          url: https://lastweekin.ai/p/last-week-in-ai-334-kimi-k25-and
          summary: China&#8217;s Moonshot releases a new open source model Kimi K2.5 and a coding agent, Google Brings Genie
            3&#8217;s Interactive World-Building Prototype to AI Ultra Subscribers, and more!
        - title: Improving Interactive In-Context Learning from Natural Language Feedback
          url: https://arxiv.org/abs/2602.16066
          summary: "arXiv:2602.16066v1 Announce Type: new Abstract: Adapting one's thought process based on corrective feedback is
            an essential ability in human learning, particularly in collaborative settings. In contra"
        - title: "Agent Skill Framework: Perspectives on the Potential of Small Language Models in Industrial Environments"
          url: https://arxiv.org/abs/2602.16653
          summary: "arXiv:2602.16653v1 Announce Type: new Abstract: Agent Skill framework, now widely and officially supported by
            major players such as GitHub Copilot, LangChain, and OpenAI, performs especially well with"
        - title: "State Design Matters: How Representations Shape Dynamic Reasoning in Large Language Models"
          url: https://arxiv.org/abs/2602.15858
          summary: "arXiv:2602.15858v1 Announce Type: cross Abstract: As large language models (LLMs) move from static reasoning
            tasks toward dynamic environments, their success depends on the ability to navigate and res"
        - title: "DataJoint 2.0: A Computational Substrate for Agentic Scientific Workflows"
          url: https://arxiv.org/abs/2602.16585
          summary: "arXiv:2602.16585v1 Announce Type: cross Abstract: Operational rigor determines whether human-agent
            collaboration succeeds or fails. Scientific data pipelines need the equivalent of DevOps -- SciOps --"
        - title: Large Language Models for Water Distribution Systems Modeling and Decision-Making
          url: https://arxiv.org/abs/2503.16191
          summary: "arXiv:2503.16191v2 Announce Type: replace Abstract: The integration of Large Language Models (LLMs) into
            engineering workflows presents new opportunities for making computational tools more accessible"
        - title: "RoboSpatial: Teaching Spatial Understanding to 2D and 3D Vision-Language Models for Robotics"
          url: https://arxiv.org/abs/2411.16537
          summary: "arXiv:2411.16537v5 Announce Type: replace-cross Abstract: Spatial understanding is a crucial capability that
            enables robots to perceive their surroundings, reason about their environment, and interact"
        - title: Experience-based Knowledge Correction for Robust Planning in Minecraft
          url: https://arxiv.org/abs/2505.24157
          summary: "arXiv:2505.24157v3 Announce Type: replace-cross Abstract: Large Language Model (LLM)-based planning has
            advanced embodied agents in long-horizon environments such as Minecraft, where acquiring latent "
        - title: "From Transcripts to AI Agents: Knowledge Extraction, RAG Integration, and Robust Evaluation of Conversational AI
            Assistants"
          url: https://arxiv.org/abs/2602.15859
          summary: "arXiv:2602.15859v1 Announce Type: new Abstract: Building reliable conversational AI assistants for
            customer-facing industries remains challenging due to noisy conversational data, fragmented knowledge"
        - title: "TabAgent: A Framework for Replacing Agentic Generative Components with Tabular-Textual Classifiers"
          url: https://arxiv.org/abs/2602.16429
          summary: "arXiv:2602.16429v1 Announce Type: new Abstract: Agentic systems, AI architectures that autonomously execute
            multi-step workflows to achieve complex goals, are often built using repeated large language"
        - title: Snowflake and OpenAI partner to bring frontier intelligence to enterprise data
          url: https://openai.com/index/snowflake-partnership
          summary: OpenAI and Snowflake partner in a $200M agreement to bring frontier intelligence into enterprise data, enabling
            AI agents and insights directly in Snowflake.
        - title: "Addendum to GPT-5 system card: GPT-5-Codex"
          url: https://openai.com/index/gpt-5-system-card-addendum-gpt-5-codex
          summary: "This addendum to the GPT-5 system card shares a new model: GPT-5-Codex, a version of GPT-5 further optimized
            for agentic coding in Codex. GPT-5-Codex adjusts its thinking effort more dynamically based"
        - title: No-code personal agents, powered by GPT-4.1 and Realtime API
          url: https://openai.com/index/genspark
          summary: Learn how Genspark built a $36M ARR AI product in 45 days—with no-code agents powered by GPT-4.1 and OpenAI
            Realtime API.
        - title: New tools and features in the Responses API
          url: https://openai.com/index/new-tools-and-features-in-the-responses-api
          summary: "New features in the Responses API: Remote MCP, image gen, Code Interpreter, and more. Powering faster, smarter
            agents with GPT-4o & o-series models, plus new features for reliability and efficiency."
        - title: New tools for building agents
          url: https://openai.com/index/new-tools-for-building-agents
          summary: We’re evolving our platform to help developers and enterprises build useful and reliable agents.
        - title: Creating agent and human collaboration with GPT 4o
          url: https://openai.com/index/altera
          summary: Altera uses GPT-4o to build a new area of human collaboration
        - title: Achieving 10x growth with agentic sales prospecting
          url: https://openai.com/index/clay
          summary: ""
        - title: Learning to communicate
          url: https://openai.com/index/learning-to-communicate
          summary: In this post we’ll outline new OpenAI research in which agents develop their own language.
        - title: Emergence of grounded compositional language in multi-agent populations
          url: https://openai.com/index/emergence-of-grounded-compositional-language-in-multi-agent-populations
          summary: ""
        - title: Our latest advances in robot dexterity
          url: https://deepmind.google/blog/advances-in-robot-dexterity/
          summary: Two new AI systems, ALOHA Unleashed and DemoStart, help robots learn to perform complex tasks that require
            dexterous movement
        - title: "LWiAI Podcast #233 - Moltbot, Genie 3, Qwen3-Max-Thinking"
          url: https://lastweekin.ai/p/lwiai-podcast-233-moltbot-genie-3
          summary: Google adds Gemini AI-powered &#8216;auto browse&#8217; to Chrome, Users flock to open source Moltbot for
            always-on AI, Qwen3-Max-Thinking debuts, and more!
        - title: Kalman-Inspired Runtime Stability and Recovery in Hybrid Reasoning Systems
          url: https://arxiv.org/abs/2602.15855
          summary: "arXiv:2602.15855v1 Announce Type: cross Abstract: Hybrid reasoning systems that combine learned components
            with model-based inference are increasingly deployed in tool-augmented decision loops, yet th"
        - title: "RoboGene: Boosting VLA Pre-training via Diversity-Driven Agentic Framework for Real-World Task Generation"
          url: https://arxiv.org/abs/2602.16444
          summary: "arXiv:2602.16444v1 Announce Type: cross Abstract: The pursuit of general-purpose robotic manipulation is
            hindered by the scarcity of diverse, real-world interaction data. Unlike data collection from w"
        - title: "MerLean: An Agentic Framework for Autoformalization in Quantum Computation"
          url: https://arxiv.org/abs/2602.16554
          summary: "arXiv:2602.16554v1 Announce Type: cross Abstract: We introduce MerLean, a fully automated agentic framework
            for autoformalization in quantum computation. MerLean extracts mathematical statements from "
        - title: "SurgRAW: Multi-Agent Workflow with Chain of Thought Reasoning for Robotic Surgical Video Analysis"
          url: https://arxiv.org/abs/2503.10265
          summary: "arXiv:2503.10265v2 Announce Type: replace Abstract: Robotic-assisted surgery (RAS) is central to modern
            surgery, driving the need for intelligent systems with accurate scene understanding. Most existi"
        - title: "BPP: Long-Context Robot Imitation Learning by Focusing on Key History Frames"
          url: https://arxiv.org/abs/2602.15010
          summary: "arXiv:2602.15010v2 Announce Type: replace-cross Abstract: Many robot tasks require attending to the history of
            past observations. For example, finding an item in a room requires remembering which plac"
        - title: ServiceNow powers actionable enterprise AI with OpenAI
          url: https://openai.com/index/servicenow-powers-actionable-enterprise-ai-with-openai
          summary: ServiceNow expands access to OpenAI frontier models to power AI-driven enterprise workflows, summarization,
            search, and voice across the ServiceNow Platform.
        - title: BNY builds “AI for everyone, everywhere” with OpenAI
          url: https://openai.com/index/bny
          summary: BNY is using OpenAI technology to expand AI adoption enterprise-wide. Through its Eliza platform, 20,000+
            employees are building AI agents that enhance efficiency and improve client outcomes.
        - title: Consensus accelerates research with GPT-5 and Responses API
          url: https://openai.com/index/consensus
          summary: Consensus uses GPT-5 and OpenAI’s Responses API to power a multi-agent research assistant that reads, analyzes,
            and synthesizes evidence in minutes—helping over 8 million researchers accelerate scient
        - title: Introducing apps in ChatGPT and the new Apps SDK
          url: https://openai.com/index/introducing-apps-in-chatgpt
          summary: We’re introducing a new generation of apps you can chat with, right inside ChatGPT. Developers can start
            building them today with the new Apps SDK, available in preview.
        - title: Resolving digital threats 100x faster with OpenAI
          url: https://openai.com/index/outtake
          summary: Discover how Outtake uses GPT-4.1 and OpenAI o3 to power AI agents that detect and resolve digital threats 100x
            faster than before.
        - title: Customizable, no-code voice agent automation with GPT-4o
          url: https://openai.com/index/retell-ai
          summary: Retell AI is transforming the call center with AI voice automation powered by GPT-4o and GPT-4.1. Its no-code
            platform enables businesses to launch natural, real-time voice agents that cut call costs,
        - title: Driving scalable growth with OpenAI o3, GPT-4.1, and CUA
          url: https://openai.com/index/unify
          summary: Unify, an AI-powered GTM platform, uses OpenAI’s o3, GPT-4.1, and CUA to automate prospecting, research, and
            outreach. With hyper-personalized messaging and an always-on workflow, Unify helps teams ge
        - title: Automating 90% of finance and legal work with agents
          url: https://openai.com/index/hebbia
          summary: Hebbia’s deep research automates 90% of finance and legal work, powered by OpenAI
        - title: Automating customer support agents
          url: https://openai.com/index/mavenagi
          summary: MavenAGI is a new software company for the AI era. They recently launched an AI customer service agent, built
            on the flexibility of GPT-4, which a number of companies like Tripadvisor, Clickup and Rho
        - title: Label-Consistent Data Generation for Aspect-Based Sentiment Analysis Using LLM Agents
          url: https://arxiv.org/abs/2602.16379
          summary: "arXiv:2602.16379v1 Announce Type: new Abstract: We propose an agentic data augmentation method for
            Aspect-Based Sentiment Analysis (ABSA) that uses iterative generation and verification to produce hig"
        - title: Model ML is helping financial firms rebuild with AI from the ground up
          url: https://openai.com/index/model-ml-chaz-englander
          summary: As part of our Executive Function series, Model ML CEO Chaz Englander discusses how AI-native infrastructure
            and autonomous agents are transforming financial services workflows.
        - title: Building an autonomous financial analyst with o1 and o3-mini
          url: https://openai.com/index/endex
          summary: Endex builds the future of financial analysis, powered by OpenAI’s reasoning models.
        - title: Towards Efficient Constraint Handling in Neural Solvers for Routing Problems
          url: https://arxiv.org/abs/2602.16012
          summary: "arXiv:2602.16012v1 Announce Type: new Abstract: Neural solvers have achieved impressive progress in addressing
            simple routing problems, particularly excelling in computational efficiency. However, the"
        - title: Causally-Guided Automated Feature Engineering with Multi-Agent Reinforcement Learning
          url: https://arxiv.org/abs/2602.16435
          summary: "arXiv:2602.16435v1 Announce Type: new Abstract: Automated feature engineering (AFE) enables AI systems to
            autonomously construct high-utility representations from raw tabular data. However, existing A"
        - title: "Fly0: Decoupling Semantic Grounding from Geometric Planning for Zero-Shot Aerial Navigation"
          url: https://arxiv.org/abs/2602.15875
          summary: "arXiv:2602.15875v1 Announce Type: cross Abstract: Current Visual-Language Navigation (VLN) methodologies face
            a trade-off between semantic understanding and control precision. While Multimodal Large L"
        - title: Federated Graph AGI for Cross-Border Insider Threat Intelligence in Government Financial Schemes
          url: https://arxiv.org/abs/2602.16109
          summary: "arXiv:2602.16109v1 Announce Type: cross Abstract: Cross-border insider threats pose a critical challenge to
            government financial schemes, particularly when dealing with distributed, privacy-sensitive "
        - title: Graphon Mean-Field Subsampling for Cooperative Heterogeneous Multi-Agent Reinforcement Learning
          url: https://arxiv.org/abs/2602.16196
          summary: "arXiv:2602.16196v1 Announce Type: cross Abstract: Coordinating large populations of interacting agents is a
            central challenge in multi-agent reinforcement learning (MARL), where the size of the joint "
        - title: "FindAnything: Open-Vocabulary and Object-Centric Mapping for Robot Exploration in Any Environment"
          url: https://arxiv.org/abs/2504.08603
          summary: "arXiv:2504.08603v3 Announce Type: replace-cross Abstract: Geometrically accurate and semantically expressive
            map representations have proven invaluable for robot deployment and task planning in unknow"
        - title: "FreqPolicy: Efficient Flow-based Visuomotor Policy via Frequency Consistency"
          url: https://arxiv.org/abs/2506.08822
          summary: "arXiv:2506.08822v2 Announce Type: replace-cross Abstract: Generative modeling-based visuomotor policies have
            been widely adopted in robotic manipulation, attributed to their ability to model multimoda"
        - title: World Action Models are Zero-shot Policies
          url: https://arxiv.org/abs/2602.15922
          summary: "arXiv:2602.15922v1 Announce Type: cross Abstract: State-of-the-art Vision-Language-Action (VLA) models excel
            at semantic generalization but struggle to generalize to unseen physical motions in novel e"
        - title: "Learning Distributed Equilibria in Linear-Quadratic Stochastic Differential Games: An $\\alpha$-Potential
            Approach"
          url: https://arxiv.org/abs/2602.16555
          summary: "arXiv:2602.16555v1 Announce Type: cross Abstract: We analyze independent policy-gradient (PG) learning in
            $N$-player linear-quadratic (LQ) stochastic differential games. Each player employs a distribu"
        - title: "Buy it in ChatGPT: Instant Checkout and the Agentic Commerce Protocol"
          url: https://openai.com/index/buy-it-in-chatgpt
          summary: We’re taking first steps toward agentic commerce in ChatGPT with new ways for people, AI agents, and businesses
            to shop together.
        - title: "EdgeNav-QE: QLoRA Quantization and Dynamic Early Exit for LAM-based Navigation on Edge Devices"
          url: https://arxiv.org/abs/2602.15836
          summary: "arXiv:2602.15836v1 Announce Type: cross Abstract: Large Action Models (LAMs) have shown immense potential in
            autonomous navigation by bridging high-level reasoning with low-level control. However, dep"
        - title: "SPARC: Scenario Planning and Reasoning for Automated C Unit Test Generation"
          url: https://arxiv.org/abs/2602.16671
          summary: "arXiv:2602.16671v1 Announce Type: cross Abstract: Automated unit test generation for C remains a formidable
            challenge due to the semantic gap between high-level program intent and the rigid syntactic "
        - title: Learning to Drive in New Cities Without Human Demonstrations
          url: https://arxiv.org/abs/2602.15891
          summary: "arXiv:2602.15891v1 Announce Type: cross Abstract: While autonomous vehicles have achieved reliable performance
            within specific operating regions, their deployment to new cities remains costly and slow"
        - title: Multi-Agent Combinatorial-Multi-Armed-Bandit framework for the Submodular Welfare Problem under Bandit Feedback
          url: https://arxiv.org/abs/2602.16183
          summary: "arXiv:2602.16183v1 Announce Type: cross Abstract: We study the \\emph{Submodular Welfare Problem} (SWP), where
            items are partitioned among agents with monotone submodular utilities to maximize the tota"
        - title: Powering tax donations with AI powered personalized recommendations
          url: https://openai.com/index/trustbank
          summary: TRUSTBANK partnered with Recursive to build Choice AI using OpenAI models, delivering personalized,
            conversational recommendations that simplify Furusato Nozei gift discovery. A multi-agent system hel
        - title: "New in ChatGPT for Business: March 2025"
          url: https://openai.com/business/new-in-chatgpt-for-work-march-updates-2025
          summary: Join us as we share our latest releases and how ChatGPT is becoming more interactive, customized to the way
            your teams work, and agentic.
        - title: "Resp-Agent: An Agent-Based System for Multimodal Respiratory Sound Generation and Disease Diagnosis"
          url: https://arxiv.org/abs/2602.15909
          summary: "arXiv:2602.15909v1 Announce Type: cross Abstract: Deep learning-based respiratory auscultation is currently
            hindered by two fundamental challenges: (i) inherent information loss, as converting signals"
        - title: Articulated 3D Scene Graphs for Open-World Mobile Manipulation
          url: https://arxiv.org/abs/2602.16356
          summary: "arXiv:2602.16356v1 Announce Type: cross Abstract: Semantics has enabled 3D scene understanding and
            affordance-driven object interaction. However, robots operating in real-world environments face a cri"
        - title: "MARVL: Multi-Stage Guidance for Robotic Manipulation via Vision-Language Models"
          url: https://arxiv.org/abs/2602.15872
          summary: "arXiv:2602.15872v1 Announce Type: cross Abstract: Designing dense reward functions is pivotal for efficient
            robotic Reinforcement Learning (RL). However, most dense rewards rely on manual engineering,"
        - title: "Harnessing Implicit Cooperation: A Multi-Agent Reinforcement Learning Approach Towards Decentralized Local
            Energy Markets"
          url: https://arxiv.org/abs/2602.16062
          summary: "arXiv:2602.16062v1 Announce Type: cross Abstract: This paper proposes implicit cooperation, a framework
            enabling decentralized agents to approximate optimal coordination in local energy markets withou"
        - title: "MARLEM: A Multi-Agent Reinforcement Learning Simulation Framework for Implicit Cooperation in Decentralized
            Local Energy Markets"
          url: https://arxiv.org/abs/2602.16063
          summary: "arXiv:2602.16063v1 Announce Type: cross Abstract: This paper introduces a novel, open-source MARL simulation
            framework for studying implicit cooperation in LEMs, modeled as a decentralized partially o"
      directions: "Review and incorporate recent developments: ML Safety Newsletter #15; Operator System Card; Practices for
        Governing Agentic AI Systems; Introducing the Gemini 2.5 Computer Use model; AI Safety Newsletter #60: The AI
        Action Plan; Keeping your data safe when an AI agent clicks a link; Introducing Aardvark: OpenAI’s agentic
        security researcher; ChatGPT agent System Card; OpenAI o3 and o4-mini System Card; PaperBench: Evaluating AI’s
        Ability to Replicate AI Research; Introducing Operator; Gemini Robotics 1.5 brings AI agents into the physical
        world; Our vision for building a universal AI assistant; Last Week in AI #329 - GPT 5.2, GenAI.mil, Disney in
        Sora; Optimization Instability in Autonomous Agentic Workflows for Clinical Symptom Detection; Toward Scalable
        Verifiable Reward: Proxy State-Based Evaluation for Multi-turn Tool-Calling LLM Agents; Verifiable Semantics for
        Agent-to-Agent Communication; Recursive language models for jailbreak detection: a procedural defense for
        tool-augmented agents; Policy Compiler for Secure Agentic Systems; Helpful to a Fault: Measuring Illicit
        Assistance in Multi-Turn, Multilingual LLM Agents; Calibrate-Then-Act: Cost-Aware Exploration in LLM Agents;
        GPT-5.3-Codex System Card; OpenAI co-founds Agentic AI Foundation, donates AGENTS.md; Notion’s rebuild for
        agentic AI: How GPT‑5 helped unlock autonomous workflows; Introducing ChatGPT agent; Introducing OpenAI o3 and
        o4-mini; BrowseComp: a benchmark for browsing agents; Computer-Using Agent; Solving complex problems with OpenAI
        o1 models; MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering; SIMA 2: An Agent that
        Plays, Reasons, and Learns With You in Virtual 3D Worlds; Gemini Robotics On-Device brings AI to local robotic
        devices; AlphaEvolve: A Gemini-powered coding agent for designing advanced algorithms; Gemini Robotics brings AI
        into the physical world; LWiAI Podcast #228 - GPT 5.2, Scaling Agents, Weird Generalization; Learning
        Personalized Agents from Human Feedback; Multi-agent cooperation through in-context co-player inference;
        CaveAgent: Transforming LLMs into Stateful Runtime Operators; AgentNoiseBench: Benchmarking Robustness of
        Tool-Using LLM Agents Under Noisy Condition; Cocoa: Co-Planning and Co-Execution with AI Agents; EconEvals:
        Benchmarks and Litmus Tests for Economic Decision-Making by LLM Agents; Rethinking the Role of Entropy in
        Optimizing Tool-Use Behaviors for Large Language Model Agents; Evaluating Language Model Agency through
        Negotiations; Introducing GPT-5.3-Codex; Introducing AgentKit, new Evals, and RFT for agents; Moving from
        intent-based bots to proactive AI agents; Introducing deep research; ChatGPT plugins; Learning to cooperate,
        compete, and communicate; Google DeepMind at NeurIPS 2024; LWiAI Podcast #231 - Claude Cowork, Anthropic $10B,
        Deep Delta Learning; EnterpriseGym Corecraft: Training Generalizable Agents on High-Fidelity RL Environments;
        Towards a Science of AI Agent Reliability; ReLoop: Structured Modeling and Behavioral Verification for Reliable
        LLM-Based Optimization; Graph Representation-based Model Poisoning on the Heterogeneous Internet of Agents;
        Language and Experience: A Computational Model of Social Learning in Complex Tasks; Introducing OpenAI Frontier;
        Unrolling the Codex agent loop; Netomi’s lessons for scaling agentic systems into the enterprise; Neural MMO: A
        massively multiagent game environment; Learning to model other minds; Genie 2: A large-scale foundation world
        model; SEISMO: Increasing Sample Efficiency in Molecular Optimization with a Trajectory-Aware LLM Agent; Does
        Socialization Emerge in AI Agent Society? A Case Study of Moltbook; MemoryArena: Benchmarking Agent Memory in
        Interdependent Multi-Session Agentic Tasks; CAST: Character-and-Scene Episodic Memory for Agents; Empirical
        Cumulative Distribution Function Clustering for LLM-based Agent System Analysis; Introducing
        GPT-5.3-Codex-Spark; Unlocking the Codex harness: how we built the App Server; Inside OpenAI’s in-house data
        agent; Cisco and OpenAI redefine enterprise engineering with AI agents; How we built OWL, the new architecture
        behind our ChatGPT-based browser, Atlas; Introducing Codex; Understanding complex trends with deep research;
        Learning policy representations in multiagent systems; Competitive self-play; Learning with opponent-learning
        awareness; Revolutionizing Long-Term Memory in AI: New Horizons with High-Capacity and High-Speed Storage; From
        Tool Orchestration to Code Execution: A Study of MCP Design Choices; HiPER: Hierarchical Reinforcement Learning
        with Explicit Credit Assignment for Large Language Model Agents; Team of Thoughts: Efficient Test-time Scaling
        of Agentic Systems through Orchestrated Tool Calling; DIAGPaper: Diagnosing Valid and Specific Weaknesses in
        Scientific Papers via Multi-Agent Reasoning; From Pixels to Policies: Reinforcing Spatial Reasoning in Language
        Models for Content-Aware Layout Design; PLAICraft: Large-Scale Time-Aligned Vision-Speech-Action Dataset for
        Embodied AI; Harness engineering: leveraging Codex in an agent-first world; Introducing the Codex app; Datadog
        uses Codex for system-level code review; Scaling accounting capacity with OpenAI; Addendum to OpenAI o3 and
        o4-mini system card: OpenAI o3 Operator; Addendum to o3 and o4-mini system card: Codex; Introducing the
        SWE-Lancer benchmark; Meta-learning for wrestling; Introducing Gemini 2.0: our new AI model for the agentic era;
        Last Week in AI #334 - Kimi K2.5 & Code, Genie 3, OpenClaw & Moltbook; Improving Interactive In-Context Learning
        from Natural Language Feedback; Agent Skill Framework: Perspectives on the Potential of Small Language Models in
        Industrial Environments; State Design Matters: How Representations Shape Dynamic Reasoning in Large Language
        Models; DataJoint 2.0: A Computational Substrate for Agentic Scientific Workflows; Large Language Models for
        Water Distribution Systems Modeling and Decision-Making; RoboSpatial: Teaching Spatial Understanding to 2D and
        3D Vision-Language Models for Robotics; Experience-based Knowledge Correction for Robust Planning in Minecraft;
        From Transcripts to AI Agents: Knowledge Extraction, RAG Integration, and Robust Evaluation of Conversational AI
        Assistants; TabAgent: A Framework for Replacing Agentic Generative Components with Tabular-Textual Classifiers;
        Snowflake and OpenAI partner to bring frontier intelligence to enterprise data; Addendum to GPT-5 system card:
        GPT-5-Codex; No-code personal agents, powered by GPT-4.1 and Realtime API; New tools and features in the
        Responses API; New tools for building agents; Creating agent and human collaboration with GPT 4o; Achieving 10x
        growth with agentic sales prospecting; Learning to communicate; Emergence of grounded compositional language in
        multi-agent populations; Our latest advances in robot dexterity; LWiAI Podcast #233 - Moltbot, Genie 3,
        Qwen3-Max-Thinking; Kalman-Inspired Runtime Stability and Recovery in Hybrid Reasoning Systems; RoboGene:
        Boosting VLA Pre-training via Diversity-Driven Agentic Framework for Real-World Task Generation; MerLean: An
        Agentic Framework for Autoformalization in Quantum Computation; SurgRAW: Multi-Agent Workflow with Chain of
        Thought Reasoning for Robotic Surgical Video Analysis; BPP: Long-Context Robot Imitation Learning by Focusing on
        Key History Frames; ServiceNow powers actionable enterprise AI with OpenAI; BNY builds “AI for everyone,
        everywhere” with OpenAI; Consensus accelerates research with GPT-5 and Responses API; Introducing apps in
        ChatGPT and the new Apps SDK; Resolving digital threats 100x faster with OpenAI; Customizable, no-code voice
        agent automation with GPT-4o; Driving scalable growth with OpenAI o3, GPT-4.1, and CUA; Automating 90% of
        finance and legal work with agents; Automating customer support agents; Label-Consistent Data Generation for
        Aspect-Based Sentiment Analysis Using LLM Agents; Model ML is helping financial firms rebuild with AI from the
        ground up; Building an autonomous financial analyst with o1 and o3-mini; Towards Efficient Constraint Handling
        in Neural Solvers for Routing Problems; Causally-Guided Automated Feature Engineering with Multi-Agent
        Reinforcement Learning; Fly0: Decoupling Semantic Grounding from Geometric Planning for Zero-Shot Aerial
        Navigation; Federated Graph AGI for Cross-Border Insider Threat Intelligence in Government Financial Schemes;
        Graphon Mean-Field Subsampling for Cooperative Heterogeneous Multi-Agent Reinforcement Learning; FindAnything:
        Open-Vocabulary and Object-Centric Mapping for Robot Exploration in Any Environment; FreqPolicy: Efficient
        Flow-based Visuomotor Policy via Frequency Consistency; World Action Models are Zero-shot Policies; Learning
        Distributed Equilibria in Linear-Quadratic Stochastic Differential Games: An $\\alpha$-Potential Approach; Buy
        it in ChatGPT: Instant Checkout and the Agentic Commerce Protocol; EdgeNav-QE: QLoRA Quantization and Dynamic
        Early Exit for LAM-based Navigation on Edge Devices; SPARC: Scenario Planning and Reasoning for Automated C Unit
        Test Generation; Learning to Drive in New Cities Without Human Demonstrations; Multi-Agent
        Combinatorial-Multi-Armed-Bandit framework for the Submodular Welfare Problem under Bandit Feedback; Powering
        tax donations with AI powered personalized recommendations; New in ChatGPT for Business: March 2025; Resp-Agent:
        An Agent-Based System for Multimodal Respiratory Sound Generation and Disease Diagnosis; Articulated 3D Scene
        Graphs for Open-World Mobile Manipulation; MARVL: Multi-Stage Guidance for Robotic Manipulation via
        Vision-Language Models; Harnessing Implicit Cooperation: A Multi-Agent Reinforcement Learning Approach Towards
        Decentralized Local Energy Markets; MARLEM: A Multi-Agent Reinforcement Learning Simulation Framework for
        Implicit Cooperation in Decentralized Local Energy Markets"
    - pageId: situational-awareness
      pageTitle: Situational Awareness
      reason: 1 news item(s) mention this entity directly
      suggestedTier: polish
      relevantNews:
        - title: "When Models Examine Themselves: Vocabulary-Activation Correspondence in Self-Referential Processing"
          url: https://arxiv.org/abs/2602.11358
          summary: "arXiv:2602.11358v2 Announce Type: replace-cross Abstract: Large language models produce rich introspective
            language when prompted for self-examination, but whether this language reflects internal comp"
      directions: "Review and incorporate recent developments: When Models Examine Themselves: Vocabulary-Activation
        Correspondence in Self-Referential Processing"
  newPageSuggestions: []
  skippedReasons:
    - item: AI Safety Solution Cruxes
      reason: Exceeded budget
    - item: Is AI Existential Risk Real?
      reason: Exceeded budget
    - item: AI Accident Risk Cruxes
      reason: Exceeded budget
    - item: AI Timelines
      reason: Exceeded budget
    - item: Alignment Progress
      reason: Exceeded budget
    - item: Reasoning and Planning
      reason: Exceeded budget
    - item: Tool Use and Computer Use
      reason: Exceeded budget
    - item: Deep Learning Revolution (2012-2020)
      reason: Exceeded page limit
    - item: Safety Research & Resources
      reason: Exceeded page limit
    - item: AI Capabilities
      reason: Exceeded page limit
    - item: Expert Opinion
      reason: Exceeded page limit
    - item: Compute (AI Capabilities)
      reason: Exceeded page limit
    - item: AI Uses (Overview)
      reason: Exceeded page limit
    - item: Intervention Effectiveness Matrix
      reason: Exceeded page limit
    - item: Large Language Models
      reason: Exceeded page limit
    - item: Provable / Guaranteed Safe AI
      reason: Exceeded page limit
    - item: AI Governance
      reason: Exceeded page limit
    - item: Disinformation Detection Arms Race Model
      reason: Exceeded page limit
    - item: Safety Culture Equilibrium
      reason: Exceeded page limit
    - item: Aligned AGI - The Good Ending
      reason: Exceeded page limit
    - item: AI Structural Risk Cruxes
      reason: Exceeded page limit
    - item: Alignment Robustness Trajectory
      reason: Exceeded page limit
    - item: Safety-Capability Tradeoff Model
      reason: Exceeded page limit
    - item: Deceptive Alignment Decomposition Model
      reason: Exceeded page limit
    - item: Public Opinion & Awareness
      reason: Exceeded page limit
    - item: AI Misuse Risk Cruxes
      reason: Exceeded page limit
    - item: AI Epistemic Cruxes
      reason: Exceeded page limit
    - item: Compute & Hardware
      reason: Exceeded page limit
    - item: Early Warnings (1950s-2000)
      reason: Exceeded page limit
    - item: Geopolitics & Coordination
      reason: Exceeded page limit
    - item: Collective Intelligence / Coordination
      reason: Exceeded page limit
    - item: AI Evaluation
      reason: Exceeded page limit
    - item: Third-Party Model Auditing
      reason: Exceeded page limit
    - item: AI Uplift Assessment Model
      reason: Exceeded page limit
    - item: Government Regulation vs Industry Self-Governance
      reason: Exceeded page limit
    - item: World Models + Planning
      reason: Exceeded page limit
    - item: Sparse / MoE Transformers
      reason: Exceeded page limit
    - item: Corrigibility Failure Pathways
      reason: Exceeded page limit
    - item: Model Organisms of Misalignment
      reason: Exceeded page limit
    - item: LAWS Proliferation Model
      reason: Exceeded page limit
    - item: Bioweapons Attack Chain Model
      reason: Exceeded page limit
    - item: Autonomous Cyber Attack Timeline
      reason: Exceeded page limit
    - item: Interpretability Coverage
      reason: Exceeded page limit
    - item: Training Methods (Overview)
      reason: Exceeded page limit
    - item: Deepfakes Authentication Crisis Model
      reason: Exceeded page limit
    - item: Defense in Depth Model
      reason: Exceeded page limit
    - item: Multipolar Trap Dynamics Model
      reason: Exceeded page limit
    - item: AGI Timeline
      reason: Exceeded page limit
    - item: Governance (Civ. Competence)
      reason: Exceeded page limit
    - item: Is Scaling All You Need?
      reason: Exceeded page limit
    - item: Scientific Research Capabilities
      reason: Exceeded page limit
    - item: Long-Horizon Autonomous Tasks
      reason: Exceeded page limit
    - item: Instrumental Convergence Framework
      reason: Exceeded page limit
    - item: Mesa-Optimization Risk Analysis
      reason: Exceeded page limit
    - item: Autonomous Coding
      reason: Exceeded page limit
    - item: Persuasion and Social Manipulation
      reason: Exceeded page limit
    - item: The Case FOR AI Existential Risk
      reason: Exceeded page limit
    - item: Open vs Closed Source AI
      reason: Exceeded page limit
    - item: Automation Bias Cascade Model
      reason: Exceeded page limit
    - item: AGI Development
      reason: Exceeded page limit
    - item: Anthropic Impact Assessment Model
      reason: Exceeded page limit
    - item: Electoral Impact Assessment Model
      reason: Exceeded page limit
    - item: Metrics & Indicators
      reason: Exceeded page limit
    - item: Is Interpretability Sufficient for Safety?
      reason: Exceeded page limit
    - item: Multipolar Competition - The Fragmented World
      reason: Exceeded page limit
    - item: Should We Pause AI Development?
      reason: Exceeded page limit
    - item: Reward Hacking Taxonomy and Severity Model
      reason: Exceeded page limit
    - item: Autonomous Weapons Escalation Model
      reason: Exceeded page limit
    - item: Projecting Compute Spending
      reason: Exceeded page limit
    - item: AI-Bioweapons Timeline Model
      reason: Exceeded page limit
    - item: Lab Behavior & Industry
      reason: Exceeded page limit
    - item: Architecture Scenarios Table
      reason: Exceeded page limit
    - item: Brain-Computer Interfaces
      reason: Exceeded page limit
    - item: Neuromorphic Hardware
      reason: Exceeded page limit
    - item: International AI Coordination Game
      reason: Exceeded page limit
    - item: Multi-Actor Strategic Landscape
      reason: Exceeded page limit
    - item: Feedback Loop & Cascade Model
      reason: Exceeded page limit
    - item: Evaluation Types Table
      reason: Exceeded page limit
    - item: Deployment Architectures Table
      reason: Exceeded page limit
    - item: Economic & Labor Metrics
      reason: Exceeded page limit
    - item: Meta & Structural Indicators
      reason: Exceeded page limit
    - item: AI Megaproject Infrastructure
      reason: Exceeded page limit
    - item: AI Talent Market Dynamics
      reason: Exceeded page limit
    - item: Frontier Lab Cost Structure
      reason: Exceeded page limit
    - item: GPT-5.1-Codex-Max System Card
      reason: System card for GPT-5.1-Codex-Max is a technical document about a specific model version; while it may contain
        safety details, it's primarily product documentation rather than substantive new information about AI safety
        approaches or risks.
    - item: Funding grants for new research into AI and mental health
      reason: Funding grants for AI and mental health research is an organizational/funding announcement; while potentially
        important, it's primarily about grant distribution rather than advancing wiki knowledge about AI safety or
        risks.
    - item: Building more with GPT-5.1-Codex-Max
      reason: Product announcement for GPT-5.1-Codex-Max is primarily a capability/feature release; lacks substantive safety
        or risk implications beyond standard model improvements.
    - item: Adversarial attacks on neural network policies
      reason: Title only provided ('Adversarial attacks on neural network policies'); insufficient content to assess relevance
        or substantive contribution.
    - item: Inside Mirakl's agentic commerce vision
      reason: Business case study about Mirakl's use of agentic AI; primarily a commercial application example without
        substantive safety or risk insights.
    - item: "Mixpanel security incident: what OpenAI users need to know"
      reason: Security incident report about Mixpanel (third-party service); not directly about AI safety or risks, and
        incident appears to have been contained with no API content compromised.
    - item: Computational limitations in robust classification and win-win results
      reason: Title only provided ('Computational limitations in robust classification and win-win results'); insufficient
        content to assess relevance.
    - item: Learning concepts with energy functions
      reason: Technical paper on energy-based models for concept learning; specialized ML research without clear connection to
        AI safety wiki topics.
    - item: Variational option discovery algorithms
      reason: Title only provided ('Variational option discovery algorithms'); insufficient content to assess relevance.
    - item: Introducing OpenAI for Australia
      reason: Regional infrastructure announcement (OpenAI for Australia); primarily about market expansion and workforce
        training rather than safety or risk content.
    - item: Inside JetBrains—the company reshaping how the world writes code
      reason: Business partnership announcement (JetBrains integrating GPT-5); primarily a product integration story without
        substantive safety implications.
    - item: OpenAI announces nonprofit commission advisors
      reason: Organizational announcement about nonprofit commission advisors; administrative/governance matter without
        substantive safety content.
    - item: Insights from global conversations
      reason: Summary of global conversations about AI; too vague without specific substantive content to warrant wiki update.
    - item: Special projects
      reason: Vague announcement about 'special projects'; insufficient detail to assess relevance or substantive contribution.
    - item: The state of enterprise AI
      reason: Enterprise adoption statistics; primarily business metrics without safety or risk implications.
    - item: Accenture and OpenAI accelerate enterprise AI success
      reason: Business partnership announcement (Accenture-OpenAI); primarily about enterprise deployment without substantive
        safety content.
    - item: Introducing OpenAI for Ireland
      reason: Regional initiative announcement (OpenAI for Ireland); primarily about market expansion and SME support without
        safety content.
    - item: Fighting the New York Times’ invasion of user privacy
      reason: Legal dispute with New York Times; while touching on privacy, this is primarily a litigation matter rather than
        substantive safety or governance content.
    - item: Combating online child sexual exploitation & abuse
      reason: Child safety policy announcement; important but primarily about content moderation policies rather than AI
        safety/risk research content.
    - item: "Spinning Up in Deep RL: Workshop review"
      reason: Workshop announcement for educational initiative; administrative/educational matter without substantive safety
        content.
    - item: Proximal Policy Optimization
      reason: Historical paper on Proximal Policy Optimization (PPO); foundational RL work but not new information and not
        directly about AI safety.
    - item: "From Collapse to Improvement: Statistical Perspectives on the Evolutionary Dynamics of Iterative Training on
        Contaminated Sources"
      reason: Technical paper on model collapse in iterative training; specialized ML research without clear connection to AI
        safety wiki topics.
    - item: OpenAI takes an ownership stake in Thrive Holdings to accelerate enterprise AI adoption
      reason: Investment announcement (OpenAI stake in Thrive Holdings); primarily about business strategy and enterprise
        adoption without safety content.
    - item: Our approach to mental health-related litigation
      reason: Litigation approach statement; primarily about legal strategy rather than substantive safety or risk content.
    - item: A free version of ChatGPT built for teachers
      reason: Product announcement (ChatGPT for Teachers); primarily an educational tool release without substantive safety
        implications.
    - item: Intuit and OpenAI join forces on new AI-powered experiences
      reason: Business partnership announcement (Intuit-OpenAI); primarily about commercial integration without substantive
        safety content.
    - item: Introducing data residency in Europe
      reason: Data residency feature announcement; already covered by item 18 and primarily a compliance/infrastructure
        feature.
    - item: "March 20 ChatGPT outage: Here’s what happened"
      reason: Technical incident report (ChatGPT outage); operational/reliability matter without substantive safety or risk
        implications.
    - item: Evolution through large models
      reason: Title only provided ('Evolution through large models'); insufficient content to assess relevance.
    - item: "OpenAI Scholars 2018: Final projects"
      reason: Historical announcement about OpenAI Scholars program completion; archival content without current substantive
        contribution.
    - item: "OpenAI Five Benchmark: Results"
      reason: Historical benchmark result (OpenAI Five vs Dota players); archival content from 2018 without current
        substantive contribution.
    - item: "OpenAI Scholars 2018: Meet our Scholars"
      reason: Historical announcement about OpenAI Scholars program; archival content without current substantive contribution.
    - item: OpenAI Five
      reason: Historical announcement about OpenAI Five; archival content without current substantive contribution.
    - item: Better exploration with parameter noise
      reason: Historical paper on parameter noise exploration; foundational RL work but not new information and not directly
        about AI safety.
    - item: Hindsight Experience Replay
      reason: Title only provided ('Hindsight Experience Replay'); insufficient content to assess relevance.
    - item: Teacher–student curriculum learning
      reason: Title only provided ('Teacher–student curriculum learning'); insufficient content to assess relevance.
    - item: Stochastic Neural Networks for hierarchical reinforcement learning
      reason: Title only provided ('Stochastic Neural Networks for hierarchical reinforcement learning'); insufficient content
        to assess relevance.
    - item: Prediction and control with temporal segment models
      reason: Title only provided ('Prediction and control with temporal segment models'); insufficient content to assess
        relevance.
    - item: "#Exploration: A study of count-based exploration for deep reinforcement learning"
      reason: "Title only provided ('#Exploration: A study of count-based exploration for deep reinforcement learning');
        insufficient content to assess relevance."
    - item: "RL²: Fast reinforcement learning via slow reinforcement learning"
      reason: "Title only provided ('RL²: Fast reinforcement learning via slow reinforcement learning'); insufficient content
        to assess relevance."
    - item: Report from the self-organizing conference
      reason: Historical announcement about self-organizing conference; archival content without current substantive
        contribution.
    - item: Transfer from simulation to real world through learning deep inverse dynamics model
      reason: Title only provided ('Transfer from simulation to real world through learning deep inverse dynamics model');
        insufficient content to assess relevance.
    - item: Adversarial training methods for semi-supervised text classification
      reason: Title only provided ('Adversarial training methods for semi-supervised text classification'); insufficient
        content to assess relevance.
    - item: "Transforming GenAI Policy to Prompting Instruction: An RCT of Scalable Prompting Interventions in a CS1 Course"
      reason: Academic paper on GenAI policy and prompting interventions in CS education; specialized educational research
        without clear connection to AI safety wiki.
    - item: "DiffusionBlocks: Block-wise Neural Network Training via Diffusion Interpretation"
      reason: Technical paper on diffusion-based neural network training; specialized ML research without clear connection to
        AI safety wiki topics.
    - item: "SNAP-UQ: Self-supervised Next-Activation Prediction for Single-Pass Uncertainty in TinyML"
      reason: Technical paper on uncertainty estimation in TinyML; specialized ML research without clear connection to AI
        safety wiki topics.
    - item: Stage-wise Dynamics of Classifier-Free Guidance in Diffusion Models
      reason: Technical paper on classifier-free guidance in diffusion models; specialized ML research without clear
        connection to AI safety wiki topics.
    - item: Imitation Learning for Combinatorial Optimisation under Uncertainty
      reason: Technical paper on imitation learning for combinatorial optimization; specialized ML research without clear
        connection to AI safety wiki topics.
    - item: Statistical Inference Leveraging Synthetic Data with Distribution-Free Guarantees
      reason: Technical paper on synthetic data and statistical inference; specialized ML research without clear connection to
        AI safety wiki topics.
  estimatedCost: 28.5
