## 2026-02-15 | claude/improve-donation-pages-WoOUF | Correct EA connections framing on Anthropic donation pages

**What was done:** Corrected the misleading "only 2/7 founders have EA connections" framing across three pages. Researched and documented EA/rationalist/AI safety network connections for all 7 Anthropic co-founders with public source citations. Updated the Individual EA Connections section with detailed per-founder evidence, and aligned all references across the Anthropic (Funder), Pledge Interventions, and Pre-IPO DAF pages.

**Pages:** anthropic-investors, anthropic-pledge-enforcement, anthropic-pre-ipo-daf-transfers

**PR:** #134

**Issues encountered:**
- pnpm install failed initially due to puppeteer network issues; resolved with --ignore-scripts

**Learnings/notes:**
- The key reframing: all 7 founders are embedded in the EA/rationalist/AI safety network, but only 2 have formal EA commitments (GWWC pledge, marriage). The relevant uncertainty is cause allocation, not connections.
- Chris Olah co-authored "Concrete Problems in AI Safety" with Dario and Christiano, appeared on 80k Hours multiple times, listed as core AI safety community member
- Sam McCandlish has a LessWrong account and has posted on EA forums on behalf of Anthropic
- Jack Clark publishes Import AI (recommended on EA Forum), works in EA-adjacent AI governance circles (CSET, Stanford HAI)
- Jared Kaplan was Dario's roommate from grad school; Holden Karnofsky now reports directly to him
- Tom Brown cited safety motivations for leaving OpenAI; collaborated with Christiano on GPT-3
- Anthropic publicly distances from the EA label (Daniela: "I don't identify with that terminology")
