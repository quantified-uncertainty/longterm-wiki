{
  "byNumericId": {
    "E1": "adversarial-robustness",
    "E2": "agentic-ai",
    "E3": "agi-race",
    "E4": "agi-timeline-debate",
    "E5": "ai-capabilities",
    "E6": "ai-control",
    "E7": "ai-control-concentration",
    "E8": "ai-executive-order",
    "E9": "ai-forecasting",
    "E10": "ai-forecasting-benchmark",
    "E11": "ai-ownership",
    "E12": "ai-risk-portfolio-analysis",
    "E13": "ai-safety-institutes",
    "E14": "ai-safety-summit",
    "E15": "ai-takeover",
    "E16": "ai-timelines",
    "E17": "ai-uses",
    "E18": "aligned-agi",
    "E19": "alignment-progress",
    "E20": "alignment-robustness",
    "E21": "alignment-robustness-trajectory",
    "E22": "anthropic",
    "E23": "anthropic-core-views",
    "E24": "apollo-research",
    "E25": "arc",
    "E26": "arc-evals",
    "E27": "authentication-collapse",
    "E28": "authentication-collapse-timeline",
    "E29": "authoritarian-takeover",
    "E30": "authoritarian-tools",
    "E31": "authoritarian-tools-diffusion",
    "E32": "automation-bias",
    "E33": "automation-bias-cascade",
    "E34": "autonomous-replication",
    "E35": "autonomous-weapons",
    "E36": "autonomous-weapons-escalation",
    "E37": "autonomous-weapons-proliferation",
    "E38": "benchmarking",
    "E39": "beth-barnes",
    "E40": "bio-risk",
    "E41": "biological-threat-exposure",
    "E42": "bioweapons",
    "E43": "bioweapons-ai-uplift",
    "E44": "bioweapons-attack-chain",
    "E45": "bioweapons-timeline",
    "E46": "buck-shlegeris",
    "E47": "cais",
    "E48": "california-sb1047",
    "E49": "canada-aida",
    "E50": "capabilities",
    "E51": "capabilities-to-safety-pipeline",
    "E52": "capability-evaluations",
    "E53": "capability-threshold-model",
    "E54": "carlsmith-six-premises",
    "E55": "case-against-xrisk",
    "E56": "case-for-xrisk",
    "E57": "chai",
    "E58": "china-ai-regulations",
    "E59": "chris-olah",
    "E60": "civilizational-competence",
    "E61": "coding",
    "E62": "colorado-ai-act",
    "E63": "compounding-risks-analysis",
    "E64": "compute-governance",
    "E65": "compute-hardware",
    "E66": "compute-monitoring",
    "E67": "compute-thresholds",
    "E68": "concentration-of-power",
    "E69": "concentration-of-power-model",
    "E70": "conjecture",
    "E71": "connor-leahy",
    "E72": "consensus-manufacturing",
    "E73": "consensus-manufacturing-dynamics",
    "E74": "content-authentication",
    "E75": "content-moderation",
    "E76": "coordination-capacity",
    "E77": "coordination-tech",
    "E78": "corporate-influence",
    "E79": "corrigibility",
    "E80": "corrigibility-failure",
    "E81": "corrigibility-failure-pathways",
    "E82": "cyber-offense",
    "E83": "cyber-psychosis",
    "E84": "cyber-psychosis-cascade",
    "E85": "cyber-threat-exposure",
    "E86": "cyberweapons",
    "E87": "cyberweapons-attack-automation",
    "E88": "cyberweapons-offense-defense",
    "E89": "dan-hendrycks",
    "E90": "daniela-amodei",
    "E91": "dario-amodei",
    "E92": "data-constraints",
    "E93": "deceptive-alignment",
    "E94": "deceptive-alignment-decomposition",
    "E95": "deep-learning-era",
    "E96": "deepfakes",
    "E97": "deepfakes-authentication-crisis",
    "E98": "deepmind",
    "E99": "defense-in-depth-model",
    "E100": "deliberation",
    "E101": "demis-hassabis",
    "E102": "disinformation",
    "E103": "disinformation-detection-race",
    "E104": "disinformation-electoral-impact",
    "E105": "distributional-shift",
    "E106": "dual-use",
    "E107": "early-warnings",
    "E108": "economic-disruption",
    "E109": "economic-disruption-impact",
    "E110": "economic-disruption-model",
    "E111": "economic-labor",
    "E112": "economic-stability",
    "E113": "effectiveness-assessment",
    "E114": "eliezer-yudkowsky",
    "E115": "elizabeth-kelly",
    "E116": "elon-musk",
    "E117": "emergent-capabilities",
    "E118": "enfeeblement",
    "E119": "epistemic-collapse",
    "E120": "epistemic-collapse-threshold",
    "E121": "epistemic-health",
    "E122": "epistemic-infrastructure",
    "E123": "epistemic-security",
    "E124": "epistemic-sycophancy",
    "E125": "epoch-ai",
    "E126": "erosion-of-agency",
    "E127": "eu-ai-act",
    "E128": "evals",
    "E129": "evan-hubinger",
    "E130": "existential-catastrophe",
    "E131": "existential-risk",
    "E132": "expert-opinion",
    "E133": "expertise-atrophy",
    "E134": "expertise-atrophy-cascade",
    "E135": "expertise-atrophy-progression",
    "E136": "export-controls",
    "E137": "failed-stalled-proposals",
    "E138": "far-ai",
    "E139": "fast-takeoff",
    "E140": "fhi",
    "E141": "field-building",
    "E142": "flash-dynamics",
    "E143": "flash-dynamics-threshold",
    "E144": "forecastbench",
    "E145": "fraud",
    "E146": "fraud-sophistication-curve",
    "E147": "fri",
    "E148": "gary-marcus",
    "E149": "geoffrey-hinton",
    "E150": "geopolitics",
    "E151": "goal-misgeneralization",
    "E152": "goal-misgeneralization-probability",
    "E153": "govai",
    "E154": "governance-policy",
    "E155": "historical-revisionism",
    "E156": "holden-karnofsky",
    "E157": "human-agency",
    "E158": "human-catastrophe",
    "E159": "human-expertise",
    "E160": "human-oversight-quality",
    "E161": "hybrid-systems",
    "E162": "ian-hogarth",
    "E163": "ilya-sutskever",
    "E164": "information-authenticity",
    "E165": "institutional-adaptation-speed",
    "E166": "institutional-capture",
    "E167": "institutional-quality",
    "E168": "instrumental-convergence",
    "E169": "instrumental-convergence-framework",
    "E170": "international-compute-regimes",
    "E171": "international-coordination",
    "E172": "international-coordination-game",
    "E173": "international-summits",
    "E174": "interpretability",
    "E175": "interpretability-coverage",
    "E176": "interpretability-sufficient",
    "E177": "intervention-effectiveness-matrix",
    "E178": "intervention-timing-windows",
    "E179": "irreversibility",
    "E180": "irreversibility-threshold",
    "E181": "is-ai-xrisk-real",
    "E182": "jan-leike",
    "E183": "knowledge-monopoly",
    "E184": "lab-behavior",
    "E185": "lab-incentives-model",
    "E186": "language-models",
    "E187": "learned-helplessness",
    "E188": "legal-evidence-crisis",
    "E189": "lock-in",
    "E190": "lock-in-mechanisms",
    "E191": "lock-in-model",
    "E192": "long-horizon",
    "E193": "long-term-lockin",
    "E194": "long-term-trajectory",
    "E195": "mainstream-era",
    "E196": "media-policy-feedback-loop",
    "E197": "mesa-optimization",
    "E198": "mesa-optimization-analysis",
    "E199": "metaculus",
    "E200": "metaforecast",
    "E201": "metr",
    "E202": "miri",
    "E203": "miri-era",
    "E204": "misaligned-catastrophe",
    "E205": "misalignment-potential",
    "E206": "misuse",
    "E207": "misuse-potential",
    "E208": "multipolar-competition",
    "E209": "multipolar-trap",
    "E210": "multipolar-trap-dynamics",
    "E211": "multipolar-trap-model",
    "E212": "nate-soares",
    "E213": "natural-abstractions",
    "E214": "neel-nanda",
    "E215": "nick-bostrom",
    "E216": "nist-ai-rmf",
    "E217": "open-vs-closed",
    "E218": "openai",
    "E219": "parameter-interaction-network",
    "E220": "paul-christiano",
    "E221": "pause-advocacy",
    "E222": "pause-and-redirect",
    "E223": "pause-debate",
    "E224": "persuasion",
    "E225": "post-incident-recovery",
    "E226": "power-seeking",
    "E227": "power-seeking-conditions",
    "E228": "prediction-markets",
    "E229": "preference-authenticity",
    "E230": "preference-manipulation",
    "E231": "preference-manipulation-drift",
    "E232": "proliferation",
    "E233": "proliferation-model",
    "E234": "proliferation-risk-model",
    "E235": "prosaic-alignment",
    "E236": "public-opinion",
    "E237": "public-opinion-evolution",
    "E238": "quri",
    "E239": "racing-dynamics",
    "E240": "racing-dynamics-impact",
    "E241": "racing-dynamics-model",
    "E242": "racing-intensity",
    "E243": "reality-coherence",
    "E244": "reality-fragmentation",
    "E245": "reality-fragmentation-network",
    "E246": "reasoning",
    "E247": "redwood",
    "E248": "regulation-debate",
    "E249": "regulatory-capacity",
    "E250": "regulatory-capacity-threshold",
    "E251": "research-agendas",
    "E252": "responsible-scaling-policies",
    "E253": "reward-hacking",
    "E254": "reward-hacking-taxonomy",
    "E255": "risk-activation-timeline",
    "E256": "risk-cascade-pathways",
    "E257": "risk-interaction-matrix",
    "E258": "risk-interaction-network",
    "E259": "rlhf",
    "E260": "robin-hanson",
    "E261": "safety-capability-gap",
    "E262": "safety-capability-tradeoff",
    "E263": "safety-culture-equilibrium",
    "E264": "safety-culture-strength",
    "E265": "safety-research",
    "E266": "safety-research-allocation",
    "E267": "safety-research-value",
    "E268": "safety-researcher-gap",
    "E269": "sam-altman",
    "E270": "sandbagging",
    "E271": "scalable-oversight",
    "E272": "scaling-debate",
    "E273": "scaling-laws",
    "E274": "scheming",
    "E275": "scheming-likelihood-model",
    "E276": "scientific-corruption",
    "E277": "scientific-research",
    "E278": "self-improvement",
    "E279": "seoul-declaration",
    "E280": "shane-legg",
    "E281": "sharp-left-turn",
    "E282": "situational-awareness",
    "E283": "slow-takeoff-muddle",
    "E284": "societal-resilience",
    "E285": "societal-trust",
    "E286": "squiggle",
    "E287": "squiggleai",
    "E288": "standards-bodies",
    "E289": "structural",
    "E290": "stuart-russell",
    "E291": "superintelligence",
    "E292": "surveillance",
    "E293": "surveillance-authoritarian-stability",
    "E294": "surveillance-chilling-effects",
    "E295": "sycophancy",
    "E296": "sycophancy-feedback-loop",
    "E297": "technical-research",
    "E298": "tmc-adaptability",
    "E299": "tmc-adoption",
    "E300": "tmc-ai-control-concentration",
    "E301": "tmc-ai-governance",
    "E302": "tmc-algorithms",
    "E303": "tmc-alignment-robustness",
    "E304": "tmc-biological-threat-exposure",
    "E305": "tmc-civ-epistemics",
    "E306": "tmc-civ-governance",
    "E307": "tmc-civcomp-adaptability",
    "E308": "tmc-companies",
    "E309": "tmc-compute",
    "E310": "tmc-compute-forecast-sketch",
    "E311": "tmc-coordination",
    "E312": "tmc-coordination-capacity",
    "E313": "tmc-countries",
    "E314": "tmc-cyber-threat-exposure",
    "E315": "tmc-economic-power",
    "E316": "tmc-economic-stability",
    "E317": "tmc-epistemic-health",
    "E318": "tmc-epistemic-lockin",
    "E319": "tmc-epistemics",
    "E320": "tmc-existential-catastrophe",
    "E321": "tmc-governance",
    "E322": "tmc-governments",
    "E323": "tmc-gradual",
    "E324": "tmc-human-agency",
    "E325": "tmc-human-expertise",
    "E326": "tmc-human-oversight-quality",
    "E327": "tmc-industries",
    "E328": "tmc-information-authenticity",
    "E329": "tmc-institutional-quality",
    "E330": "tmc-international-coordination",
    "E331": "tmc-interpretability-coverage",
    "E332": "tmc-lab-safety",
    "E333": "tmc-long-term-trajectory",
    "E334": "tmc-political-power",
    "E335": "tmc-preference-authenticity",
    "E336": "tmc-racing-intensity",
    "E337": "tmc-rapid",
    "E338": "tmc-reality-coherence",
    "E339": "tmc-recursive-ai",
    "E340": "tmc-regulatory-capacity",
    "E341": "tmc-robot-threat",
    "E342": "tmc-robot-threat-exposure",
    "E343": "tmc-rogue-actor",
    "E344": "tmc-safety-capability-gap",
    "E345": "tmc-safety-culture-strength",
    "E346": "tmc-shareholders",
    "E347": "tmc-societal-resilience",
    "E348": "tmc-societal-trust",
    "E349": "tmc-state-actor",
    "E350": "tmc-suffering-lock-in",
    "E351": "tmc-surprise-threat",
    "E352": "tmc-surprise-threat-exposure",
    "E353": "tmc-technical-ai-safety",
    "E354": "tmc-values",
    "E355": "toby-ord",
    "E356": "tool-use",
    "E357": "transformative-ai",
    "E358": "transition-turbulence",
    "E359": "treacherous-turn",
    "E360": "trust-cascade",
    "E361": "trust-cascade-model",
    "E362": "trust-decline",
    "E363": "trust-erosion-dynamics",
    "E364": "uk-aisi",
    "E365": "us-aisi",
    "E366": "us-executive-order",
    "E367": "us-state-legislation",
    "E368": "value-learning",
    "E369": "voluntary-commitments",
    "E370": "warning-signs-model",
    "E371": "whistleblower-dynamics",
    "E372": "why-alignment-easy",
    "E373": "why-alignment-hard",
    "E374": "winner-take-all",
    "E375": "winner-take-all-concentration",
    "E376": "winner-take-all-model",
    "E377": "worldview-intervention-mapping",
    "E378": "xai",
    "E379": "xpt",
    "E380": "yoshua-bengio",
    "E381": "community-notes",
    "E382": "stampy-aisafety-info",
    "E383": "mit-ai-risk-repository",
    "E384": "longterm-wiki",
    "E385": "roastmypost",
    "E386": "ai-watch",
    "E387": "timelines-wiki",
    "E388": "org-watch",
    "E389": "donations-list-website",
    "E390": "wikipedia-views",
    "E391": "ai-welfare",
    "E392": "misuse-risks",
    "E393": "solutions",
    "E394": "accident-risks",
    "E395": "structural-risks",
    "E396": "epistemic-risks",
    "E397": "governance-focused",
    "E398": "critical-uncertainties",
    "E399": "agi-timeline",
    "E400": "large-language-models",
    "E401": "heavy-scaffolding",
    "E402": "provable-safe",
    "E403": "dense-transformers",
    "E404": "openai-foundation-governance",
    "E405": "anthropic-valuation",
    "E406": "anthropic-investors",
    "E407": "long-term-benefit-trust",
    "E408": "musk-openai-lawsuit",
    "E409": "anthropic-ipo",
    "E410": "elon-musk-philanthropy",
    "E411": "anthropic-pledge-enforcement",
    "E412": "anthropic-pre-ipo-daf-transfers",
    "E413": "anthropic-impact",
    "E414": "capability-alignment-race",
    "E415": "short-timeline-policy-implications",
    "E416": "technical-pathways",
    "E417": "feedback-loops",
    "E418": "multi-actor-landscape",
    "E419": "model-organisms-of-misalignment",
    "E420": "ea-biosecurity-scope",
    "E421": "openai-foundation",
    "E422": "leading-the-future",
    "E423": "johns-hopkins-center-for-health-security",
    "E424": "nist-ai",
    "E425": "ssi",
    "E426": "controlai",
    "E427": "frontier-model-forum",
    "E428": "palisade-research",
    "E429": "centre-for-long-term-resilience",
    "E430": "goodfire",
    "E431": "david-sacks",
    "E432": "marc-andreessen",
    "E433": "max-tegmark",
    "E434": "philip-tetlock",
    "E435": "eli-lifland",
    "E436": "dustin-moskovitz",
    "E437": "eval-saturation",
    "E438": "evaluation-awareness",
    "E439": "alignment",
    "E440": "scalable-eval-approaches",
    "E441": "scheming-detection",
    "E442": "dangerous-cap-evals",
    "E443": "capability-elicitation",
    "E444": "safety-cases",
    "E445": "sleeper-agent-detection",
    "E446": "ai-assisted",
    "E447": "evaluation",
    "E448": "alignment-evals",
    "E449": "red-teaming",
    "E450": "model-auditing",
    "E451": "constitutional-ai",
    "E452": "weak-to-strong",
    "E453": "capability-unlearning",
    "E454": "preference-optimization",
    "E455": "process-supervision",
    "E456": "refusal-training",
    "E457": "california-sb53",
    "E458": "intervention-portfolio",
    "E459": "evals-governance",
    "E460": "pause-moratorium",
    "E461": "rsp",
    "E462": "corporate",
    "E463": "hardware-enabled-governance",
    "E464": "monitoring",
    "E465": "thresholds",
    "E466": "lab-culture",
    "E467": "pause",
    "E468": "training-programs",
    "E469": "bletchley-declaration",
    "E470": "coordination-mechanisms",
    "E471": "new-york-raise-act",
    "E472": "model-registries",
    "E473": "international-regimes",
    "E474": "open-source",
    "E475": "whistleblower-protections",
    "E476": "field-building-analysis",
    "E477": "mech-interp",
    "E478": "circuit-breakers",
    "E479": "representation-engineering",
    "E480": "sparse-autoencoders",
    "E481": "eliciting-latent-knowledge",
    "E482": "debate",
    "E483": "formal-verification",
    "E484": "provably-safe",
    "E485": "sandboxing",
    "E486": "structured-access",
    "E487": "tool-restrictions",
    "E488": "multi-agent",
    "E489": "sleeper-agents",
    "E490": "rogue-ai-scenarios",
    "E491": "biological-organoid",
    "E492": "brain-computer-interfaces",
    "E493": "collective-intelligence",
    "E494": "genetic-enhancement",
    "E495": "light-scaffolding",
    "E496": "minimal-scaffolding",
    "E497": "neuro-symbolic",
    "E498": "neuromorphic",
    "E499": "novel-unknown",
    "E500": "sparse-moe",
    "E501": "ssm-mamba",
    "E502": "whole-brain-emulation",
    "E503": "world-models",
    "E504": "doomer",
    "E505": "long-timelines",
    "E506": "optimistic",
    "E507": "longtermwiki-impact",
    "E508": "societal-response",
    "E509": "1day-sooner",
    "E510": "80000-hours",
    "E511": "ai-futures-project",
    "E512": "ai-impacts",
    "E513": "ai-revenue-sources",
    "E514": "arb-research",
    "E515": "blueprint-biosecurity",
    "E516": "bridgewater-aia-labs",
    "E517": "cea",
    "E518": "center-for-applied-rationality",
    "E519": "chan-zuckerberg-initiative",
    "E520": "coalition-for-epidemic-preparedness-innovations",
    "E521": "coefficient-giving",
    "E522": "council-on-strategic-risks",
    "E523": "cser",
    "E524": "cset",
    "E525": "ea-global",
    "E526": "elicit",
    "E527": "epistemic-orgs-epoch-ai",
    "E528": "fli",
    "E529": "founders-fund",
    "E530": "futuresearch",
    "E531": "giving-pledge",
    "E532": "good-judgment",
    "E533": "gpai",
    "E534": "gratified",
    "E535": "hewlett-foundation",
    "E536": "ibbis",
    "E537": "kalshi",
    "E538": "lesswrong",
    "E539": "lighthaven",
    "E540": "lightning-rod-labs",
    "E541": "lionheart-ventures",
    "E542": "longview-philanthropy",
    "E543": "ltff",
    "E544": "macarthur-foundation",
    "E545": "manifest",
    "E546": "manifold",
    "E547": "manifund",
    "E548": "mats",
    "E549": "meta-ai",
    "E550": "microsoft",
    "E551": "nti-bio",
    "E552": "open-philanthropy",
    "E553": "pause-ai",
    "E554": "peter-thiel-philanthropy",
    "E555": "polymarket",
    "E556": "red-queen-bio",
    "E557": "redwood-research",
    "E558": "rethink-priorities",
    "E559": "safety-orgs-epoch-ai",
    "E560": "samotsvety",
    "E561": "schmidt-futures",
    "E562": "secure-ai-project",
    "E563": "securebio",
    "E564": "securedna",
    "E565": "seldon-lab",
    "E566": "sentinel",
    "E567": "sff",
    "E568": "situational-awareness-lp",
    "E569": "swift-centre",
    "E570": "the-sequences",
    "E571": "turion",
    "E572": "vara",
    "E573": "vitalik-buterin-philanthropy",
    "E574": "gwern",
    "E575": "helen-toner",
    "E576": "issa-rice",
    "E577": "jaan-tallinn",
    "E578": "leopold-aschenbrenner",
    "E579": "nuno-sempere",
    "E580": "vidur-kapur",
    "E581": "vipul-naik",
    "E582": "yann-lecun",
    "E583": "adversarial-training",
    "E584": "agent-foundations",
    "E585": "ai-for-human-reasoning-fellowship",
    "E586": "cirl",
    "E587": "coe-ai-convention",
    "E588": "collective-epistemics-design-sketches",
    "E589": "community-notes-for-everything",
    "E590": "cooperative-ai",
    "E591": "deepfake-detection",
    "E592": "epistemic-virtue-evals",
    "E593": "labor-transition",
    "E594": "model-spec",
    "E595": "output-filtering",
    "E596": "probing",
    "E597": "provenance-tracing",
    "E598": "public-education",
    "E599": "reliability-tracking",
    "E600": "reward-modeling",
    "E601": "rhetoric-highlighting",
    "E602": "texas-traiga",
    "E603": "steganography",
    "E604": "agi-development",
    "E605": "claude-code-espionage-2025",
    "E606": "adaptability",
    "E607": "adoption",
    "E608": "ai-governance",
    "E609": "algorithms",
    "E610": "companies",
    "E611": "compute-forecast-sketch",
    "E612": "compute",
    "E613": "coordination",
    "E614": "countries",
    "E615": "economic-power",
    "E616": "epistemics",
    "E617": "governance",
    "E618": "governments",
    "E619": "gradual",
    "E620": "industries",
    "E621": "lab-safety-practices",
    "E622": "political-power",
    "E623": "rapid",
    "E624": "recursive-ai-capabilities",
    "E625": "robot-threat-exposure",
    "E626": "rogue-actor",
    "E627": "shareholders",
    "E628": "state-actor",
    "E629": "suffering-lock-in",
    "E630": "surprise-threat-exposure",
    "E631": "technical-ai-safety",
    "E632": "values",
    "E633": "goal-misgeneralization-research"
  },
  "bySlug": {
    "adversarial-robustness": "E1",
    "agentic-ai": "E2",
    "agi-race": "E3",
    "agi-timeline-debate": "E4",
    "ai-capabilities": "E5",
    "ai-control": "E6",
    "ai-control-concentration": "E7",
    "ai-executive-order": "E8",
    "ai-forecasting": "E9",
    "ai-forecasting-benchmark": "E10",
    "ai-ownership": "E11",
    "ai-risk-portfolio-analysis": "E12",
    "ai-safety-institutes": "E13",
    "ai-safety-summit": "E14",
    "ai-takeover": "E15",
    "ai-timelines": "E16",
    "ai-uses": "E17",
    "aligned-agi": "E18",
    "alignment-progress": "E19",
    "alignment-robustness": "E20",
    "alignment-robustness-trajectory": "E21",
    "anthropic": "E22",
    "anthropic-core-views": "E23",
    "apollo-research": "E24",
    "arc": "E25",
    "arc-evals": "E26",
    "authentication-collapse": "E27",
    "authentication-collapse-timeline": "E28",
    "authoritarian-takeover": "E29",
    "authoritarian-tools": "E30",
    "authoritarian-tools-diffusion": "E31",
    "automation-bias": "E32",
    "automation-bias-cascade": "E33",
    "autonomous-replication": "E34",
    "autonomous-weapons": "E35",
    "autonomous-weapons-escalation": "E36",
    "autonomous-weapons-proliferation": "E37",
    "benchmarking": "E38",
    "beth-barnes": "E39",
    "bio-risk": "E40",
    "biological-threat-exposure": "E41",
    "bioweapons": "E42",
    "bioweapons-ai-uplift": "E43",
    "bioweapons-attack-chain": "E44",
    "bioweapons-timeline": "E45",
    "buck-shlegeris": "E46",
    "cais": "E47",
    "california-sb1047": "E48",
    "canada-aida": "E49",
    "capabilities": "E50",
    "capabilities-to-safety-pipeline": "E51",
    "capability-evaluations": "E52",
    "capability-threshold-model": "E53",
    "carlsmith-six-premises": "E54",
    "case-against-xrisk": "E55",
    "case-for-xrisk": "E56",
    "chai": "E57",
    "china-ai-regulations": "E58",
    "chris-olah": "E59",
    "civilizational-competence": "E60",
    "coding": "E61",
    "colorado-ai-act": "E62",
    "compounding-risks-analysis": "E63",
    "compute-governance": "E64",
    "compute-hardware": "E65",
    "compute-monitoring": "E66",
    "compute-thresholds": "E67",
    "concentration-of-power": "E68",
    "concentration-of-power-model": "E69",
    "conjecture": "E70",
    "connor-leahy": "E71",
    "consensus-manufacturing": "E72",
    "consensus-manufacturing-dynamics": "E73",
    "content-authentication": "E74",
    "content-moderation": "E75",
    "coordination-capacity": "E76",
    "coordination-tech": "E77",
    "corporate-influence": "E78",
    "corrigibility": "E79",
    "corrigibility-failure": "E80",
    "corrigibility-failure-pathways": "E81",
    "cyber-offense": "E82",
    "cyber-psychosis": "E83",
    "cyber-psychosis-cascade": "E84",
    "cyber-threat-exposure": "E85",
    "cyberweapons": "E86",
    "cyberweapons-attack-automation": "E87",
    "cyberweapons-offense-defense": "E88",
    "dan-hendrycks": "E89",
    "daniela-amodei": "E90",
    "dario-amodei": "E91",
    "data-constraints": "E92",
    "deceptive-alignment": "E93",
    "deceptive-alignment-decomposition": "E94",
    "deep-learning-era": "E95",
    "deepfakes": "E96",
    "deepfakes-authentication-crisis": "E97",
    "deepmind": "E98",
    "defense-in-depth-model": "E99",
    "deliberation": "E100",
    "demis-hassabis": "E101",
    "disinformation": "E102",
    "disinformation-detection-race": "E103",
    "disinformation-electoral-impact": "E104",
    "distributional-shift": "E105",
    "dual-use": "E106",
    "early-warnings": "E107",
    "economic-disruption": "E108",
    "economic-disruption-impact": "E109",
    "economic-disruption-model": "E110",
    "economic-labor": "E111",
    "economic-stability": "E112",
    "effectiveness-assessment": "E113",
    "eliezer-yudkowsky": "E114",
    "elizabeth-kelly": "E115",
    "elon-musk": "E116",
    "emergent-capabilities": "E117",
    "enfeeblement": "E118",
    "epistemic-collapse": "E119",
    "epistemic-collapse-threshold": "E120",
    "epistemic-health": "E121",
    "epistemic-infrastructure": "E122",
    "epistemic-security": "E123",
    "epistemic-sycophancy": "E124",
    "epoch-ai": "E125",
    "erosion-of-agency": "E126",
    "eu-ai-act": "E127",
    "evals": "E128",
    "evan-hubinger": "E129",
    "existential-catastrophe": "E130",
    "existential-risk": "E131",
    "expert-opinion": "E132",
    "expertise-atrophy": "E133",
    "expertise-atrophy-cascade": "E134",
    "expertise-atrophy-progression": "E135",
    "export-controls": "E136",
    "failed-stalled-proposals": "E137",
    "far-ai": "E138",
    "fast-takeoff": "E139",
    "fhi": "E140",
    "field-building": "E141",
    "flash-dynamics": "E142",
    "flash-dynamics-threshold": "E143",
    "forecastbench": "E144",
    "fraud": "E145",
    "fraud-sophistication-curve": "E146",
    "fri": "E147",
    "gary-marcus": "E148",
    "geoffrey-hinton": "E149",
    "geopolitics": "E150",
    "goal-misgeneralization": "E151",
    "goal-misgeneralization-probability": "E152",
    "govai": "E153",
    "governance-policy": "E154",
    "historical-revisionism": "E155",
    "holden-karnofsky": "E156",
    "human-agency": "E157",
    "human-catastrophe": "E158",
    "human-expertise": "E159",
    "human-oversight-quality": "E160",
    "hybrid-systems": "E161",
    "ian-hogarth": "E162",
    "ilya-sutskever": "E163",
    "information-authenticity": "E164",
    "institutional-adaptation-speed": "E165",
    "institutional-capture": "E166",
    "institutional-quality": "E167",
    "instrumental-convergence": "E168",
    "instrumental-convergence-framework": "E169",
    "international-compute-regimes": "E170",
    "international-coordination": "E171",
    "international-coordination-game": "E172",
    "international-summits": "E173",
    "interpretability": "E174",
    "interpretability-coverage": "E175",
    "interpretability-sufficient": "E176",
    "intervention-effectiveness-matrix": "E177",
    "intervention-timing-windows": "E178",
    "irreversibility": "E179",
    "irreversibility-threshold": "E180",
    "is-ai-xrisk-real": "E181",
    "jan-leike": "E182",
    "knowledge-monopoly": "E183",
    "lab-behavior": "E184",
    "lab-incentives-model": "E185",
    "language-models": "E186",
    "learned-helplessness": "E187",
    "legal-evidence-crisis": "E188",
    "lock-in": "E189",
    "lock-in-mechanisms": "E190",
    "lock-in-model": "E191",
    "long-horizon": "E192",
    "long-term-lockin": "E193",
    "long-term-trajectory": "E194",
    "mainstream-era": "E195",
    "media-policy-feedback-loop": "E196",
    "mesa-optimization": "E197",
    "mesa-optimization-analysis": "E198",
    "metaculus": "E199",
    "metaforecast": "E200",
    "metr": "E201",
    "miri": "E202",
    "miri-era": "E203",
    "misaligned-catastrophe": "E204",
    "misalignment-potential": "E205",
    "misuse": "E206",
    "misuse-potential": "E207",
    "multipolar-competition": "E208",
    "multipolar-trap": "E209",
    "multipolar-trap-dynamics": "E210",
    "multipolar-trap-model": "E211",
    "nate-soares": "E212",
    "natural-abstractions": "E213",
    "neel-nanda": "E214",
    "nick-bostrom": "E215",
    "nist-ai-rmf": "E216",
    "open-vs-closed": "E217",
    "openai": "E218",
    "parameter-interaction-network": "E219",
    "paul-christiano": "E220",
    "pause-advocacy": "E221",
    "pause-and-redirect": "E222",
    "pause-debate": "E223",
    "persuasion": "E224",
    "post-incident-recovery": "E225",
    "power-seeking": "E226",
    "power-seeking-conditions": "E227",
    "prediction-markets": "E228",
    "preference-authenticity": "E229",
    "preference-manipulation": "E230",
    "preference-manipulation-drift": "E231",
    "proliferation": "E232",
    "proliferation-model": "E233",
    "proliferation-risk-model": "E234",
    "prosaic-alignment": "E235",
    "public-opinion": "E236",
    "public-opinion-evolution": "E237",
    "quri": "E238",
    "racing-dynamics": "E239",
    "racing-dynamics-impact": "E240",
    "racing-dynamics-model": "E241",
    "racing-intensity": "E242",
    "reality-coherence": "E243",
    "reality-fragmentation": "E244",
    "reality-fragmentation-network": "E245",
    "reasoning": "E246",
    "redwood": "E247",
    "regulation-debate": "E248",
    "regulatory-capacity": "E249",
    "regulatory-capacity-threshold": "E250",
    "research-agendas": "E251",
    "responsible-scaling-policies": "E252",
    "reward-hacking": "E253",
    "reward-hacking-taxonomy": "E254",
    "risk-activation-timeline": "E255",
    "risk-cascade-pathways": "E256",
    "risk-interaction-matrix": "E257",
    "risk-interaction-network": "E258",
    "rlhf": "E259",
    "robin-hanson": "E260",
    "safety-capability-gap": "E261",
    "safety-capability-tradeoff": "E262",
    "safety-culture-equilibrium": "E263",
    "safety-culture-strength": "E264",
    "safety-research": "E265",
    "safety-research-allocation": "E266",
    "safety-research-value": "E267",
    "safety-researcher-gap": "E268",
    "sam-altman": "E269",
    "sandbagging": "E270",
    "scalable-oversight": "E271",
    "scaling-debate": "E272",
    "scaling-laws": "E273",
    "scheming": "E274",
    "scheming-likelihood-model": "E275",
    "scientific-corruption": "E276",
    "scientific-research": "E277",
    "self-improvement": "E278",
    "seoul-declaration": "E279",
    "shane-legg": "E280",
    "sharp-left-turn": "E281",
    "situational-awareness": "E282",
    "slow-takeoff-muddle": "E283",
    "societal-resilience": "E284",
    "societal-trust": "E285",
    "squiggle": "E286",
    "squiggleai": "E287",
    "standards-bodies": "E288",
    "structural": "E289",
    "stuart-russell": "E290",
    "superintelligence": "E291",
    "surveillance": "E292",
    "surveillance-authoritarian-stability": "E293",
    "surveillance-chilling-effects": "E294",
    "sycophancy": "E295",
    "sycophancy-feedback-loop": "E296",
    "technical-research": "E297",
    "tmc-adaptability": "E298",
    "tmc-adoption": "E299",
    "tmc-ai-control-concentration": "E300",
    "tmc-ai-governance": "E301",
    "tmc-algorithms": "E302",
    "tmc-alignment-robustness": "E303",
    "tmc-biological-threat-exposure": "E304",
    "tmc-civ-epistemics": "E305",
    "tmc-civ-governance": "E306",
    "tmc-civcomp-adaptability": "E307",
    "tmc-companies": "E308",
    "tmc-compute": "E309",
    "tmc-compute-forecast-sketch": "E310",
    "tmc-coordination": "E311",
    "tmc-coordination-capacity": "E312",
    "tmc-countries": "E313",
    "tmc-cyber-threat-exposure": "E314",
    "tmc-economic-power": "E315",
    "tmc-economic-stability": "E316",
    "tmc-epistemic-health": "E317",
    "tmc-epistemic-lockin": "E318",
    "tmc-epistemics": "E319",
    "tmc-existential-catastrophe": "E320",
    "tmc-governance": "E321",
    "tmc-governments": "E322",
    "tmc-gradual": "E323",
    "tmc-human-agency": "E324",
    "tmc-human-expertise": "E325",
    "tmc-human-oversight-quality": "E326",
    "tmc-industries": "E327",
    "tmc-information-authenticity": "E328",
    "tmc-institutional-quality": "E329",
    "tmc-international-coordination": "E330",
    "tmc-interpretability-coverage": "E331",
    "tmc-lab-safety": "E332",
    "tmc-long-term-trajectory": "E333",
    "tmc-political-power": "E334",
    "tmc-preference-authenticity": "E335",
    "tmc-racing-intensity": "E336",
    "tmc-rapid": "E337",
    "tmc-reality-coherence": "E338",
    "tmc-recursive-ai": "E339",
    "tmc-regulatory-capacity": "E340",
    "tmc-robot-threat": "E341",
    "tmc-robot-threat-exposure": "E342",
    "tmc-rogue-actor": "E343",
    "tmc-safety-capability-gap": "E344",
    "tmc-safety-culture-strength": "E345",
    "tmc-shareholders": "E346",
    "tmc-societal-resilience": "E347",
    "tmc-societal-trust": "E348",
    "tmc-state-actor": "E349",
    "tmc-suffering-lock-in": "E350",
    "tmc-surprise-threat": "E351",
    "tmc-surprise-threat-exposure": "E352",
    "tmc-technical-ai-safety": "E353",
    "tmc-values": "E354",
    "toby-ord": "E355",
    "tool-use": "E356",
    "transformative-ai": "E357",
    "transition-turbulence": "E358",
    "treacherous-turn": "E359",
    "trust-cascade": "E360",
    "trust-cascade-model": "E361",
    "trust-decline": "E362",
    "trust-erosion-dynamics": "E363",
    "uk-aisi": "E364",
    "us-aisi": "E365",
    "us-executive-order": "E366",
    "us-state-legislation": "E367",
    "value-learning": "E368",
    "voluntary-commitments": "E369",
    "warning-signs-model": "E370",
    "whistleblower-dynamics": "E371",
    "why-alignment-easy": "E372",
    "why-alignment-hard": "E373",
    "winner-take-all": "E374",
    "winner-take-all-concentration": "E375",
    "winner-take-all-model": "E376",
    "worldview-intervention-mapping": "E377",
    "xai": "E378",
    "xpt": "E379",
    "yoshua-bengio": "E380",
    "community-notes": "E381",
    "stampy-aisafety-info": "E382",
    "mit-ai-risk-repository": "E383",
    "longterm-wiki": "E384",
    "roastmypost": "E385",
    "ai-watch": "E386",
    "timelines-wiki": "E387",
    "org-watch": "E388",
    "donations-list-website": "E389",
    "wikipedia-views": "E390",
    "ai-welfare": "E391",
    "misuse-risks": "E392",
    "solutions": "E393",
    "accident-risks": "E394",
    "structural-risks": "E395",
    "epistemic-risks": "E396",
    "governance-focused": "E397",
    "critical-uncertainties": "E398",
    "agi-timeline": "E399",
    "large-language-models": "E400",
    "heavy-scaffolding": "E401",
    "provable-safe": "E402",
    "dense-transformers": "E403",
    "openai-foundation-governance": "E404",
    "anthropic-valuation": "E405",
    "anthropic-investors": "E406",
    "long-term-benefit-trust": "E407",
    "musk-openai-lawsuit": "E408",
    "anthropic-ipo": "E409",
    "elon-musk-philanthropy": "E410",
    "anthropic-pledge-enforcement": "E411",
    "anthropic-pre-ipo-daf-transfers": "E412",
    "anthropic-impact": "E413",
    "capability-alignment-race": "E414",
    "short-timeline-policy-implications": "E415",
    "technical-pathways": "E416",
    "feedback-loops": "E417",
    "multi-actor-landscape": "E418",
    "model-organisms-of-misalignment": "E419",
    "ea-biosecurity-scope": "E420",
    "openai-foundation": "E421",
    "leading-the-future": "E422",
    "johns-hopkins-center-for-health-security": "E423",
    "nist-ai": "E424",
    "ssi": "E425",
    "controlai": "E426",
    "frontier-model-forum": "E427",
    "palisade-research": "E428",
    "centre-for-long-term-resilience": "E429",
    "goodfire": "E430",
    "david-sacks": "E431",
    "marc-andreessen": "E432",
    "max-tegmark": "E433",
    "philip-tetlock": "E434",
    "eli-lifland": "E435",
    "dustin-moskovitz": "E436",
    "eval-saturation": "E437",
    "evaluation-awareness": "E438",
    "alignment": "E439",
    "scalable-eval-approaches": "E440",
    "scheming-detection": "E441",
    "dangerous-cap-evals": "E442",
    "capability-elicitation": "E443",
    "safety-cases": "E444",
    "sleeper-agent-detection": "E445",
    "ai-assisted": "E446",
    "evaluation": "E447",
    "alignment-evals": "E448",
    "red-teaming": "E449",
    "model-auditing": "E450",
    "constitutional-ai": "E451",
    "weak-to-strong": "E452",
    "capability-unlearning": "E453",
    "preference-optimization": "E454",
    "process-supervision": "E455",
    "refusal-training": "E456",
    "california-sb53": "E457",
    "intervention-portfolio": "E458",
    "evals-governance": "E459",
    "pause-moratorium": "E460",
    "rsp": "E461",
    "corporate": "E462",
    "hardware-enabled-governance": "E463",
    "monitoring": "E464",
    "thresholds": "E465",
    "lab-culture": "E466",
    "pause": "E467",
    "training-programs": "E468",
    "bletchley-declaration": "E469",
    "coordination-mechanisms": "E470",
    "new-york-raise-act": "E471",
    "model-registries": "E472",
    "international-regimes": "E473",
    "open-source": "E474",
    "whistleblower-protections": "E475",
    "field-building-analysis": "E476",
    "mech-interp": "E477",
    "circuit-breakers": "E478",
    "representation-engineering": "E479",
    "sparse-autoencoders": "E480",
    "eliciting-latent-knowledge": "E481",
    "debate": "E482",
    "formal-verification": "E483",
    "provably-safe": "E484",
    "sandboxing": "E485",
    "structured-access": "E486",
    "tool-restrictions": "E487",
    "multi-agent": "E488",
    "sleeper-agents": "E489",
    "rogue-ai-scenarios": "E490",
    "biological-organoid": "E491",
    "brain-computer-interfaces": "E492",
    "collective-intelligence": "E493",
    "genetic-enhancement": "E494",
    "light-scaffolding": "E495",
    "minimal-scaffolding": "E496",
    "neuro-symbolic": "E497",
    "neuromorphic": "E498",
    "novel-unknown": "E499",
    "sparse-moe": "E500",
    "ssm-mamba": "E501",
    "whole-brain-emulation": "E502",
    "world-models": "E503",
    "doomer": "E504",
    "long-timelines": "E505",
    "optimistic": "E506",
    "longtermwiki-impact": "E507",
    "societal-response": "E508",
    "1day-sooner": "E509",
    "80000-hours": "E510",
    "ai-futures-project": "E511",
    "ai-impacts": "E512",
    "ai-revenue-sources": "E513",
    "arb-research": "E514",
    "blueprint-biosecurity": "E515",
    "bridgewater-aia-labs": "E516",
    "cea": "E517",
    "center-for-applied-rationality": "E518",
    "chan-zuckerberg-initiative": "E519",
    "coalition-for-epidemic-preparedness-innovations": "E520",
    "coefficient-giving": "E521",
    "council-on-strategic-risks": "E522",
    "cser": "E523",
    "cset": "E524",
    "ea-global": "E525",
    "elicit": "E526",
    "epistemic-orgs-epoch-ai": "E527",
    "fli": "E528",
    "founders-fund": "E529",
    "futuresearch": "E530",
    "giving-pledge": "E531",
    "good-judgment": "E532",
    "gpai": "E533",
    "gratified": "E534",
    "hewlett-foundation": "E535",
    "ibbis": "E536",
    "kalshi": "E537",
    "lesswrong": "E538",
    "lighthaven": "E539",
    "lightning-rod-labs": "E540",
    "lionheart-ventures": "E541",
    "longview-philanthropy": "E542",
    "ltff": "E543",
    "macarthur-foundation": "E544",
    "manifest": "E545",
    "manifold": "E546",
    "manifund": "E547",
    "mats": "E548",
    "meta-ai": "E549",
    "microsoft": "E550",
    "nti-bio": "E551",
    "open-philanthropy": "E552",
    "pause-ai": "E553",
    "peter-thiel-philanthropy": "E554",
    "polymarket": "E555",
    "red-queen-bio": "E556",
    "redwood-research": "E557",
    "rethink-priorities": "E558",
    "safety-orgs-epoch-ai": "E559",
    "samotsvety": "E560",
    "schmidt-futures": "E561",
    "secure-ai-project": "E562",
    "securebio": "E563",
    "securedna": "E564",
    "seldon-lab": "E565",
    "sentinel": "E566",
    "sff": "E567",
    "situational-awareness-lp": "E568",
    "swift-centre": "E569",
    "the-sequences": "E570",
    "turion": "E571",
    "vara": "E572",
    "vitalik-buterin-philanthropy": "E573",
    "gwern": "E574",
    "helen-toner": "E575",
    "issa-rice": "E576",
    "jaan-tallinn": "E577",
    "leopold-aschenbrenner": "E578",
    "nuno-sempere": "E579",
    "vidur-kapur": "E580",
    "vipul-naik": "E581",
    "yann-lecun": "E582",
    "adversarial-training": "E583",
    "agent-foundations": "E584",
    "ai-for-human-reasoning-fellowship": "E585",
    "cirl": "E586",
    "coe-ai-convention": "E587",
    "collective-epistemics-design-sketches": "E588",
    "community-notes-for-everything": "E589",
    "cooperative-ai": "E590",
    "deepfake-detection": "E591",
    "epistemic-virtue-evals": "E592",
    "labor-transition": "E593",
    "model-spec": "E594",
    "output-filtering": "E595",
    "probing": "E596",
    "provenance-tracing": "E597",
    "public-education": "E598",
    "reliability-tracking": "E599",
    "reward-modeling": "E600",
    "rhetoric-highlighting": "E601",
    "texas-traiga": "E602",
    "steganography": "E603",
    "agi-development": "E604",
    "claude-code-espionage-2025": "E605",
    "adaptability": "E606",
    "adoption": "E607",
    "ai-governance": "E608",
    "algorithms": "E609",
    "companies": "E610",
    "compute-forecast-sketch": "E611",
    "compute": "E612",
    "coordination": "E613",
    "countries": "E614",
    "economic-power": "E615",
    "epistemics": "E616",
    "governance": "E617",
    "governments": "E618",
    "gradual": "E619",
    "industries": "E620",
    "lab-safety-practices": "E621",
    "political-power": "E622",
    "rapid": "E623",
    "recursive-ai-capabilities": "E624",
    "robot-threat-exposure": "E625",
    "rogue-actor": "E626",
    "shareholders": "E627",
    "state-actor": "E628",
    "suffering-lock-in": "E629",
    "surprise-threat-exposure": "E630",
    "technical-ai-safety": "E631",
    "values": "E632",
    "goal-misgeneralization-research": "E633"
  }
}